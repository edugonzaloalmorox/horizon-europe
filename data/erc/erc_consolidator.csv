"project_acronym","project","main_researcher","institution","details_project","budget_project","date_start_project","date_end_project"
"DNA ORIGAMI MOTORS","Constructing and powering nanoscale DNA origami motors","Hendrik DIETZ","TECHNISCHE UNIVERSITAET MUENCHEN","Our goal is to advance the field of DNA nanotechnology by achieving directed transport on the nanoscale using robustly functioning synthetic motor units. To do so, we propose to construct spatially periodic, diffusive mechanisms that have broken inversion symmetry and to subject these mechanisms to conditions away from thermal equilibrium. We will build on recent progress in creating complex DNA-based structures and construct various nanoscale rotary and translational Brownian ratchet mechanisms that have well- defined degrees of freedom for motion within periodic and asymmetric energy landscapes. The mechanisms will be self-assembled from DNA origami components. We will use cryo-Transmission Electron Microscopy (TEM) to evaluate and iteratively refine our structures. Conventional video-rate fluorescence microscopy, in addition to super-resolution microscopy, will be employed to study in solution and in real time the diffusive motion of the mechanisms on the single particle level. We will introduce various deterministic or stochastic thermal, mechanical, or chemical perturbations to drive the systems away from thermal equilibrium. We will use laser heating and cooling to experimentally test thermal and flashing ratcheting mechanisms; we will employ dissipative asymmetric fluxes arising in active matter as realized in high-density ATP-hydrolysing motility assays; and we will couple out-of-equilibrium chemical reactions to the motion of our mechanisms. The ultimate goal of our work is to take insights from these experiments and create robustly functioning nanoscale motor units that can drive directed motion against external load and perform at levels comparable to those of natural macromolecular motor proteins. Achieving this goal will create unprecedented technological opportunities, for example, to drive chemical synthesis, actively propel nanoscale drug- delivery vehicles, pump and separate molecules across barriers or package molecules into cargo components.","2000000","2017-05-01","2022-04-30"
"DNAFOLDIMS","Advanced mass spectrometry approaches to reveal nucleic acid folding energy landscapes","Valérie Gabelica","INSTITUT NATIONAL DE LA SANTE ET DE LA RECHERCHE MEDICALE","""50 years after the discovery of the DNA double helix, the variety of structures that nucleic acids can adopt continues to surprise the scientific community. Specific structures and conformational changes are linked to important functions in cell regulation. Understanding the principles that govern how small molecules such as natural metabolites or synthetic drugs modulate the nucleic acid structures is of prime importance for molecular biology and pharmacology. The field however suffers from the lack of suitable experimental tools to monitor all assemblies and structures formed when a small molecule encounters its targets.

The goal of my project is to develop unique mass spectrometry-based approaches to detect, quantify and characterize all these assemblies and structures. Our team’s strength will be to integrate a multidisciplinary approach, from physical and analytical chemistry to molecular biology. We will address the fundamentals of nucleic acid ionization and transfer in the gas phase, develop a unique instrumental setup combining mass spectrometry, ion mobility and circular dichroism ion spectroscopy, and apply these new approaches to biologically important nucleic acids, in order to reveal the mechanisms of ligand-induced conformational changes in important regulatory structures such as G-quadruplex or riboswitches.

This research will also have broader impact, as the approaches and concepts developed here for nucleic acids will contribute fundamental advances in mass spectrometry, and will be transferrable to other supramolecular or biological complexes.""","2021755","2014-06-01","2019-05-31"
"DOiCV","Discrete Optimization in Computer Vision: Theory and Practice","Vladimir Kolmogorov","INSTITUTE OF SCIENCE AND TECHNOLOGYAUSTRIA","This proposal aims at developing new inference algorithms for graphical models with discrete variables, with a focus on the MAP estimation task. MAP estimation algorithms such as graph cuts have transformed computer vision in the last decade; they are now routinely used and are also utilized in commercial systems.
Topics of this project fall into 3 categories.
Theoretically-oriented: Graph cut techniques come from combinatorial optimization. They can minimize a certain class of functions, namely submodular functions with unary and pairwise terms. Larger classes of functions can be minimized in polynomial time. A complete characterization of such classes has been established. They include k-submodular functions for an integer k _ 1.
I investigate whether such tools from discrete optimization can lead to more efficient inference algorithms for practical problems. I have already found an important application of k-submodular functions for minimizing Potts energy functions that are frequently used in computer vision. The concept of submodularity also recently appeared in the context of the task of computing marginals in graphical models, here discrete optimization tools could be used.
Practically-oriented: Modern techniques such as graph cuts and tree-reweighted message passing give excellent results for some graphical models such as with the Potts energies. However, they fail for more complicated models. I aim to develop new tools for tackling such hard energies. This will include exploring tighter convex relaxations of the problem.
Applications, sequence tagging problems: Recently, we developed new algorithms for inference in pattern-based Conditional Random Fields (CRFs) on a chain. This model can naturally be applied to sequence tagging problems; it generalizes the popular CRF model by giving it more flexibility. I will investigate (i) applications to specific tasks, such as the protein secondary structure prediction, and (ii) ways to extend the model.","1641585","2014-06-01","2019-05-31"
"DOQS","Many-Body Physics with Driven Open Quantum Systems of Atoms, Light and Solids","Sebastian Ludwig Diehl","UNIVERSITAET ZU KOELN","Understanding the quantum many-particle problem is one of the grand challenges of modern physics. While tremendous progresses have been made over the past decades in thermodynamic equilibrium, nonequilibrium many-body quantum physics is still in its infancy. Strong motivation for addressing this challenge comes from recent experimental developments in diverse areas, ranging from cold atomic gases over light-driven semiconductors to microcavity arrays. This moves systems into the focus, which are located on the interface of quantum optics, many-body physics and statistical mechanics. They share in common that coherent and driven-dissipative quantum dynamics occur on an equal footing, creating scenarios without immediate counterpart in traditional condensed matter systems. This project has the goal of pushing forward the understanding of such driven open quantum systems. To this end, we follow a combined approach structured around three key challenges. (i) We aim to identify novel macroscopic phenomena, which manifestly witness microscopic non-equilibrium conditions. This concerns non-thermal stationary states, where we will shape an understanding of non-equilibrium phase diagrams and the associated phase transitions, in particular constructing a notion of driven quantum criticality. But it also encompasses the identification of new universal regimes in open system time evolution. Finally, we will extend the concept of topological order to a broader non-equilibrium context, motivated by quantum information applications. (ii) We will create new theoretical tools, in particular advancing a flexible Keldysh dynamical quantum field theory for driven open quantum systems. (iii) We will address a broad spectrum of cutting edge experimental platforms in view of exploring our theoretical scenarios, and to foster mutual cross-fertilization. With an emphasis on cold atomic gases, this program also comprises exciton-polariton condensates and coupled circuit QED architectures.","1676424","2016-02-01","2021-01-31"
"DROUGHT-HEAT","Land-Climate Interactions: Constraints for Droughts and Heatwaves in a Changing Climate","Sonia Isabelle Seneviratne","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","""Land-climate interactions mediated through soil moisture and vegetation play a critical role in the climate system, in particular for the occurrence of extreme events such as droughts and heatwaves. They are, however, poorly constrained in current Earth System Models (ESMs), leading to large uncertainties in climate projections. These uncertainties affect the quality and accuracy of projections of temperature, water availability, and carbon concentrations, as well as that of projected impacts on agriculture, ecosystems, and health.

In the past years, in-situ and remote sensing-based datasets of soil moisture, evapotranspiration, and energy and carbon fluxes have become increasingly available, providing untapped potential for reducing associated uncertainties in current climate models. The DROUGHT-HEAT project aims at innovatively exploiting these new information sources in order to 1) derive observations-based diagnostics to quantify and isolate the role of land-climate interactions in past extreme events (""""Diagnostic Atlas""""), 2) evaluate and improve current ESMs and constrain climate-change projections using the derived diagnostics, and 3) apply the newly gained knowledge to frontier developments in the attribution of climate extremes to land processes and their mitigation through """"land geoengineering"""".

The DROUGHT-HEAT project integrates the newest land observational datasets with the latest stream of ESMs. Novel methodologies will be applied to extract functional relationships from the data, and identify key gaps in the ESMs' representation of underlying processes. These will build on physically-based relationships, machine learning tools, and model calibration. In addition, they will encompass the mapping and merging of derived diagnostics in space and time to reduce """"blank spaces"""" in the datasets. The project is unprecedented in its breadth and scope and will allow a major breakthrough in our understanding of the processes leading to heatwaves and droughts.""","1952285","2014-09-01","2019-08-31"
"DUALITY","Theoretical Foundations of Memory Micro-Insertions in Wireless Communications","Petros ELIA","EURECOM","We propose to develop the theoretical foundations of transforming memory into data rates, and to explore their practical ramifications in wireless communication networks.

Motivated by the long-lasting open challenge to invent a communication technology that scales with the network size, we have recently discovered early indications of how preemptive use of distributed data-storage at the receiving communication nodes (well before transmission), can offer unprecedented throughput gains by surprisingly bypassing the dreaded bottleneck of real-time channel-feedback. For an exploratory downlink configuration, we unearthed a hidden duality between feedback and preemptive use of memory, which managed to doubly-exponentially reduce the needed memory size, and consequently offered unbounded throughput gains compared to all existing solutions with the same resources. This was surprising because feedback and memory were thought to be mostly disconnected; one is used on the wireless PHY layer, the other on the wired MAC.

This development prompts our key scientific challenge which is to pursue the mathematical convergence between feedback-information-theory and preemptive distributed data-storage, and to then design ultra-fast memory-aided communication algorithms that pass real-life testing.
This is a structurally new approach, which promises to reveal deep links between feedback information theory and memory, for a variety of envisioned wireless-network architectures of exceptional promise. In doing so, our new proposed theory stands to identify the basic principles of how a splash of memory can surgically alter the informational-structure of these networks, rendering them faster, simpler and more efficient. In the end, this study has the potential to directly translate the continuously increasing data-storage capabilities, into gains of wireless network capacity, and to ultimately avert the looming network-overload caused by these same indefinite increases of data volumes.","1978778","2017-04-01","2022-03-31"
"DURACELL","Cell Migration under Mechanical Constraints","Benoît Ladoux","UNIVERSITE PARIS DIDEROT - PARIS 7","Control of cell migration is crucial for many biological processes. Cells sense mechanical cues to guide their migration. As opposed to passive materials, living cells actively respond to the mechanical stimuli of their environment through the transduction of mechanical information into biochemical signaling events. These responses, particularly to rigidity, include differentiation, migration and alterations in cell-matrix and cell-cell adhesion and thus occur over a wide range of time and length scales. I propose to address the effect of substrate mechanical properties on cell migration using quantitative in vitro methods based on micro-fabrication and micro-mechanical techniques. My main objectives are to:
1/ Discover specific mechanisms that guide single cells toward stiffer substrates (a process known as durotaxis), investigate the range of stiffness-sensitive responses and determine the molecular mechanisms based on actin dynamics and cell adhesion assembly. 2/ Characterize the emergence of coordinated cell movements and thus how cells move in concert under external mechanical constraints. In addition to cell-substrate interactions, the role of cell-cell junctions is crucial in the transmission of mechanical signals over the cell population. By analyzing tissue dynamics at both mesoscopic and molecular scales, we hope to unravel how epithelial cell sheets mechanically integrate multiple adhesive cues to drive collective cell migration.3/ Elucidate the role of 3D mechanical environments in collective cell migration. In contrast to migration in 2D, cells in 3D must overcome the biophysical resistance of their surrounding milieu. Based on optical and innovative micro-fabrication techniques to modify the stiffness of 3D scaffolds, we will study its influence on cell migration modes and invasion. The goal of this interdisciplinary project is to understand how cells integrate mechanical adhesive signals to adapt their internal organization and ensure tissue integrity","1762734","2014-06-01","2019-05-31"
"DYNACQM","Dynamics of Correlated Quantum Matter: From Dynamical Probes to Novel Phases of Matter","Frank POLLMANN","TECHNISCHE UNIVERSITAET MUENCHEN","The interplay of quantum fluctuations and correlation effects in condensed matter can yield emergent phases with fascinating properties. Understanding these challenging quantum-many body systems is a problem of central importance in theoretical physics and the basis for the development of new materials for future technologies. Dynamical properties can provide characteristic fingerprints that allow to identify novel phases in newly synthesized materials and optical lattice systems. Moreover, when brought out of equilibrium, correlated quantum matter can exhibit dynamical phases that cannot occur in equilibrium settings. 

DYNACQM will develop new theoretical and numerical frameworks to study dynamical properties of correlated quantum matter. On the theoretical side, we will investigate how many-body entanglement affects dynamical properties and predict universal features that can be measured in experiments. For example, dynamical spin correlation functions, measured in neutron scattering experiments, provide signatures of topologically ordered spin liquids. Furthermore, we will study the role of disorder and many-body localization in static as well as in driven quantum systems. On the numerical side, we will develop efficient tensor-product state based algorithms to simulate the dynamics of quantum many-body systems. These will allow us to study realistic microscopic model systems and to understand their dynamical properties.

Recent developments in the creation of synthetic quantum systems and advances in high resolution spectroscopy allow for an unprecedented precision with which the dynamics of quantum systems can be studied and manipulated experimentally. In this light, it is particularly important to theoretically understand the dynamics of correlated quantum systems and to make testable predictions. DYNACQM will bridge between the fundamental understanding of many-body entanglement in correlated quantum matter and experiments.","1998750","2018-06-01","2023-05-31"
"DYNAFLUORS","Dynamic Activatable Fluorophores","Marc VENDRELL ESCOBAR","THE UNIVERSITY OF EDINBURGH","In DYNAFLUORS I will develop the first chemical toolbox for imaging in real time the activity of immune cells in tumours.
Although the management of cancer has improved over the years, the cure rates for patients with metastasis and advanced tumours remain low due to lack of appropriate therapies. Recent studies suggest that drugs empowering host immune cells (i.e. immunotherapies) are promising approaches for intractable tumours. However, there are no tools to visualise and understand how host immune cells stop cancer progression in vivo. This important unmet challenge drives the ambitious targets of this proposal.

Over the past 10 years, I have pioneered the development of chemical fluorophores that allow unparalleled analysis of biological systems. In this project, I will implement an innovative approach to unify cutting-edge methodologies in chemistry and biology and develop Dynamic Activatable Fluorophores (DYNAFLUORS) as a chemical toolbox with enhanced imaging capabilities over current technologies. 

The cross-disciplinary and ambitious nature of this project will open multiple avenues for broad impact in many areas of chemistry as well as in basic biology, imaging and medicine. DYNAFLUORS will allow us to image, from the molecular level to human tissue, the activity of immune cells in tumours and the response to therapy in real time. This ground-breaking chemical platform will represent a step forward in the forefront of chemical imaging and will create new opportunities in the personalised management of cancer.

In the long term, DYNAFLUORS will become a transformative toolbox for monitoring disease in humans. The integration of functional fluorophores into imaging technologies to perform ‘optical biopsies’ in vivo and to create patient-specific drug-response assays has the potential to revolutionise the diagnosis, stratification and personalised treatment of disease.","1986650","2018-06-01","2023-05-31"
"DYNAMO","Energy and charge transfer nonadiabatic dynamics in light-harvesting molecules and nanostructures","Roland Mitric","JULIUS-MAXIMILIANS UNIVERSITAET WUERZBURG","The goal of DYNAMO is to develop an efficient mixed quantum-classical methodology for the simulation of light-induced nonadiabatic processes in multichromophoric light-harvesting assemblies and to apply it to explore energy and charge transport dynamics in novel classes of light-harvesting systems. There is growing evidence that nonadiabatic relaxation processes play a fundamental role in determining the efficiency of the excitonic transfer or charge injection. In addition to the intramolecular nonradiative transitions through conical intersections, well known from photochemistry, the coupling between the chromophores in multichromophoric assemblies gives rise to novel intermolecular nonadiabatic relaxation channels through funnels between the delocalized excitonic and/or charge transfer states. In order to simulate coupled electron-nuclear dynamics in multichromophoric nanostructures we will develop and implement light-induced surface hopping methods and combine them with efficient electronic structure methods. For a unified description of excitonic and charge transfer states we will combine constrained density functional theory (CDFT) and linear response time-resolved density functional theory (TDDFT) within the configuration interaction framework. The direct link with the experiment will be provided through the simulation of time-resolved multidimensional spectra in the mixed quantum-classical framework. We will apply the new methodology to investigate energy and charge transport in nanostructures of self-assembled organic molecules (e.g. tubular J-aggregates), in low band-gap organic polymers (e.g. squaraines) and in hybrid plasmon-exciton architectures, where the photon capture and charge injection efficiency can be enhanced by the interaction with plasmonic fields. The ultimate goal is to reveal mechanisms of efficient energy and charge transfer using a first principles methodology, providing guidance for the design of efficient light-harvesting systems.","1501188","2015-06-01","2020-05-31"
"DYNAPOL","Modeling approaches toward bioinspired dynamic materials","Giovanni Maria PAVAN","SCUOLA UNIVERSITARIA PROFESSIONALE DELLA SVIZZERA ITALIANA","Nature uses self-assembly to build fascinating supramolecular materials, such as microtubules and protein filaments, that can self-heal, reconfigure, adapt or respond to specific stimuli in dynamic way. Building synthetic (polymeric) supramolecular materials possessing similar bioinspired properties via the same self-assembly principles is interesting for many applications. But their rational design requires a detailed comprehension of the molecular determinants controlling the assembly (structure, dynamics and properties) that is typically very difficult to reach experimentally.
The aim of this project is to obtain structure-dynamics-property relationships to learn how to control the dynamic bioinspired properties of supramolecular polymers. I propose to unravel the molecular origin of the bioinspired behavior through massive multiscale modeling, advanced simulations and machine learning. First, we will develop ad hoc molecular models to study monomer assembly and the supramolecular structure of various types of self-assembled materials on multiple scales. Second, using advanced simulation approaches we will characterize the supramolecular dynamics of these materials (dynamic exchange of monomers) at high (submolecular) resolution. We will then study bioinspired properties such as the ability of various supramolecular materials to self-heal, adapt or reconfigure dynamically in response to specific stimuli. Our models will be systematically validated by comparison with the experimental evidence from our collaborators. Finally, we will use machine learning approaches to analyze our high-resolution simulations and to identify the key monomer features that control and determine the structure, dynamics and dynamic properties of a supramolecular material (i.e., structure-dynamics-property relationships). This research will produce unprecedented insight and fundamental models for the rational design of artificial dynamic materials with controllable bioinspired properties.","1999623","2019-06-01","2024-05-31"
"Dynasore","Dynamical magnetic excitations with spin-orbit interaction in realistic nanostructures","Samir Lounis","FORSCHUNGSZENTRUM JULICH GMBH","Nano-spin-orbitronics is an emerging and fast growing field that aims at combining three degrees of freedom − spin, charge and spin-orbit interaction − to explore new nanotechnologies stemming from fundamental physics. New magnetic phases of matter are investigated using, in particular, atomic design to tailor beneficial physical properties down to the atomic level. Storage, transport and manipulation of magnetic information within a small set of atoms does not only require a fundamental understanding of their ground-state properties from the perspective of quantum mechanics, but crucially also their dynamical excited states. We propose to go beyond the state of the art by investigating from first-principles the dynamical properties of chiral spin textures in nanostructures from 2-dimensions to 0-dimension with these nanostructures being deposited on different substrates where spin-orbit interaction plays a major role. Understanding their response to external dynamical fields (electric/magnetic) or currents will impact on the burgeoning field of nano-spin-orbitronics. Indeed, to achieve efficient manipulation of nano-sized functional spin textures, it is imperative to exploit and understand their resonant motion, analogous to the role of ferromagnetic resonance in spintronics. A magnetic skyrmion is an example of a spin-swirling texture characterized by a topological number that will be explored. This spin state has huge potential in nanotechnologies thanks to the low spin currents needed to manipulate it. Based on time-dependent density functional theory and many-body perturbation theory, our innovative scheme will deliver a paradigm shift with respect to existing theoretical methodologies and will provide a fundamental understanding of: (i) the occurrence of chiral spin textures in reduced dimensions, (ii) their dynamical spin-excitation spectra and the coupling of the different excitation degrees of freedom and (iii) their impact on the electronic structure.","1994879","2016-06-01","2021-05-31"
"DyNET","Dynamical river NETworks: climatic controls and biogeochemical function","Gianluca BOTTER","UNIVERSITA DEGLI STUDI DI PADOVA","Despite the ubiquity of expansion and retraction dynamics of flowing streams, the large majority of biogeochemical and hydrological studies conceive river networks as static elements of the landscape, and a coherent framework to quantify nature and extent of drainage network dynamics is lacking. The implications of this phenomenon extend far beyond hydrology and involve key ecological and biogeochemical function of riparian corridors. The proposed research project will move beyond the traditional paradigm of static river networks by unravelling, for the first time, physical causes and biogeochemical consequences of stream dynamics. In particular, the project will undertake the following overarching scientific questions: 1) what are the climatic and geomorphic controls on the expansion/contraction of river networks? 2) what is the length of temporary streams and what is their impact on catchment-scale biogeochemical processes and stream water quality across scales? These challenging issues will be addressed by developing a novel theoretical framework complemented by extensive field observations within four representative sites along a climatic gradient in the EU. Field measurements will include long-term weekly mapping of the active drainage network and daily hydro-chemical data across scales. The experimental dataset will be used to develop and inform a set of innovative modelling tools, including an analytical framework for the description of spatially explicit hydrologic dynamics driven by stochastic rainfall and a modular hydro-chemical model based on the concept of water age, able to account for the variable connectivity among soil, groundwater and channels as induced by stream network dynamics. The project will open new avenues to quantify freshwater carbon emissions - crucially dependent on the extent of ephemeral streams - and it will provide a robust basis to identify temporary rivers and maintain their biogeochemical function in times of global change.","1999758","2018-05-01","2023-04-30"
"DYNPOR","First principle molecular dynamics simulations for complex chemical transformations in nanoporous materials","Véronique Van Speybroeck","UNIVERSITEIT GENT","Chemical transformations in nanoporous materials are vital in many application domains, such as catalysis, molecular separations, sustainable chemistry,….  Model-guided design is indispensable to tailoring materials at the nanometer scale level.    
At real operating conditions, chemical transformations taking place at the nanometer scale have a very complex nature, due to the interplay of several factors such as the number of particles present in the pores of the material, framework flexibility, competitive pathways, entropy effects,…  The textbook concept of a single transition state is far too simplistic in such cases.  A restricted number of configurations of the potential energy surface is not sufficient to capture the complexity of the transformation.    

My objective is to simulate complex chemical transformations in nanoporous materials using first principle molecular dynamics methods at real operating conditions, capturing the full complexity of the free energy surface.  To achieve these goals advanced sampling methods will be used to explore the interesting regions of the free energy surface. The number of guest molecules at real operating conditions will be derived and the diffusion of small molecules through pores with blocking molecules will be studied.  New theoretical models will be developed to keep track of both the framework flexibility and entropy of the lattice.  

The selected applications are timely and rely on an extensive network with prominent experimental partners.  The applications will encompass contemporary catalytic conversions in zeolites, active site engineering in metal organic frameworks and structural transitions in nanoporous materials, and the expected outcomes will have the potential to yield groundbreaking new insights.  

The results  are expected to have impact far beyond the horizon of the current project as they will contribute to the transition from static to dynamically based modeling tools within heterogeneous catalysis","1993750","2015-08-01","2020-07-31"
"E-motion","Electro-motion for the sustainable recovery of high-value nutrients from waste water","Louis Cornelia Patrick Maria de Smet","WAGENINGEN UNIVERSITY","Current water treatment technologies are mainly aimed to improve the quality of water. High-value nutrients, like nitrate and phosphate ions, often remain present in waste streams. Electro-driven separation processes offer a sustainable way to recover these nutrients. Ion-selective polymer membranes are a strong candidate to achieve selectivity in such processes.

The aim of E-motion is to chemically modify porous electrodes with membranes to introduce selectivity in electro-driven separation processes. New, ultrathin ion-selective films will be designed, synthesized and characterized. The films will be made by successively adsorbing polycations and polyanions onto the electrodes. Selectivity will be introduced by the incorporation of ion-selective receptors. The adsorbed multilayer films will be studied in detail regarding their stability, selectivity and transport properties under varying experimental conditions of salinity, pH and applied electrical field, both under adsorption and desorption conditions.

The first main challenge is to optimize and to understand the film architecture in terms of 1) stability towards an electrical field, 2) ability to facilitate ion transport. Also the influence of ion charge and ion size on the transport dynamics will be addressed. The focus of E-motion is set on phosphate ions, which is rather complex due to their large size, pH-dependent speciation and the development of phosphate-selective materials. Theoretical modelling of the solubility equilibria and electrical double layers will be pursued to frame the details of the electrosorption of phosphate.

E-motion represents a major step forward in the selective recovery of nutrients from water in a cost-effective, chemical-free way at high removal efficiency. The proposed surface modification strategies and the increased understanding of ion transport and ionic interactions in membrane media offer also applications in the areas of batteries, fuel cells and solar fuel devices.","1950000","2016-11-01","2021-10-31"
"e-Sequence","e-Sequence: a sequential approach to engineer heteroatom doped graphene nanoribbons for electronic applications","Aurelio MATEO ALONSO","UNIVERSIDAD DEL PAIS VASCO/ EUSKAL HERRIKO UNIBERTSITATEA","Graphene nanoribbons (NR) are quasi-1D nanostructures with discrete band gaps, ballistic conduction, and one-atom thickness. Such properties make them ideal candidates to develop low-dimensional semiconductors, which are essential components in nanoelectronics. Atomically-precise control over the structure of NR (width, length, edge, doping) is crucial to fully exploit their potential. However, current approaches for the synthesis of NR suffer from several drawbacks that do not allow attaining such level of precision, therefore alternative methods need to be sought.

e-Sequence will develop an unprecedented approach that assembles stepwise small molecular building blocks into NR to specifically target the most important challenges in NR synthesis. Such approach will enable the preparation of an unlimited number of NR with atomically-precise control over their structure and with almost no synthetic and purification effort, exceeding the limits of existing methods.

The impact of e-Sequence will not be limited to NR synthesis but it will also extend to other disciplines, since NR are promising candidates to develop new technologies with applications in electronics, sensing, photonics, energy storage and conversion, spintronics, etc.

e-Sequence ambitious research programme will be orchestrated by an independent scientist with an excellent track record of achievements in low-dimensional carbon nanostructures, and who has already established a fledgling and internationally competitive research group. Building on this and on his recent permanent appointment as Research Professor, the award of this ERC project will enable him to consolidate his group, build a portfolio of excellent research, and produce results that compete on the world stage.","2000000","2017-11-01","2022-10-31"
"Earth core","Exploring Thermodynamic Properties of Earth’s Core-Forming Materials","Tetsuya Komabayashi","THE UNIVERSITY OF EDINBURGH","It is known that the Earth’s core is less dense than pure iron by about 7%, which is due to the presence of a light element(s) such as Si, S, C, O, and H. The goal of this project is to construct a thermodynamic model of the Earth’s central core. A particular focus is on the identification of the light element because the inclusion of these elements in iron liquid depends on the pressure (P), temperature (T), and chemical environment and hence provides us invaluable information about the origin and evolution of the solid Earth. We will examine phase relations and density of phases in Fe-light element systems by conducting high-P-T experiments and employing thermodynamic calculations based on the experimental data. 
High-P-T experiments will be conducted in a diamond anvil cell with three different kinds of heating techniques: laser heating, external-resistive heating, and internal-resistive heating. Of the three, the internal-resistive heating system is a special technique that I have developed and employed and I am currently generating 5000 K at 200 GPa with it. Structure of phases will be analysed by in-situ X-ray diffraction. Chemical analysis will also be employed on samples to determine element partitioning between the phases. 
I will also employ thermodynamic calculations based on the experimental data to fully understand the thermodynamic properties of the materials and obtain physical properties which are difficult to directly determine by experiment such as sound velocity of liquids. 
From the thermodynamic models, I will calculate the physical properties of light element-bearing iron liquids and compare them with seismologically constrained values of the Earth’s core to find out the best matching composition. From these results, I will discuss the physical and chemical environments during the core formation and implicate in the origin and evolution of the Earth. Also the results will be applied to other terrestrial planets which have metallic cores.","1891765","2015-06-01","2020-05-31"
"EARTHSEQUENCING","A new approach to sequence Earth history at high resolution over the past 66 million years","Heiko Pälike","UNIVERSITAET BREMEN","""One major challenge to be addressed by this proposal is to overcome fundamental obstacles to generate a first high-resolution and continuous fully integrated record of geological events, ages and durations
(a ‘sequence of Earth history’) for the past 66 million years, anchored to the present, to extract properties of Earth’s and solar system orbital motion, and then to apply this time scale to solve first order questions about Earth’s climate system and Earth System sensitivity. The project will bridge the long-standing ‘Eocene tuning gap’, primarily using spectacular new data recovered during Integrated Ocean Drilling Expedition 342 and integrated with a new consistent and integrated approach with existing data that currently only provide time sequences floating in time, not anchored to the present. The proposal will extract astronomical parameters (tidal dissipation, dynamical ellipticity) and verify astronomical models to provide long term amplitude modulation patterns of Earth’s orbital variations (obliquity and short eccentricity) beyond 40 million years before present.  It will also search for the fingerprint of chaotic transitions in the solar system that will allow astronomical models to be tested. The improved geologic time scale will then be applied, exploited, and combined with modern Earth System Models of Intermediate Complexity to quantify Earth System sensitivity to orbital forcing during a world of elevated carbon-dioxide concentrations during the ‘greenhouse’ Paleogene. Using novel new pattern matching and recognition algorithms as well as time series analysis methods, the full record of Earth history will be fully integrated and analysed with a consistent and documented workflow. This development will have the ground-breaking potential to take ‘Earth sequencing’ to the next level.""","1998343","2014-04-01","2019-03-31"
"eAXON","Electronic AXONs: wireless microstimulators based on electronic rectification of epidermically applied currents","Antonio IVORRA Cano","UNIVERSIDAD POMPEU FABRA","To build interfaces between the electronic domain and the human nervous system is one of the most demanding challenges of nowadays engineering. Fascinating developments have already been performed such as visual cortical implants for the blind and cochlear implants for the deaf. Yet implantation of most electrical stimulation systems requires complex surgeries which hamper their use for the development of so-called electroceuticals. More importantly, previously developed systems based on central stimulation units are not adequate for applications in which a large number of sites must be individually stimulated over large and mobile body parts, thus hindering neuroprosthetic solutions for patients suffering paralysis due to spinal cord injury or other neurological disorders. A solution to these challenges could consist in developing addressable single-channel wireless microstimulators which could be implanted with simple procedures such as injection. And, indeed, such solution was proposed and tried in the past. However, previous attempts did not achieve satisfactory success because the developed implants were stiff and too large. Further miniaturization was prevented because of the use of inductive coupling and batteries as energy sources. Here I propose to explore an innovative method for performing electrical stimulation in which the implanted microstimulators will operate as rectifiers of bursts of innocuous high frequency current supplied through skin electrodes shaped as garments. This approach has the potential to reduce the diameter of the implants to one-fifth the diameter of current microstimulators and, more significantly, to allow that most of the implants’ volume consists of materials whose density and flexibility match those of neighbouring living tissues for minimizing invasiveness. In fact, implants based on the proposed method will look like short pieces of flexible thread.","1999813","2017-05-01","2022-04-30"
"ECHO","Extending Coherence for Hardware-Driven Optimizations in Multicore Architectures","Alberto ROS","UNIVERSIDAD DE MURCIA","Multicore processors are present nowadays in most digital devices, from smartphones to high-performance servers. The increasing computational power of these processors is essential for enabling many important emerging application domains such as big-data, media, medical, or scientific modeling. A fundamental technique to improve performance is speculation, a technique that consists in executing work before it is known if it is actually needed. In hardware, speculation significantly increases energy consumption by performing unnecessary operations, while speculation in software (e.g., compilers) is not the default thus preventing performance optimizations. Since performance in current multicores is limited by their power budget, it is imperative to make multicores as energy-efficient as possible to increase performance even further.
In a multicore architecture, the cache coherence protocol is an essential component since its unique but challenging role is to offer a simple and unified view of the memory hierarchy. This project envisions that extending the role of the coherence protocol to simplify other system components will be the key to overcome the performance and energy limitations of current multicores. In particular, ECHO proposes to add simple but effective extensions to the cache coherence protocol in order to (i) reduce and even eliminate misspeculations at the processing cores and synchronization mechanisms and to (ii) enable speculative optimizations at compile time. The goal of this innovative approach is to improve the performance and energy efficiency of future multicore architectures. To accomplish the objectives proposed in this project, I will build on my 14 years expertise in cache coherence, documented in over 40 publications of high impact.","1999955","2019-09-01","2024-08-31"
"ECLAIR","Emulation of subgrid-scale aerosol-cloud interactions in climate models: towards a realistic representation of aerosol indirect effect","Sari Hannele Korhonen","ILMATIETEEN LAITOS","I propose to develop an innovative interdisciplinary model framework to refine the estimate of aerosol indirect effect (i.e. influence of atmospheric aerosol particles on cloud properties), which remains the single largest uncertainty in the current drivers of climate change. 

A major reason for this uncertainty is that current climate models are unable to resolve the spatial scales for aerosol-cloud interactions. We will resolve this scale problem by using statistical emulation to build computationally fast surrogate models (i.e. emulators) that can reproduce the effective output of a detailed high-resolution cloud-resolving model. By incorporating these emulators into a state-of-the-science climate model, we will for the first time achieve the accuracy of a limited-area high-resolution model on a global scale with negligible computational cost.

The main scientific outcome of the project will be a highly refined and physically sound estimate of the aerosol indirect effect that enables more accurate projections of future climate change, and thus has high societal relevance. In addition, the developed emulators will help to quantify how the remaining uncertainties in aerosol properties propagate to predictions of aerosol indirect effect. This information will be used, together with an extensive set of remote sensing, in-situ and laboratory data from our collaborators, to improve the process-level understanding of aerosol-cloud interactions. 

The comprehensive uncertainty analyses performed during this project will be highly valuable for future research efforts as they point to processes and interactions that most urgently need to be experimentally constrained. Furthermore, our pioneering model framework that incorporates emulators to represent subgrid- scale processes will open up completely new research opportunities also in other fields that deal with heterogeneous spatial scales.","1999511","2015-09-01","2020-08-31"
"ECM_INK","Cells-self Extracellular Matrices-based Bioinks to create accurate 3D diseased skin tissue models","Alexandra Margarida PINTO MARQUES","UNIVERSIDADE DO MINHO","It has been recognized that growing cells within 3D structures reduces the gap between 2D in vitro cell cultures and native tissue physiology. This has been paving the way for the development of reliable 3D in vitro cell-based platforms with major impact in the reduction/elimination of animal experimentation, diseases modelling and drug development. So far, the many strategies that have been followed to bioengineer in vitro 3D human tissue models mostly rely on the random culture of cells within a 3D structure without reflecting the compositional and structural complexity of the native tissues. Recently proposed bioprinting technologies that allow accurate and high speed deposition of various cells and matrices at high resolution, have therefore great potential in the development of physiologically reliable 3D in vitro tissue models by recreating the different microenvironments/microfunctionalities found in each tissue. Nonetheless, among the components required for bioprinting, bioinks in particular have demanding requirements and much has still to be done regarding their intrinsic formulation to lead cell behaviour and support specific functionalities.
ECM_INK intends to tackle this issue by developing cells-self extracellular matrices-based bioinks to create accurate and pathophysiological relevant 3D in vitro diseased skin tissue models. The development of cell phenotype-driven bioinks will generate complex microenvironments comprising varied cell types within matrices that were specifically designed to attain a particular response from each one of those cell types. The use of cells from patients suffering from chronic, genetic and neoplastic skin diseases represents a major advantage that will be reflected in the accuracy and functionality of the respective 3D in vitro models. The ultimate confirmation of their potential will be complete after validation using animal-free approaches reinforcing the intrinsic relationship of ECM_INK with the 3Rs policy.","1998939","2017-05-01","2022-04-30"
"ECO-ZEN","Enabling Catalytic Cross Couplings with only Zinc Electrophiles, Nucleophiles and Boranes","Michael James INGLESON","THE UNIVERSITY OF MANCHESTER","This high-impact, challenging CoG Proposal integrates multiple novel ideas in boron and zinc chemistry into an overarching project to open up new horizons across synthesis and catalysis. The Applicant’s successful ERC StG has opened up new avenues of pioneering research in main group element mediated transformations that were not conceivable before the work was done. Components of this proposal extend out from the StG into new, exciting research areas that are completely different. Developing low toxicity earth abundant catalysts for important transformations is vital to the EU with the focus herein being on; (i) the Suzuki-Miyaura (S-M) cross coupling reaction which is ubiquitous in industry and academia, and (ii) the formation of organoboranes that are essential synthetic intermediates. Both of these are currently dominated by toxic, expensive and low abundance precious metal catalysts (e.g. Pd, Ir). This project will deliver innovation through utilising combinations of main group Lewis acids and nucleophilic anions that do not react with each other, i.e. are frustrated pairs. This “frustration” enables the two species to concertedly transform substrates to achieve:

(i) Precious metal-free S-M cross coupling reactions of sp3C electrophiles catalysed by zinc and boron compounds, including stereospecific couplings and one pot two step cross electrophile couplings.

(ii) Trans-elementoboration of alkynes, including the unprecedented fluoroboration of alkynes.

Other new approaches will be developed to access novel (hetero)arylboronic acid derivatives using only simple boranes and without requiring noble metal catalysts, specifically: (i) boron directed C-H borylation and (ii) directed ortho borylation to enable subsequent meta selective SEAr C-H functionalisation. 

This CoG will afford the freedom and impetus via consolidated funding to undertake fundamental research to deliver high impact results, including developing a new area of cross coupling catalysis research.","2070093","2018-05-01","2023-04-30"
"ECOHERB","Drivers and impacts of invertebrate herbivores across forest ecosystems globally.","Daniel Metcalfe","LUNDS UNIVERSITET","Forests slow global climate change by absorbing atmospheric carbon dioxide but this ecosystem service is limited by soil nutrients. Herbivores potentially alter soil nutrients in a range of ways, but these have mostly only been recorded for large mammals. By comparison, the impacts of the abundant invertebrates in forests have largely been ignored and are not included in current models used to generate the climate predictions so vital for designing governmental policies
The proposed project will use a pioneering new interdisciplinary approach to provide the most complete picture yet available of the rates, underlying drivers and ultimate impacts of key nutrient inputs from invertebrate herbivores across forest ecosystems worldwide. Specifically, we will:

(1) Establish a network of herbivory monitoring stations across all major forest types, and across key environmental gradients (temperature, rainfall, ecosystem development).
(2) Perform laboratory experiments to examine the effects of herbivore excreta on soil processes under different temperature and moisture conditions.
(3) Integrate this information into a cutting-edge ecosystem model, to generate more accurate predictions of forest carbon sequestration under future climate change.

The network established will form the foundation for a unique long-term global monitoring effort which we intend to continue long after the current funding time scale. This work represents a powerful blend of several disciplines harnessing an array of cutting edge tools to provide fundamentally novel insights into an area of direct and urgent importance for the society.","1750000","2016-03-01","2021-02-28"
"ELECNANO","Electrically Tunable Functional Lanthanide Nanoarchitectures on Surfaces","DAVID ECIJA FERNANDEZ","FUNDACION IMDEA NANOCIENCIA","Lanthanide metals are ubiquitous nowadays, finding use in luminescent materials, optical amplifiers and waveguides, lasers, photovoltaics, rechargeable batteries, catalysts, alloys, magnets, bio-probes, and therapeutic agents. In addition, they bear potential for high temperature superconductivity, magnetic refrigeration, molecular magnetic storage, spintronics and quantum information. 

Surprisingly, the study of lanthanide physico-chemical properties on surfaces is at its infancy, particularly at the nanoscale. To address this extraordinary scientific opportunity, I will research the foundations and prospects of lanthanide elements to design functional nanoarchitectures on surfaces and I will study their inherent physico-chemical phenomena in distinct coordination environments, targeting novel approaches for sensing, nanomagnetism and electroluminescence. Importantly, our studies will encompass both metal substrates and decoupling surfaces including ultra-thin film insulators and graphene. Nurturing from these studies and in parallel, we will focus on graphene voltage back-gated supports, thus surpassing the seminal knowledge on electrically-inert substrates and enhancing the scope of our research to address the overarching objective of the proposal, i.e., the design of electrically tunable functional lanthanide nanomaterials.

The culmination of ELECNANO project will provide strategies for:
1.-Design of functional nanomaterials on high-technological supports.
2.-Development of advanced coordination chemistry on surfaces.
3.-Rationale of the physico-chemical properties of lanthanide-coordination environments.
4.-Engineering of lanthanide nanoarchitectures for ultimate sensing, nanomagnetism and electroluminescence.
5.-In-situ atomistic views of electrically tunable materials and unprecedented fundamental studies of charge-molecule/metal physics on devices.","1994713","2018-09-01","2023-08-31"
"eLightning","Lightning propagation and high-energy emissions within coupled multi-model simulations","Alejandro Luque Estepa","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","More than 250 years after establishing the electrical nature of the lightning flash, we still do not understand how a lightning channel advances. Most of these channels progress not continuously but in a series of sudden jumps and, as they jump, they emit bursts of energetic radiation.  Despite increasingly accurate observations, there is no accepted explanation for this stepped progression.

This proposal addresses this open question.  First, we propose a methodological breakthrough that will allow us to tackle the main bottleneck in the theoretical understanding of lightning: the wide disparity between length-scales within a lightning flash.  We plan to apply techniques that have succeeded in other fields, such as multi-model coupled simulations and moving-mesh finite elements methods.  Acting as a computational microscope, these techniques will reveal the small-scale electrodynamics around a lightning channel.

We will then apply these techniques to elucidate the intertwined problems of lightning channel stepping and thunderstorm-related high-energy emissions.   The main hypothesis that we will test is that stepping is due to the formation of low-conductivity spots within the filamentary-discharge region that surrounds a lightning channel.  This idea is motivated by observations from high-altitude atmospheric discharges.  By resolving the small-scale dynamics, with our numerical method, we will also test hypothesis for high-energy emissions from the lighting channel, which crucially depend on the microscopic distribution of electric fields.

This interdisciplinary proposal, straddling between geophysics and gas discharge physics, seeks a double breakthrough: the methodological one of building multi-scale lightning simulations and the hypothesis-driven one of finding out the reason for stepping.  If it succeeds, it will achieve a leap forward in our knowledge of lightning, undoubtedly one of the greatest spectacles in our planet's repertoire.","1960826","2016-06-01","2021-05-31"
"ElIonT","Electron- and Ion Transfer at the Interface: a Hyphenated Dynamic Multi-Frequency Approach","Fabio LA MANTIA","UNIVERSITAET BREMEN","It is undisputed that electrochemistry has a central role in our contemporary society. This is demonstrated by its profound involvement in many aspects of everyday life: from powering portable electronic devices to personal electro-mobility, passing through recycling, waste water treatment, clean energy production, water desalination, personal care, and others. It appears that we have reached the limits of the technological development and no further revolutionary progresses can be achieved without a deeper understanding of the electron- and ion-transfer process at the interface. The objective of this proposal is to achieve a phenomenological modeling of the electron- and ion-transfer processes, by extending the Marcus-Hush theory of the electron transfer to a general kinetic equation based on experimental data. The extended kinetic equation should include and clarify the role of the excess free Gibbs energy on the kinetics of electron- and ion-transfer, as well as the role of the double layer charge (Frumkin effect). A unified theory of charge transfer and transport will be proposed in the frame of the phenomenological theory of transport and of classic and extended irreversible thermodynamics. Since the investigated phenomena are complex and inter-linked, the investigation techniques must seize snapshots of the system during its evolution; this will be done by hyphenating the electrochemical techniques with quartz crystal microbalance, able to measure in real time nanogram mass changes. In order to cover the time-scales necessary to develop the phenomenological theory, we will measure dynamic impedance and differential immitance spectra with a dynamic multi-frequency approach. This is based on perturbing the system with a multi-sine signal and extracting the linear and non-linear current response and mass change. The evaluation of the phenomenological parameters will rely on novel analysis algorithms and on precise modeling of the interface.","1943600","2018-05-01","2023-04-30"
"Emergence","Emergence of wild differentiable dynamical systems","pierre berger","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Many physical or biological systems display time-dependent states which can be mathematically modelled by a differentiable dynamical system. The state of the system consists of a finite number of variables, and the short time evolution is given by a differentiable equation or the iteration of a differentiable map. The evolution of a state is called an orbit of the system. The theory of dynamical systems studies the long time evolution of the orbits.
For some systems, called chaotic, it is impossible to predict the state of an orbit after a long period of time. However, in some cases, one may predict the probability of an orbit to have a certain state. A paradigm is given by the Boltzmann ergodic hypothesis in thermodynamics: over long periods of time, the time spent by a typical orbit in some region of the phase space is proportional to the “measure” of this region. The concept of Ergodicity has been mathematically formalized by Birkhoff. Then it has been successfully applied (in particular) by the schools of Kolmogorov and Anosov in the USSR, and Smale in the USA to describe the statistical behaviours of typical orbits of many differentiable dynamical systems.
For some systems, called wild, infinitely many possible statistical behaviour coexist. Those are spread all over a huge space of different ergodic measures, as initially discovered by Newhouse in the 70's. Such systems are completely misunderstood. In 2016, contrarily to the general belief, it has been discovered that wild systems form a rather typical set of systems (in some categories).
This project proposes the first global, ergodic study of wild dynamics, by focusing on dynamics which are too complex to be well described by means of finitely many statistics, as recently quantified by the notion of Emergence. Paradigmatic examples will be investigated and shown to be typical in many senses and among many categories. They will be used to construct a theory on wild dynamics around the concept of Emergence.","1070343","2019-09-01","2024-08-31"
"EMPIRE","Galaxy Evolution in the ALMA Era - The Baryon Cycle and Star Formation in Nearby Galaxies","Frank BIGIEL","RHEINISCHE FRIEDRICH-WILHELMS-UNIVERSITAT BONN","A thorough understanding of the processes regulating the conversion of gas into stars is key to understand structure formation in the universe and the evolution of galaxies through cosmic time. Despite significant progress over the past years, the properties of the actual dense, star forming gas across normal disk galaxies remain largely unknown. This will be changed with EMPIRE, a comprehensive 500hr large program led by the PI at the IRAM 30m mm-wave telescope. EMPIRE will provide for the first time extended maps of a suite of dense gas tracers (e.g., HCN, HCO+, HNC) for a sample of nearby, star-forming, disk galaxies.

By means of detailed analysis, including radiative transfer and chemical modelling, we will constrain a variety of physical quantities (in particular gas densities). We will relate these directly to the local star formation efficiency and to a variety of other dynamical, stellar and local ISM properties from existing pan-chromatic mapping of these galaxies (HI, IR, CO, UV, optical) to answer the question: ``how is star formation regulated across galaxy disks?''. By determining true abundance variations, we will contribute key constraints to the nascent field of galaxy-scale astrochemistry. Detailed comparisons to data for star forming regions in the Milky Way will link core, cloud and galactic scales towards a coherent view of dense gas and star formation. These results will provide an essential anchor point to Milky Way and high redshift observations alike.

Analysis, interpretation and modelling of this complex data set requires a team of two postdocs and two PhD students. The PI has demonstrated his ability to successfully lead a research group through his current position as a DFG funded Emmy-Noether group leader. In combination with his widely recognized previous work and his expertise in mm-wave astronomy and ISM/star formation studies, the PI and the proposed group are uniquely positioned to make significant impact during this ERC grant.","1659451","2017-07-01","2022-06-30"
"EMPOWER","Medium Voltage Direct Current Electronic Transformer","Drazen DUJIC","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","More than a century ago, the invention of alternating current (AC) transformer has made AC the preferred choice over the direct current (DC) technologies. Line AC transformers are bulky but simple and reliable devices, made out of copper and iron, providing voltage adaptation and galvanic isolation in AC power systems. 

Currently, DC technology is increasing its presence in AC power systems, enabled by progress in semiconductor devices and power electronics based energy conversion. DC power distribution networks can effectively support energy transformation and high penetration of distributed energy resources and energy storage integration (both increasingly being DC by nature) in future energy systems. Despite this shift towards the DC power distribution networks, DC Transformer, offering AC transformer like features (and beyond) does not exist, either conceptually or practically.

To enable the next (r)evolution in power systems, the EMPOWER project will develop the DC Transformer, a novel, flexible, highly efficient, compact, and reliable conversion principle for seamless energy routing in high-power DC distribution networks. Through a holistic approach, novel concepts, integration and optimization, we will demonstrate new design paradigms for galvanically-isolated power conversion. Our approach relies on resonant conversion utilizing high-voltage semiconductor devices in combination with high-frequency magnetic materials. We propose a new approach for the DC Transformer, avoiding active power flow control and instead utilizing control effort for the safety and protection. The DC Transformer will unify functions of a power converter and a protection device into a single power electronics system, improving drastically the conversion efficiency, reliability and power density in future DC power distribution networks. The success of this project will place Europe at the edge of reliable, efficient and safe energy distribution and transmission technologies.","2198145","2019-06-01","2024-05-31"
"ENCOMOLE-2i","Endoscopic Comprehensive Optical Multimodal Molecular Intelligent Imaging","Robert Huber","UNIVERSITAT ZU LUBECK","Optical imaging has exceptional potential for medical diagnosis, because it can provide high spatial resolution and molecular contrast. However, for in vivo imaging in humans, the poor penetration of only a few millimetres is a major obstacle. Optical endoscopes solve this problem, but currently most of them only perform non-advanced, classical white light imaging. Also, the speed of current devices is not sufficient to comprehensively scan entire organs at microscopic resolution. Hence, medical imaging is still dominated by non-optical techniques like X-ray, ultrasound and magnetic resonance imaging.
The objective of ENCOMOLE-2i is to push the performance of advanced optical in vivo imaging techniques to cross the application threshold for clinical research and practice. An endoscopic multi-modal molecular imaging platform will be developed with unprecedented capabilities for the diagnosis of disease.
The hardware technology development includes three novel imaging modalities. Optical coherence tomography with line rates of several Megahertz will be used for comprehensive structural imaging over large areas. Time encoded stimulated Raman sensing, supported by a new type of two photon microscopy, will be used for guided and referenced molecular imaging. Combining these techniques into one system and interfacing it with a newly developed endoscope will generate great synergy. Moreover, the unique synchronization capabilities of these modalities enable a radically new strategy for more efficient data acquisition: The concept of adaptive “Intelligent Imaging”.
The goal is to develop a universal endoscopy platform which can then be specifically tailored to the individual application. In the project the focus is on gastrointestinal imaging. The synergy between technological and algorithmic advances in ENCOMOLE-2i will break ground for more optical in vivo imaging in clinical research and routine, which can finally lead to improved diagnosis of many types of disease.","1998530","2016-01-01","2020-12-31"
"ENERCAPSULE","Nanoencapsulation for Energy Storage and Controlled Release","Dzmitry Shchukin","THE UNIVERSITY OF LIVERPOOL","The main vision of the project ENERCAPSULE is the development of nanoencapsulation technologies based on switchable nanoscale barriers for novel generation of controlled energy storage and delivery systems. These systems will be based on the “smart” nanocontainers (size below 200 nm) loaded with the energy-enriched active components: materials for thermal energy (both latent and based on chemical reactions) storage and substances for bioenergy (ATP or its components) storage for synthetic biology platforms. First novelty of the proposed project is the protection of the nanoscaled energy-enriched materials against environment during storage and controlled release of the encapsulated energy on demand only using both inherent properties of nanocontainer shell or biomimetic nanovalves introduced as shell components. Another main objective of the project is to study the structure and surface-to-volume properties of the energy enriched materials dispersed and encapsulated on nanoscale. The questions of stability of energy nanomaterials, influence of the nanocontainer shell on their energy capacity, homogeneity and operation lifetime will be investigated. Polymer organic nanocapsules with hollow interior and mesoporous carbon nanoparticles are chosen in the project as main types of the nanocontainer scaffolds for energy-enriched materials due to their high loading capacity and potential to design their shells to attain them controlled permeability properties. At the end of the project, developed novel energy storage and delivery systems will be combined within one network having several mechanisms for release and uptake of energy, which can be activated depending on type and intensity of the external impact (demand). The potential applications of such multienergy storage systems will be tested by industrial companies supporting the project.","2004500","2015-09-01","2020-08-31"
"ENFORCE","ENgineering FrustratiOn in aRtificial Colloidal icEs:degeneracy, exotic lattices and 3D states","pietro TIERNO","UNIVERSITAT DE BARCELONA","Geometric frustration, namely the impossibility of satisfying competing interactions on a lattice, has recently
become a topic of considerable interest as it engenders emergent, fundamentally new phenomena and holds
the exciting promise of delivering a new class of nanoscale devices based on the motion of magnetic charges.
With ENFORCE, I propose to realize two and three dimensional artificial colloidal ices and investigate the
fascinating manybody physics of geometric frustration in these mesoscopic structures. I will use these soft
matter systems to engineer novel frustrated states through independent control of the single particle
positions, lattice topology and collective magnetic coupling. The three project work packages (WPs) will
present increasing levels of complexity, challenge and ambition:
(i) In WP1, I will demonstrate a way to restore the residual entropy in the square ice, a fundamental longstanding
problem in the field. Furthermore, I will miniaturize the square and the honeycomb geometries and investigate the dynamics of thermally excited topological defects and the formation of grain boundaries.
(ii) In WP2, I will decimate both lattices and realize mixed coordination geometries, where the similarity
between the colloidal and spin ice systems breaks down. I will then develop a novel annealing protocol based
on the simultaneous system visualization and magnetic actuation control.
(iii) In WP3, I will realize a three dimensional artificial colloidal ice, in which interacting ferromagnetic
inclusions will be located in the voids of an inverse opal, and arranged to form the FCC or the pyrochlore
lattices. External fields will be used to align, bias and stir these magnetic inclusions while monitoring in situ
their orientation and dynamics via laser scanning confocal microscopy.
ENFORCE will exploit the accessible time and length scales of the colloidal ice to shed new light on the
exciting and interdisciplinary field of geometric frustration.","1850298","2020-01-01","2024-12-31"
"ENGAGES","Next generation algorithms for grabbing and exploiting symmetry","Pascal Schweitzer","TECHNISCHE UNIVERSITAET KAISERSLAUTERN","Symmetry is a phenomenon that appears in many different contexts. 
Algorithmic symmetry detection and exploitation is the concept of finding intrinsic symmetries of a given object and then using these symmetries to our advantage. Application areas of algorithmic symmetry detection and exploitation range from convolutional neural networks in machine learning to computer graphics, chemical data bases and beyond. 
In contrast to this widespread use, our understanding of the theoretical foundation (namely the graph isomorphism problem) is incomplete and current algorithmic symmetry tools are inadequate for big data applications. Hence, EngageS addresses these key challenges in the field using a systematic approach to the theory and practice of symmetry detection. It thereby also fixes the existing lack of interplay between theory and practice, which is part of the problem.

EngageS' main aims are to tackle the classical and descriptive complexity of the graph isomorphism problem and to design the next generation of symmetry detection algorithms. As key ideas to resolve the complexity, EngageS offers three  new approaches on how to prove lower bounds and a new method to settle the descriptive complexity.

EngageS will also develop practical symmetry detection algorithms for big data, exploiting parallelism and memory hierarchies of modern machines, and will introduce the concept of and a road map to exploiting absence of symmetry. Overall EngageS will establish a comprehensive software library that will serve as a  platform for integrated research on the algorithmic treatment of symmetry.

In summary, EngageS will develop fast, efficient and accessible symmetry detection tools that will be used to solve complex algorithmic problems in a range of fields including combinatorial algorithms, generation problems, and canonization.","1999094","2019-03-01","2024-02-29"
"ENLIGHTENED","Nanophotonic Nanomechanical Mass Spectrometry for Biology and Health","Sébastien Claude Hentz","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","« Mass Spectrometry has become a routine analytical tool in modern biological research, and has gained in recent years a foothold in the realm of clinical diagnostic and screening. However, it is still costly, complex and because its principle relies on ionization, it is incapable of analyzing biomolecules with masses greater than a few MDa. Averaging more than 100 million particles per measurement, it is also incapable of characterizing the diversity of such heavy entities. ENLIGHTENED aims at demonstrating a breakthrough concept based on Photonic Nano-Mechanical Mass Spectrometry, able to perform analysis of bioparticles of high biomedical significance, of ultra-high mass, never so far characterized, with single-molecule sensitivity and unprecedented resolution. The long-term vision beyond the current proposal is to provide the biologists with a tool which will be transformative for fundamental knowledge, and to make possible cheap, handheld devices for personalized medicine.
ENLIGHTENED proposes to use photons to shed light on unexplored species at the individual level, which is of high biomedical significance and will expand our understanding of simple life forms.”","1999090","2014-06-01","2020-05-31"
"ENSURE","Exploring the New Science and engineering unveiled by Ultraintense ultrashort Radiation interaction with mattEr","Matteo Passoni","POLITECNICO DI MILANO","With the ENSURE project I aim at attaining ground-breaking results in the field of superintense laser-driven ion acceleration, proposing a multidisciplinary research program in which theoretical, numerical and experimental research will be coherently developed in a team integrating in an unprecedented way advanced expertise from materials engineering and nanotechnology, laser-plasma physics, computational science. The aim will be to bring this topic from the realm of fundamental basic science into a subject having realistic engineering applications.
The discovery in 2000 of brilliant, multi-MeV, collimated ion sources from targets irradiated by intense laser pulses stimulated great interest worldwide, due to the ultra-compact spatial scale of the accelerator and ion beam properties. The laser-target system provides unique appealing features to fundamental physics which can be studied in a small lab. At the same time, laser-ion beams could have future potential in many technological areas. This is boosting the development of new labs and facilities all over Europe, but to support these efforts, crucial challenges need to be faced to make these applications a reality.
The goals of ENSURE are: i) design and production of nanoengineered targets, with properties tailored to achieve optimized ion acceleration regimes. This will be pursued exploiting advanced techniques of material science & nanotechnology ii) design of laser-ion beams for novel, key applications in nuclear and materials engineering iii) realization of engineering-oriented ion acceleration experiments, in advanced facilities iv) synergic development of all the required theoretical support for i,ii,iii).
The results of the project can determine a unique impact in the research on laser-driven ion acceleration in Europe, providing new directions to support the attainment, in the next future, of concrete applications of great societal relevance, in medical, energy and materials areas.","1887500","2015-09-01","2020-08-31"
"ENUBET","Enhanced NeUtrino BEams from kaon Tagging","Andrea Longhin","ISTITUTO NAZIONALE DI FISICA NUCLEARE","ENUBET has been designed to open a new window of opportunities in accelerator neutrino physics.  

The proposed project enables for the first time the measurement of the positrons produced in the decay tunnel of conventional neutrino beams: these particles signal uniquely the generation of an electron neutrino at source. 
Neutrino facilities enhanced by the ENUBET technique will have an unprecedented control of the neutrino flux. This will allow to reduce by one order of magnitude the uncertainties on neutrino cross sections: a leap that has been sought after since decades and that is needed to address the challenges of discovering matter-antimatter asymmetries in the leptonic sector.

The apparatus is a highly specialized electromagnetic calorimeter with fast response, sustaining particle rates as high as 0.5 MHz/cm^2, having excellent electron/pion separation capabilities with a reduced number of read-out channels. ENUBET will boost technologies that have been envisaged for high energy colliders to address this new challenge. On the other hand it will operate in a substantially different configuration. The experiment will be performed at the CERN Neutrino Platform, a recently approved facility where innovative neutrino detectors will be developed exploiting dedicated hadron beam-lines from the SPS accelerator. In the first phase of the project, ENUBET will address the challenges of particle identification from extended sources, developing innovative optical readout systems and cost-effective solutions for radiation imaging. This approach is based on cutting-edge technologies for single photon sensitive devices. During the second phase, the detector will be assembled and characterized at CERN with particle beams. Finally, it will be operated in time coincidence with Liquid Argon neutrino detectors, achieving a major step towards the realization of the concept of tagging individual neutrinos both at production and interaction level, on an event-by-event basis.","2000000","2016-06-01","2021-05-31"
"EPGR","The Evolution Problem in General Relativity","Jérémie Szeftel","SORBONNE UNIVERSITE","General relativity has been introduced by A. Einstein in 1915. It is a major theory of modern physics and at the same time has led to fascinating mathematical problems. The present proposal focusses on two aspects of the evolution problem for the Einstein equations which has been initiated by the pioneering work of Y. Choquet-Bruhat in 1952.

The Einstein equations form a nonlinear system of partial differential equations of hyperbolic type whose complexity raises significant challenges to its mathematical analysis. The goal of this project is to strengthen our understanding of two important themes concerning the evolution problem in general relativity. On the one hand, the control of low regularity solutions of the Einstein equations, a topic which is intimately linked with the celebrated cosmic censorship conjectures of R. Penrose, a major open problem in the field. On the other hand, the question of the stability of particular solutions of the Einstein equations in the wake of the groundbreaking proof of the stability of the Minkowski space-time due to D. Christodoulou and S. Klainerman. These directions are extremely active and have recently led to impressive results. More specifically, this project proposes to consider the following two work packages

-Going beyond the bounded L2 curvature theorem. This result has been recently obtained by the PI in collaboration with S. Klainerman and I. Rodnianski and is the sharpest result in so far as low regularity solutions of the Einstein equations are concerned. Yet, the fundamental quest towards a scale invariant well-posedness criterion for the Einstein equations remains wide open.

-The black hole stability problem. This problem concerns the stability of the Kerr metrics which form a 2-parameter family of solutions to  the Einstein vacuum equations. Many results have been obtained concerning various versions of linear stability, but significant challenges remain in order to tackle the nonlinear stability result.","1455000","2017-05-01","2022-04-30"
"EPIC","Earth-like Planet Imaging with Cognitive computing","Olivier ABSIL","UNIVERSITE DE LIEGE","One of the most ambitious goals of modern astrophysics is to characterise the physical and chemical properties of rocky planets orbiting in the habitable zone of nearby Sun-like stars. Although the observation of planetary transits could in a few limited cases be used to reach such a goal, it is widely recognised that only direct imaging techniques will enable such a feat on a statistically significant sample of planetary systems. Direct imaging of Earth-like exoplanets is however a formidable challenge due to the huge contrast and minute angular separation between such planets and their host star. The proposed EPIC project aims to enable the direct detection and characterisation of terrestrial planets located in the habitable zone of nearby stars using ground-based high-contrast imaging in the thermal infrared domain. To reach that ambitious goal, the project will focus on two main research directions: (i) the development and implementation of high-contrast imaging techniques and technologies addressing the smallest possible angular separations from bright, nearby stars, and (ii) the adaptation of state-of-the-art machine learning techniques to the problem of image processing in high-contrast imaging. While the ultimate goal of this research can likely only be reached with the advent of giant telescopes such as the Extremely Large Telescope (ELT) around 2025, the EPIC project will lay the stepping stones towards that goal and produce several high-impact results along the way, e.g. by re-assessing the occurrence rate of giant planets in direct imaging surveys at the most relevant angular separations (i.e., close to the snow line), by conducting the deepest high-contrast imaging search for rocky planets in the alpha Centauri system, by preparing the scientific exploitation of the ELT, and by providing the first open-source high-contrast image processing toolbox relying on supervised machine learning techniques.","2178125","2019-05-01","2024-04-30"
"EPICODE","Programmable Readers, Writers, and Erasers of the Epigenetic Cytosine Code","Daniel SUMMERER","TECHNISCHE UNIVERSITAT DORTMUND","Human DNA contains two types of biologically instructive information: the canonical nucleobases A, G, T, C, and the epigenetic nucleobases mC, hmC, fC, and caC. Canonical nucleobases encode the identity of all RNAs and proteins that are synthesized by a cell, whereas epigenetic nucleobases regulate this synthesis. This regulation shapes the phenotype of cells, and its perturbation is a key trigger of cancer.
Canonical nucleobases can be decoded in a programmable manner by nucleic acids and their analogs via Watson-Crick-base pairing, and the simplicity of this recognition has enabled revolutionary developments in the biological sciences. In contrast, comparable developments in epigenetics have not yet been possible, since a molecular scaffold with  programmable recognition of epigenetic nucleobases does not exist. 
We will establish the first class of molecules capable of the expanded programmable recognition of both canonical and epigenetic DNA nucleobases in vitro and in vivo. This is based on transcription-activator-like effectors (TALEs) that consist of four types of concatenated modules, each of which recognizes a canonical nucleobase. We have recently reported the detection of single epigenetic nucleobases by TALEs. 
In this project, we will 
1. engineer a toolbox of TALE modules with selectivity for C, mC, hmC, fC, and caC,
2. employ them for TALE-based in vitro typing and profiling (reading) of cancer biomarker mC/hmC, and 
3. design photoactivatable TALE-fusions that enable the writing and erasing of mC at user-defined genomic loci in vivo with spatiotemporal resolution. This will provide the first insights into the dynamic effects of de novo editing on chromatin regulation, and enables the imprinting of regulatory states.
Given the central role of epigenetic nucleobases in cancer and the universality of our approach, this project will provide enabling and broadly applicable methodology for cancer epigenetics research, diagnosis and therapy.","1979679","2017-11-01","2022-10-31"
"EpiMech","Epithelial cell sheets as engineering materials: mechanics, resilience and malleability","Marino Arroyo Balaguer","UNIVERSITAT POLITECNICA DE CATALUNYA","The epithelium is a cohesive two-dimensional layer of cells attached to a fluid-filled  fibrous matrix, which lines most free surfaces and cavities of the body. It serves as a protective barrier with tunable permeability, which must retain integrity in a mechanically active environment. Paradoxically, it must also be malleable enough to self-heal and remodel into functional 3D structures such as villi in our guts or tubular networks. Intrigued by these conflicting material properties, the main idea of this proposal is to view epithelial monolayers as living engineering materials. Unlike lipid bilayers or hydrogels, widely used in biotechnology, cultured epithelia are only starting to be integrated in organ-on-chip microdevices. As for any complex inert material, this program requires a fundamental understanding of the structure-property relationships. (1) Regarding their effective in-plane rheology, at short time-scales epithelia exhibit solid-like behavior while at longer times they flow as a consequence of the only qualitatively understood dynamics of the cell-cell junctional network. (2) As for material failure, excessive tension can lead to epithelial fracture, but as we have recently shown, matrix poroelasticity can also cause hydraulic fracture under stretch. However, it is largely unknown how adhesion molecules, membrane, cytoskeleton and matrix interact to give epithelia their robust and flaw-tolerant resilience. (3) Regarding shaping 3D epithelial structures, besides the classical view of chemical patterning, mechanical buckling is emerging as a major morphogenetic driving force, suggesting that it may be possible design 3D epithelial structures in vitro by mechanical self-assembly. Towards understanding (1,2,3), we will combine a broad range of theoretical, computational and experimental methods. Besides providing fundamental mechanobiological understanding, this project will provide a framework to manipulate epithelia in bioinspired technologies.","1989875","2016-09-01","2021-08-31"
"EQEC","Engineering Quantum Error Correction","Barbara Terhal","TECHNISCHE UNIVERSITEIT DELFT","This proposal will advance the theory of quantum error correction towards its application in real physical devices, in particular superconducting transmon qubit systems. The research will result in proposals for experiments: how to use physical qubits to redundantly represent logical quantum information and how error information can be obtained and classically processed. The research will consider novel ways of using transmon qubits to achieve a universal fault-tolerant surface code architecture. The research will produce a design of a universal fault-tolerant architecture in which qubits are encoded in the electromagnetic field of a (microwave) cavity. Research will also focus on mathematical and numerical studies in quantum error correction which are technology-independent, but shed light on coding overhead, decoding efficiency and logical universality.","1786563","2016-04-01","2021-03-31"
"EQuO","Electron Quantum optics in quantum Hall edge channels","Gwendal Feve","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Quantum effects have been studied on photon propagation in the context of quantum optics since the second half of the last century. In particular, using single photon emitters, fundamental tests of quantum mechanics were explored by manipulating single to few photons in Hanbury-Brown and Twiss and Hong Ou Mandel experiments. 
 In nanophysics, there is a growing interest to translate these concepts of quantum optics to electrons propagating in nanostructures. Single electron emitters have been realized such that single elementary electronic excitations can now be manipulated in the analog of pioneer quantum optics experiments.
 Electron quantum optics goes beyond the mere reproduction of optical setups using electron beams, as electrons, being interacting fermions, differ strongly from photons. Contrary to optics, understanding the propagation of an elementary excitation requires replacing the single body description by a many body one. 
 The purpose of this proposal is to specifically explore the emergence of many body physics and its effects on electronic propagation using the setups and concepts of electron quantum optics. The motivations are numerous: firstly single particle emission initializes a simple and well controlled state. I will take this unique opportunity to test birth, life and death scenarii of Landau quasiparticles and observe the emergence of many-body physics. Secondly, I will address the generation of entangled few electrons quantum coherent states and study how they are affected by interactions. Finally, I will attempt to apply electron quantum optics concepts to a regime where the ground state itself is a strongly correlated state of matter. In such a situation, elementary excitations are no longer electrons but carry a fractional charge and obey fractional statistics. No manipulation of single quasiparticles has been reported yet and the determination of some quasiparticle characteristics, such as the fractional statistics remains elusive.","1997878","2015-10-01","2020-09-30"
"ERCC","Efficient Resource Constrained Cryptography","Eike Kiltz","RUHR-UNIVERSITAET BOCHUM","""Traditionally, cryptographic protocols were run on servers or personal computers which have large and easily scalable computational resources. For these applications there exist a large variety of well-established cryptographic systems. Right now, we are in the midst of the shift toward ubiquitous computing on resource constrained devices (RCDs): small devices with severe constraints in terms of computing power, code size, and network capacities. RCDs are used virtually everywhere: smart phones, bank cards, electronic ID-cards, medical implants, cars, RFIDs as bar code replacement, etc. Due to their computational constraints, many current cryptographic security solutions are no longer applicable to RCDs. Existing solutions are often “ad-hoc” and do not come with a formal security treatment.

The central objective of the ERCC project is to initiate an overarching formal treatment of cryptographic solutions for RCDs, particularly focusing on efficiency. The main conceptual novelty is to follow the concept of provable security. We intend to design new cryptographic protocols that have a mathematical proof of security (assuming the hardness of some mathematical problem) and are still competitive with constructions currently used on RCDs. While we certainly cannot hope that all our new provably secure constructions will be superior to existing ad-hoc constructions, recent preliminary research
results give rise to optimism. Concretely, we will base our new protocols on hard problems in ideal and structures lattices and we will study weaker (yet still realistic) security models for RCDs allowing for efficient instantiations.""","1874960","2014-11-01","2019-10-31"
"ErgComNum","Ergodic theory and additive combinatorics","Tamar Ziegler","THE HEBREW UNIVERSITY OF JERUSALEM","The last decade has witnessed a new spring for dynamical systems. The field - initiated by Poincare in the study of the N-body problem - has become essential in the understanding of seemingly far off fields such as combinatorics, number theory and theoretical computer science. In particular, ideas from ergodic theory played an important role in the resolution of long standing open problems in combinatorics and number theory. A striking example is the role of dynamics on nilmanifolds in the recent proof of Hardy-Littlewood estimates for the number of solutions to systems of linear equations of finite complexity in the prime numbers. The interplay between ergodic theory, number theory and additive combinatorics has proved very fruitful; it is a fast growing area in mathematics attracting many young researchers. We propose to tackle central open problems in the area.","1342500","2016-05-01","2021-04-30"
"EspLORE","Extending the science perspectives of linear wires of carbon atoms from fundamental research to emerging materials","Carlo Spartaco CASARI","POLITECNICO DI MILANO","EspLORE aims at addressing the potential of carbon-atom wires for developing novel functional coatings in an application-oriented approach. Carbon-atom wires, based on sp-hybridization, are the ultimate 1-dimensional carbon nanostructure (1-atom diameter) with functional properties strongly dependent on the wire length and termination. The design and control of the wire structure opens the way to build materials with tunable properties, which is at present a largely unexplored topic. The core concept of EspLORE is to exploit the present fundamental knowledge of carbon-atom wires as isolated molecules/nanostructures to explore the applied science and engineering of new materials in the form of thin film assemblies and nanocomposites, so to fill the large existing gap between basic science and engineering. To this aim the main challenging goals are: 
1) the controlled synthesis of wires; 
2) the development of strategies to assemble wires in thin films and nanocomposites; 
3) the exploration of potential use of wire-based materials in direct energy conversion devices (e.g. photovoltaics, water splitting, fuel cells).
The proposed methodology includes fabrication of wires by physical methods, their deposition/assembling on surfaces, and the experimental study of structural, electronic and optical properties. Structure-property relationship is investigated at a multiscale level, moving from the single wire level (atomic scale) to multi-wire interactions (nanoscale) and up to extended systems (macroscale). 
The outcomes of the project will put the foundations for the materials engineering of wire-based systems and their realistic implementation in advanced technological applications. These materials, able to provide complementary properties to graphene, will synergistically contribute to open new perspectives for an innovative ‘all-carbon’ approach to present and future challenges in many fields of engineering and technology.","1981875","2017-05-01","2022-04-30"
"ESTUARIES","Estuaries shaped by biomorphodynamics, inherited landscape conditions and human interference","Maarten Gabriel Kleinhans","UNIVERSITEIT UTRECHT","ESTUARIES are shallow coastal water bodies with river inflow shaped by biomorphological processes, with patterns of channels and shoals, sand/mud flats, tidal marshes, vegetated banks and peat. Development was influenced by early Holocene landscape that drowned under sealevel rise, and by human interference. 
Estuaries harbour highly productive natural habitats and are of pivotal economic importance for food production, access to harbours and urban safety. Accelerating sealevel rise, changing river discharge and interference threaten these functions, but we lack fundamental understanding and models to predict combined effects of biomorphological interactions, inherited landscape and changing drivers.
We do not understand to what extent present estuary planform shape and shoal patterns resulted from biomorphological processes interacting with inherited conditions and interference. Ecology suggests dominant effects of flow-resisting and sediment de/stabilising eco-engineering species. Yet abiotic physics-based models reproduce channel-shoal patterns surprisingly well, but must assume a fixed planform estuary shape. Holocene reconstructions emphasise inherited landscape- and agricultural effects on this planform shape, yet fossil shells and peat also imply eco-engineering effects.
My aims are to develop models for large-scale planform shape and size of sandy estuaries and predict past and future, large-scale effects of biomorphological interactions and inherited conditions.
We will significantly advance our understanding by our state-of-the-art eco-morphological model, my unique analogue landscape models with eco-engineers and a new, automated paleogeographic reconstruction of 10 data-rich Holocene estuaries on the south-east North Sea coast. We will systematically compare these to modelled scenarios with biomorphological processes, historic interference and inherited valley geometry and substrate. Outcomes will benefit ecology, archeology, oceanography and engineering","2000000","2015-12-01","2020-11-30"
"ESTYMA","Excited state quantum dynamics in molecular aggregates: a unified description from biology to devices","Alessandro Troisi","THE UNIVERSITY OF LIVERPOOL","The coherent dynamics of excitons in systems of biological interest and in organic materials can now be studied with advanced experimental techniques, including two dimensional electronic spectroscopy, with time resolution of few femtoseconds. The theory of open quantum systems, that should support the interpretation of these new experiments, has been developed in different contexts over the past 60 years but seems now very inadequate for the problems of current interest.  First of all, the systems under investigation are extremely complex and the most common approach, based on the development of phenomenological models, is often not very informative.  Many different models yield results in agreement with the experiments and there is no systematic way to derive these models or to select the best model among many.  Secondly, the quantum dynamics of excitons is so fast that one cannot assume that the dynamics of environment is much faster than the dynamics of the system, an assumption crucial for most theories.  A remedy to the current limitation is proposed here through the following research objectives.
(1) A general and automatic protocol will be developed to generate simple treatable models of the system from an accurate atomistic description of the same system based on computational chemistry methods.
(2) A professionally-written software will be developed to study the quantum dynamics of model Hamiltonians for excitons in molecular aggregates. This software will incorporate different methodologies and will be designed to be usable also by non-specialists in the theory of quantum open systems (e.g. spectroscopists, computational chemists).
(3) A broad number of problems will be studied with this methodology including (i) exciton dynamics in light harvesting complexes and artificial proteins and (ii) exciton dynamics in molecular aggregates of relevance for organic electronics devices.","1512873","2014-04-01","2019-03-31"
"ETASECS","Extremely Thin Absorbers for Solar Energy Conversion and Storage","Avner Rothschild","TECHNION - ISRAEL INSTITUTE OF TECHNOLOGY","ETASECS aims at making a breakthrough in the development of photoelectrochemical (PEC) cells for solar-powered water splitting that can be readily integrated with PV cells to provide storage capacity in the form of hydrogen. It builds upon our recent invention for resonant light trapping in ultrathin films of iron oxide (a-Fe2O3), which enables overcoming the deleterious trade-off between light absorption and charge carrier collection efficiency. Although we recently broke the water photo-oxidation record by any a-Fe2O3 photoanode reported to date, the losses are still high and there is plenty of room for further improvements that will lead to a remakable enhancement in the performance of our photoanodes, reaching quantum efficiency level similar to state-of-the-art PV cells. ETASECS aims at reaching this ambitious goal, which is essential for demonstrating the competitiveness of PEC+PV tandem systems for solar energy conversion and storage. Towards this end WP1 will combine theory, modelling and simulations, state-of-the-art experimental methods and advanced diagnostic techniques in order to identify and quantify the different losses in our devices. This work will guide the optimization work in WP2 that will suppress the losses at the photoanode and insure optimal electrical and optical coupling of the PEC and PV cells. We will also explore advanced photon management schemes that will go beyond our current light trapping scheme by combining synergic optical and nanophotonics effects. WP3 will integrate the PEC and PV cells and test their properties and performance. WP4 will disseminate our progress and achievements in professional and public forums. The innovations that will emerge from this frontier research will be further pursued in proof of concept follow up investigations that will demonstrate the feasibility of this technology. Success along these lines holds exciting promises for ground breaking progress towards large scale deployment of solar energy.","2150000","2014-09-01","2019-08-31"
"Euler systems","Euler systems and the Birch--Swinnerton-Dyer conjecture","Sarah Zerbes","UNIVERSITY COLLEGE LONDON","The Birch--Swinnerton-Dyer conjecture, one of the Millennium Prize Problems, is one of the central unsolved problems in mathematics. It predicts a relation between the arithmetic of an elliptic curve and the properties of the L-function of the elliptic curve. Some special cases of the conjecture were proven by Kolyvagin; the main ingredient in his proof is an algebraic construction called an Euler system. Even though Euler systems are extremely powerful tools, so far only five examples are known to exist. I propose to construct several new examples of Euler systems, in order to prove new cases of the Birch--Swinnerton-Dyer conjecture. In particular, I believe the following theorem to be within reach:

Let A be either a modular elliptic curve over a (real or imaginary) quadratic number field, or a modular abelian surface over the rational numbers. If the L-value L(A, 1) is non-zero, then the Mordell--Weil group of A is finite (i.e. the Birch--Swinnerton-Dyer conjecture holds for A).","1070473","2015-07-01","2020-06-30"
"EvoStruc","The physics of antibiotic resistance evolution in spatially-structured multicellular assemblies","Rosalind Allen","THE UNIVERSITY OF EDINBURGH","The rise in bacterial infections that are resistant to antibiotic treatment poses a major global health challenge. Addressing this challenge is not just a clinical issue: understanding bacterial resistance evolution calls for an interdisciplinary approach, in which the development of new physics, in coordination with biology, chemistry and engineering, has a central role to play. In particular, statistical physics, to predict the stochastic emergence of drug-resistant mutants, must be integrated with soft matter and chemical physics, to understand the spatial organization of the bacterial populations within which this happens.

Bacterial infections are very often spatially heterogeneous. This is known to influence the outcome of antibiotic treatment – for example bacterial biofilms, which form on the surfaces of medical implants, are notoriously hard to remove. However, much less attention has been paid to the role of spatial structure in the evolution of drug resistance, i.e. the emergence and spread of genetically drug-resistant bacterial strains. 

I will lead a research programme which will for the first time uncover the two-way link between the emergence of spatial structure in bacterial multicellular assemblies and the evolution of drug resistance. The programme builds on my current theoretical, simulation and experimental work. I will first determine the basic principles of evolution in drug gradients using theoretical models, combined with experiments in a controlled, 1D geometry. I will then explore how these principles translate to the more realistic scenario of bacterial biofilms, where spatial structure and drug gradients are emergent properties, using advanced computer simulation methods and both confocal microscopy and evolution experiments. In the final part of the programme, I will use these insights to reveal optimization principles for the design of evolution-resistant surface coatings for applications in medical devices.","1826984","2016-06-01","2022-05-31"
"EXCITERS","Extreme Ultraviolet Circular Time-Resolved Spectroscopy","Yann Mairesse","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Chiral molecules exist as two forms, so-called enantiomers, which have essentially the same physical and chemical properties and can only be distinguished via their interaction with a chiral system, such as circularly polarized light. Many biological processes are chiral-sensitive and unraveling the dynamical aspects of chirality is of prime importance for chemistry, biology and pharmacology. Studying the ultrafast electron dynamics of chiral processes requires characterization techniques at the attosecond (10−18 s) time-scale.
Molecular attosecond spectroscopy has the potential to resolve the couplings between electronic and nuclear degrees of freedom in such chiral chemical processes. There are, however, two major challenges: the generation of chiral attosecond light pulse, and the development of highly sensitive chiral discrimination techniques for time-resolved spectroscopy in the gas phase.
This ERC research project aims at developing vectorial attosecond spectroscopy using elliptical strong fields and circular attosecond pulses, and to apply it for the investigation of chiral molecules. To achieve this, I will (1) establish a new type of highly sensitive chiroptical spectroscopy using high-order harmonic generation by elliptical laser fields; (2) create and characterize sources of circular attosecond pulses; (3) use trains of circularly polarized attosecond pulses to probe the dynamics of photoionization of chiral molecules and (4) deploy ultrafast dynamical measurements to address the link between nuclear geometry and electronic chirality.
The developments from this project will set a landmark in the field of chiral recognition. They will also completely change the way ellipticity is considered in attosecond science and have an impact far beyond the study of chiral compounds, opening new perspectives for the resolution of the fastest dynamics occurring in polyatomic molecules and solid state physics.","1691865","2016-09-01","2021-08-31"
"EXMAG","Excitonic Magnetism in Strongly Correlated Materials","Jan Kunes","TECHNISCHE UNIVERSITAET WIEN","Spontaneous symmetry breaking leading to states of matter with long-range order is one of the central topics in condensed matter physics. Common types of order, such as ferro- and anti-ferromagnetic, are characterized by spin or charge densities modulated on inter-atomic scale, therefore well studied thanks to various scattering experiments. Order parameters that are not of this type are much more difficult to detect, giving rise to names such as hidden order or electronic nematicity. Their impact on transport or thermodynamic properties may, nevertheless, be substantial. In the EXMAG project we will investigate excitonic condensation in systems with strongly correlated electrons as a new mechanism leading to unconventional ordered states. The objective of the project is to characterize the physical properties of various excitonic phases and to find their realization in real materials. We will focus on intermediate coupling strength and doped systems where the interaction between the excitonic order and the charge carriers is expected to lead to new physics. In particular, we want to explore the potential of the excitonic order to induce instabilities, e.g. magnetic or superconducting, that are not present in the normal phase. We will also address the possibility of topologically non-trivial quasi-particle band-structures in the excitonic phase. Our main tool will be numerical simulations based on the dynamical mean-field theory and ab initio band-structure methods. We will pursue two main lines of research: investigation of simple models allowing access to many physical observables and studies of real materials capturing the chemical complexities at the cost of more severe approximations. Ultimately, we want to understand in detail the properties of the excitonic magnets and their potential functionalities,and to identify the main control parameters and promising materials.","1382500","2015-06-01","2020-05-31"
"EXOKLEIN","The Climates and Habitability of Small Exoplanets Around Red Stars","Kevin HENG","UNIVERSITAET BERN","The detection of life beyond our Solar System is possible only via the remote sensing of the atmospheres of exoplanets.  The recent discovery that small exoplanets are common around cool, red stars offers an exciting opportunity to study the atmospheres of Earth-like worlds.  Motivated by this revelation, the EXOKLEIN project proposes to construct a holistic climate framework to understand astronomical observations in the context of the atmosphere, geochemistry and biosignatures of the exoplanet.  The proposed research is divided into three major themes.  Research Theme 1 aims to construct a virtual laboratory of an atmosphere that considers atmospheric dynamics, chemistry and radiation, as well as how they interact.  This virtual laboratory enables us to understand the physical and chemical mechanisms involved, as well as predict the observed properties of an exoplanet.  Research Theme 2 aims to generalize the carbonate-silicate cycle (also known as the long-term carbon cycle) by considering variations in rock composition, water acidity and atmospheric conditions.  The carbonate-silicate cycle is important because it regulates the long-term presence of carbon dioxide (a vital greenhouse gas) in atmospheres.  We also aim to investigate the role of the cycle in determining the fates of ocean-dominated exoplanets called “water worlds”.  Research Theme 3 aims to investigate the long-term stability of biosignature gases in the context of the climate.  Whether a gas uniquely indicates the presence of biology on an exoplanet depends on the atmospheric properties and ultraviolet radiation environment.  We investigate three prime candidates for biosignature gases: methyl chloride, dimethylsulfide and ammonia.  Overall, the EXOKLEIN project will significantly advance our understanding of whether the environments of rocky exoplanets around red stars are stable and conducive for life, and whether the tell-tale signatures of life may be detected by astronomers.","1984729","2018-02-01","2023-01-31"
"ExoLights","Decoding Lights from Exotic Worlds","Giovanna Tinetti","UNIVERSITY COLLEGE LONDON","It is now accepted that exoplanets are ubiquitous. However little is known about those planets we have detected beyond the fact they exist and their location. For a minority, we know their weight, size and orbital parameters. For less than twenty, we have some clues about their atmospheric temperature and composition. How do we progress from here?
We are still far from a hypothetical Hertzsprung–Russell diagram for planets and we do not even know whether there ever will be such classification for planets. The planetary parameters mass, radius and temperature alone do not explain the diversity revealed by current observations. The chemical composition of these planets is needed to trace back their formation history and evolution, as was the case for the Solar System.
Pioneering results were obtained through transit spectroscopy with Hubble, Spitzer and ground-based facilities, enabling the detection of ionic, atomic and molecular species and of the planet’s thermal structure. With the arrival of improved or dedicated instruments in the coming decade, planetary science will expand beyond the narrow boundaries of our Solar System to encompass our whole Galaxy.
In the next five years, ExoLights will address the following fundamental questions:
– Why are exoplanets as they are?
– What are the causes for the observed diversity?
– Can their formation history be traced back from their current composition and evolution?
New spectroscopic observations of a select sample of exoplanets’ atmospheres (~ 20 out of the 150 observable today) will be analysed with state-of-the art statistical techniques and interpreted through a comprehensive set of spectral retrieval models, developed by the PI and her team. This programme, together with the homogeneous re-analysis of archive observations of a larger sample of exoplanets, will allow us to use the chemical composition as a powerful diagnostic of the history, formation mechanisms and evolution of gaseous and rocky exoplanets.","2080502","2014-05-01","2019-04-30"
"EXONMR","""Exploiting 17O NMR Spectroscopy: Atomic-Scale Structure, Disorder and Dynamics in Solids""","Sharon Elizabeth Marie Ashbrook","THE UNIVERSITY COURT OF THE UNIVERSITY OF ST ANDREWS","""The fundamental importance of oxide-based systems in technology, energy materials, geochemistry and catalysis, and the presence of oxygen in many biomaterials, should have resulted in oxygen nuclear magnetic resonance (NMR) spectroscopy emerging as a vital tool for materials characterization. NMR offers an element-specific, atomic-scale probe of the local environment, providing a potentially powerful probe of local structure, disorder and dynamics in solids. However, despite the almost ubiquitous presence of oxygen in inorganic solids, oxygen NMR studies have been relatively scarce in comparison to other nuclei, owing primarily to the low natural abundance of the  NMR-active isotope, 17O (0.037%). Hence, isotopic enrichment is necessary, often at considerable cost and effort. Furthermore, the presence of anisotropic quadrupolar broadening (and the need for complex high-resolution experiments) has also limited the development and application of 17O NMR to date. Here, we propose to develop an internationally-leading research programme to exploit the largely untapped potential of 17O spectroscopy. This wide-ranging programme will involve (i) the exploration of novel synthetic approaches for cost-efficient isotopic enrichment, (ii) the development of new solid-state NMR methodology, specific for 17O, (iii) the application of state-of-the-art first-principles calculations of 17O NMR parameters and (iv) the application of these methods to three different areas of investigation: high-pressure silicate minerals, microporous materials and ceramics for waste encapsulation. The ultimate long-term aim is to change the way in which solid-state chemists characterise materials; so that solid-state NMR (and 17O NMR in particular) is viewed as a necessary and important step in the refinement of a detailed structural model.""","1902188","2014-04-01","2019-03-31"
"EXPLORINGMATTER","Exploring Matter with Precision Charm and Beauty Production Measurements in Heavy Nuclei Collisions at LHCb","Giulia Manca","UNIVERSITA DEGLI STUDI DI CAGLIARI","Collisions of ultra relativistic nuclei are a tool to reach huge energy densities and to form a new state of matter called Quark-Gluon Plasma (QGP), where quarks and gluons can move freely. A number of experiments have studied the possible formation of QGP, but the behaviour of heavy particles such as charm (c) and beauty (b) quarks when they traverse this medium is largely unknown and is the most powerful tool to prove the creation of the QGP and to characterise it. I will perform novel measurements using the LHCb detector at CERN, which covers an unique kinematic region, essential for a full understanding of QGP and nuclear matter in general. LHCb has been optimised to perform c and b quark physics measurements in proton-proton collisions. In EXPLORINGMATTER I propose to extend the LHCb programme to collect for the first time data in heavy ion collisions. Three experimental scenarios are foreseen: (1) Collisions of protons, benchmark to understand the behaviour of the c and b particles in other more complicated environments, as well as providing the final answers to the mechanism of heavy quarkonium production; (2) Collisions of protons with heavy nuclei, where cold nuclear matter effects in high-energy collisions can be studied in detail to understand lead nuclei collisions, where QGP is expected to be formed. (3) Collisions of heavy nuclei, pursued (a) by analysing heavy nuclei interactions through a dedicated setup in which gas will be injected in the LHCb interaction region, reaching energy densities typical of dedicated fixed target experiments; (b) by collecting heavy ion collision data at the LHC. This second setup, which has not been envisaged by LHCb up to now will revolutionise the measurements in this area thanks to the LHCb coverage and precision not achievable by any other experiment. My measurements will furthermore indicate the route to new experiments that could be designed on the basis of these findings.","1849957","2015-04-01","2020-03-31"
"EXQUISITE","External Quantum Control of Photonic Semiconductor Nanostructures","Stephan Erich Reitzenstein","TECHNISCHE UNIVERSITAT BERLIN","In this project, we will control photonic nanostructures by external feedback, optical injection and synchronization. This will allow us to study nonlinear dynamics in quantum systems and to externally manipulate and stabilize light-matter interaction in the regime of quantum electrodynamics (cQED). We will experimentally and theoretically address a) optical injection and feedback control of quantum dot (QD)–microlasers, b) quantum control cQED systems via delayed single photon feedback, and c) mutually coupled and synchronized chaotic microcavity systems. In a) we will advance the concepts of time-delayed coupling in standard semiconductor laser diodes to few photon states, where quantum fluctuations contribute to or even dominate over the usual classical dynamics. Feedback-coupling in microlasers will allow us to explore the limits of a classical description of chaotic laser dynamics via the Lang-Kobayashi rate equations and to develop an advanced model taking cQED- and QD-specific effects into account. This subject will be complemented by the study of optical injection of coherent light and non-classical light into microlasers to influence and study mode-locking, chaos and stimulated emission down to the quantum level. Single photon feedback in b) will be applied to stabilize coherent coupling of light and matter and to act against decoherence which constitutes a major bottleneck for application of semiconductor nanostructures in quantum information technology. In c) the mutual coupling of microlasers will be used to study synchronization of chaotic quantum devices at the single photon limit and to explore the underlying physics of isochronal synchronization. Our work will have important impact at an interdisciplinary level on the development of nonlinear dynamical systems towards the quantum limit and the understanding of fundamental light-matter interaction in the presence of time delayed single photon feedback.","1999800","2014-04-01","2019-03-31"
"EXSEED","Extreme-Light Seeded Control of Ultrafast Laser Material Modifications","David GROJO","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","High-peak power compact femtosecond lasers allow strong-field interactions that are the basis for high-precision laser micro-fabrication. They also create extreme conditions within the matter, leading to the generation of rainbow light used to produce even shorter pulses and new frequencies that can extend from the X-ray to the TeraHertz domain. However, due to the low conversion efficiencies, these attractive light pulses remain unexploited in the context of laser nano-/micro-fabrication.
The main objective of this project is to exceed the intrinsic limits of ultrafast laser material processing by developing novel seeded-control technologies with extreme light pulses. In the proposed concept, seed free carriers are injected into materials from extreme light and then avalanched with perfectly synchronized infrared pulses to extract all potential benefits from modest energy new types of radiation.
The project includes the study of interactions seeded with deep-ultraviolet, few-optical-cycle and mid-infrared ultrashort pulses. The expected nonlinear processes with these radiations open new and exciting opportunities to tailor material properties with nanometer-scale spatial resolutions and in the three dimensions (3D) for materials inside which the occurrence of breakdown is, today, inaccessible (e.g. semiconductors). This will lead to the first demonstrations of rapid 3D prototyping by laser of silicon photonics microdevices.
A long term objective is to open the door to the use of the most extreme ultrashort laser-induced radiations, including extreme-ultraviolet attosecond pulses that hold promises to reach the highest degree of control in the time and space of the interactions.
These and other ideas require investigations on ionization physics by ultrashort pulses at extreme wavelengths. They also require tight control of the ultrafast pulses, broadband manipulations and novel interaction diagnostics technologies that will be developed as parts of the project.","1833406","2017-05-01","2022-04-30"
"EXTREME","EXtreme Tectonics and Rapid Erosion in Mountain Environments","Todd Alan Ehlers","EBERHARD KARLS UNIVERSITAET TUEBINGEN","""Tectonic plate corners are hotspots for high rates of continental deformation and erosion, and associated with human-relevant hazards including poorly understood earthquakes, destructive landslides, and extreme climate. A better understanding of continental deformation can mitigate these hazards. However, the coupling between climate and tectonic interactions at plate corners is a key unknown and the focus of this study. My recent work, published in international journals including Science and Nature, quantifies mountain building and climate change and provides a baseline for an innovative study of plate corner dynamics.
This proposal challenges the geoscience ‘tectonic aneurysm’ paradigm that rapid deformation and erosion at plate corners is initiated from the “top down” by localized precipitation, and erosion. Rather, I hypothesize that these processes are: 1) initiated from the “bottom up” by the 3D geometry of the subducting plate; and 2) require a threshold rate of both “bottom up” deformation and surface erosion to initiate a feedback between climate and tectonics.
I propose, for the first time, a holistic modeling and data collection approach that quantifies the temporal and spatial evolution of all aspects of plate corner evolution, including: 3D thermomechanical modeling of plate corner deformation and uplift for different plate geometries; Atmospheric modeling to quantify the climate response to evolving topography, a topic spearheaded by my research group; And surface process modeling to close the loop and couple the atmospheric and mechanical models. Model predictions will be vetted against observed deformation and erosion histories from existing and new cosmogenic isotope and thermochronometer data from end-member locations including the Himalaya, Alaskan, Olympic, and Andean plate corners. EXTREME will produce a globally integrated atmospheric and solid Earth understanding of continental deformation, a task only possible at the scale of an ERC grant.""","1999956","2014-04-01","2019-03-31"
"ExtremeQuantum","Quantum materials under extreme conditions","Paul Andrew Goddard","THE UNIVERSITY OF WARWICK","New states of matter offer an unparalleled testing ground for studying fundamental physics, particularly interacting quantum systems. The EXTREMEQUANTUM project will significantly advance our knowledge of these states by using extreme conditions of magnetic field and pressure to enable a continuous, clean and reversible tuning of quantum interactions, thereby shedding light on the building blocks of exotic magnetism and unconventional superconductivity. By developing the materials and methodology to achieve this, we will push our understanding of quantum systems beyond current limitations and open a route for exploiting the untapped potential of these materials to underpin future technology in fields as diverse as electrical power networks, quantum computation and healthcare.

EXTREMEQUANTUM takes as its starting point recent theoretical and experimental discoveries in the area of quantum materials and will capitalize on a novel measurement technique developed in my research group over the past few years. By utilizing both atomic and molecular substitution, the project will focus on a series of materials that are on the verge of a phase instability. Ultra-high fields and applied pressure will push these systems through the critical region where the state of matter changes and inherently quantum effects dominate. Electronic, magnetic and structural properties will be measured as the tipping point is breached and the resulting data compared with predictions of theoretical models. The results will provide answers to questions of deep concern to modern physics, such how quantum fluctuations, topology and disorder can be used to create states of matter with novel and functional properties.","1840513","2016-09-01","2021-08-31"
"EyeCode","Perceptual encoding of high fidelity light fields","Rafal Konrad MANTIUK","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","One of the grand challenges of computer graphics has been to generate images indistinguishable from photographs for a naïve observer. As this challenge is mostly completed and computer generated imagery starts to replace photographs (product catalogues, special effects in cinema), the next grand challenge is to produce imagery that is indistinguishable from the real-world.

Tremendous progress in capture, manipulation and display technologies opens the potential to achieve this new challenge (at the research stage) in the next 5-10 years. Electronic displays offer sufficient resolution, frame rate, dynamic range, colour gamut and, in some configurations, can produce binocular and focal depth cues. However, most of the work done in this area ignores or does not sufficiently address one of the key aspects of this problem - the performance and limitations of the human visual system.

The objective of this project is to characterise and model the performance and limitations of the human visual system when observing complex dynamic 3D scenes. The scene will span a high dynamic range (HDR) of luminance and provide binocular and focal depth cues. In technical terms, the project aims to create a visual model and difference metric for high dynamic range light fields (HDR-LFs). The visual metric will replace tedious subjective testing and provide the first automated method that can optimize encoding and processing of HDR-LF data. 

Perceptually realistic video will impose enormous storage and processing requirements compared to traditional video. The bandwidth of such rich visual content will be the main bottleneck for new imaging and display technologies. Therefore, the final objective of this project is to use the new visual metric to derive an efficient and approximately perceptually uniform encoding of HDR-LFs. Such encoding will radically reduce storage and bandwidth requirements and will pave the way for future highly realistic image and video content.","1868855","2017-07-01","2022-06-30"
"F-BioIce","Fundamentals of Biological Ice Nucleation","Tobias WEIDNER","AARHUS UNIVERSITET","Ice active bacteria can promote the growth of ice more effectively than any other material known. Using specialized ice nucleating proteins (INPs), they attack plants by frost damage and, when airborne in the atmosphere, they drive ice nucleation within clouds and control global precipitation patterns. The control INPs exert over water phase transitions has relevance for disciplines as diverse as climatology, plant pathology, biomedicine and material science. Despite the apparent importance, the molecular mechanisms behind INP freezing have remained largely elusive. This lack of our knowledge can be traced back to the challenges in studying protein and water structure and dynamics at the very interface between monolayers of proteins and water.
With F-BioIce my team and I want to reveal the molecular details of INP function. We ask the questions: What is the structural basis for protein control of freezing? What structural motifs do proteins use to interact with water, and what is the configuration of water molecules that INPs imprint into interfacial water layers? What is the role of structural dynamics and for surface freezing? We will develop new methods based on sum frequency generation (SFG) spectroscopy to determine mode of action by which INPs interact with and manipulate water. The INPs and water structure will be obtained by combining three rising methods in the field: SFG techniques that I have been spearheading, computer simulations and cryo-electron microscopy. We will study model water surfaces and, for the first time, realistic water aerosols interacting with INPs. These new strategies could lead to a paradigm shift in the entire field of ice nucleation and a search for similar processes in ice active fungi and pollen and abiotic ice nucleators – feldspar, silica and soot. The obtained information will provide critical input for climate models and revolutionary new freezing technologies for food preservation, cryomedicine and cloud seeding.","1999936","2019-04-01","2024-03-31"
"F-ELEMENT_ARCHITECT","Building Precise Molecular Architectures to Unlock Remarkable f-Element Properties","David MILLS","THE UNIVERSITY OF MANCHESTER","The astonishing properties of the f-elements have been exploited in numerous consumer technologies, despite their fundamental chemistry being poorly developed. It is now crucial to address this issue to provide the necessary insights to develop future applications. Design criteria exist to build f-element complexes with maximised physical attributes. This adventurous proposal targets the synthesis and thorough analysis of two complementary molecular f-element architectures that 1) optimise magnetic properties and 2) stabilise unusual oxidation states.

In Part 1, we target highly axial f-element complexes that lack equatorial ligand interactions. These molecules can exhibit maximised single-molecule magnet properties, including magnetic hysteresis, a memory effect and as a prerequisite of data storage, at liquid nitrogen temperatures. This is the necessary first step towards achieving high-density molecular data storage without expensive liquid helium cooling and future commercial applications.

In Part 2, we target trigonal f-element complexes that lack axial ligand interactions. These are optimal ligand fields for the stabilisation of low oxidation states, thus we aim for rare lanthanide/actinide(II) and unprecedented lanthanide/actinide(I) complexes. These compounds are ideal candidates for unique measurements of covalency by pulsed electron paramagnetic resonance spectroscopy, which will provide textbook data that can be transferable to nuclear fuel cycles.

An ERC CoG will provide the necessary resources to build a world-leading research team that will deliver landmark synthetic results and fresh insights into f-element electronic structure, whilst opening up new chemical space for future exploitation. These findings will underpin current technologies and will facilitate the discovery of future applications, supporting key Horizon 2020 priority areas including the Flagship on Quantum Technologies, and enhancing the scientific reputation and economy of the EU.","1990801","2019-09-01","2024-08-31"
"FACTORY","New paradigms for latent factor estimation","Cédric Févotte","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Data is often available in matrix form, in which columns are samples, and processing of such data often entails finding an approximate factorisation of the matrix in two factors. The first factor yields recurring patterns characteristic of the data. The second factor describes in which proportions each data sample is made of these patterns. Latent factor estimation (LFE) is the problem of finding such a factorisation, usually under given constraints. LFE appears under other domain-specific names such as dictionary learning, low-rank approximation, factor analysis or latent semantic analysis. It is used for tasks such as dimensionality reduction, unmixing, soft clustering, coding or matrix completion in very diverse fields.

In this project, I propose to explore three new paradigms that push the frontiers of traditional LFE. First, I want to break beyond the ubiquitous Gaussian assumption, a practical choice that too rarely complies with the nature and geometry of the data. Estimation in non-Gaussian models is more difficult, but recent work in audio and text processing has shown that it pays off in practice. Second, in traditional settings the data matrix is often a collection of features computed from raw data. These features are computed with generic off-the-shelf transforms that loosely preprocess the data, setting a limit to performance. I propose a new paradigm in which an optimal low-rank inducing transform is learnt together with the factors in a single step. Thirdly, I show that the dominant deterministic approach to LFE should be reconsidered and I propose a novel statistical estimation paradigm, based on the marginal likelihood, with enhanced capabilities. The new methodology is applied to real-world problems with societal impact in audio signal processing (speech enhancement, music remastering), remote sensing (Earth observation, cosmic object discovery) and data mining (multimodal information retrieval, user recommendation).","1931776","2016-09-01","2021-08-31"
"FADAMS","Foundations of Factorized Data Management Systems","Dan Olteanu","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","The objective of this project is to investigate scalability questions arising with a new wave of smart relational data management systems that integrate analytics and query processing. These questions will be addressed by a fundamental shift from centralized processing on tabular data representation, as supported by traditional systems and analytics software packages, to distributed and approximate processing on factorized data representation.

Factorized representations exploit algebraic properties of relational algebra and the structure of queries and analytics to achieve radically better data compression than generic compression schemes, while at the same time allowing processing in the compressed domain. They can effectively boost the performance of relational processing by avoiding redundant computation in the one-server setting, yet they can also be naturally exploited for approximate and distributed processing. Large relations can be approximated by their subsets and supersets, i.e., lower and upper bounds, that factorize much better than the relations themselves. Factorizing relations, which represent intermediate results shuffled between servers in distributed processing, can effectively reduce the communication cost and improve the latency of the system.

The key deliverables will be novel algorithms that combine distribution, approximation, and factorization for computing mixed loads of queries and predictive and descriptive analytics on large-scale data. This research will result in fundamental theoretical contributions, such as complexity results for large-scale processing and tractable algorithms, and also in a scalable factorized data management system that will exploit these theoretical insights. We will collaborate with industrial partners, who are committed to assist in providing datasets and realistic workloads, infrastructure for large-scale distributed systems, and support for transferring the products of the research to industrial users.","1980966","2016-06-01","2021-05-31"
"FanCY","Flow and Deformation of Cancer tumours near Yielding","Pouyan BOUKANY","TECHNISCHE UNIVERSITEIT DELFT","The aim of this proposal is to understand when, how and why metastatic tumour cells detach from a tumour. 

Often, primary tumours do not kill patients, but secondary tumours do. These so-called metastatic tumour cells disassociate from a primary tumour and, ultimately, prove fatal. Currently, we do not understand the fundamentals of the biophysical pathways and mechanisms of the metastasis of cancer, hampering medical intervention. I propose a multidisciplinary approach, combining engineering, chemistry, biophysics and cell biology to identify the mechanical pathways for the creation of metastatic cancer cells.

Biological cells in tissue are very densely packed, which locks them in place relative to their neighbours, a state referred to as jammed. The collective system of cells can become fluidised locally and flow when pushed or deformed. Even greater forces can make the entire tissue fluid-like, referred to as yielding. The crucial open questions are: how does tissue yield, and what universal physics underlies yielding? 

I will develop a novel fundamental and predictive description of yielding in jammed living tissue to show: 
1. How and when jammed living cells are driven to fluid-like state. 
2. How confinement tunes the migration mode of cancer cells. 
3. How yielding is related to the structural evolution of detached cells.
4. How critical scaling controls deformation and flow of living cells near yielding.

I will demonstrate that the distance to yielding governs the mechanical response in collective cell motion inside a tumour, and that exploiting critical scaling allows predicting the dynamics of cell detachment near yielding. The outcomes will significantly aid the treatment of cancer in the near future by bridging the gap between chemical and mechanical pathways of cancer metastasis. I have the required multidisciplinary track record. Moreover, preliminary experiments show highly promising results.","2000000","2019-04-01","2024-03-31"
"FANOEC","Fundamentals and Applications of Inorganic Oxygen Evolution Catalysts","Xile Hu","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","The oxygen evolution reaction (OER) is the key reaction to enable the storage of solar energy in the form of hydrogen fuel through water splitting. Efficient, Earth-abundant, and robust OER catalysts are required for a large-scale and cost-effective production of solar hydrogen. While OER catalysts based on metal oxides exhibit promising activity and stability, their rational design and developments are challenging due to the heterogeneous nature of the catalysts. Here I propose a project to (i) understand OER on metal oxides at the molecular level and engineer catalytic sites at the atomic scale; (ii) develop and apply practical OER catalysts for high-efficiency water splitting in electrochemical and photoelectrochemical devices. The first general objective will be obtained by using 2-dimensional metal oxide nanosheets as a platform to probe the intrinsic activity and active sites of metal oxide OER catalysts, as well as by developing sub-nanocluster and single-atom metal oxide OER catalysis. The second general objective will be obtained by establishing new and better synthetic methods, developing new classes of catalysts, and applying catalysts in innovative water splitting devices. 
The project employs methodologies from many different disciplines in chemistry and materials science. Synthesis is the starting point and the backbone of the project, and the synthetic efforts are complemented and valorised by state-of-the-art characterization and catalytic tests. The project will not only yield significant fundamental insights and knowledge in heterogeneous OER catalysis, but also produce functional and economically viable catalysts for solar fuel production.","2199983","2016-07-01","2021-06-30"
"FastMat","Fast determination of fatigue properties of materials beyond one billion cycles","Nicolas RANC","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Many mechanical structures are submitted to repeated loadings and can break under stress lower than the ultimate tensile stress. This phenomenon is called the fatigue of materials and can be found in many industrial sectors, such as the transport industry, aeronautic industry and energy production. Fatigue design is thus crucial in engineering and it requires the precise characterization of material behavior under cyclic loadings to ensure the safety and reliability of structures throughout their life. An increase in the life span of a structure or a reduction in the number of maintenance phases leads to an increases in the number of cycles applied to this structure. It is presently common to find mechanical systems subjected to several billion cycles, in what is called the gigacycle fatigue domain. The characterization of the fatigue behavior of materials requires fatigue tests to be conducted until fracture for different stress amplitudes. One problem with this method is the test duration, which becomes excessive and beyond possible, particularly for a very high number of cycles. The goal of FastMat is to develop a new method that reduces considerably the duration of fatigue characterization. This method involves the use of only short interrupted tests coupled with a self-heating measurement to characterize the fatigue behavior for very low stress amplitudes. The scientific objective is to develop simultaneously experimental and numerical tools for the fast determination of fatigue behavior. The experimental approach will be developed to estimate simultaneously the dissipation and the stored energy, which directly reflect fatigue damage. For the numerical approach, discrete dislocation dynamics simulations will be developed to establish links between the fatigue damage associated with the evolution of dislocation structures, the stored energy and the dissipated energy.","1860963","2017-07-01","2022-06-30"
"FaultScan","Passive seismic scanning of the preparation phase of damaging earthquakes","Florent BRENGUIER","UNIVERSITE GRENOBLE ALPES","The recent September 2017, magnitude 7.1, central Mexico earthquake that caused 370 casualties reminds us that earthquakes are among the most dramatic natural disasters worldwide. Causal physical processes are not instantaneous and laboratory and numerical experiments predict that earthquakes should be preceded by a detectable slow preparation phase. Despite considerable efforts, however, robust geophysical precursors have not yet been observed before damaging earthquakes. 
My FaultScan project will revolutionize our ability to directly observe transient deformation within the core of active faults and provide unprecedented accuracy in the detection of earthquake precursors. My ambition is to develop a new, noise-based, high resolution, seismic monitoring approach. I intend to grasp the opportunity of a recent step change in seismic instrumentation and data processing capabilities to achieve a dream for seismologists: reproduce repeatable, daily, virtual seismic sources that can probe the core of active faults at seismogenic depths using only passive seismic records. 
I plan to target the San Jacinto Fault (a branch of the San Andreas Fault system) that is currently believed to pose one of the largest seismic risks in California. It is an ideal fault for this project because it is very active, already extensively studied and easily accessible for the pilot field data acquisition work.
This project is in collaboration with the Univ. of South. California, the Univ. of Cal. San Diego and specialists in earthquake mechanics and will include earthquake preparation processes and seismic modeling that will guide us for our long-term (3 years), breakthrough, passive seismic experiment and further data analysis and interpretation.
I strongly believe that this project has a very high potential for providing fundamental results on the physics of earthquakes and faults and that it will have a major impact on earthquake prediction worldwide in the near future.","2524630","2019-06-01","2024-05-31"
"Feel your Reach","Non-invasive decoding of cortical patterns induced by goal directed movement intentions and artificial sensory feedback in humans","Gernot Rudolf Mueller-Putz","TECHNISCHE UNIVERSITAET GRAZ","In Europe estimated 300.000 people are suffering from a spinal cord injury (SCI) with 11.000 new injuries per year. The consequences of spinal cord injury are tremendous for these individuals. The loss of motor functions especially of the arm and grasping function – 40% are tetraplegics – leads to a life-long dependency on care givers and therefore to a dramatic decrease in quality of life in these often young individuals. With the help of neuroprostheses, grasp and elbow function can be substantially improved. However, remaining body movements often do not provide enough degrees of freedom to control the neuroprosthesis.
The ideal solution for voluntary control of an upper extremity neuroprosthesis would be to directly record motor commands from the corresponding cortical areas and convert them into control signals. This would realize a technical bypass around the interrupted nerve fiber tracts in the spinal cord.
A Brain-Computer Interface (BCI) transform mentally induced changes of brain signals into control signals and serve as an alternative human-machine interface. We showed first results in EEG-based control of a neuroprosthesis in several persons with SCI in the last decade, however, the control is still unnatural and cumbersome. 
The objective of FEEL YOUR REACH is to develop a novel control framework that incorporates goal directed movement intention, movement decoding, error processing, processing of sensory feedback to allow a more natural control of a neuroprosthesis. To achieve this aim a goal directed movement decoder will be realized, and continuous error potential decoding will be included. Both will be finally joined together with an artificial kinesthetic sensory feedback display attached to the user. We hypothesize that with these mechanisms a user will be able to naturally control an neuroprosthesis with his/ her mind only.","1994161","2016-05-01","2021-04-30"
"FeMiT","Ferrites-by-design for Millimeter-wave and Terahertz Technologies","Martí GICH","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Robust disruptive materials will be essential for the “wireless everywhere” to become a reality.  This is because we need a paradigm shift in mobile communications to meet the challenges of such an ambitious evolution. In particular, some of these emerging technologies will trigger the replacement of the magnetic microwave ferrites in use today. This will namely occur with the forecasted shift to high frequency mm-wave and THz bands and in novel antennas that can simultaneously transmit and receive data on the same frequency. In both cases, operating with state-of-the-art ferrites would require large external magnetic fields incompatible with future needs of smaller, power-efficient devices. 
To overcome these issues, we target ferrites featuring the so far unmet combinations of low magnetic loss and large values of magnetocrystalline anisotropy, magnetostriction or magnetoelectric coupling.  
The objective of FeMiT is developing a novel family of orthorhombic ferrites based on ε-Fe2O3, a room-temperature multiferroic with large magnetocrystalline anisotropy. Those properties and unique structural features make it an excellent platform to develop the sought-after functional materials for future compact and energy-efficient wireless devices. 
In the first part of FeMiT we will explore the limits and diversity of this new family by exploiting rational chemical substitutions, high pressures and strain engineering. Soft chemistry and physical deposition methods will be both considered at this stage.
The second part of FeMiT entails a characterization of functional properties and selection of the best candidates to be integrated in composite and epitaxial films suitable for application. The expected outcomes will provide proof-of-concept self-biased or voltage-controlled signal-processing devices with low losses in the mm-wave to THz bands, with high potential impact in the development of future wireless technologies.","1989967","2019-05-01","2024-04-30"
"FeREDCOUPLS","FeREDCOUPLS - Reduced Iron Catalysts for Reduction and Coupling Reactions","Axel Jacobi von Wangelin","UNIVERSITAET HAMBURG","The aerobic conditions on our planet enable the accumulation of oxidized matter whereas reduced chemicals are the most valuable energy carriers. Future shortages of energy-rich resources make efficient reductive transformations one of the greatest scientific challenges. To address this societal, economic and environmental demand, we propose new approaches to the design and application of stabilized iron catalysts. Our endeavour exploits the higher reducing power of Fe (vs. noble metals) in challenging reductive transformations and capitalizes on the high sustainability of Fe catalysis over noble metal technologies. 
The use of low-valent Fe catalysts, the realization of new catalytic reactions and their mechanistic understanding will only be possible through the controlled generation and effective stabilization of reduced Fe species and active nanoparticles. Major emphasis will be placed on coordinative ligand/solvent systems which accommodate electron-rich Fe centers (olefins, arenes, Lewis acids, redox-ligands, ionic liquids). We address new approaches to the synthesis of low-valent Fe complexes and bottom-up/top-down preparations of Fe(0) nanoparticles. Catalytic reactions of high relevance to the manufacture of chemicals and materials will be studied (reduction, cross-coupling, hydrogenation, defunctionalization) with special emphasis on cheap abundant substrates. Mechanistic studies aim at understanding Fe-centered reductive bond activations and ligand co-operation. The proposed use of the most abundant transition metal for challenging reductive processes under practical conditions extends beyond the realm of synthesis, catalysis, and materials into spectroscopy, solvent technologies and reaction processing with direct relevance to sustainable chemicals and energy production. Our multidisciplinary program will provide new sets of active iron catalysts for reductive processes and is a major puzzle piece toward a greener chemical synthesis.","1995400","2016-10-01","2021-09-30"
"FermiSurfaceFlavours","FLAVOURS OF FERMI SURFACE IN THE ABSENCE OF A CONVENTIONAL FERMI LIQUID","Suchitra SEBASTIAN","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Quantum oscillations have revealed signature Fermi surfaces in a diverse range of materials families, with breakthrough advances made by a synthesis of theoretical modelling, experimental vision, materials preparation, and advances in measurement technique. Traditionally, the very observation of a Fermi surface has been taken to imply an underlying Fermi liquid. In this proposal, we seek to transcend this traditional paradigm in the field of correlated electron systems and define a new framework for the observation of quantum oscillations associated with a novel Fermi surface in the absence of a conventional Fermi liquid. Guided by a selection of theoretical proposals, we identify for study materials families starting from the more readily modellable correlated Mott insulators and Kondo insulators without the complication of mobile electrons. We progress to regions where mobile electrons are introduced – where we select for study the doped Mott insulating cuprate superconductors. Eventually we access the intervening region of unconventional quantum critical physics where a Fermi surface in the absence of a conventional Fermi liquid transitions to a Fermi surface underpinned by a conventional Fermi liquid, by lattice-density tuning of selected materials. We propose to investigate the Fermi surface of these regimes of correlated materials phase space that defy conventional Fermi liquid behaviour by the use of advanced quantum oscillation techniques in selected high purity correlated materials, under either ambient pressure conditions or under lattice-density tuning, and using high magnetic fields. We expect the project outcome to have a substantive impact on our understanding of correlated electron systems, especially in hitherto opaque regions of phase space where Fermi liquid behaviour breaks down. We thus anticipate a new era where quantum oscillations serve as a diagnostic for novel phases of correlated matter that lack a conventional Fermi liquid description.","2127851","2019-04-01","2024-03-31"
"FHiCuNCAG","Foundations for Higher and Curved Noncommutative Algebraic Geometry","Wendy LOWEN","UNIVERSITEIT ANTWERPEN","With this research programme, inspired by open problems within noncommutative algebraic geometry (NCAG) as well as by actual developments in algebraic topology, it is our aim to lay out new foundations for NCAG. On the one hand, the categorical approach to geometry put forth in NCAG has seen a wide range of applications both in mathematics and in theoretical physics. On the other hand, algebraic topology has received a vast impetus from the development of higher topos theory by Lurie and others. The current project is aimed at cross-fertilisation between the two subjects, in particular through the development of “higher linear topos theory”. We will approach the higher structure on Hochschild type complexes from two angles. Firstly, focusing on intrinsic incarnations of spaces as large categories, we will use the tensor products developed jointly with Ramos González and Shoikhet to obtain a “large version” of the Deligne conjecture. Secondly, focusing on concrete representations, we will develop new operadic techniques in order to endow complexes like the Gerstenhaber-Schack complex for prestacks (due to Dinh Van-Lowen) and the deformation complexes for monoidal categories and pasting diagrams (due to Shrestha and Yetter) with new combinatorial structure. In another direction, we will move from Hochschild cohomology of abelian categories (in the sense of Lowen-Van den Bergh) to Mac Lane cohomology for exact categories (in the sense of Kaledin-Lowen), extending the scope of NCAG to “non-linear deformations”. One of the mysteries in algebraic deformation theory is the curvature problem: in the process of deformation we are brought to the boundaries of NCAG territory through the introduction of a curvature component which disables the standard approaches to cohomology. Eventually, it is our goal to set up a new framework for NCAG which incorporates curved objects, drawing inspiration from the realm of higher categories.","1171360","2019-06-01","2024-05-31"
"FICOMOL","Field Control of Cold Molecular Collisions","Sebastiaan Y T VAN DE MEERAKKER","STICHTING KATHOLIEKE UNIVERSITEIT","It is a long held dream of chemical physicists to study (and to control!) the interactions between individual molecules in completely specified collisions. This project brings this goal within reach. I will develop novel methods to study collisions between individual molecules at temperatures between 10 mK and 10 K, and to manipulate their interaction using electric and magnetic fields. Under these cold conditions, the collisions are dominated by quantum effects such as interference and tunneling. Scattering resonances occur that respond sensitively to external electric or magnetic fields, yielding the thrilling perspective to provide “control knobs” to steer the outcome of a collision. Building on my unique experience with state-of-the-art molecular beam deceleration methods, I will study scattering resonances for chemically relevant systems involving molecules such as OH, NO, NH3 and H2CO in crossed beam experiments. Using external electric or magnetic fields, we will tune the positions and widths of resonances, such that collision rates can be changed by orders of magnitude. This type of “collision engineering” will be used to induce and study hitherto unexplored quantum phenomena, such as the merging of individual resonances, and resonant energy transfer in bimolecular collisions. Measurements of exotic collision phenomena under yet unexplored conditions as proposed here provide excellent tests for quantum theories of molecular interactions, and pave the way towards the engineering of novel quantum structures, or the collective properties of interacting molecular systems. The proposed research program will transform this field from merely “probing nature” with the highest possible detail to “manipulating nature” with the highest possible level of control. It will open up a new and intellectually rich research field in chemical physics and physical chemistry, and will be a major breakthrough in the emerging research field of cold molecules.","2000000","2019-03-01","2024-02-29"
"Fields4CAT","Force Fields in Redox Enzymatic Catalysis","Ismael DÍEZ PÉREZ","KING'S COLLEGE LONDON","Fields4CAT aims to identify the nature and directionality of the driving forces in a redox enzyme that govern the catalytic chemical process.
Industrial bio-manufacturing is one of the pillars of today’s world economy making its way to a sustainable development. Redox enzymes catalyze the most demanding chemical reactions under mild conditions, such as the oxy-functionalization of non-activated hydrocarbons, which usually requires harsh reaction conditions. Enzyme Biotechnology has greatly progressed thanks to rational mutagenesis schemes that draw upon the static X-ray structural information. The high complexity of enzymatic catalysis has, however, hampered its development because a single point mutation near the active site can affect several relevant parameters at the same time, obscuring the interpretation and constraining the rational design of technological biocatalysts.
Fields4CAT proposes dissecting the relevant forces exerted over an individual catalytic active site in its wild-type state, and then using the resulting forces map to design enzyme/metal platforms with enhanced capabilities. To this aim, it develops in 3 blocks organized in a step-wise fashion: (i) block 1 sets up a electrochemical multi-stimuli single-protein toolbox (Ec-SPT) with capabilities to trap individual proteins in a nanoscale tunnelling junction and subject them to a variety of force stimuli, i.e. mechanical, electrostatic and magnetic. (ii) Block 2 designs the chemical electrical plugs that will specifically connect the enzyme to the junction electrodes with precise controlled orientation. (iii) Block 3 characterizes the single-protein electrical signatures of the enzyme activity and quantifies the catalytic effect of the different force stimuli along the vertical junction axis.
Fields4CAT will identify new guidelines to bioengineer a redox enzyme/metal platform with tuned catalytic activity, bringing about new breakthroughs in the future of Bio-Catalysis.","1998700","2019-03-01","2024-02-29"
"Fireworks","Celestial fireworks: revealing the physics of the time-variable sky","Avishay Gal-Yam","WEIZMANN INSTITUTE OF SCIENCE LTD","Experimental time-domain astrophysics is on the verge of a new era as technological, computational, and operational progress combine to revolutionise the manner in which we study the time-variable sky. This proposal consolidates previous breakthrough work on wide-field surveys into a coherent program to advance our study of the variable sky on ever decreasing time-scales: from days, through hours, to minutes. We will watch how stars explode in real time in order to study the complex physics of stellar death, build new tools to handle and analyse the uniquely new data sets we are collecting, and shed light on some of the most fundamental questions in modern astrophysics: from the origin of the elements, via the explosions mechanism of supernova explosions, to the feedback processes that drive star formation and galaxy evolution.","2461111","2017-09-01","2022-08-31"
"FLAMENCO","A Fully-Implantable MEMS-Based Autonomous Cochlear Implant","Kulah Haluk","MIDDLE EAST TECHNICAL UNIVERSITY","Sensorineural impairment, representing the majority of the profound deafness, can be restored using cochlear implants (CIs), which electrically stimulates the auditory nerve to repair hearing in people with severe-to-profound hearing loss. A conventional CI consists of an external microphone, a sound processor, a battery, an RF transceiver pair, and a cochlear electrode. The major drawback of conventional CIs is that, they replace the entire natural hearing mechanism with electronic hearing, even though most parts of the middle ear are operational. Also, the power hungry units such as microphone and RF transceiver cause limitations in continuous access to sound due to battery problems. Besides, damage risk of external components especially if exposed to water and aesthetic concerns are other critical problems. Limited volume of the middle ear is the main obstacle for developing fully implantable CIs.
FLAMENCO proposes a fully implantable, autonomous, and low-power CI, exploiting the functional parts of the middle ear and mimicking the hair cells via a set of piezoelectric cantilevers to cover the daily acoustic band. FLAMENCO has a groundbreaking nature as it revolutionizes the operation principle of CIs. The implant has five main units: i) piezoelectric transducers for sound detection and energy harvesting, ii) electronics for signal processing and battery charging, iii) an RF coil for tuning the electronics to allow customization, iv) rechargeable battery, and v) cochlear electrode for neural stimulation. The utilization of internal energy harvesting together with the elimination of continuous RF transmission, microphone, and front-end filters makes this system a perfect candidate for next generation autonomous CIs. In this project, a multi-frequency self-powered implant for in vivo operation will be implemented, and the feasibility will be proven through animal tests.","1993750","2016-07-01","2021-06-30"
"FLATLAND","Electron-lattice-spin correlations and many-body phenomena in 2D semiconductors and related heterostructures","Ralph Bernhard Ernstorfer","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Two-dimensional crystalline materials exhibit exceptional physical properties and offer fascinating potential as fundamental building blocks for future two-dimensional electronic and optoelectronic devices.  Transition metal dichalcogenides (TMDCs) are of particular interest as they show a variety of many-body phenomena and correlation effects. Key properties are: i) additional internal degrees of freedom of the electrons, described as valley pseudospin and layer pseudospin, ii) electronic many-body effects like strongly-bound excitons and trions, and iii) electron-lattice correlations like polarons. While these phenomena represent intriguing fundamental solid state physics problems, they are of great practical importance in view of the envisioned nanoscopic devices based on two-dimensional materials. 

The experimental research project FLATLAND will address the exotic spin-valley-layer correlations in few-layer thick TMDC crystals and TMDC-based heterostructures. The latter comprise other 2D materials, organic crystals, metals and phase change materials as second constituent. Microscopic coupling and correlation effects, both within pure materials as well as across the interface of heterostructures, will be accessed by time- and angle-resolved extreme ultraviolet-photoelectron spectroscopy, femtosecond electron diffraction, and time-resolved optical spectroscopies. The project promises unprecedented insight into the microscopic coupling mechanisms governing the performance of van der Waals-bonded devices.","2640633","2016-10-01","2021-09-30"
"FlexNets","Quantifying Flexibility in Communication Networks","Wolfgang Leonhard Kellerer","TECHNISCHE UNIVERSITAET MUENCHEN","Communication networks have emerged to become the basic infrastructure for all areas of our society with application areas ranging from social media to industrial production and healthcare. New requirements include the need for dynamic changes of the required resources, for example, to react to social events or to shifts of demands. Existing networks and, in particular, the Internet cannot meet those requirements mainly due to their ossification and hence limitation in resource allocation, i.e., lack of flexibility to adapt the available resources to changes of demands on a small time-scale and in an efficient way. In recent years, several concepts have emerged in networking research to provide more flexibility in networks through virtualization and control plane programmability. In particular, the split between data plane and a centralized control plane as defined by Software Defined Networking (SDN) is regarded as the basic concept to allow flexibility in networks. However, a deeper understanding of what flexibility means remains open. In this project, flexibility focuses on the dynamic changes in time and size of a network that is characterized by its resources (link rate and node capacities) and connectivity (network graph). It is the objective of this research to analyse the fundamental design space for flexibility in SDN-based networks with respect to cost such as resource usage, traffic overhead and delay. The outcome will be a set of quantitative arguments pro and contra certain design choices. An analytical cost model to quantitatively assess the trade-off for flexibility vs. cost will be developed. To assess flexibility with respect to general graph properties a graph model will be designed. The detailed analysis is based on three use cases: dynamic resource allocation, QoS control, and resilience. In the state of the art, selected aspects of flexibility have been explored for certain network scenarios, a fundamental and comprehensive analysis is missing.","1931250","2015-09-01","2020-08-31"
"FLUDYCO","Fluid dynamics of planetary cores: formation, heterogeneous convection and rotational dynamics","Michael Le Bars","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Understanding the flows in planetary cores from their formation to their current dynamics is a tremendous interdisciplinary challenge. Beyond the challenge in fundamental fluid dynamics to understand these extraordinary flows involving turbulence, rotation and buoyancy at typical scales well beyond our day-to-day experience, a global knowledge of the involved processes is fundamental to a better understanding of the initial state of planets, of their thermal and orbital evolution, and of magnetic field generation, all key ingredients for habitability. The purpose of the present project is to go beyond the state-of-the-art in tackling three barriers at the current frontier of knowledge. It combines groundbreaking laboratory experiments, complementary pioneering numerical simulations, and fruitful collaborations with leaders in various fields of planetary sciences. Improving on the latest advances in the field, I will address the fluid dynamics of iron fragmentation during the later stages of planetary accretion, in order to produce innovative, dynamically reliable models of planet formation. Considering the latest published data for Earth, I will investigate the flows driven in a stratified layer at the top of a liquid core and their influence on the global convective dynamics and related dynamo. Finally, building upon the recent emergence of alternative models for core dynamics, I will quantitatively examine the non-linear saturation and turbulent state of the flows driven by libration, as well as the shape and intensity of the corresponding dynamo. In the context of an international competition, the originality of my work comes from its multi-method and interdisciplinary character, building upon my successful past researches. Beyond scientific advances, this high-risk/high-gain project will benefit to a larger community through the dissemination of experimental and numerical improvements, and allow promoting science through an original outreach program.","1992602","2016-07-01","2021-06-30"
"FNPMLS","Fundamental nuclear properties measured with laser spectroscopy","Kieran Thomas Joseph Flanagan","THE UNIVERSITY OF MANCHESTER","The prime research theme of this project is the study of short-lived exotic nuclei with laser spectroscopy. Over the next 5 years my team will study the role of three-nucleon forces and their associated influence on nuclear structure and the limits of nuclear existence. This work will investigate the interplay between tensor and central forces and the associated effect on quantum shells in exotic nuclear systems. This proposal will study how the shape of the nucleus is modified at the limits of nuclear existence. We will use innovative laser spectroscopy methods to achieve these goals. The project will be carried out at the ISOLDE facility, CERN, which is the premier radioactive beam facility at the precision frontier. The proposed research activity closely matches the NuPECC (Nuclear Physics European Collaboration Committee) 2010 Long Range Plan. The wider scientific impact of this research will influence modelling explosive stellar processes and nuclear synthesis, understanding the structure of astrophysical compact-objects such as neutron stars and predicting regions of enhanced stability in the super heavy elements. The FNPMLS project will develop ultra-sensitive methodologies that set a new paradigm in laser spectroscopy. It builds on the cutting edge technology of collinear resonance ionization spectroscopy (CRIS) that I have developed during my STFC Advanced Fellowship.  The CRIS technique combines the high resolution nature of collinear laser spectroscopy with the high sensitivity of resonance ionization spectroscopy. The research programme and investment outlined in this proposal will place my team in a unique and world leading position. This work will happen in advance of the next generation of radioactive beam facility such as SPIRAL2, FAIR and FRIB and will provide the essential ingredients for future fundamental questions.","1846542","2015-04-01","2020-03-31"
"FOGHORN","FOG-aided wireless networks for communication, cacHing and cOmputing: theoRetical and algorithmic fouNdations","Osvaldo SIMEONE","KING'S COLLEGE LONDON","""The FOGHORN project aims at developing the theoretical and algorithmic foundations of fog-aided wireless networks. This is an emerging class of wireless systems that leverages the synergy and complementarity of cloudification and edge processing, two key technologies in the evolution towards 5G systems and beyond. Fog-aided wireless networks can reap the bene 
fits of centralization via cloud processing, in terms of capital and operating cost reductions, greening, and
enhanced spectral e fficiency, while, at the same time, being able to cater to low-latency applications, such as the """"tactile"""" internet, by means of localized intelligence at the network edge. The operation of fog-aided wireless networks poses novel fundamental research problems pertaining to the optimal management of the communication, caching and computing resources at the
cloud and at the edge, as well as to the transmission on the fronthaul network connecting cloud and edge. The solution of these problems challenges the theoretical principles and engineering insights which have underpinned the design of existing networks. The initial research activity on the topic, of which the EU is at the forefront, focuses, by and large, on ad hoc solutions and technologies. In contrast, the goal of this project is to develop fundamental theoretical insights
and algorithmic principles with the main aim of guiding engineering choices, unlocking new academic opportunities and disclosing new technologies. The theoretical framework is grounded in network information theory, which enables the distillation of design principles, along with signal processing, (non-convex) optimization, queuing and distributed computing to develop and analyse algorithmic solutions.""","2318719","2017-06-01","2022-05-31"
"FORCASTER","Force, Motion and Positioning of Microtubule Asters","Nicolas David Minc","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Cells must move and position internal components to perform their function. We here focus on the physical designs which allow microtubule (MT) asters to exert forces in order to move and position themselves in vivo. These are arrays of MTs radiating from the centrosome, which fill up large portions of cells. They orchestrate nuclear positioning and spindle orientation for polarity, division and development. Forces that move asters are generated at nanometer and second scales by MT-associated motors from sites in the cytoplasm or at the cell surface. How MTs and force-generators self-organize to control aster motion and position at millimeter and hour scales is not known. We will use a suit of biophysical experiments and models to address how aster micro-mechanics contribute to aster migration, centration, de-centration and orientation in a single in vivo system, using the early stages of Sea urchin development as a quantitative model. 
We aim to: 1) Elucidate mechanisms that drive aster large-scale motion, using sperm aster migration after fertilization during which asters grow and move rapidly and persistently to the large-egg center. We will investigate how speeds and trajectories depend on boundary conditions and on the dynamic spatial organization of force-generators.
 2) Implement magnetic-based subcellular force measurements of MT asters. We will use this to understand how single force-events are integrated at the scale of asters, how global forces may evolve will aster size, shape, in centration and de-centration processes, using various stages of development, and cell manipulation; and to compute aster friction. 
 3) Couple computational models and 3D imaging to understand and predict stereotyped division patterns driven by subsequent aster positioning and aster-pairs orientation in the early divisions of Sea urchin embryos and in other tissues. 
This framework bridging multiple scales will bring unprecedented insights on the physics of living active matter.","2199310","2015-07-01","2020-06-30"
"FOREFRONT","Frontiers of Extended Formulations","Samuel Fiorini","UNIVERSITE LIBRE DE BRUXELLES","""Linear programming has proved to be an invaluable tool both in theory and practice. Semidefinite programming  surpasses linear programming in terms of expressivity while remaining tractable. This project proposal investigates the modeling power of linear and semidefinite programming, in the context of combinatorial optimization. Within the emerging framework of extended formulations (EFs), I seek a decisive answer to the following question: Which problems can be modeled by a linear or semidefinite program, when the number of constraints and variables are limited? EFs are based on the idea that one should choose the """"right"""" variables to model a problem. By extending the set of variables of a problem by a few carefully chosen variables, the number of constraints can in some cases dramatically decrease, making the problem easier to solve. Despite previous high-quality research, the theory of EFs is still on square one. This project proposal aims at (i) transforming our current zero-dimensional state of knowledge to a truly three-dimensional state of knowledge by pushing the boundaries of EFs in three directions (models, types and problems); (ii) using EFs as a lens on complexity by proving strong consequences of important conjectures such as P != NP, and leveraging strong connections to geometry to make progress on the log-rank conjecture. The proposed  methodology is: (i) experiment-aided; (ii) interdisciplinary; (iii) constructive.""","1455479","2014-09-01","2019-08-31"
"FOREMAT","Finding a needle in a haystack: efficient identification of high performing organic energy materials","Mariano Campoy Quiles","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Following promising early breakthroughs, progress in the development of high-performance multicomponent organic energy materials has stalled due to a bottleneck in device optimization. FOREMAT will develop a breakthrough technology to overcome this bottleneck by shifting from fabrication-intense to measurement-intense assessment methods, enabling rapid multi-parameter optimization of novel systems. Our goal is to deliver organic material systems with a step-change in performance, bringing them close to the expected market turn point, including panchromatic organic photovoltaics with ca 15% efficiencies and thermoelectric devices that could revolutionize waste heat recovery by their flexibility, lightweight and high power factor.

The development of multicomponent materials promises to dramatically improve the cost, efficiency and stability of organic energy devices. For example, they allow to engineer broad-band absorption in photovoltaics matched to the sun’s spectrum, or to create composites that conduct electricity like metals while thermally insulate like cotton yielding thermoelectric devices beyond the state-of-the-art. Despite these advantages, the long time required to evaluate promising organic multinaries currently limits their development. 

We will circumvent this problem by developing a high-throughput technology that will allow evaluation times up to two orders of magnitude faster saving, at the same time, around 90% of material. To meet these ambitious goals, we will advance novel fabrication tools and create samples bearing a high density of information arising from 2-dimensional gradual variations in relevant parameters that will be sequentially tested with increasing resolution in order to determine optimum values with high precision. This quantitative step will enable a disruptive qualitative change as in depth multidimensional studies will lead to design rationales for multicomponent systems with step-change performance in energy applications.","2423894","2015-10-01","2020-09-30"
"FORSIED","Formalizing Subjective Interestingness in Exploratory Data Mining","Tijl De Bie","UNIVERSITEIT GENT","""The rate at which research labs, enterprises and governments accumulate data is high and fast increasing. Often, these data are collected for no specific purpose, or they turn out to be useful for unanticipated purposes: Companies constantly look for new ways to monetize their customer databases; Governments mine various databases to detect tax fraud; Security agencies mine and cross-associate numerous heterogeneous information streams from publicly accessible and classified databases to understand and detect security threats. The objective in such Exploratory Data Mining (EDM) tasks is typically ill-defined, i.e. it is unclear how to formalize how interesting a pattern extracted from the data is. As a result, EDM is often a slow process of trial and error.

During this fellowship we aim to develop the mathematical principles of what makes a pattern interesting in a very subjective sense. Crucial in this endeavour will be research into automatic mechanisms to model and duly consider the prior beliefs and expectations of the user for whom the EDM patterns are intended, thus relieving the users of the complex task to attempt to formalize themselves what makes a pattern interesting to them.

This project will represent a radical change in how EDM research is done. Currently, researchers typically imagine a specific purpose for the patterns, try to formalize interestingness of such patterns given that purpose, and design an algorithm to mine them. However, given the variety of users, this strategy has led to a multitude of algorithms. As a result, users need to be data mining experts to understand which algorithm applies to their situation. To resolve this, we will develop a theoretically solid framework for the design of EDM systems that model the user's beliefs and expectations as much as the data itself, so as to maximize the amount of useful information transmitted to the user. This will ultimately bring the power of EDM within reach of the non-expert.""","1549315","2014-05-01","2019-04-30"
"FORWARD","New Frontiers for Optoelectronics with Artificial Media","ALOYSE MARIE CHARLES DEGIRON","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","To detect or generate complex light beams that are increasingly needed in biology and photonics (light with non-zero angular momentum and non-classical light), it is necessary to rely on bulky and sophisticated setups, considerably limiting their potential. The FORWARD project aims at obtaining the same functionalities with a new generation of optoelectronic components of submicron thickness in the near infrared range. This ambitious objective implies to devise radically new ways of creating and manipulating complex light at the nanoscale. In FORWARD, this tremendous challenge will be addressed by hybridizing two classes of artificial media-colloidal quantum dots (CQDs) and metamaterials-and leveraging advanced cooperative behaviours within the hybrids. In the new devices, which will be pumped electrically, the active layers will be made of a film of CQDs interwoven with the metallic inclusions of an optical metamaterial.
FORWARD has a strong multidisciplinary character as it lies at the crossroads of nanocrystal processing, nanofabrication, nanophotonics, condensed matter physics and optoelectronics. First, we will hybridize metallic metamaterials and CQDs, study the transport properties in these devices and develop metamaterial/CQD photodetectors demonstrating the advantage of the hybridization. Second, we will induce classical cooperative effects between the different metamaterial inclusions and utilize this approach to fabricate hybrids LEDs capable of emitting optical vortices. Last, we will induce quantum synchronizations among the CQDs and demonstrate hybrids LEDs that produce coherent and non-classical light.
Each demonstrator of the project will be a world first in terms of functionalities, miniaturization and operation principle. Besides, this initiative can be seen as the first of its kind that takes a unified and multidisciplinary view at artificial media, opening new horizons for synthetic composite materials in optics, electronics and optoelectronics.","1965045","2018-11-01","2023-10-31"
"FoTran","Found in Translation – Natural Language Understanding with Cross-Lingual Grounding","Jörg TIEDEMANN","HELSINGIN YLIOPISTO","""Natural language understanding is the """"holy grail"""" of computational linguistics and a long-term goal in research on artificial intelligence. Understanding human communication is difficult due to the various ambiguities in natural languages and the wide range of contextual dependencies required to resolve them.  Discovering the semantics behind language input is necessary for proper interpretation in interactive tools, which requires an abstraction from language-specific forms to language-independent meaning representations.  With this project, I propose a line of research that will focus on the development of novel data-driven models that can learn such meaning representations from indirect supervision provided by human translations covering a substantial proportion of the linguistic diversity in the world. A guiding principle is cross-lingual grounding, the effect of resolving ambiguities through translation. The beauty of that idea is the use of naturally occurring data instead of artificially created resources and costly manual annotations. The framework is based on deep learning and neural machine translation and my hypothesis is that training on increasing amounts of linguistically diverse data improves the abstractions found by the model. Eventually, this will lead to universal sentence-level meaning representations and we will test our ideas with multilingual machine translation and tasks that require semantic reasoning and inference.""","1817622","2018-09-01","2023-08-31"
"FOUR ACES","Future of upper atmospheric characterisation of exoplanets with spectroscopy","David René Bernard EHRENREICH","UNIVERSITE DE GENEVE","This project will open a new path to characterise the atmospheres of exoplanets down to Earth-size objects, using the spatial extension of upper atmospheres as a magnifying glass to access the atmospheric properties. The tremendous energy received by exoplanets close to their stars leads to dramatic atmospheric expansion and escape, which could result in the formation of hot rocky super-Earths seen in recent years. While the escape mechanisms and evolutionary impact on planets and atmospheres remain debated, the atmospheric expansion gives rise to spectacular spectroscopic signatures in the UV, only detectable with the Hubble Space Telescope (HST). In 2015, I discovered a huge extended atmosphere escaping from a “warm Neptune”, which represents a milestone on the road to the atmospheres of lower-mass, more temperate planets. Using HARPS spectroscopy from the ground, I revealed the extreme conditions in the upper atmosphere of a “hot Jupiter”, probing the onset of atmospheric escape in the optical, linking the upper and lower atmospheres. I propose to consolidate these breakthroughs via a thorough exploitation of the vast amount of observations I obtained for ~20 planets (100+ hours on HST and 250+ hours on HARPS and HARPS-N) in the wake of my results. I will use those data to bind theories describing the lower and upper atmospheres of exoplanets, and determine how these are impacted by stellar activity. In a second step, I will build and deliver a legacy archive of UV observations by the end of HST in ~2020. In an era where new transit surveys will provide hundreds of easier-to-study exoplanets transiting bright stars, I will use my priviledged access to the reconnaissance capabilities of the ESA CHEOPS mission (2018–2022) to cherry-pick the very best planets for atmospheric characterisation. I will combine the space-borne and ground-based high-resolution spectroscopic follow-ups of these planets to deliver a novel, comprehensive view of exoplanetary atmospheres.","1999475","2017-06-01","2022-05-31"
"FRAGMENT","FRontiers in dust minerAloGical coMposition and its Effects upoN climaTe","Carlos Perez Garcia-Pando","BARCELONA SUPERCOMPUTING CENTER - CENTRO NACIONAL DE SUPERCOMPUTACION","Soil dust aerosols are mixtures of different minerals, whose relative abundances, particle size distribution (PSD), shape, surface topography and mixing state influence their effect upon climate. However, Earth System Models typically assume that dust aerosols have a globally uniform composition, neglecting the known regional variations in the mineralogy of the sources. The goal of FRAGMENT is to understand and constrain the global mineralogical composition of dust along with its effects upon climate. The representation of the global dust mineralogy is hindered by our limited knowledge of the global soil mineral content and our incomplete understanding of the emitted dust PSD in terms of its constituent minerals that results from the fragmentation of soil aggregates during wind erosion. The emitted PSD affects the duration of particle transport and thus each mineral’s global distribution, along with its specific effect upon climate. Coincident observations of the emitted dust and soil PSD are scarce and do not characterize the mineralogy. In addition, the existing theoretical paradigms disagree fundamentally on multiple aspects. We will contribute new fundamental understanding of the size-resolved mineralogy of dust at emission and its relationship with the parent soil, based on an unprecedented ensemble of measurement campaigns that have been designed to thoroughly test our theoretical hypotheses. To improve knowledge of the global soil mineral content, we will evaluate and use available remote hyperspectral imaging, which is unprecedented in the context of dust modelling. Our new methods will anticipate the coming innovation of retrieving soil mineralogy through high-quality spaceborne hyperspectral measurements. Finally, we will generate integrated and quantitative knowledge of the role of dust mineralogy in dust-radiation, dust-chemistry and dust-cloud interactions based on modeling experiments constrained with our theoretical innovations and field measurements.","2000000","2018-10-01","2023-09-30"
"FRECOM","Nonlinear-Distortion Free Communication over the Optical Fibre Channel","Darko ZIBAR","DANMARKS TEKNISKE UNIVERSITET","Motivation
The enormous growth in the Internet of Things and server farms for cloud services has increased the strain on the optical communication infrastructure. By 2025, our society will require data rates that are physically impossible to implement using current state-of-the-art optical communication technologies. This is because fibre-optic communication systems are rapidly approaching their fundamental capacity limits imposed by the Kerr nonlinearity of the fibre. Nonlinear distortion limits the ability to transport and detect the information stream. This is a very critical problem for increasing the data rates of any optical fibre communication system. 

Proposed research 
The only physical quantities not affected by the nonlinearity are eigenvalues, associated with the optical fibre propagation equation. Eigenvalues are thereby ideal candidates for information transport. The concept of eigenvalues is derived under the assumption that the fibre is lossless and that there is no noise in the system which is not strictly correct. Therefore, novel methodologies and concepts for the design of a noise mitigating receiver and a noise robust transmitter are needed to reap the full benefits of optical communication systems employing eigenvalues. This proposal will develop such strategies. This will be achieved by combining, for the first time, the fields of nonlinear optics, optical communication and nonlinear digital signal processing. The results from the project will be verified experimentally, and will form the basis for a new generation of commercial optical communication systems.

Preliminary results
Our proof-of-concept results demonstrate, for the first time, that noise can be handled by employing novel receiver concepts. An order of magnitude improvement compared to the state-of-the-art is demonstrated.

Environment 
The research will be carried out in close cooperation with leading groups at Stanford University and Technical University of Munich.","2000000","2018-03-01","2023-02-28"
"FRICatANIONS","Frontiers in Catalytic Anion-Binding Chemistry","Olga GARCIA MANCHENO","WESTFAELISCHE WILHELMS-UNIVERSITAET MUENSTER","Chemical transformations comprise the polarization of the reacting species. As a consequence, partially or fully charged reagents and intermediates are omnipresent in chemistry. Although anion-binding processes are well-known for their crucial role in molecular recognition, this type of phenomenon has only recently been utilized for catalysis. Since catalytic reactions are of utmost relevance to construct valuable chemicals and materials, this mode of catalytic chemical activation might be the key for the future design of original and more efficient synthetic transformations. However, the effects of anions in catalytic processes are still largely unknown. 
Aiming at providing a novel general synthetic toolbox, in this project I propose several anion-binding activation concepts to solve current challenging catalytic synthetic problems. To achieve this goal, structurally different chiral anion-binding catalysts will be developed and incorporated into the existing limited palette of catalyst library. Furthermore, I propose a significant expansion of the application scope of anion-binding catalysis based on the activation and modulation of anionic nucleophiles and oxidants to develop organocatalytic reactions such as halogenations and oxidations, including the asymmetric functionalization of C-H bonds. In addition, anion-binding processes will be used to facilitate key steps in cross-coupling reactions such as the transmetallation, as well as the photoactivity modulation of readily available photosensitizers and the introduction of asymmetric photocatalysis involving radical-anions.
The proposed groundbreaking approaches will revolutionize not only anion-binding catalysis but also all the scientific areas relying on catalytic synthetic methods. Thus, the results derived from this project will have a tremendous impact in diverse fields such as catalysis, organic synthesis and material sciences, as well as in economical, environmental and industrial issues.","1997763","2017-06-01","2022-05-31"
"FricLess","A seamless multi-scale model for contact, friction, and solid lubrication","Lucia Nicola","UNIVERSITA DEGLI STUDI DI PADOVA","Friction and wear are liable for enormous losses in terms of energy and  resources in modern society. Costs related to unwanted friction in industrialised countries are estimated to be about 3% of the gross domestic product. Urgency is even greater nowadays as friction between micro-components has become the bottleneck of several applications for which miniaturisation is critical.

Lubrication is a commonly adopted solution to reduce friction. Graphite is a broadly used solid lubricant for large scale applications, while the lubricating properties of a few-layers graphene hold great promise especially for smaller scale applications. At present, our knowledge of the friction and lubrication of rough surfaces is essentially phenomenological. This is because friction is only deceivingly a simple mechanisms, which instead requires understanding of physical phenomena simultaneously acting at different length scales. The change in contact size, which controls the friction stress, depends on nano-scale phenomena such as atomic de-adhesion, sliding, dislocation nucleation in metals, but also on micro- and macro-scale phenomena as (size-dependent) plastic deformation.

The objective of this proposal is to reach an unprecedented understanding of metal friction and lubrication by accounting, for the first time, for all relevant phenomena occurring from the atomic to the macro-scale, and their interplay.
To this end, a seamless concurrent multi-scale model will be developed. The power of this new model lies in its capability of describing three-dimensional bodies with realistic roughness in sliding lubricated contact, with the accuracy of an atomistic simulation.

This research builds towards a complete picture of metal friction and lubrication. The materials chosen for the proposed research are copper and  multi-layer graphene. However, the model that will be developed is general and can be used to study different materials, lubricants and environmental conditions.","1999985","2016-06-01","2022-11-30"
"FTHPC","Fault Tolerant High Performance Computing","Oded Schwartz","THE HEBREW UNIVERSITY OF JERUSALEM","Supercomputers are strategically crucial for facilitating advances in science and technology: in climate change research, accelerated genome sequencing towards cancer treatments, cutting edge physics, devising engineering innovative solutions, and many other compute intensive problems. However, the future of super-computing depends on our ability to cope with the ever increasing rate of faults (bit flips and component failure), resulting from the steadily increasing machine size and decreasing operating voltage. Indeed, hardware trends predict at least two faults per minute for next generation (exascale) supercomputers.

The challenge of ascertaining fault tolerance for high-performance computing is not new, and has been the focus of extensive research for over two decades.  However, most solutions are either (i) general purpose, requiring little to no algorithmic effort, but severely degrading performance (e.g., checkpoint-restart), or (ii) tailored to specific applications and very efficient, but requiring high expertise and significantly increasing programmers' workload. We seek the best of both worlds: high performance and general purpose fault resilience.

Efficient general purpose solutions (e.g., via error correcting codes) have revolutionized memory and communication devices over two decades ago, enabling programmers to effectively disregard the very
likely memory and communication errors. The time has come for a similar paradigm shift in the computing regimen. I argue that exciting recent advances in error correcting codes, and in short probabilistically checkable proofs, make this goal feasible. Success along these lines will eliminate the bottleneck of required fault-tolerance expertise, and open exascale computing to all algorithm designers and programmers, for the benefit of the scientific, engineering, and industrial communities.","1824467","2019-06-01","2024-05-31"
"FUN POLYSTORE","FUNctionalized POLYmer electrolytes for energy STORagE","Daniel BRANDELL","UPPSALA UNIVERSITET","Besides the need for large-scale implementation of renewable energy sources, there is an equivalent need for new energy storage solutions. This is not least true for the transport sector, where electric vehicles are expanding rapidly. The rich flora of battery chemistries – today crowned by the Li-ion battery – is likewise expected to expand in upcoming years. Novel types of batteries, “post-lithium ion”, will challenge the Li-ion chemistries by advantages in cost, sustainability, elemental abundance or energy density. This requires significant improvements of the materials, not least regarding the electrolyte. The conventional liquid battery electrolytes pose a problem already for the mature Li-ion chemistries due to safety and cost, but are particularly destructive for future battery types such as Li-metal, organic electrodes, Li-S, Li-O2, Na- or Mg-batteries, where rapid degradation and loss of material are associated with incompatibilities with the electrolytes. In this context, solid state polymer electrolytes (SPEs) could provide a considerable improvement.

The field of solid polymer electrolytes (SPEs) is dominated by polyethers, particularly poly(ethylene oxide) (PEO). This application regards moving out of the established PEO-paradigm and exploring alternative polymer hosts for SPEs, primarily polycarbonates and polyesters. These ‘alternative’ polymers are comparatively easy to work with synthetically, and their possible functionalization is straightforward. The work aims at exploring functionalized alternative polymer host for mechanically robust block-copolymer systems, for alternative cation chemistries (Na, Mg, etc.), for extremely high and low electrochemical potentials, and for unstable and easily dissolved electrode materials (sulfur, organic). Moreover, since the ion transport processes in the host materials are fundamentally different from polyethers, there is a need for investigating the conduction mechanisms using simulations.","1950732","2018-09-01","2023-08-31"
"FunctionalP4","Metal-Mediated Methods for the Functionalization of White Phosphorus (P4)","Robert Matthias WOLF","UNIVERSITAET REGENSBURG","Organophosphorus compounds are an important and industrially relevant class of molecules with numerous uses, e.g. as reagents in organic synthesis, ligands in catalytically active metal complexes, and in pest control. State-of-the-art synthesis methods for all these valuable and useful compounds rely on an atom inefficient and hazardous multi-step procedure involving the oxidation of white phosphorus (P4) with toxic chlorine gas. Less wasteful and more environmentally benign methods are highly desirable, but transformations of white phosphorus directly into organophosphorus compounds are hardly developed.
This project explores new methods for the activation and functionalization of white phosphorus. The metal-mediated stepwise transformation of P4 into organophosphorus compounds is a key objective. Novel transition metal compounds are designed and synthesized, which can generate reactive phosphorus units. The concept of heterobimetallic P4 activation, where two electronically different metal complexes interact with P4 cooperatively, is introduced for this purpose. Reactions of the phosphorus fragments in these new, reactive complexes with electrophiles will produce novel, fundamentally interesting organophosphorus compounds avoiding chlorinated intermediates. Catalytic methods for P4 functionalization are currently unknown, and developing such methods using transition metal and photoredox catalysts is an additional objective of this proposal.
By providing novel synthetically useful and even catalytic procedures for converting P4 into organophosphorus compounds, this project will significantly contribute to the development of phosphorus chemistry and more sustainable synthesis methods.","1955846","2018-09-01","2023-08-31"
"GAINBYSTRAIN","Gain by Strain: Precise Cuts of Cyclopropanes as Key to Molecular Complexity","Daniel Bodo Werz","TECHNISCHE UNIVERSITAET BRAUNSCHWEIG","A central discipline of chemistry is the design und creation of molecules with defined structural and chemical properties. Stretching synthetic horizons is a never-ending endeavor to inspirit the chemist’ s creativity in preparing compounds and materials yet to be discovered. Relying on their high strain energy cyclopropanes, as carriers of the most fundamental ring geometry, offer a unique reactivity which allows for a multitude of transformations being grouped in ring-opening reactions, cycloadditions and rearrangements. Major advantage of all these processes is the cyclopropane-derived intrinsic atom-economy.
In this research project, we propose a number of uncommon and challenging reactions making use of donor-acceptor cyclopropanes. Introducing a distinctively controlled bond cleavage we seek to develop novel modes of 1,3-bifunctionalization by σ-bond metathesis, by using hypervalent iodine reagents and by merging organocatalysis with photoredox catalysis. Unprecedented ring-enlargements to four-membered rings by [3+1]-cycloadditions employing isonitriles, carbenes and nitrenes are envisioned, aryne insertions into the three-membered ring leading to indane systems are planned and a general concept for [3+3]-cycloadditions with 1,3-dipoles is presented paving the way to unusual syntheses of heterocycles.
A distinct class of compounds obtainable by our methodology will set the stage to access completely unexplored heterocyclic π-systems being of interest for material science and molecular electronics.
Besides our central goals of advancing organic methodology and to demonstrating the synthetic utility of these novel reactions, we anticipate that mechanistic insights gained by experimental and computational means will be of high impact for the chemistry of this fundamental structural unit in general.","1994250","2015-07-01","2021-06-30"
"GALACTICNUCLEUS","The Fingerprint of a Galactic Nucleus: A Multi-Wavelength, High-Angular Resolution, Near-Infrared Study of the Centre of the Milky Way","Rainer Schödel","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Galactic stellar nuclei are very common in all types of galaxies and are marked by the presence of nuclear star clusters, the densest and most massive star clusters in the present-day Universe. Their formation is still an unresolved puzzle. The centre of the Milky Way contains a massive black hole and a stellar nucleus and is orders of magnitude closer than any comparable target. It is the only galactic nucleus and the most extreme astrophysical environment that we can examine on scales of milli-parsecs. It is therefore a crucial laboratory for studying galactic nuclei and their role in the context of galaxy evolution. Yet, suitable data that would allow us to examine the stellar component of the Galactic Centre exist for less than 1% of its projected area. Moreover, the well-explored regions are extraordinary, like the central parsec around the massive black hole, and therefore probably not representative for the overall environment. Fundamental questions on the stellar population, structure and assembly history of the Galactic Centre remain therefore unanswered. This project aims at addressing the open questions by obtaining accurate, high-angular resolution, multi-wavelength near-infrared photometry for an area of several 100 pc^2, a more than ten-fold increase compared to the current state of affairs. The Galactic Centre presents unique observational challenges because of a combination of high extinction and extreme stellar crowding. It is therefore not adequately covered by existing or upcoming imaging surveys. I present a project that is specifically tailored to overcome these observational challenges. In particular, I have developed a key technique to obtain the necessary sensitive, high-angular resolution images with a stable point spread function over large, crowded fields. It works with a range of existing ground-based instruments and will serve to complement existing data to provide a global and detailed picture of the stellar nucleus of the Milky Way.","1547657","2014-02-01","2019-01-31"
"CASSANDRA","Accelerating mass loss of Greenland: firn and the shifting runoff limit","Horst MACHGUTH","UNIVERSITE DE FRIBOURG","Meltwater running off the flanks of the Greenland ice sheet contributes roughly 60% to its mass loss, the rest being due to calving. Only meltwater originating from below the elevation of the runoff limit leaves the ice sheet, contributing to mass loss; melt at higher elevations refreezes in the porous firn and does not drive mass loss. Therefore any shift in the runoff limit modifies mass loss and subsequent sea level rise. New evidence shows surface runoff at increasingly high elevations, outpacing the rate at which the equilibrium line elevation rises. This research proposal focuses on the runoff limit as a powerful yet poorly understood modulator of Greenland mass balance. We will track the runoff limit over the full satellite era using two of the largest and oldest remote sensing archives, Landsat and the Advanced Very High Resolution Radiometer (AVHRR). We will establish time series of the runoff limit for all regions of Greenland to identify the mechanisms driving fluctuations in the runoff limit. This newly gained process understanding and a wealth of in-situ measurements will then be used to build firn hydrology models capable of simulating runoff and the associated runoff limit over time. Eventually, the firn hydrology models will be applied to reconcile estimates of Greenland past, present and future mass balance. Covering the entire satellite era and all of Greenland, the focus on the runoff limit will constitute a paradigm shift leading to major advance in our understanding of how vulnerable the surface of the ice sheet reacts to climate change and how the changing surface impacts runoff and thus Greenland's role in the global sea level budget.","1989181","2019-05-01","2024-04-30"
"CATA-LUX","Light-Driven Asymmetric Organocatalysis","Paolo Melchiorre","FONDAZIONE ISTITUTO ITALIANO DI TECNOLOGIA","Visible light photocatalysis and metal-free organocatalytic processes are powerful strategies of modern chemical research with extraordinary potential for the sustainable preparation of organic molecules. However, these environmentally respectful approaches have to date remained largely unrelated. The proposed research seeks to merge these fields of molecule activation to redefine their synthetic potential. 
Light-driven processes considerably enrich the modern synthetic repertoire, offering a potent way to build complex organic frameworks. In contrast, it is extremely challenging to develop asymmetric catalytic photoreactions that can create chiral molecules with a well-defined three-dimensional arrangement. By developing innovative methodologies to effectively address this issue, I will provide a novel reactivity framework for conceiving light-driven enantioselective organocatalytic processes. 
I will translate the effective tools governing the success of ground state asymmetric organocatalysis into the realm of photochemical reactivity, exploiting the potential of key organocatalytic intermediates to directly participate in the photoexcitation of substrates. At the same time, the chiral organocatalyst will ensure effective stereochemical control. This single catalyst system, where stereoinduction and photoactivation merge in a sole organocatalyst, will serve for developing novel enantioselective photoreactions. In a complementary dual catalytic approach, the synergistic activities of an organocatalyst and a metal-free photosensitiser will combine to realise asymmetric variants of venerable photochemical processes, which have never before succumbed to a stereocontrolled approach. 
This proposal challenges the current perception that photochemistry is too unselective to parallel the impressive levels of efficiency reached by the asymmetric catalysis of thermal reactions, expanding the way chemists think about making chiral molecules","2000000","2016-11-01","2021-10-31"
"CAtMolChip","Cold Atmospheric Molecules on a Chip","Stephen Dermot Hogan","UNIVERSITY COLLEGE LONDON","Highly excited electronic states of small atmospheric molecules play an important, but as yet little explored, role in the reactivity, and in the evolution of plasmas, including the Aurora Borealis, in the upper atmosphere of the Earth. Processes involving these highly excited states are very challenging to investigate theoretically because of the high density of states close to the ionization limits where they lie. Therefore, experimental input is essential for the identification of the reaction and decay mechanisms, and the quantum states of importance in future studies. However, experimental techniques that can be exploited to provide this input have only become available very recently. These techniques permit gas-phase molecular samples in these highly excited states to be confined in traps for sufficient lengths of time (e.g. 1 ms – 10 ms) for detailed studies to be performed in a controlled laboratory environment. They include resonance-enhanced and non-resonance-enhanced multiphoton excitation of long-lived high angular momentum Rydberg states of small molecules, and chip-based devices for efficiently decelerating, transporting and trapping these samples.

With the support of this Consolidator Grant a new experimental research program will be developed in the Department of Physics and Astronomy at University College London involving laboratory based studies of (1) inelastic scattering processes, and (2) the decay mechanisms of gas-phase atmospheric molecules, including N2, O2 and NO, and their constituent atoms, in high Rydberg states. The planned experiments will be directed toward understanding the effects of static and time-dependent electric and magnetic fields, and blackbody radiation fields on slow dissociation processes that occur in highly excited states of N2, O2 and NO, investigations of collisional energy transfer processes, and studies of the role that these excited electronic states play in the evolution and reactivity of atmospheric plasmas incl","1985553","2016-06-01","2021-05-31"
"CaTs n DOCs","Chemically and Thermally Stable Nano-sized Discrete Organic Cage Compounds","Michael Günther MASTALERZ","RUPRECHT-KARLS-UNIVERSITAET HEIDELBERG","Shape-persistent organic cage compounds consisting only of covalent bonds are fascinating synthetically targets, because they are studied as hosts for the selective recognition of guest molecules, such as artificial lectins, for catalysis in confined space or for the construction of a new type of porous material. For the latter, the shape-persistency and rigidity of the cage cavity is of utmost importance. There are in principle two existing strategies for the synthesis of shape-persistent organic cage compounds. Strategy I: A stepwise approach by irreversible reactions. Here, the advantage is the chemical stability of the target compound due to the intrinsic stabilities of the formed bonds. The disadvantage of this approach is in general the low overall yield, because the system does not allow any ‘self-correction’ of once formed bonds. This is different for the other approach used in Strategy II: By using dynamic covalent bond formation as synthetic tool, shape-persistent organic cages can be constructed from rather simple molecular building blocks in one step. Here, the yields are usually very high or even quantitatively, because the reversibility of the reaction allows the system to self-correct. Unfortunately, the resulting compounds are more prone to chemical cleavage of the cages than those synthesized by the irreversible approach.
Within this project, we will combine the advantages of both strategies to synthesize chemically and thermally stable nano-sized discrete organic cage compounds in a two-step approach in high yields. To demonstrate the versatility and synthetic power of this approach, pure hydrocarbon cages will be synthesized in a few steps in high yields. Finally, this strategy will make for the first time open and closed-shell fullerenes and heterofullerenes that are isomerically pure, accessible.","1996000","2017-04-01","2022-03-31"
"CAUSALPATH","Next Generation Causal Analysis: Inspired by the Induction of Biological Pathways from Cytometry Data","Ioannis Tsamardinos","PANEPISTIMIO KRITIS","Discovering the causal mechanisms of a complex system of interacting components is necessary in order to control it. Computational Causal Discovery (CD) is a field that offers the potential to discover causal relations under certain conditions from observational data alone or with a limited number of interventions/manipulations.

An important, challenging biological problem that may take decades of experimental work is the induction of biological cellular pathways; pathways are informal causal models indispensable in biological research and drug design. Recent exciting advances in flow/mass cytometry biotechnology allow the generation of large-sample datasets containing measurements on single cells, thus setting the problem of pathway learning suitable for CD methods.
CAUSALPATH builds upon and further advances recent breakthrough developments in CD methods to enable the induction of biological pathways from cytometry and other omics data. As a testbed problem we focus on the differentiation of human T-cells; these are involved in autoimmune and inflammatory diseases, as well as cancer and thus, are targets of new drug development for a range of chronic diseases. The biological problem acts as our campus for general novel formalisms, practical algorithms, and useful tools development, pointing to fundamental CD problems: presence of feedback cycles, presence of latent confounding variables, CD from time-course data, Integrative Causal Analysis (INCA) of heterogeneous datasets and others.

Three features complement CAUSALPATH’s approach: (A) methods development will co-evolve with biological wet-lab experiments periodically testing the algorithmic postulates, (B) Open-source tools will be developed for the non-expert, and (C) Commercial exploitation of the results will be sought out.

CAUSALPATH brings together an interdisciplinary team, committed to this vision. It builds upon the PI’s group recent important results on INCA algorithms.","1724000","2015-01-01","2019-12-31"
"CAVE","Challenges and Advancements in Virtual Elements","Lourenco Beirao da veiga","UNIVERSITA' DEGLI STUDI DI MILANO-BICOCCA","The Virtual Element Method (VEM) is a novel technology for the discretization of partial differential equations (PDEs), that shares the same variational background as the Finite Element Method. First but not only, the VEM responds to the strongly increasing interest in using general polyhedral and polygonal meshes in the approximation of PDEs without the limit of using tetrahedral or hexahedral grids. By avoiding the explicit integration of the shape functions that span the discrete space and introducing an innovative construction of the stiffness matrixes, the VEM acquires very interesting properties and advantages with respect to more standard Galerkin methods, yet still keeping the same coding complexity. For instance, the VEM easily allows for polygonal/polyhedral meshes (even non-conforming) with non-convex elements and possibly with curved faces; it allows for discrete spaces of arbitrary C^k regularity on unstructured meshes.
The main scope of the project is to address the recent theoretical challenges posed by VEM and to assess whether this promising technology can achieve a breakthrough in applications. First, the theoretical and computational foundations of VEM will be made stronger. A deeper theoretical insight, supported by a wider numerical experience on benchmark problems, will be developed to gain a better understanding of the method's potentials and set the foundations for more applicative purposes. Second, we will focus our attention on two tough and up-to-date problems of practical interest: large deformation elasticity (where VEM can yield a dramatically more efficient handling of material inclusions, meshing of the domain and grid adaptivity, plus a much stronger robustness with respect to large grid distortions) and the cardiac bidomain model (where VEM can lead to a more accurate domain approximation through MRI data, a flexible refinement/de-refinement procedure along the propagation front, to an exact satisfaction of conservation laws).","980634","2016-07-01","2021-06-30"
"CAVITYQPD","Cavity quantum phonon dynamics","Mika Antero Sillanpää","AALTO KORKEAKOULUSAATIO SR","""Large bodies usually follow the classical equations of motion. Deviations from this can be called
macroscopic quantum behavior. These phenomena have been experimentally verified with cavity Quantum
Electro Dynamics (QED), trapped ions, and superconducting Josephson junction systems. Recently, evidence
was obtained that also moving objects can display such behavior. These objects are micromechanical
resonators (MR), which can measure tens of microns in size and are hence quite macroscopic. The degree of
freedom is their vibrations: phonons.

I propose experimental research in order to push quantum mechanics closer to the classical world than ever
before. I will try find quantum behavior in the most classical objects, that is, slowly moving bodies. I will use
MR's, accessed via electrical resonators. Part of it will be in analogy to the previously studied macroscopic
systems, but with photons replaced by phonons. The experiments are done in a cryogenic temperature mostly
in dilution refrigerator. The work will open up new perspectives on how nature works, and can have
technological implications.

The first basic setup is the coupling of MR to microwave cavity resonators. This is a direct analogy to
optomechanics, and can be called circuit optomechanics. The goals will be phonon state transfer via a cavity
bus, construction of squeezed states and of phonon-cavity entanglement. The second setup is to boost the
optomechanical coupling with a Josephson junction system, and reach the single-phonon strong-coupling for
the first time. The third setup is the coupling of MR to a Josephson junction artificial atom. Here we will
access the MR same way as the motion of a trapped ions is coupled to their internal transitions. In this setup,
I am proposing to construct exotic quantum states of motion, and finally entangle and transfer phonons over
mm-distance via cavity-coupled qubits. I believe within the project it is possible to perform rudimentary Bell
measurement with phonons.""","2004283","2015-01-01","2019-12-31"
"CC","Combinatorial Construction","Peter Keevash","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","Combinatorial Construction is a mathematical challenge with many applications. Examples include the construction of networks that are very sparse but highly connected, or codes that can correct many transmission errors with little overhead in communication costs. For a general class of combinatorial objects, and some desirable property, the fundamental question in Combinatorial Construction is to demonstrate the existence of an object with the property, preferably via an explicit algorithmic construction. Thus it is ubiquitous in Computer Science, including applications to expanders, sorting networks, distributed communication, data storage, codes, cryptography and derandomisation. In popular culture it appears as the unsolved `lottery problem' of determining the minimum number of tickets that guarantee a prize. In a recent preprint I prove the Existence Conjecture for combinatorial designs, via a new method of Randomised Algebraic Constructions; this result has already attracted considerable attention in the mathematical community. The significance is not only in the solution of a problem posed by Steiner in 1852, but also in the discovery of a powerful new method, that promises to have many further applications in Combinatorics, and more widely in Mathematics and Theoretical Computer Science. I am now poised to resolve many other problems of combinatorial construction.","1706729","2016-01-01","2020-12-31"
"CellStructure","Structural cell biology in situ using superresolution microscopy","Jonas RIES","EUROPEAN MOLECULAR BIOLOGY LABORATORY","Supra-molecular protein machineries control diverse cellular processes. Knowing their structural organization is crucial for understanding their function. As classical structural biology techniques are limited in studying such assemblies in their natural cellular environment, there is a critical methodological gap inhibiting a direct link between structure and function. Consequently, the structural intermediates underlying a full activity cycle of a large multi-protein complex have been impossible to visualize. Recent advances in fluorescence microscopy, in particular the development of groundbreaking superresolution microscopy (SRM) methods, can now help bridge this gap. With this interdisciplinary proposal, my group will develop unique and innovative optical, biological and computational imaging technologies to determine the structural organization of multi-protein assemblies in their functional cellular context.
We will reach this goal by developing a method to robustly measure the precise 3D arrangements of proteins in supra-molecular assemblies in situ with nanometer isotropic resolution based on supercritical-angle detection and by measuring their absolute stoichiometries with engineered counting standards. We will also develop new data analysis tools to statistically analyze such data, taking into account the functional cellular context measured with correlative superresolution and electron microscopy, multi-color SRM and molecular biology tools. We will apply these new methods to address key questions on endocytosis, a fundamental membrane trafficking process. Our aim is to determine a time-resolved 3D superresolution localization map of the yeast endocytic proteins during the major functional transitions and to integrate these data into a mechanistic model of endocytosis. Importantly, the methods we develop here can be applied to many other large protein-based machines, and thus have the potential to have high impact in other key areas of cell biology.","1686469","2017-06-01","2022-05-31"
"CeraText","Tailoring Microstructure and Architecture to Build Ceramic Components with Unprecedented Damage Tolerance","Raul BERMEJO","MONTANUNIVERSITAET LEOBEN","Advanced ceramics are often combined with metals, polymers or other ceramics to produce structural and functional systems with exceptional properties. Examples are resistors and capacitors in microelectronics, piezo-ceramic actuators in car injection devices, and bio-implants for hip joint replacements. However, a critical issue affecting the functionality, lifetime and reliability of such systems is the initiation and uncontrolled propagation of cracks in the brittle ceramic parts, yielding in some cases rejection rates up to 70% of components production.
The remarkable “damage tolerance” found in natural materials such as wood, bone or mollusc, has yet to be achieved in technical ceramics, where incipient damage is synonymous with catastrophic failure. Novel “multilayer designs” combining microstructure and architecture could change this situation. Recent work of the PI has shown that tuning the location of “protective” layers within a 3D multilayer ceramic can increase its fracture resistance by five times (from ~3.5 to ~17 MPa∙m1/2) relative to constituent bulk ceramic layers, while retaining high strength (~500 MPa). By orienting the grain structure, similar to the textured and organized microstructure found in natural systems such as nacre, the PI has shown that crack propagation can be controlled within the textured ceramic layer. Thus, I believe tailored microstructures with controlled grain boundaries engineered in a layer-by-layer 3D architectural design hold the key to a new generation of “damage tolerant” ceramics.
This proposal outlines a research program to establish new scientific principles for the fabrication of innovative ceramic components that exhibit unprecedented damage tolerance. The successful implementation of microstructural features (e.g. texture degree, tailored internal stresses, second phases, interfaces) in a layer-by-layer architecture will provide outstanding lifetime and reliability in both structural and functional ceramic devices.","1985000","2019-05-01","2024-04-30"
"CerQuS","Certified Quantum Security","Dominique UNRUH","TARTU ULIKOOL","""Digital communication permeates all areas of today's daily life. Cryptographic protocols are used to secure that
communication. Quantum communication and the advent of quantum computers both threaten existing cryptographic
solutions, and create new opportunities for secure protocols. The security of cryptographic systems is normally ensured by
mathematical proofs. Due to human error, however, these proofs often contain errors, limiting the usefulness of said proofs.
This is especially true in the case of quantum protocols since human intuition is well-adapted to the classical world, but not
to quantum mechanics. To resolve this problem, methods for verifying cryptographic security proofs using computers (i.e.,
for """"certifying"""" the security) have been developed. Yet, all existing verification approaches handle classical cryptography
only - for quantum protocols, no approaches exist.

This project will lay the foundations for the verification of quantum cryptography. We will design logics and software tools
for developing and verifying security proofs on the computer, both for classical protocols secure against quantum computer
(post-quantum security) and for protocols that use quantum communication.

Our main approach is the design of a logic (quantum relational Hoare logic, qRHL) for reasoning about the relationship
between pairs of quantum programs, together with an ecosystem of manual and automated reasoning tools, culminating in
fully certified security proofs for real-world quantum protocols.

As a final result, the project will improve the security of protocols in the quantum age, by removing one possible source of
human error. In addition, the project directly impacts the research community, by providing new foundations in program
verification, and by providing cryptographers with new tools for the verification of their protocols.
""","1716475","2019-06-01","2024-05-31"
"CGCglasmaQGP","The nonlinear high energy regime of Quantum Chromodynamics","Tuomas Veli Valtteri Lappi","JYVASKYLAN YLIOPISTO","""This proposal concentrates on Quantum Chromodynamics (QCD) in its least well  understood ""final frontier"": the high energy limit. The aim is to treat the formation of quark gluon plasma in relativistic nuclear collisions together with other high energy processes in a consistent QCD framework.  This project is topical now in order to fully understand the results from the maturing LHC heavy ion program. The high energy regime is characterized by a high density of gluons, whose nonlinear interactions are beyond the reach of simple perturbative calculations. High energy particles also propagate nearly on the light cone, unaccessible to Euclidean lattice calculations. The nonlinear interactions at high density lead to the phenomenon of gluon saturation. The emergence of the ""saturation scale"", a semihard typical transverse momentum, enables a weak coupling expansion around a nonperturbatively large color field. This project aims to make progress both in collider phenomenology and in more conceptual aspects of nonabelian gauge field dynamics at high energy density:
1. Significant advances towards higher order accuracy will be made in cross section calculations for processes where a dilute probe collides with the strong color field of a high energy nucleus. 
2. The quantum fluctuations around the strong color fields in the initial stages of a relativistic heavy ion collision will be analyzed with a new numerical method based on an explicit linearization of the equations of motion, maintaining a well defined weak coupling limit.
3. Initial conditions for fluid dynamical descriptions of the quark gluon plasma phase in heavy ion collisions will be obtained from a constrained QCD calculation.
We propose to achieve these goals with modern analytical and numerical methods, on which the P.I. is a leading expert.  This project would represent a leap in the field towards better quantitative first principles understanding of QCD in a new kinematical domain.""","1935000","2016-10-01","2021-09-30"
"CHAMELEON","Intuitive editing of visual appearance from real-world datasets","Diego Gutierrez Pérez","UNIVERSIDAD DE ZARAGOZA","Computer-generated imagery is now ubiquitous in our society, spanning fields such as games and movies, architecture, engineering, or virtual prototyping, while also helping create novel ones such as computational materials. With the increase in computational power and the improvement of acquisition techniques, there has been a paradigm shift in the field towards data-driven techniques, which has yielded an unprecedented level of realism in visual appearance. Unfortunately, this leads to a series of problems, identified in this proposal: First, there is a disconnect between the mathematical representation of the data and any meaningful parameters that humans understand; the captured data is machine-friendly, but not human friendly. Second, the many different acquisition systems lead to heterogeneous formats and very large datasets. And third, real-world appearance functions are usually nonlinear and high-dimensional. As a result, visual appearance datasets are increasingly unfit to editing operations, which limits the creative process for scientists, engineers, artists and practitioners in general.  There is an immense gap between the complexity, realism and richness of the captured data, and the flexibility to edit such data. 

We believe that the current research path leads to a fragmented space of isolated solutions, each tailored to a particular dataset and problem. We propose a research plan at the theoretical, algorithmic and application levels, putting the user at the core. We will learn key relevant appearance features in terms humans understand, from which intuitive, predictable editing spaces, algorithms, and workflows will be defined. In order to ensure usability and foster creativity, we will also extend our research to efficient simulation of visual appearance, exploiting the extra dimensionality of the captured datasets. Achieving our goals will finally enable us to reach the true potential of real-world captured datasets in many aspects of society.","1629519","2016-11-01","2021-10-31"
"CHEMMINE","Chemical proteome mining for functional annotation of disease relevant proteins","Stephan SIEBER","TECHNISCHE UNIVERSITAET MUENCHEN","Genome sequencing projects have provided unique insights into the cellular inventory of genes and their corresponding protein products. Despite this success, a large fraction of cellular proteins remains functionally uncharacterized. Their annotation represents a major challenge for contemporary research, reaching beyond the power of bioinformatic sequence similarity searches. Thus multidisciplinary strategies consolidating chemical and biological methods are required to close this gap. We here approach the challenge by two chemical proteomic platforms that focus on disease relevant sub-fractions of the uncharacterized proteome. The first platform utilizes functionalized cofactors that exploit cognate cellular uptake systems and report specific binding of large enzyme families. The molecules will be applied to mine cellular proteomes for unknown family members with crucial roles in diseases and assign their function. The second platform exploits phosphoaspartate as an important disease-related post-translational modification. Due to low stability, this transient modification currently escapes detection by established proteomic procedures. Moreover, little is known about the enzymes that catalyze aspartate phosphorylation. We here use specific nucleophilic traps that convert phosphoaspartate into stable modifications suitable for analytic detection. In addition, the complement of currently unknown phosphodonor proteins will be identified with customized tools. With these platforms we aim to functionally annotate sub-fractions of the uncharacterized proteome and utilize our tools for the identification of new drug targets by comparative analysis of healthy and diseased cells. Finally, we apply the camouflaged molecular design strategy in the synthesis of compound libraries to screen for candidate inhibitors against selected, disease-modulating targets. The previous record of my group in chemical proteomics provides a strong basis to achieve these challenging goals.","1936250","2017-03-01","2022-02-28"
"chemREPEAT","Structure and Dynamics of Low-Complexity Regions in Proteins: The Huntingtin Case","Pau Bernado Pereto","INSTITUT NATIONAL DE LA SANTE ET DE LA RECHERCHE MEDICALE","Proteins hosting regions highly enriched in one or few amino acids, the so-called Low-Complexity Regions (LCR), are very common in eukaryotes and play crucial roles in biology. Homorepeats, a subfamily of LCR that present stretches of the same amino acid, perform very specialized functions facilitated by the localized enrichment of the same physicochemical property. In contrast, numerous severe pathologies have been associated to abnormally long repetitions. Despite the relevance of homorepeats, their high-resolution characterization by traditional structural biology techniques is hampered by the degeneracy of the amino acid environments and their intrinsic flexibility. In chemREPEAT, I will develop strategies to incorporate isotopically labelled and unnatural amino acids at specific positions within homorepeats that will overcome present limitations. These labelled positions will be unique probes to investigate for first time the structure and dynamics of homorepeats at atomic level using complementary biophysical techniques. Computational tools will be specifically developed to derive three-dimensional conformational ensembles of homorepeats by synergistically integrating experimental data.
chemREPEAT strategies will be developed on huntingtin (Htt), the prototype of repetitive protein. Htt hosts a glutamine tract that is linked with Huntington’s disease (HD), a deadly neuropathology appearing in individuals with more than 35 consecutive Glutamine residues that represent a pathological threshold. The application of the developed approaches to several Htt constructions with different number of Glutamines will reveal the structural bases of the pathological threshold in HD and the role played by the regions flanking the Glutamine tract.
The strategies designed in chemREPEAT will expand present frontiers of structural biology to unveil the structure/function relationships for LCRs. This capacity will pave the way for a rational intervention in associated diseases.","1999844","2015-09-01","2020-08-31"
"CheSSTaG","Chemotactic Super-Selective Targeting of Gliomas","Giuseppe BATTAGLIA","UNIVERSITY COLLEGE LONDON","I propose here a research program aimed to the design a completely new platform for drug delivery. I will combine our existing repertoire of molecular engineering tools based around our established approach to design responsive nanoparticles known as Polymersomes to integrate new features using clinically safe and biodegradable components that will make them super-selective and chemotactic toward glucose gradients so to deliver large therapeutic payload into the central nervous systems and the brain in particular targeting cancer cells harbouring within the healthy. We will do so by engineering components using supramolecular interaction inspired by biological complexity equipping carriers with the ability to self-propelled as a function of glucose gradient. I will complement our proposed design with advanced biological characterisation associating functional information arising form the physiological barrier to structural parameters integrated into the final carrier design.","2081747","2018-05-01","2023-04-30"
"CHIC","On CHip terahertz frequency Combs","Giacomo Scalari","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","The terahertz (THz) portion of the electromagnetic spectrum is the junction between optics and electronics.   THz is a gate to sensing applications and spectroscopy as well as appealing for material inspection,  non-invasive imaging for safety and medical applications and short-range high data rate wireless communication  which are being extended to higher frequencies entering the THz range. Optical frequency combs have dominated the scene of laser physics in the last 10 years revolutionizing many fields of optics from metrology to high precision spectroscopy. Optical frequency combs act as rulers in the frequency domain and are characterized by their perfectly equally spaced and coherent modes. An extremely appealing application of optical frequency combs is the so-called dual-comb spectroscopy where multi-heterodyne detection is performed allowing Fourier transform spectroscopy with high resolution, high sensitivity and no moving parts. 
The objective of this proposal is to create on-chip, self-referenced frequency combs operating in the spectral region from 1.5-5-5 THz.  Two main approaches will be followed: direct generation with THz QC lasers (cryogenically cooled) and room temperature non-linear generation by means of Mid-IR QCL combs.  Such devices will be groundbreaking since they will allow high resolution THz spectroscopy and they will pave the way to high-rate local data transmission and coherent communication. We recently demonstrated octave spanning lasing from a THz QCL: this will constitute the foundation of our efforts. The developed combs will be implemented in the extremely powerful dual-comb scheme with innovative on-chip self-stabilization and detection of the multi-heterodyne signals.  The self-referencing and the independence from an external detector makes the proposed devices disruptive due to their extreme compactness, intrinsic stability and large bandwidth.","1999055","2017-03-01","2022-02-28"
"CHRiSHarMa","Commutators, Hilbert and Riesz transforms,Shifts, Harmonic extensions and Martingales","Stefanie Petermichl","UNIVERSITE PAUL SABATIER TOULOUSE III","This project aims to develop two arrays of questions at the heart of harmonic
analysis, probability and operator theory:

Multi-parameter harmonic analysis.

Through the use of wavelet methods in harmonic analysis, we plan to shed new
light on characterizations for boundedness of multi-parameter versions of
classical Hankel operators in a variety of settings. The classical Nehari's theorem on
the disk (1957)  has found an important generalization to Hilbert space
valued functions, known as Page's theorem. A relevant extension of Nehari's
theorem to the bi-disk had been a long standing problem, finally solved in
2000, through novel harmonic analysis methods. It's operator analog remains
unknown and constitutes part of this proposal.

Sharp estimates for Calderon-Zygmund operators and martingale
inequalities.

We make use of the interplay between objects central to
Harmonic analysis, such as the Hilbert transform, and objects central to
probability theory, martingales. This connection has seen many faces, such as
in the UMD space classification by Bourgain and Burkholder or in the formula
of Gundy-Varapoulos, that uses orthogonal martingales to model the behavior of
the Hilbert transform. Martingale methods in combination with optimal control
have advanced an array of questions in harmonic analysis in recent years. In
this proposal we wish to continue this direction as well as exploit advances
in dyadic harmonic analysis for use in questions central to probability. There
is some focus on weighted estimates in a non-commutative and scalar setting, in the understanding of discretizations
of classical operators, such as the Hilbert transform and their role played
when acting on functions defined on discrete groups. From a martingale
standpoint, jump processes come into play. Another direction is the use of
numerical methods in combination with harmonic analysis achievements for martingale estimates.","1523963","2017-01-01","2021-12-31"
"chromo-SUMMIT","Decoding dynamic chromatin signaling by single-molecule multiplex detection","Beat FIERZ","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Transient multivalent interactions are critical for biological processes such as signaling pathways controlling chromatin function. Chromatin, the nucleoprotein complex organizing the genome, is dynamically regulated by post-translational modifications (PTMs) of the chromatin fiber. Protein effectors interact with combinations of these PTMs through multivalent interactions, deposit novel PTMs, thereby propagate signaling cascades and remodel chromatin structure. To reveal the underlying molecular mechanisms, methods outside classical biochemistry are required, in particular due to the combinational complexity of chromatin PTMs and the transient supramolecular interactions crucial for their recognition. Here, we develop a novel approach, where we synthesize arrays of chemically defined designer chromatin fibers and use dynamic multiplex single-molecule imaging to dissect multivalent signaling processes in chromatin. Our studies target a key pathway, the DNA damage response (DDR), which regulates DNA repair processes central to cell survival and is critically implicated in cancer. Detailed knowledge is of utmost importance to develop targeted therapeutic interventions. We thus employ advanced peptide and protein chemistry to generate libraries of chromatin fibers of a defined PTM state that is encoded in the chromatin DNA. With the library immobilized in a flow cell, we use single-molecule detection to directly observe signaling processes by key DDR effectors in real time. Subsequent in situ polony decoding allows the identification of each chromatin fiber’s modification state, enabling broad sampling of signaling outcomes. Finally, we use dynamic computational models to integrate the effector-chromatin interaction network and test key mechanisms in cancer-based cell culture. Together, these methods will yield fundamental insight into chromatin and DDR signaling and will be of broad use for chemical and biomedical research with applications beyond the chromatin field.","1999815","2017-05-01","2022-04-30"
"CHRONOS","A geochemical clock to measure timescales of volcanic eruptions","Diego Perugini","UNIVERSITA DEGLI STUDI DI PERUGIA","""The eruption of volcanoes appears one of the most unpredictable phenomena on Earth. Yet the situation is rapidly changing. Quantification of the eruptive record constrains what is possible in a given volcanic system. Timing is the hardest part to quantify.
The main process triggering an eruption is the refilling of a sub-volcanic magma chamber by a new magma coming from depth. This process results in magma mixing and provokes a time-dependent diffusion of chemical elements. Understanding the time elapsed from mixing to eruption is fundamental to discerning pre-eruptive behaviour of volcanoes to mitigate the huge impact of volcanic eruptions on society and the environment.
The CHRONOS project proposes a new method that will cut the Gordian knot of the presently intractable problem of volcanic eruption timing using a surgical approach integrating textural, geochemical and experimental data on magma mixing. I will use the compositional heterogeneity frozen in time in the rocks the same way a broken clock at a crime scene is used to determine the time of the incident. CHRONOS will aim to:
1) be the first study to reproduce magma mixing, by performing unique experiments constrained by natural data and using natural melts, under controlled rheological and fluid-dynamics conditions;
2) obtain unprecedented high-quality data on the time dependence of chemical exchanges during magma mixing;
3) derive empirical relationships linking the extent of chemical exchanges and the mixing timescales;
4) determine timescales of volcanic eruptions combining natural and experimental data.
CHRONOS will open a new window on the physico-chemical processes occurring in the days preceding volcanic eruptions providing unprecedented information to build the first inventory of eruption timescales for planet Earth. If these timescales can be linked with geophysical signals occurring prior to eruptions, this inventory will have an immense value, enabling precise prediction of volcanic eruptions.""","1993813","2014-05-01","2019-04-30"
"CIRCUS","An end-to-end verification architecture for building Certified Implementations of Robust,  Cryptographically Secure web applications","Karthikeyan Bhargavan","INSTITUT NATIONAL DE RECHERCHE ENINFORMATIQUE ET AUTOMATIQUE","The security of modern web applications depends on a variety of critical components including cryptographic libraries, Transport Layer Security (TLS), browser security mechanisms, and single sign-on protocols. Although these components are widely used, their security guarantees remain poorly understood, leading to subtle bugs and frequent attacks.
Rather than fixing one attack at a time, we advocate the use of formal security verification to identify and eliminate entire classes of vulnerabilities in one go. With the aid of my ERC starting grant, I have built a team that has already achieved landmark results in this direction. We built the first TLS implementation with a cryptographic proof of security. We discovered high-profile vulnerabilities such as the recent Triple Handshake and FREAK attacks, both of which triggered critical security updates to all major web browsers and TLS libraries.
So far, our security theorems only apply to carefully-written standalone reference implementations. CIRCUS proposes to take on the next great challenge: verifying the end-to-end security of web applications running in mainstream software. The key idea is to identify the core security components of web browsers and servers and replace them by rigorously verified components that offer the same functionality but with robust security guarantees.
Our goal is ambitious and there are many challenges to overcome, but we believe this is an opportune time for this proposal. In response to the Snowden reports, many cryptographic libraries and protocols are currently being audited and redesigned. Standards bodies and software developers are inviting researchers to help analyse their designs and code. Responding to their call requires a team of researchers who are willing to deal with the messy details of nascent standards and legacy code, and at the same time prove strong security theorems based on precise cryptographic assumptions. We are able, we are willing, and the time is now.","1885248","2016-04-01","2021-03-31"
"CIRQUSS","Circuit Quantum Electrodynamics with Single Electronic and Nuclear Spins","Patrice Emmanuel Bertet","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","""Electronic spins are usually detected by their interaction with electromagnetic fields at microwave frequencies. Since this interaction is very weak, only large ensembles of spins can be detected. In circuit quantum electrodynamics (cQED) on the other hand, artificial superconducting atoms are made to interact strongly with microwave fields at the single photon level, and quantum-limited detection of few-photon microwave signals has been developed.

The goal of this project is to apply the concepts and techniques of cQED to the detection and manipulation of electronic and nuclear spins, in order to reach a novel regime in which a single electronic spin strongly interacts with single microwave photons. This will lead to

1)	A considerable enhancement of the sensitivity of spin detection by microwave methods. We plan to detect resonantly single electronic spins in a few milliseconds. This could enable A) to perform electron spin resonance spectroscopy on few-molecule samples B) to measure the magnetization of various nano-objects at millikelvin temperatures, using the spin as a magnetic sensor with nanoscale resolution.

2)	Applications in quantum information science. Strong interaction with microwave fields at the quantum level will enable the generation of entangled states of distant individual electronic and nuclear spins, using superconducting qubits, resonators and microwave photons, as “quantum data buses” mediating the entanglement. Since spins can have coherence times in the seconds range, this could pave the way towards a scalable implementation of quantum information processing protocols.

These ideas will be primarily implemented with NV centers in diamond, which are electronic spins with properties suitable for the project.""","1999995","2014-03-01","2019-02-28"
"CITRES","Chemistry and interface tailored lead-free relaxor thin films for energy storage capacitors","Marco DELUCA","MATERIALS CENTER LEOBEN FORSCHUNG GMBH","The goal of CITRES is to provide new energy storage devices with high power and energy density by developing novel multilayer ceramic capacitors (MLCCs) based on relaxor thin films (RTF). 

Energy storage units for energy autonomous sensor systems for the Internet of Things (IoT) must possess high power and energy density to allow quick charge/recharge and long-time energy supply. Current energy storage devices cannot meet those demands: Batteries have large capacity but long charging/discharging times due to slow chemical reactions and ion diffusion. Ceramic dielectric capacitors – being based on ionic and electronic polarisation mechanisms – can deliver and take up power quickly, but store much less energy due to low dielectric breakdown strength (DBS), high losses, and leakage currents. 

RTF are ideal candidates: (i) Thin film processing allows obtaining low porosity and defects, thus enhancing the DBS; (ii) slim polarisation hysteresis loops, intrinsic to relaxors, allow reducing the losses. High energy density can be achieved in RTF by maximising the polarisation and minimising the leakage currents. Both aspects are controlled by the amount, type and local distribution of chemical substituents in the RTF lattice, whereas the latter depends also on the chemistry of the electrode metal. 
 
In CITRES, we will identify the influence of substituents on electric polarisation from atomic to macroscopic scale by combining multiscale atomistic modelling with advanced structural, chemical and electrical characterizations on several length scales both in the RTF bulk and at interfaces with various electrodes. This will allow for the first time the design of energy storage properties of RTF by chemical substitution and electrode selection.

The ground-breaking nature of CITRES resides in the design and realisation of RTF-based dielectric MLCCs with better energy storage performances than supercapacitors and batteries, thus enabling energy autonomy for IoT sensor systems.","1996519","2019-04-01","2024-03-31"
"CLIMAHAL","Climate dimension of natural halogens in the Earth system: Past, present, future","Alfonso SAIZ LOPEZ","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Naturally-emitted very short-lived halogens (VSLH) have a profound impact on the chemistry and composition of the atmosphere, destroying greenhouse gases and altering aerosol production, which together can change the Earth´s radiative balance. Therefore, natural halogens possess leverage to influence climate, although their contribution to climate change is not well established and most climate models have yet to consider their effects. Also, there is increasing evidence that natural halogens i) impact on the air quality of coastal cities,  ii) accelerates the atmospheric deposition of mercury (a toxic heavy metal) and iii) that their natural ocean and ice emissions are controlled by biological and photochemical mechanisms that may respond to climate changes. Motivated by the above, this project aims to quantify the so far unrecognized natural halogen-climate feedbacks and the impact of these feedbacks on global atmospheric oxidizing capacity (AOC) and radiative forcing (RF) across pre-industrial, present and future climates. Answering these questions is essential to predict if these climate-mediated feedbacks can reduce or amplify future climate change. To this end we will develop a multidisciplinary research approach using laboratory and field observations and models interactively that will allow us to peel apart the detailed physical processes behind the contribution of natural halogens to global climate change. Furthermore, the work plan also involves examining past-future climate impacts of natural halogens within a holistic Earth System model, where we will develop the multidirectional halogen interactions in the land-ocean-ice-biosphere-atmosphere coupled system. This will provide a breakthrough in our understanding of the importance of these natural processes for the composition and oxidation capacity of the Earth´s atmosphere and climate, both in the presence and absence of human influence.","1979112","2017-09-01","2022-08-31"
"CLUSTER","Birth of solids: atomic-scale processes in crystal nucleation","Rolf Erni","EIDGENOSSISCHE MATERIALPRUFUNGS- UND FORSCHUNGSANSTALT","The goal of this project is to explore the fundamental processes which trigger the nucleation and growth of solids. Condensed matter is formed by clustering of atoms, ions or molecules. This initial step is key for the onset of crystallization, condensation and precipitate formation. Yet, despite of the scientific and technological significance of these phenomena, on an atomistic level we merely have expectations on how atoms should behave rather than experimental evidence about how the growth of solid matter is initiated. The classical nucleation theory is commonly in agreement with experiments, provided the original and the final stages are inspected qualitatively. However, the classical theory does not define what fundamentally constitutes a pre-nucleation state or how a nucleus is formed at all. CLUSTER aims at investigating the very early stages of crystalline matter formation on an unprecedented length scale. It shall explore the atomic mechanisms which prompt the formation of solids. Complemented by density functional theory calculations and molecular dynamics simulations, in-situ high-resolution electron microscopy shall be used to investigate the formation, dynamics, stability and evolution of tiniest atomic clusters which represent the embryos of solid matter. Firstly, we investigate the 3D structure of clusters deposited on suspended graphene. Secondly, we focus on cluster formation, the evolution of sub-critical nuclei and the onset of particle growth by thermal activation. Thirdly, using a novel liquid-cell approach in the transmission electron microscope, we control and monitor in-situ cluster formation and precipitation in supersaturated solutions. The results of CLUSTER, which will advance the understanding of the birth of solid matter, are important for the controlled synthesis of (nano-)materials, for cluster science and catalysis and for the development of novel materials.","2271250","2016-06-01","2021-05-31"
"CMBSPEC","Next Steps in Cosmology with CMB Spectral Distortions","Jens CHLUBA","THE UNIVERSITY OF MANCHESTER","The average spectrum of the cosmic microwave background (CMB) has long been known to be extremely close to a perfect blackbody. Yet, several processes, standard and non-standard, exist that may cause deviations from a blackbody spectrum, commonly referred to as CMB spectral distortions. Classical distortion shapes are known as Compton-y and chemical potential (µ-type) distortions; however, recently it has been shown that more general distortions can be created at redshifts 10^4 < z < 3×10^5. This makes spectral distortions a unique and powerful probe of different early-universe processes. The immense potential of CMB spectral distortion measurements and their synergies with upcoming CMB anisotropy studies (Litebird, COrE+, Stage-IV CMB) has identified them as an important future target, with several innovative experimental concepts (e.g., PIXIE, APSERa) being actively discussed by the cosmology community.

This proposal has one main goal: to transform the emerging field of CMB spectral distortions into a mature scientific discipline. The team will significantly expand and strengthen the spectral distortion science case with particular emphasis on novel time-dependent information from the recombination era (10^3 < z < 10^4) and various photon injection processes. By combining all available information, we will investigate what spectral distortions could teach us about early-universe physics and the cosmological ionization history. Novel foreground parameterizations and experimental setups will be studied and simulation pipelines will be developed. Our work could deliver new tests for inflation, reionization and particle physics as well as extend our ability to distinguish sources of different distortion signals in the presence of foregrounds. We will identify novel spectral distortion science goals that will drive the experimental designs of future CMB spectroscopy experiments, pioneering and facilitating spectral distortion activities in Europe and worldwide.","1965171","2017-09-01","2022-08-31"
"CNT-QUBIT","Carbon Nanotube Quantum Circuits","Mark Robertus Buitelaar","UNIVERSITY COLLEGE LONDON","The aim of this proposal is to use spin qubits defined in carbon nanotube quantum dots to demonstrate measurement-based entanglement in an all-electrical and scalable solid-state architecture. The project makes use of spin-orbit interaction to drive spin rotations in the carbon nanotube host system and hyperfine interaction to store quantum information in the nuclear spin states. The proposal builds on techniques developed by the principal investigator for fast and non-invasive read-out of the electron spin qubits using radio-frequency reflectometry and spin-to-charge conversion.

Any quantum computer requires entanglement. One route to achieve entanglement between electron spin qubits in quantum dots is to use the direct interaction of neighbouring qubits due to their electron wavefunction overlap. This approach, however, becomes rapidly impractical for any large scale quantum processor, as distant qubits can only be entangled through the use of qubits in between. Here I propose an alternative strategy which makes use of an intriguing quantum mechanical effect by which two spatially separated spin qubits coupled to a single electrical resonator become entangled if a measurement cannot tell them apart.

The quantum information encoded in the entangled electron spin qubits will be transferred to carbon-13 nuclear spins which are used as a quantum memory with coherence times that exceed seconds. Entanglement with further qubits then proceeds again via projective measurements of the electron spin qubits without risk of losing the existing entanglement. When entanglement of the electron spin qubits is heralded – which might take several attempts – the quantum information is transferred again to the nuclear spin states. This allows for the coupling of large numbers of physically separated qubits, building up so-called graph or cluster states in an all-electrical and scalable solid-state architecture.","1998574","2015-09-01","2020-08-31"
"COAT","Collapse Of Atmospheric Turbulence","Bas Johannes Henricus Van de wiel","TECHNISCHE UNIVERSITEIT DELFT","This project aims to predict the cessation of continuous turbulence in the evening boundary layer. The interaction between the lower atmosphere and the surface is studied in detail, as this plays a crucial role in the dynamics. Present generation forecasting models are incapable to predict whether or not turbulence will survive or collapse under cold conditions. In nature, both situations frequently occur and lead to completely different temperature signatures. As such, significant forecast errors are made, particularly in arctic regions and winter conditions. Therefore, prediction of turbulence collapse is highly relevant for weather and climate prediction.
Key innovation lies in our hypothesis. The collapse of turbulence is explained from a maximum sustainable heat flux hypothesis which foresees in an enforcing positive feedback between the atmosphere and the underlying surface. A comprehensive theory for the transition between the main two nocturnal regimes would be ground-breaking in meteorological literature.
We propose an integrated approach, which combines in-depth theoretical work, simulation with models of various hierarchy (DNS, LES, RANS), and observational analysis. Such comprehensive methodology is new with respect to the problem at hand.  An innovative element is the usage of Direct Numerical Simulation in combination with dynamical surface interactions. This advanced technique fully resolves turbulent motions up to their smallest scale without the need to rely on subgrid closure assumptions. From a 10-year dataset (200m mast at Cabauw, Netherlands) nights are classified according to their turbulence characteristics. Multi-night composites are used as benchmark-cases to guide realistic numerical modelling. In the validation phase, generality of the results with respect to both climate and surface characteristics is assessed by comparison with the FLUXNET data-consortium, which operates on a long-term basis over 240 sites across the globe.","1659580","2016-01-01","2020-12-31"
"CoCoSym","Symmetry in Computational Complexity","Libor BARTO","UNIVERZITA KARLOVA","The last 20 years of rapid development in the computational-theoretic aspects of the fixed-language Constraint Satisfaction Problems (CSPs) has been fueled by a connection between the complexity and a certain concept capturing symmetry of computational problems in this class.


My vision is that this connection will eventually evolve into the organizing principle of computational complexity and will lead to solutions of fundamental problems such as the Unique Games Conjecture or even the P-versus-NP problem.  In order to break through the current limits of this algebraic approach, I will concentrate on specific goals designed to

(A) discover suitable objects capturing symmetry that reflect the complexity in problem classes, where such an object is not known yet;

(B) make the natural ordering of symmetries coarser so that it reflects the complexity more faithfully;

(C) delineate the borderline between computationally hard and easy problems;

(D) strengthen characterizations of existing borderlines to increase their usefulness as tools for proving hardness and designing efficient algorithm; and

(E) design efficient algorithms based on direct and indirect uses of symmetries.

The specific goals concern the fixed-language CSP over finite relational structures and its generalizations to infinite domains (iCSP) and weighted relations (vCSP), in which the algebraic theory is highly developed and the limitations are clearly visible. 

The approach is based on joining the forces of the universal algebraic methods in finite domains, model-theoretical and topological methods in the iCSP, and analytical and probabilistic methods in the vCSP. The starting point is to generalize and improve the Absorption Theory from finite domains.","1211375","2018-02-01","2023-01-31"
"CODA","Custom-Made Ontology Based Data Access","Carsten Lutz","UNIVERSITAET BREMEN","The emerging and vibrant area of ontology-based data access (OBDA) is currently establishing itself as an important paradigm for processing incomplete and heterogeneous data. The goal of the CODA project is to make OBDA radically more useful for real-world applications by taking a ground-breaking new perspective on its foundations, algorithms, and tools. The project will rest on an ultimately fine-grained complexity analysis that allows to identify islands of tractability inside practically important ontology and query languages that are otherwise intractable. Based on these islands, novel OBDA querying tools will be developed that are custom-made for ontologies from applications in the sense that high computational cost is incurred only when unavoidable for the concrete ontology used (`pay as you go' behaviour). The key deliverables of the project are a set of tailor-made OBDA querying tools that form a precision tool belt for real-world OBDA applications, theoretical results regarding the structure and computational complexity of important islands of tractability, efficient algorithms that allow to put these to work in practice, and optimization techniques and heuristics that support the algorithms in the tools developed. We will also collect and make available a library of case studies for evaluating OBDA tools. The project is both timely and essential. It is timely because our economy and society are currently experiencing a revolution in data processing and availability, and dealing with incompleteness and heterogeneity is one of the major arising challenges. The project is essential because it has become apparent now that current OBDA tools cannot satisfy industry requirements. In particular, they do not adequately support the limited use of expressive features (`a little bit of disjunction') which intuitively should not result in high computational cost, but with current technology often does.","1922115","2015-08-01","2020-07-31"
"COGRA","Decoding the Mechanics of Metals by Coarse-Grained Atomistics","Dennis Michael KOCHMANN","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","""""""First principles"""" and """"bottom-up"""" have become buzz words across scientific and engineering disciplines when it comes to the discovery, prediction and understanding of material properties and their link to processing and microstructure. Reality, however, teaches us that in the foreseeable future computational resources will be insufficient to apply predictive techniques such as quantum mechanics or atomistics to the technologically most relevant length and time scales - far above nanometers and nanoseconds. This proposal aims for nothing less but the seemingly impossible: the application of atomistic techniques to problems occurring over microns to millimeters and seconds to minutes. Instead of relying on computational power, this will be achieved by a combination of scale-bridging methodologies (involving the PI's nonlocal and meshless quasicontinuum techniques, concepts from particle methods, continuum and statistical mechanics) and computational science strategies in order to produce new theory and an open-source, computational toolset for long-term, large-scale simulations relying solely on atomistic input. Spatial upscaling, temporal upscaling as well as heat and mass transfer will be addressed. Enabled by the new scale-bridging capabilities, two representative, open challenges will be investigated: recrystallization in magnesium during thermo-mechanical processing and corrosion in steel by hydrogen embrittlement. Both are of enormous technological and economic importance but current techniques are insufficient to bridge the gap between the macroscopic mechanical performance, microstructural mechanisms and predictive atomic-scale simulations. The outcomes of this five-year research program will provide never-before techniques and numerical tools to catalyze a user community across science and technology. Although the focus is on metals, several of the proposed techniques are applicable to a significantly wider range of materials and applications.""","1995128","2018-03-01","2023-02-28"
"COHERENCE","Exploiting light coherence in photoacoustic imaging","Emmanuel Bossy","UNIVERSITE GRENOBLE ALPES","Photoacoustic imaging is an emerging multi-wave imaging modality that couples light excitation to acoustic detection, via the photoacoustic effect (sound generation via light absorption). Photoacoustic imaging provides images of optical absorption (as opposed to optical scattering). In addition, as photoacoustic imaging relies on detecting ultrasound waves that are very weakly scattered in biological tissue, it provides acoustic-resolution images of optical absorption non-invasively at large depths (up to several cm), where purely optical techniques have a poor resolution because of multiple scattering. As for conventional purely optical approaches, optical-resolution photoacoustic microscopy can also be performed non-invasively for shallow depth (< 1 mm), or invasively at depth by endoscopic approaches.  However, photoacoustic imaging suffers several limitations. For imaging at greater depths, non-invasive photoacoustic imaging in the acoustic-resolution regime is limited by a depth-to-resolution ratio of about 100, because ultrasound attenuation increases with frequency. Optical-resolution photoacoustic endoscopy has very recently been introduced as a complementary approach, but is currently limited in terms of resolution (> 6 µm) and footprint (diameter > 2 mm).
The overall objective of COHERENCE is to break the above limitations and reach diffraction-limited optical-resolution photoacoustic imaging at depth in tissue in vivo. To do so, the core concept of COHERENCE is to use and manipulate coherent light in photoacoustic imaging. Specifically, COHERENCE will develop novel methods based on speckle illumination, wavefront shaping and super-resolution imaging. COHERENCE will result in two prototypes for tissue imaging, an optical-resolution photoacoustic endoscope for minimally-invasive any-depth tissue imaging, and a non-invasive photoacoustic microscope with enhanced depth-to-resolution ratio, up to optical resolution in the multiply-scattered light regime.","2116290","2016-10-01","2021-09-30"
"ColloQuantO","Colloidal Quantum Dot Quantum Optics","Dan Oron","WEIZMANN INSTITUTE OF SCIENCE LTD","Colloidal semiconductor nanocrystals have already found significant use in various arenas, including bioimaging, displays, lighting, photovoltaics and catalysis. Here we aim to harness the extremely broad synthetic toolbox of colloidal semiconductor quantum dots in order to utilize them as unique sources of quantum states of light, extending well beyond the present attempts to use them as single photon sources. By tailoring the shape, size, composition and the organic ligand layer of quantum dots, rods and platelets, we propose their use as sources exhibiting a deterministic number of emitted photons upon saturated excitation and as tunable sources of correlated and entangled photon pairs. The versatility afforded in their fabrication by colloidal synthesis, rather than by epitaxial growth, presents a potential pathway to overcome some of the significant limitations of present-day solid state sources of nonclassical light, including color tunability, fidelity and ease of assembly into devices.
This program is a concerted effort both on colloidal synthesis of complex multicomponent semiconductor nanocrystals and on cutting edge photophysical studies at the single nanocrystal level. This should enable new types of emitters of nonclassical light, as well as provide a platform for the implementation of recently suggested schemes in quantum optics which have never been experimentally demonstrated. These include room temperature sources of exactly two (or more) photons, correlated photon pairs from quantum dot molecules and entanglement based on time reordering. Fulfilling the optical and material requirements from this type of system, including photostability, control of carrier-carrier interactions, and a large quantum yield, will inevitably reveal some of the fundamental properties of coupled carriers in strongly confined structures.","2000000","2016-05-01","2021-04-30"
"COMANCHE","Coherent manipulation and control of heat in solid-state nanostructures: the era of coherent caloritronics","Francesco Giazotto","CONSIGLIO NAZIONALE DELLE RICERCHE","""Electronic nanodevices have demonstrated to be versatile and effective tools for the investigation of exotic quantum phenomena under controlled and adjustable conditions. Yet, these have enabled to give access to the manipulation of charge flow with unprecedented precision. On the other hand, the wisdom dealing with control, measurements, storage, and conversion of heat in nanoscale devices, the so-called “caloritronics” (from the Latin word “calor”, i.e., heat),  despite a number of recent advances is still at its infancy. Although coherence often plays a crucial role in determining the functionalities of nanoelectronic devices very little is known of its role in caloritronics. In such a context, coherent control of heat seems at present still very far from reach, and devising methods to phase-coherently manipulate the thermal current would represent a crucial breakthrough which could open the door to unprecedented possibilities in several fields of science.
Here we propose an original approach to set the experimental ground for the investigation and implementation of a new branch of science, the “coherent caloritronics”, which will take advantage of quantum circuits to phase-coherently manipulate and control the heat current in solid-state nanostructures. To tackle this challenging task our approach will follow three main separate approaches, i.e., the coherent control of heat transported by electrons in Josephson nanocircuits, the coherent manipulation of heat carried by electrons and exchanged between electrons and lattice phonons in superconducting proximity systems,
and finally, the control of the heat exchanged between electrons and photons by coherently tuning the coupling with the electromagnetic environment. We will integrate superconductors with normal-metal or semiconductor electrodes thus exploring new device concepts such as heat transistors, heat diodes, heat splitters, where thermal flux control is achieved thanks to the use of the quantum phase.""","1754897","2014-05-01","2019-04-30"
"COMANFLO","Computation and analysis of statistical solutions of fluid flow","Siddhartha MISHRA","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","Entropy (admissible) weak solutions are widely considered to be the standard solution framework for hyperbolic systems of conservation laws and incompressible Euler equations. However, the lack of global existence results in several space dimensions, the recent demonstration of non-uniqueness of these solutions and computations showing the lack of convergence of state of the art numerical methods to them, have reinforced the need to seek alternative solution paradigms. 

Although one can show that numerical approximations of these nonlinear PDEs converge to measure-valued solutions i.e Young measures, these solutions are not unique and we need to constrain them further. Statistical solutions i.e, time-parametrized probability measures on spaces of integrable functions, are a promising framework in this regard as they can be characterized as a measure-valued solution that also contains information about all possible multi-point spatial correlations. So far, well-posedness of statistical solutions has been shown only in the case of scalar conservation laws.

The main aim of the proposed project is to analyze statistical solutions of systems of conservation laws and incompressible Euler equations and to design efficient numerical approximations for them. We aim to prove global existence of statistical solutions in several space dimensions, by showing convergence of these numerical approximations, and to identify suitable additional admissibility criteria for statistical solutions that can ensure uniqueness. We will use these numerical methods to compute statistical quantities of interest and relate them to existing theories (and observations) for unstable and turbulent fluid flows. Successful completion of this project aims to establish statistical solutions as the appropriate solution paradigm for inviscid fluid flows, even for deterministic initial data, and will pave the way for applications to astrophysics, climate science and uncertainty quantification.","1959323","2018-08-01","2023-07-31"
"COMBAT","Computational Modeling and Design of Lithium-Ion Batteries","Timon Rabczuk","BAUHAUS-UNIVERSITAET WEIMAR","""Lithium-ion batteries (LIBs) are among the most promising solutions for energy storage. Compared with other resources such as bio-fuel, solar cells, fuel cells or lead acid batteries, rechargeable batteries are more portable and allow for quick energy storage and release. The higher power and energy density make batteries suitable as the energy resource for most portable elect. devices including future vehicles. Among the rechargeable batteries, LIBs have the most potential because of their quick charging rate and high power and energy density. However, ageing of LIBs and the related capacity and power fade is a major concern. For the improvement and future development of batteries, computational modeling and design is an important complementary part to experimental testing which is expensive, time-consuming and sometimes unfeasible.

In this project, the PI proposes to develop, implement, verify and validate a computational multifield and multiscale framework to support the design and optimization of new batteries. The computational framework will support the design and optimization of new anode, separator and cathode materials as well as their structure inside the battery. The measurable outcome of this research will be an open-source software package that can be used to support the design and optimization of LIBs.

Within the computational framework, different (mechanical-thermal-electro-chemical) fields will be linked over multiple scales: from fundamental physics to the design of new battery materials. We will quantify uncertainties in order to provide upper and lower bounds of our predictions and use graph-theory, error-estimation and adaptivity to choose the appropriate model and discretization. The computational framework will be verified and validated by comparison to experiments. Finally, multi-objective optimization over multiple scales will provide a new battery prototype that will be manufactured, tested and compared to the computational predictions.""","1975071","2014-06-01","2019-05-31"
"COMIET","Engineering Complex Intestinal Epithelial Tissue Models","Elena Martínez Fraiz","FUNDACIO INSTITUT DE BIOENGINYERIA DE CATALUNYA","Epithelial barriers protect the body against physical, chemical, and microbial insults. Intestinal epithelium is one of the most actively renewing tissues in the body and a major site of carcinogenesis. Functional in vitro models of intestinal epithelium have been pursued for a long time. They are key elements in basic research, disease modelling, drug discovery, and tissue replacing and have become prime models for adult stem cell research. By taking advantage of the self-organizing properties of intestinal stem cells, intestinal organoids have been recently established, showing cell renewal’s kinetics resembling to the one found in vivo. However, the development of in vitro 3D tissue equivalents accounting for the dimensions, architecture and access to the luminal contents of the in vivo human intestinal tissue together with its self-renewal properties and cell complexity, remains a challenge. The goal of this project is to engineer intestinal epithelial tissue models that mimic physiological characteristics found in in vivo human intestinal tissue, to open up new areas of research on human intestinal diseases. The proposed models will address the in vivo intestinal epithelial cell renewal and migration, the multicell-type differentiation and the epithelial cell interactions with the underlying basement membrane while providing access to the luminal content to go beyond the state-of-the-art organoid models. To do this, we propose to develop an experimental setup that combines microfabrication techniques, tissue engineering components and recent advances in intestinal stem cell research, exploiting stem cell self-organizing characteristics. We anticipate this setup to recapitulate the 3D morphology, the spatio-chemical gradients and the dynamic microenvironment of the living tissue. We expect the new device to prove useful in understanding cell physiology, adult stem cell behaviour, and organ development as well as in modelling human intestinal diseases.","1997190","2015-12-01","2020-11-30"
"COMOTION","Controlling the Motion of Complex Molecules and Particles","Jochen Küpper","STIFTUNG DEUTSCHES ELEKTRONEN-SYNCHROTRON DESY","""The main objective of COMOTION is to enable novel experiments for the investigation of the intrinsic properties of large molecules, including biological samples like proteins, viruses, and small cells
-X-ray free-electron lasers have enabled the observation of near-atomic-resolution structures in diffraction- before-destruction experiments, for instance, of isolated mimiviruses and of proteins from microscopic crystals. The goal to record molecular movies with spatial and temporal atomic-resolution (femtoseconds and picometers) of individual molecules is near.
-The investigation of ultrafast, sub-femtosecond electron dynamics in small molecules is providing first results. Its extension to large molecules promises the unraveling of charge migration and energy transport in complex (bio)molecules.
-Matter-wave experiments of large molecules, with currently up to some hundred atoms, are testing the limits of quantum mechanics, particle-wave duality, and coherence. These metrology experiments also allow the precise measurement of molecular properties.
The principal obstacle for these and similar experiments in molecular sciences is the controlled production of samples of identical molecules in the gas phase. We will develop novel concepts and technologies for the manipulation of complex molecules, ranging from amino acids to proteins, viruses, nano-objects, and small cells: We will implement new methods to inject complex molecules into vacuum, to rapidly cool them, and to manipulate the motion of these cold gas-phase samples using combinations of external electric and electromagnetic fields. These external-field handles enable the spatial separation of molecules according to size, shape, and isomer.
The generated controlled samples are ideally suited for the envisioned precision experiments. We will exploit them to record atomic-resolution molecular movies using the European XFEL, as well as to investigate the limits of quantum mechanics using matter-wave interferometry.""","1982500","2014-09-01","2019-08-31"
"CompDB","The Computational Database for Real World Awareness","Thomas NEUMANN","TECHNISCHE UNIVERSITAET MUENCHEN","Two major hardware trends have a significant impact on the architecture of database management systems (DBMSs): First, main memory sizes continue to grow significantly. Machines with 1TB of main memory and more are readily available at a relatively low price. Second, the number of cores in a system continues to grow, from currently 64 and more to hundreds in the near future. 
This trend offers radically new opportunities for both business and science.  It promises to allow for information-at-your-fingertips, i.e., large volumes of data can be analyzed and deeply explored online, in parallel to regular transaction processing. Currently, deep data exploration is performed outside of the database system which necessitates huge data transfers. This impedes the processing such that real-time interactive exploration is impossible.  These new hardware capabilities now allow to build a true computational database system that integrates deep exploration functionality at the source of the data. This will lead to a drastic shift in how users interact with data, as for the first time interactive data exploration becomes possible at a massive scale.

Unfortunately, traditional DBMSs are simply not capable to tackle these new challenges.
Traditional techniques like interpreted code execution for query processing become a severe bottleneck in the presence of such massive parallelism, causing poor utilization of the hardware. I pursue a radically different approach: Instead of adapting the traditional, disk-based approaches, I am integrating a new just-in-time compilation framework into the in-memory database that directly exploits the abundant, parallel hardware for large-scale data processing and exploration. By explicitly utilizing cores, I will be able to build a powerful computational database engine that scales the entire spectrum of data processing - from transactional to analytical to exploration workflows - far beyond traditional architectures.","1918750","2017-06-01","2022-05-31"
"COMPUSAPIEN","Computing Server Architecture with Joint Power and Cooling Integration at the Nanoscale","David ATIENZA ALONSO","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","The soaring demand for computing power in the last years has grown faster than semiconductor technology evolution can sustain, and has produced as collateral undesirable effect a surge in power consumption and heat density in computing servers. Although computing servers are the foundations of the digital revolution, their current designs require 30-40% of the energy supplied to be dissipated in cooling. The remaining energy is used for computation, but their complex many-core designs produce very high operating temperatures. Thus, operating all the cores continuously at maximum performance levels results in system overheating and failures. This situation is limiting the benefits of technology scaling.

The COMPUSAPIEN proposal aims to completely revise the current computing server architecture. In particular, inspired by the mammalian brain, this proposal targets to design a disruptive three-dimensional (3D) computing server architecture that overcomes the prevailing worst-case power and cooling provisioning paradigm for servers. This new 3D server design champions a heterogeneous many-core architecture template with an integrated on-chip microfluidic fuel cell network for joint cooling delivery and power supply. Also, it will include a novel predictive controller based on holistic power-temperature models, which exploit the server software stack to achieve energy-scalable computing capabilities. Because of its integrated electronic-electrochemical architecture design, COMPUSAPIEN is clearly a high-risk high-reward proposal that will bring drastic energy savings with respect to current server design approaches, and will guarantee energy scalability in future server architectures. To realize this vision, COMPUSAPIEN will develop and integrate breakthrough innovations in heterogeneous computing architectures, cooling-power subsystem design, combined microfluidic power delivery and temperature management in computers.","1999281","2017-06-01","2022-05-31"
"CONCERT","Description of information transfer across macromolecules by concerted conformational changes","Xavier Salvatella Giralt","","Signal transduction in biology relies on the transfer of information across biomolecules by concerted conformational changes that cannot currently be characterized experimentally at high resolution. In CONCERT we will develop a method based on the use of nuclear magnetic resonance spectroscopy in solution that will provide very detailed descriptions of such changes by using the information about structural heterogeneity contained in a parameter that is exquisitely sensitive to molecular shape called residual dipolar coupling measured in steric alignment.  To show how this new method will allow the study of information transfer we will determine conformational ensembles that will report on the intra and inter-domain concerted conformational changes that activate the androgen receptor, a large allosteric multi-domain protein that regulates the male phenotype and is a therapeutic target for castration resistant prostate cancer, the condition suffered by prostate cancer patients that have become refractory to hormone therapy, the first line of treatment for this disease. To complement the structural information obtained by nuclear magnetic resonance and, especially, measure the rate of information transfer across the androgen receptor we will carry out in a collaborative fashion high precision single molecule Förster resonance energy transfer and fluorescence correlation spectroscopy experiments on AR constructs labelled with fluorescent dyes. In summary we will develop a method that will make it possible to describe some of the most fascinating biological phenomena, such as allostery and signal transduction, and will, in the long term, be an instrument for the discovery of drugs to treat castration resistant prostate cancer, a late stage of prostate cancer that is incurable and kills ca. 70.000 European men every year.","1950000","2015-07-01","2020-06-30"
"CONSYN","Contextualizing biomolecular circuit models for synthetic biology","Heinz KOEPPL","TECHNISCHE UNIVERSITAT DARMSTADT","Synthetic biology is the bottom-up engineering of new molecular functionality inside a biological cell. Although it aims at a quantitative and compositional approach, most of today’s implementations of synthetic circuits are based on inefficient trial-and-error runs. This approach to circuit design does not scale well with circuit complexity and is against the basic paradigm of synthetic biology. This unsatisfactory state of affairs is partly due to the lack of the right computational methodology that can support the quantitative characterization of circuits and their significant context dependency, i.e., their change in behavior upon interactions with the host machinery and with other circuit elements.
CONSYN will contribute computational methodology to overcome the trial-and-error approach and to ultimately turn synthetic circuit design into a rational bottom-up process that heavily relies on computational analysis before any actual biomolecular implementation is considered. In order to achieve this goal, we will work on the following agenda: (i) develop biophysical and statistical models of biomolecular contexts into which the synthetic circuit or synthetic part can be embedded in silico; (ii) devise new statistical inference methods that can deliver accurate characterization of circuits and their context dependency by making use of cutting-edge single-cell experimental data; (iii) derive new context-insensitive circuit designs through in silico sensitivity analysis and application of filtering theory; (iv) optimize protocols and measurement infrastructure using model-based experimental design yielding a better circuit and context characterization; (v) experimentally build synthetic circuits in vivo and in cell-free systems in order to validate and bring to life the above theoretical investigations. We are in the unique position to also address (v) in-house due to the experimental wetlab facilities in our group.","1996579","2018-04-01","2023-03-31"
"ConTExt","Connecting the Extreme","Sune Toft","KOBENHAVNS UNIVERSITET","Advances in technology and methodology over the last decade, have enabled the study of galaxies to the highest redshifts. This has revolutionized our understanding of the origin and evolution of galaxies. I have played a central role in this revolution, by discovering that at z=2, when the universe was only 3 Gyr old, half of the most massive galaxies were extremely compact and had already completed their star formation. During the last five years I have led a successful group of postdocs and students dedicated to investigating the extreme properties of these galaxies and place them into cosmological context. Combining a series of high profile observational studies published by my group and others, I recently proposed an evolutionary sequence that ties together the most extreme galaxies in the universe, from the most intense dusty starburst at cosmic dawn, through quasars: the brightest sources in the universe, driven by feedback from supermassive black holes, and galaxy cores hosting the densest conglomerations of stellar mass known, to the sleeping giants of the local universe, the giant ellipticals. The proposed research program will explore if such an evolutionary sequence exists, with the ultimate goal of reaching, for the first time, a coherent physical understanding of how the most massive galaxies in the universe formed. While there is a chance the rigorous tests may ultimately reveal the proposed sequence to be too simplistic, a guarantied outcome of the program is a significantly improved understanding of the physical mechanisms that shape galaxies and drive their star formation and quenching","1999526","2015-09-01","2020-08-31"
"CONTROLPASTCO2","Quantifying the link between weathering and past CO2 levels","Philip Pogge von Strandmann","UNIVERSITY COLLEGE LONDON","The carbon cycle is a vital aspect of our planet’s well-being. However, there are fundamental aspects of it that we do not understand, without which we cannot accurately quantify CO2 budgets. How, and at what rate, does the carbon cycle respond to, and recover from, events of rapid and extreme global warming or cooling? What process has maintained the climate within a habitable range for billions of years? Silicate weathering is Earth’s main long-term CO2 removal process, and therefore a dominant climate control mechanism. Critically, we do not understand the controls on silicate weathering, or its full effects on atmospheric pCO2 and climate. 
The goal of this project is to determine and quantify how weathering responded during past periods of rapid climate change, using an innovative combination of novel stable isotope techniques, laboratory experiments and advanced carbon cycle modelling. This will determine the behaviour of a key, relatively unknown, factor in the carbon cycle. This project comprises three, highly novel, interlinked strands: 1) Examination of the palaeo-weathering record through recent glacial timescales using cave speleothems as a climate archive, 2) Determination of palaeo-weathering records through older, Cenozoic, rapid shifts in climate, using marine carbonates and clays as an archive, and 3) Advanced models to enhance our understanding of this record. 
This project will radically improve our quantitative knowledge of the controls over the carbon cycle. This is critical because 1) it is possible that weathering is the process that has maintained Phanerozoic climate in the relatively narrow bands required for life; 2) it is impossible to decipher the causes and consequences of long-term climate variations through Earth’s history without accurate weathering data; 3) detailed comprehension of rapid climate variations will enable more accurate predictions of future CO2 drawdown.","2000000","2017-02-01","2022-01-31"
"COQCOoN","COntinuous variables Quantum COmplex Networks","Valentina PARIGI","SORBONNE UNIVERSITE","At different scales, from molecular systems to technological infrastructures, physical systems group in structures which are neither simply regular or random, but can be represented by networks with complex shape. Proteins in metabolic structures and the World Wide Web, for example, share the same kind of statistical distribution of connections of their constituents. In addition, the individual elements of natural samples, like atoms or electrons, are quantum objects. Hence replicating complex networks in a scalable quantum platform is a formidable opportunity to learn more about the intrinsic quantumness of real world and for the efficient exploitation of quantum-complex structures in future technologies. Future trusted large-scale communications and efficient big data handling, in fact, will depend on at least one of the two aspects -quantum or complex- of scalable systems, or on an appropriate combination of the two.

In COQCOoN I will tackle both the quantum and the complex structure of physical systems. I will implement large quantum complex networks via multimode quantum systems based on both temporal and frequency modes of parametric processes pumped by pulsed lasers. Quantum correlations between amplitude and phase continuous variables will be arranged in complex topologies and delocalized single and multiple photon excitations will be distributed in the network.  I aim at:
-Learn from nature: I will reproduce complex topologies in the quantum network to query the quantum properties of natural processes, like energy transport and synchronization, and investigate how nature-inspired efficient strategies can be transferred in quantum technologies. 
-Control large quantum architectures: I will experiment network topologies that make quantum communication and information protocols resilient against internal failures and environmental changes. I will setup distant multi-party quantum communications and quantum simulation in complex networks.","1990000","2019-06-01","2024-05-31"
"CoreSat","Dynamics of Earth’s core from multi-satellite observations","Christopher FINLAY","DANMARKS TEKNISKE UNIVERSITET","Earth's magnetic field plays a fundamental role in our planetary habitat, controlling interactions between the Earth and the solar wind.  Here, I propose to use magnetic observations, made simultaneously by multiple satellites, along with numerical models of outer core dynamics, to test whether convective processes can account for ongoing changes in the field.  The geomagnetic field is generated by a dynamo process within the core converting kinetic energy of the moving liquid metal into magnetic energy.  Yet observations show a region of persistently weak field in the South Atlantic that has grown in size in recent decades.   Pinning down the core dynamics responsible for this behaviour is essential if we are to understand the detailed time-dependence of the geodynamo, and to forecast future field changes.

Global magnetic observations from the Swarm constellation mission, with three identical satellites now carrying out the most detailed ever survey of the geomagnetic field,  provide an exciting opportunity to probe the dynamics of the core in exquisite detail. To exploit this wealth of data, it is urgent that contaminating magnetic sources in the lithosphere and ionosphere are better separated from the core-generated field. I propose to achieve this, and to test the hypothesis that core convection has controlled the recent field evolution in the South Atlantic, via three interlinked projects.  First I will co-estimate separate models for the lithospheric and core fields, making use of prior information from crustal geology and dynamo theory.  In parallel, I will develop a new scheme for isolating and removing the signature of polar ionospheric currents,  better utilising ground-based data. Taking advantage of these improvements, data from Swarm and previous missions will be reprocessed and then assimilated into a purpose-built model of quasi-geostrophic core convection.","1828708","2018-03-01","2023-02-28"
"CORNEA","Controlling evolutionary dynamics of networked autonomous agents","Ming CAO","RIJKSUNIVERSITEIT GRONINGEN","Large-scale technological, biological, economic, and social complex systems act as complex networks of interacting autonomous agents. Large numbers of interacting agents making self-interested decisions can result in highly complex, sometimes surprising, and often suboptimal, collective behaviors. Empowered by recent breakthroughs in data-driven cognitive learning technologies, networked agents collectively give rise to evolutionary dynamics that cannot be easily modeled, analysed and/or controlled using current systems and control theory. Consequently, there is an urgent need to develop new theoretical foundations to tackle the emerging challenging control problems associated with evolutionary dynamics for networked autonomous agents.

The aim of this project is to develop a rigorous theory for the control of evolutionary dynamics so that interacting autonomous agents can be guided to solve group tasks through the pursuit of individual goals in an evolutionary dynamical process. The theory will then be tested, validated and improved against experimental results using robotic fish.

To achieve the aim, I will: (1) develop a general formulation for stochastic evolutionary dynamics with control inputs, enabling the study on controllability and stabilizability for evolutionary processes; (2) introduce stochastic control Lyapunov functions to design control laws; (3) construct new classes of conditional strategies that may propagate controlled actions effectively from focal agents in multiple time scales; and (4) validate experimentally on tasks with unknown difficulties that require a group of robotic fish to evolve and adapt. 

The project will result in a major advance from the conventional usage of evolutionary game theory with the systematic design to actively control evolutionary outcomes. The combination of theory with experimentation and the multi-disciplinary nature of the approach will lead to new applications of autonomous robotic systems.","1998933","2018-05-01","2023-04-30"
"CORONALDOLLS","Multi-Scale Coronal Heating: A New Approach to an Old Question.","Ine Marie J Ineke De Moortel","THE UNIVERSITY COURT OF THE UNIVERSITY OF ST ANDREWS","CORONALDOLLS will tackle the long-standing question of the extremely high temperatures in the Sun’s outer atmosphere (corona) by taking a modern, progressive approach: forward modelling (creating synthetic observations) will be used to (i) link 3D numerical simulations of in-depth models with large scale computational experiments and (ii) provide observational diagnostics to compare models to high resolution, multi wavelength observations both qualitatively and quantitatively. This timely, multi-scale (‘russian dolls’) approach will achieve an innovative synergy between coronal heating and coronal seismology, where the coronal heating models will use input from, and be benchmarked against, information gained about the solar atmosphere through coronal seismology.

From a series of in-depth, 3D numerical studies, considering, in turn, three of the most promising heating processes (Taylor relaxation, braiding and Alfvén wave heating) at their particular spatial and temporal scales, we will determine:
- the cadence of the heating: low-frequency (‘bursty’) vs high-frequency (‘near-continuous’);
- the range of parameters for which heating is most efficient (i.e. reaches a threshold temperature and is distributed throughout the 3D volume);
- observational diagnostics to compare with large scale computational experiments and observational data.

This systematic, comprehensive study will allow CORONALDOLLS to answer the fundamental question: Can we unambiguously identify physical heating mechanisms and determine their relative contributions, both in large-scale numerical simulations and high resolution observations and, if so, how?

In parallel, the advanced 3D computational models will provide a ‘proof of concept’ for coronal seismology, i.e. establish the robustness of the currently used simple models and how the interpretation of observed waves and oscillations in the optically thin solar atmosphere is affected by line-of-sight integration and instrument resolution.","2000000","2015-10-01","2020-09-30"
"CORPHO","Theory of strongly correlated photonic systems","Cristiano Ciuti","UNIVERSITE PARIS DIDEROT - PARIS 7","""The physics of complex quantum systems with controllable interactions is emerging as a fundamental topic for a broad community, providing an opportunity to test theories of strongly correlated quantum many-body systems and opening interesting applications such as quantum simulators. Recently, in solid-state structures with effective photon-photon interactions the rich physics of quantum fluids of light has been explored, albeit not yet in the regime of strong photonic correlations. Exciting advances in cavity Quantum Electro-Dynamics (QED) and superconducting circuit QED make strong photon-photon interactions now accessible. A growing interest is focusing on lattices of coupled resonators, implementing Hubbard-like Hamiltonians for photons injected by pump driving fields. Similarly to electronic systems, the physics of large two-dimensional (2D) photonic lattices is a fundamental theoretical challenge in the regime of strong correlations. CORPHO has the ambition to develop novel scalable theoretical methods for 2D lattices of cavities, including spatially inhomogeneous driving and dissipation. The proposed methods are based on a hybrid strategy combining cluster mean-field theory and Wave Function Monte Carlo on a physical ‘Corner’ of the Hilbert space in order to calculate the steady-state density matrix and the properties of the non-equilibrium phases. We will study 2D lattices with complex unit cells and ‘fractional’ driving (only a fraction of the sites is pumped), a configuration that, according to recent preliminary studies, is expected to dramatically enhance and enrich quantum correlations.  We will also investigate the interplay between driving and geometric frustration in 2D lattices with polarization-dependent interactions. Finally, the quantum control of strongly correlated photonic systems will be explored, including quantum feedback processes, cooling of thermal fluctuations and switching between multi-stable phases.""","1378440","2014-06-01","2019-05-31"
"corr-DFT","Improving the accuracy and reliability of electronic structure calculations: New exchange-correlation functionals from a rigorous expansion at infinite coupling strength","Paola Gori-Giorgi","STICHTING VU","By virtue of its computational efficiency, Kohn-Sham (KS) density functional theory (DFT) is the method of choice for the electronic structure calculations in computational chemistry and solid-state physics. Despite its enormous successes, KS DFT’s predictive power and overall usefulness are still hampered by inadequate approximations for near-degenerate and strongly-correlated systems. Crucial examples are transition metal complexes (key for catalysis), stretched chemical bonds (key to predict chemical reactions), technologically advanced functional materials, and manmade nanostructures.  
I aim to address these fundamental issues, by constructing a novel framework for electronic structure calculations at all correlation regimes. This new approach is based on recent formal developments from my group, which reproduce key features of strong correlation within KS DFT, without any artificial symmetry breaking. My results on the exact infinite-coupling-strength expansion of KS DFT will be used to endow that theory with many-body properties from the ground up, thereby removing its intrinsic bias for weak correlation regimes.
This requires novel combinations of ideas from three research communities: chemists and physicists that develop approximations for KS DFT, condensed matter physicists that work on strongly-correlated systems using lattice hamiltonians, and mathematicians working on mass transportation theory. The strong-correlation limit of DFT enables these links by defining a natural framework for extending lattice-based results to the real space continuum. On the other hand, this limit has a mathematical structure formally equivalent to the optimal transport problem of mathematics, enabling adaptation of methods and algorithms.
The new approximations will be implemented with the assistance of an industrial partner and validated on representative benchmark chemical and physical systems.","1999891","2015-08-01","2020-07-31"
"CORRELMAT","Predictive electronic structure calculations for materials with strong electronic correlations: long-range Coulomb interactions and many-body screening","Silke Biermann","ECOLE POLYTECHNIQUE","""Materials with strong electronic Coulomb correlations present unique electronic properties such as exotic magnetism, charge or orbital order, or unconventional optical or transport properties, including superconductivity, thermoelectricity or metal-insulator transitions. The concerted behavior of the electrons in these ``correlated materials"""" moreover leads to an extreme sensitivity to external stimuli such as changes in temperature, pressure, or external fields. This tuneability of even fundamental properties is both a harbinger for technological applications and a challenge to currently available theoretical methods: Indeed, these properties are the result of strong electron-electron interactions and subtle quantum correlations, and cannot be understood without a proper description of excited states.
The aim of the present project is to elaborate, implement and test new approaches to investigate the spectral and optical properties of correlated materials ``from first principles"""", that is, without adjustable parameters. I will build on the success of state-of-the-art dynamical mean field-based electronic structure techniques, but aim at developing them into truly first-principles methods, where a full treatment of the long-range Coulomb interactions replaces the current practice of purely local Hubbard interaction parameters. My target materials are among the most interesting for modern technologies, such as transition metal oxides (with potential applications ranging from oxide electronics to battery materials) and rare earth compounds used as environmentally-responsible pigments. Establishing first-principles techniques with truly predictive power for these classes of materials will bring us closer to the final goal of tailoring correlated materials with preassigned properties.""","1713600","2014-07-01","2019-06-30"
"COSMIC LENS","Delivering on the Promise of Measuring Dark Energy from Cosmic Lensing","Sarah Louise Bridle","THE UNIVERSITY OF MANCHESTER","The apparent gravitational distortion of distant galaxies, ‘cosmic lensing’, allows us to map dark matter and hence unveil the nature of the mysterious dark energy. I will develop novel approaches to cosmic lensing and use these to place constraints on dark energy using the Dark Energy Survey (DES). Themes 1 and 2 address key systematic effects crucial for the extraction of cosmology in theme 3. Theme 1: The lensing community has spent two decades trying to find the perfect galaxy shape measurement method. We will take a unique approach by translating a technique common in particle physics and the CMB to lensing: we will simulate images matched to observed galaxy positions and shapes, and vary lensing to accurately calibrate shapes. We will make the code public and use it to produce the final public DES shear catalogues. Theme 2: We will exploit my innovative and successful program of coordinated international challenges from shear measurement and apply it to mitigating galaxy intrinsic alignments (IA). I have shown that knowledge of IAs is essential for leveraging the potential of cosmic lensing for cosmology and described a mitigation method, but this needs to be tested on simulations. I will coordinate international IA simulation efforts and identify the optimum method for removing intrinsic alignments and apply it to the DES data. Theme 3: We have developed a skeleton software framework for cosmology, CosmoSIS. We will write modules for cosmology from imaging data incorporating the main systematic effects, and use CosmoSIS to produce the final constraints on cosmology from DES lensing. We will incorporate constraints on sterile neutrinos from particle physics for the first time. If the current tensions between cosmic lensing the CMB are confirmed by this work we will have discovered the need for new physics. Furthermore, the work in this proposal will place us in prime position to exploit the main cosmology surveys of the next decade (LSST, Euclid, WFIRST).","1997219","2016-05-01","2021-04-30"
"COSMIC-DANCE","Unraveling the origin of the Initial Mass Function","Herve Bouy","UNIVERSITE DE BORDEAUX","Despite the tremendous progress achieved over the past decade, the study of stellar formation is far from complete. We have not yet measured the minimum mass for star formation, nor the shape of the IMF down to the least massive free-floating planets, or know how universal this shape is. Although clusters are the building blocks of galaxies, little is known about their early dynamical evolution and dispersal into the field. The main culprit for this state of affairs is the high level of contamination and incompleteness in the sub-stellar regime, even for the best photometric and astrometric surveys.
COSMIC-DANCE aims at overcoming these drawbacks and revealing the shape of the IMF with a precision and completeness surpassing current and foreseeable surveys of the next 15 years. We will: 
1) Measure: using a groundbreaking, proven and so far unique method I designed, we will measure proper motions with an accuracy comparable to Gaia but 5 magnitudes deeper, reaching the planetary mass domain, and, critically, piercing through the dust obscured young clusters inaccessible to Gaia’s optical sensors.
2) Discover: feeding these proper motions and the multi-wavelength photometry to innovative hyper-dimensional data mining techniques, we will securely identify cluster members within the millions of sources of the COSMIC-DANCE database, complemented by Gaia at the bright end, to obtain the final census over the entire mass spectrum for 20 young nearby clusters, the end of a 60-year quest.
3) Understand: by providing conclusive empirical constraints over a broad parameter space unaccessible to current state-of-the-art surveys on the much debated respective contributions of evolutionary effects (dynamics, feedback and competitive accretion) and initial conditions (core properties) to the shape and bottom of the IMF, the most fundamental and informative product of star formation, with essential bearings on many areas of general astrophysics.","1859413","2016-10-01","2021-09-30"
"COSMIC-LITMUS","Turning cosmic shear into a litmus test for the standard model of cosmology","Hendrik Jurgen HILDEBRANDT","RHEINISCHE FRIEDRICH-WILHELMS-UNIVERSITAT BONN","The standard model of cosmology is impressively consistent with a large number of observations. Its parameters have been determined with great accuracy with the Planck CMB (cosmic microwave background) mission. However, recently local determinations of the Hubble constant as well as ob- servations of strong and weak gravitational lensing have found some tension with Planck. Are those observations first glimpses at a crack in the standard model and hints of an evolving dark energy com- ponent? With this ERC Consolidator Grant I will answer these questions by greatly increasing the robustness of one of those cosmological probes, the weak lensing effect of the large scale structure of the Universe also called cosmic shear.
In order to reach this goal I will concentrate on the largest outstanding source of systematic error: photometric redshifts (photo-z). I will exploit the unique combination of two European imaging surveys in the optical and infrared wavelength regime, an additional narrow-band imaging survey with extremely precise photo-z, and spectroscopic calibration data from a recently approved ESO large program on the VLT. Using angular cross-correlations and machine-learning I will calibrate the photo- z in a two-stage process making sure that this crucial systematic uncertainty will keep pace with the growing statistical power of imaging surveys. This will yield an uncertainty on the amplitude of the clustering of dark matter that is smaller than the best constraints from the CMB.
I will also apply these methods to ESA’s Euclid mission launching in 2020, which will fail if photo-z are not better understood by then. If the discrepancy between lensing and CMB measurements holds this would potentially result in a revolution of our understanding of the Universe. Regardless of this spectacular short-term possibility I will turn cosmic shear – one of the most powerful cosmological probes of dark energy – into a litmus test for our cosmological paradigm.","1931493","2018-06-01","2023-05-31"
"CosmicDust","Lighting up the dark - the evolution of dust throughout cosmic time","Haley Louise Gomez","CARDIFF UNIVERSITY","After more than two decades of infrared astronomy, we still know very little about the origin and evolution of cosmic dust in galaxies, responsible for obscuring half of all starlight since the Big Bang. This obscured starlight is re-radiated in a region of the electromagnetic spectrum that is still relatively unexplored. Herschel provides a unique opportunity to resolve this by revealing the 90% of dust too cold to be detected before, yet only a tiny fraction of the largest survey of the sky carried out with Herschel has been exploited.
 
This project aims to unravel the dust and gas content of galaxies in the local universe and over cosmic time.  I will produce the first statistical census of dust in galaxies, pushing out to earlier cosmic epochs than previously possible. This also provides us with an opportunity to detect unusual objects not seen in other surveys, including a population of extremely dusty galaxies found in Herschel with blue optical colours and very different properties to more evolved spirals typical of the Milky Way.  I will use our multi-wavelength data to investigate the emissivity, gas and star formation conditions on resolved spatial scales.  Our Herschel data will also expose the role of environment in the interstellar content of early-type and spiral galaxies.
 
I propose a novel approach to resolve the controversy of whether dust forms in exploding stars using polarized light. This could have implications for the detection of polarized signals in the relic radiation from the Big Bang, currently attributed to primordial gravitational waves.  Our polarized dust maps of nearby supernova will reveal whether this could be a major contaminant to cosmological signals.
 
This project is timely due to the availability of final Herschel data products and new facilities in 2015-16 in combination with tools and techniques that we have tried and tested.  This ERC award will provide me with the resources to continue to lead this emerging field.","1789714","2015-09-01","2020-08-31"
"Cosmoglobe","Cosmoglobe -- mapping the universe from the Milky Way to the Big Bang","Ingunn Kathrine WEHUS","UNIVERSITETET I OSLO","In the aftermath of the high-precision Planck and BICEP2 experiments, cosmology has undergone a critical transition. Before 2014, most breakthroughs came as direct results of improved detector technology and increased noise sensitivity. After 2014, the main source of uncertainty will be due to astrophysical foregrounds, typically in the form of dust or synchrotron emission from the Milky Way. Indeed, this holds as true for the study of reionization and the cosmic dawn as it does for the hunt for inflationary gravitational waves. To break through this obscuring veil, it is of utmost importance to optimally exploit every piece of available information, merging the world's best observational data with the world's most advanced theoretical models. A first step toward this ultimate goal was recently published as the Planck 2015 Astrophysical Baseline Model, an effort led and conducted by myself.

Here I propose to build Cosmoglobe, a comprehensive model of the radio, microwave and sub-mm sky, covering 100 MHz to 10 THz in both intensity and polarization, extending existing models by three orders of magnitude in frequency and a factor of five in angular resolution. I will leverage a recent algorithmic breakthrough in multi-resolution component separation to jointly analyze some of the world's best data sets, including C-BASS, COMAP, PASIPHAE, Planck, SPIDER, WMAP and many more. This will result in the best cosmological (CMB, SZ, CIB etc.) and astrophysical (thermal and spinning dust, synchrotron and free-free emission etc.) component maps published to date. I will then use this model to derive the world's strongest limits on, and potentially detect, inflationary gravity waves using SPIDER observations; forecast, optimize and analyze observations from the leading next-generation CMB experiments, including LiteBIRD and S4; and derive the first 3D large-scale structure maps from CO intensity mapping from COMAP, potentially opening up a new window on the cosmic dawn.","1999382","2019-06-01","2024-05-31"
"CosmoPars","Precision Cosmological Parameters","Antony Martin Lewis","THE UNIVERSITY OF SUSSEX","Proposal summary (half page, possibly copy/paste abstract from the administrative form A1)

Observations of the Cosmic Microwave Background (CMB) allow us to see 98% of the way to the big bang, back to a time when the Universe was only a few hundred thousand years old. Other forthcoming data will probe the more local universe in great detail. To test different possible universe models we need accurate theoretical predictions for this data in each model, and new sampling methods to solve the inference problem.

CMB data is most powerful if combined with information from other sources, allowing us to test many possible models of the universes and constrain cosmological parameters. As more models and parameters can be constrained, and higher precision means that more small uncertain corrections need to be consistently modelled, the problem of inference becomes challenging. I propose to develop ground-breaking new sampling methods for testing models with many parameters. To do this I will find novel sampling techniques, make efficient use of qualitatively different properties of different parameters, and develop a new parallelized sampling code that can be run on-demand in the cloud, leveraging the power of potentially vast and cheap cloud computing facilities and freeing up dedicated supercomputers for the problems where they are really needed.

In addition my team will develop new accurate theoretical predictions for confrontation with data, including analysis of new non-linear processes that will be a major source of confusion for dark energy and early universe studies, as well as correlations between different data sets.

I am applying for 70% of my time and two ERC postdocs to tackle these challenges.","1372496","2014-05-01","2019-04-30"
"COSMOS","Control and measurement of single macromolecules in space and time","Madhavi KRISHNAN","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","The desire to “freely suspend the constituents of matter” in order to study their behaviour can be traced back over 200 years to Lichtenberg’s diaries. From radio-frequency ion traps to optical tweezing of colloidal particles, existing methods to trap matter in free space or solution rely on the use of external fields that often strongly perturb the integrity of a macromolecule in solution. Recently, I invented the ‘electrostatic fluidic trap’, a “field-free” principle that supports stable, non-destructive confinement of single macromolecules in room temperature fluids, representing a paradigm shift in a nearly century-old field. The spatio-temporal dynamics of a single electrostatically trapped molecule reveals fundamental information on its properties, e.g., size and electrical charge. The charge of a macromolecule is in turn a strong function of its 3D conformation - the molecular basis of biological function. I now aim to develop a new platform to study 3D macromolecular structure and temporal conformation by measuring the electrical charge of a single trapped molecule in real time, using both optical microscopy and electrical detection. Beyond the conformational dynamics of a single molecule, we will also examine interactions between two or more molecules, and the detection of minute structural differences between closely related molecular isoforms. We will further develop a novel approach to electrical transport measurements on single molecules aimed at generating for the first time a catalog of ‘electrical signatures’ for biomolecules in solution. The ability to experimentally link electrical charge and molecular structure will not only open up a new physical dimension in our understanding of macromolecules, but also advance the development of ultrasensitive, high-throughput molecular sensors for biomedical detection and analytics, potentially enabling an optical or electrical “single-snapshot” read-out of the proteome or transcriptome of a single cell.","2124965","2018-06-01","2023-05-31"
"CosTesGrav","Cosmological Tests of Gravity","Kazuya Koyama","UNIVERSITY OF PORTSMOUTH HIGHER EDUCATION CORPORATION","Einstein’s theory of General Relativity (GR) is tested accurately within the local universe i.e., the solar system, but this leaves open the possibility that it is not a good description at the largest scales in the Universe. The standard model of cosmology assumes GR as a theory to describe gravity on all scales. In 1998, astronomers made a surprising discovery that the expansion of the Universe is accelerating, not slowing down. This late-time acceleration of the Universe has become the most challenging problem in theoretical physics. Within the framework of GR, the acceleration would originate from an unknown “dark energy.” Alternatively, it could be that there is no dark energy and GR itself is in error on cosmological scales. The standard model of cosmology is based on a huge extrapolation of our limited knowledge of gravity. This discovery of the late time acceleration of the Universe may require us to revise the theory of gravity and the standard model of cosmology based on GR. 

The main objective of my project is to develop cosmological tests of gravity and seek solutions to the origin of the observed accelerated expansion of the Universe by challenging conventional GR. Upcoming surveys will make cosmological tests of gravity a reality in the next five years. There are remaining issues in developing theoretical frameworks for probing gravitational physics on cosmological scales. We construct modified gravity theories as an alternative to dark energy and analyse “screening mechanisms” to restore GR on scales where it is well tested. We then develop better theoretical frameworks to perform cosmological tests of gravity that include non-linear scales by exploiting our theoretical knowledge of the models and our state-of-the-art simulations.

This grant will exploit and develop the world-leading position of the group initiated by Kazuya Koyama at the University of Portsmouth funded by the ERC starting grant (2008-2013).","1701133","2015-09-01","2020-08-31"
"CRAGSMAN","The Impact of Cosmic Rays on Galaxy and Cluster Formation","Christoph Pfrommer","","""Understanding the physics of galaxy formation is arguably among the greatest problems in modern astrophysics. Recent cosmological simulations have demonstrated that """"feedback"""" by star formation, supernovae and active galactic nuclei appears to be critical in obtaining realistic disk galaxies, to slow down star formation to the small observed rates, to move gas and metals out of galaxies into the intergalactic medium, and to balance radiative cooling of the low-entropy gas at the centers of galaxy clusters. This progress still has the caveat that """"feedback"""" was modeled empirically and involved tuning to observed global relations, substantially weakening the predictive power of hydrodynamic simulations. More problematic, these simulations neglected cosmic rays and magnetic fields, which provide a comparable pressure support in comparison to turbulence in our Galaxy, and are known to couple dynamically and thermally to the gas. Building on our previous successes in investigating these high-energy processes, we propose a comprehensive research program for studying the impact of cosmic rays on the formation of galaxies and clusters. To this end, we will study cosmic-ray propagation in magneto-hydrodynamic turbulence and improve the modeling of the plasma physics. This will enable us to perform the first consistent magneto-hydrodynamical and cosmic-ray simulations in a cosmological framework, something that has just now become technically feasible. Through the use of an advanced numerical technique that employs a moving mesh for calculating hydrodynamics, we will achieve an unprecedented combination of accuracy, resolution and physical completeness. We complement our theoretical efforts with a focused observational program on the non-thermal emission of galaxies and clusters, taking advantage of new capabilities at radio to gamma-ray wavelengths and neutrinos. This promises important and potentially transformative changes of our understanding of galaxy formation.""","2000000","2016-04-01","2021-03-31"
"Critical","Behaviour near criticality","Martin Hairer","THE UNIVERSITY OF WARWICK","""One of the main challenges of modern mathematical physics is to understand the behaviour of systems at or near criticality. In a number of cases, one can argue heuristically that this behaviour should be described by a nonlinear stochastic partial differential equation. Some examples of systems of interest are models of phase coexistence near the critical temperature, one-dimensional interface growth models, and models of absorption of a diffusing particle by random impurities. Unfortunately, the equations arising in all of these contexts are mathematically ill-posed. This is to the extent that they defeat not only """"standard"""" stochastic PDE techniques (as developed by Da Prato / Zabczyk / Röckner / Walsh / Krylov / etc), but also more recent approaches based on Wick renormalisation of nonlinearities (Da Prato / Debussche / etc).

Over the past year or so, I have been developing a theory of regularity structures that allows to give a rigorous mathematical interpretation to such equations, which therefore allows to build the mathematical objects conjectured to describe the abovementioned systems near criticality. The aim of the proposal is to study the convergence of a variety of concrete microscopic models to these limiting objects. The main fundamental mathematical tools to be developed in this endeavour are a discrete analogue to the theory of regularity structures, as well as a number of nonlinear invariance principles.
If successful, the project will yield unique insight in the large-scale behaviour of a number of physically relevant systems in regimes where both nonlinear effects and random fluctuations compete with equal strength.""","1526234","2014-09-01","2019-08-31"
"CRYOMATH","Cryo-electron microscopy: mathematical foundations and algorithms","Yoel SHKOLNISKY","TEL AVIV UNIVERSITY","The importance of understanding the functions of the basic building blocks of life, such as proteins, cannot be overstated (as asserted by two recent Nobel prizes in Chemistry), as this understanding unravels the mechanisms that control all organisms. The critical step towards such an understanding is to reveal the structures of these building blocks. A leading method for resolving such structures is cryo-electron microscopy (cryo-EM), in which the structure of a molecule is recovered from its images taken by an electron microscope, by using sophisticated mathematical algorithms (to which my group has made several key mathematical and algorithmic contributions). Due to hardware breakthroughs in the past three years, cryo-EM has made a giant leap forward, introducing capabilities that until recently were unimaginable, opening an opportunity to revolutionize our biological understanding. As extracting information from cryo-EM experiments completely relies on mathematical algorithms, the method’s deep mathematical challenges that have emerged must be solved as soon as possible. Only then cryo-EM could realize its nearly inconceivable potential. These challenges, for which no adequate solutions exist (or none at all), focus on integrating information from huge sets of extremely noisy images reliability and efficiently. Based on the experience of my research group in developing algorithms for cryo-EM data processing, gained during the past eight years, we will address the three key open challenges of the field – a) deriving reliable and robust reconstruction algorithms from cryo-EM data, b) developing tools to process heterogeneous cryo-EM data sets, and c) devising validation and quality measures for structures determined from cryo-EM data. The fourth goal of the project, which ties all goals together and promotes the broad interdisciplinary impact of the project, is to merge all our algorithms into a software platform for state-of-the-art processing of cryo-EM data.","1751250","2017-03-01","2022-02-28"
"CRYSBEAM","Crystal channeling to extract a high energy hadron beam from an accelerator","Gianluca Cavoto","ISTITUTO NAZIONALE DI FISICA NUCLEARE","A new generation of parasitic beam extraction of high energy particles from an accelerator is proposed in CRYSBEAM. Instead of massive magnetic kickers, bent thin crystals trapping particles within the crystal lattice planes are used. This type of beam manipulation opens new fields of investigation of fundamental interactions between particles and of coherent interactions between particles and matter. An experiment in connection to Ultra High Energy Cosmic Rays study in Earth’s high atmosphere can be conducted.
Several TeV energy protons or ions are deflected towards a chosen target by the bent lattice planes only when the lattice planes are parallel to the incoming particles direction.
The three key ingredients of CRYSBEAM are:
- a goniometer based on piezoelectric devices that orients a bent finely-polished low-miscut silicon crystal with a high resolution and repeatability, monitoring its position with synthetic diamond sensors. Novel procedures in crystal manufacturing & testing and cutting-edge mechanical solutions for motion technology in vacuum are developed;
- a silica screen that measures the deflected particles via Cherenkov radiation  emission in micrometric optical waveguides. These are obtained with an ultra-short laser micro-machining technique as for photonic devices used in quantum optics and quantum computing. The screen is a direct beam-imaging detector for a high radiation dose environment;
- a smart absorber, which simulates the Earth’s atmosphere, where particles are smashed and secondary showers are initiated. This sets the path to measure hadronic cross sections at an energy relevant for cosmic rays investigation.
The R&D for the various components of such a system are carried out within this project and direct tests at CERN Super Proton Synchrotron to be performed prior to the final installation in the Large Hadron Collider at CERN are proposed. A new concept of particle accelerator operations will be finally set in place.","1989746","2014-05-01","2019-04-30"
"CRYSTAL CLEAR","CRYSTAL CLEAR: determining the impact of charge on crystal nucleation","Mariette WOLTHERS","UNIVERSITEIT UTRECHT","All of the crystals that form in water on Earth are formed through reaction between oppositely charged ions. In these crystals, the ions are present in an ideal, charge-balanced ionic ratio. In contrast, the natural solutions in which they form, contain widely diverging ionic ratios. When crystals nucleate from natural solutions, they will be charged, and charge has a massive impact on the behaviour of small new crystals. 
Most nucleation experiments have been conducted in solutions with charge-balanced ionic ratios. This leads to uncharged crystal formation, which can be described with nucleation theories based on uncharged gas condensation into droplets. My pilot data show that this does not apply when ionic ratios diverge. New crystals then form and grow much slower than expected. Similarly, in natural solutions, crystals are often expected to form, but they do not, and vice versa. Clearly, we still have no idea how, why and how fast crystals nucleate in Earth surface environments. 
In this project, I will test the hypothesis that ionic ratio has a dramatic impact on nucleation: crystals will be charged, and this charge will determine their size, how and how fast they grow, aggregate, and transform.
I will conduct state-of-the-art experiments and analyses that will provide in situ knowledge of the impact of ionic ratio on the charge, size, growth, aggregation and transformation of nuclei. Experiments will be complemented with advanced modelling to derive charged-nuclei stability and surrounding water properties. The results will be assimilated in a new crystal nucleation theory. 
CRYSTAL CLEAR will focus on barite, calcite and pyrite as examples of highly relevant Earth Materials. The outcome will be improved geoengineering options such as drinking water production and CO2 sequestration. My project will bring a new vision on crystal formation in nature, with radically improved predictions of rates and mechanisms, and a paradigm shift in nucleation theory.","2000000","2019-04-01","2024-03-31"
"CSF","From Cloud to Star Formation","Henrik Beuther","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Star Formation is a hierarchical process from the build-up of large clouds to the assembly of stars. This ERC project aims at studying the multi-scale processes of this conversion from diffuse gas to stars. The fundamental data are provided by two PI-led large observing programs at two of the most advanced radio and mm interferometers, the Very Large Array (VLA) and the Plateau de Bure Interferometer (PdBI). This combined approach is designed to address outstanding key questions in the field of cloud and star formation.
The 225 hours THOR program at the VLA investigates the cloud formation and conversion of atomic to molecular gas, as well as feedback processes back to the interstellar medium (ISM). To reach these goals, THOR observes the Milky Way in atomic HI, molecular OH, and cm continuum and radio recombination lines tracing the ionized components of the ISM.  
At smaller spatial scales, the 300 hours PdBI project CORE will study the fragmentation of the gas clumps to form clusters, the formation of accretion disks and outflows, and the gas infall rates as proxy for the accretion rates. Therefore, assisted by Atacama Large Millimeter Array (ALMA) observations, we will investigate a sample of high-mass star-forming regions at the highest spatial resolution of 0.2'' to dissect the physical processes during the assembly of the highest mass stars. 
The core aim of this ERC project is to study all spatial scales from molecular clouds to individual massive cores. This will be a decisive step in the understanding of the conversion of gas and dust into stars. Through his decade-long expertise and leadership in star/cloud formation, the PI is uniquely positioned to advance the field significantly. The surveys at the heart of the program are extremely computing and work intensive accumulating data in the 100 TByte regime. This proposals asks for a strong core group of three postdocs and one PhD student to conduct the project and fully exploit the scientific results.","1616050","2015-09-01","2020-08-31"
"CSP","Cross-Layer Design of Securing Positioning","Srdan Capkun","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","With the development of new location-based services and the expected deployment of cyber-physical systems (e.g., autonomous cars and drones) the reliance on location and time information in critical applications will only increase. Today's positioning systems are vulnerable to location spoofing by which devices can cheat on their own positions or can manipulate the measured positions of other devices. This problem cannot be fixed by a simple upgrade - existing positioning systems rely on legacy distance measurement techniques and protocols that were designed without security considerations or with security as an after-thought. We therefore need a new approach to the design of positioning systems that takes security requirements into account from the very start, and also accounts for the way that positioning systems are built and used. This is a cross-layer endeavor. In this project we will address the following fundamental questions: (1) Physical Layer. How can we design the right distance measurement (i.e., distance bounding) techniques that provide resilience to physical-layer and logical-layer attacks but retain the performance (range, accuracy and speed of execution) of equivalent non-secure systems? We will extend the existing knowledge in terms of the attacker models as well as achievable limits of security and performance of distance measurement techniques under realistic attacker models. (2) Link Layer. What are the right Medium Access Control (MAC) protocols for secure positioning, what are their performance and scalability limits? (3) Systems. How can distance bounding be integrated in mobile platforms, especially with trusted execution environments. How can this integration strengthen the security of distance bounding and support its use in a wide range of applications?","1952274","2017-03-01","2022-02-28"
"CSP-Infinity","Homogeneous Structures, Constraint Satisfaction Problems, and Topological Clones","Manuel Bodirsky","TECHNISCHE UNIVERSITAET DRESDEN","The complexity of constraint satisfaction problems (CSPs) is a field in rapid development, and involves central questions in graph homomorphisms, finite model theory, reasoning in artificial intelligence, and, last but not least, universal algebra. In previous work, it was shown that a substantial part of the results and tools for the study of the computational complexity of CSPs can be generalised to infinite domains when the constraints are definable over a homogeneous structure. There are many computational problems, in particular in temporal and spatial reasoning, that can be modelled in this way, but not over finite domains. Also in finite model theory and descriptive complexity, CSPs over infinite domains arise systematically as problems in monotone fragments of existential second-order logic.

In this project, we will advance in three directions:
(a) Further develop the universal-algebraic approach for CSPs over homogeneous structures. E.g., provide evidence for a universal-algebraic tractability conjecture for such CSPs.
(b) Apply the universal-algebraic approach. In particular, classify the complexity of all problems in guarded monotone SNP, a logic discovered independently in finite model theory and ontology-based data-access.
(c) Investigate the complexity of CSPs over those infinite domains that are most relevant in computer science, namely the integers, the rationals, and the reals. Can we adapt the universal-algebraic approach to this setting?","1416250","2016-10-01","2021-09-30"
"CutLoops","Loop amplitudes in quantum field theory","Ruth Britto","THE PROVOST, FELLOWS, FOUNDATION SCHOLARS & THE OTHER MEMBERS OF BOARD OF THE COLLEGE OF THE HOLY & UNDIVIDED TRINITY OF QUEEN ELIZABETH NEAR DUBLIN","The traditional formulation of relativistic quantum theory is ill-equipped to handle the range of difficult computations needed to describe particle collisions at the Large Hadron Collider (LHC) within a suitable time frame. Yet, recent work shows that probability amplitudes in quantum gauge field theories, such as those describing the Standard Model and its extensions, take surprisingly simple forms. The simplicity indicates deep structure in gauge theory that has already led to dramatic computational improvements, but remains to be fully understood. For precision calculations and investigations of the deep structure of gauge theory, a comprehensive method for computing multi-loop amplitudes systematically and efficiently must be found.

The goal of this proposal is to construct a new and complete approach to computing amplitudes from a detailed understanding of their singularities, based on prior successes of so-called on-shell methods combined with the latest developments in the mathematics of Feynman integrals. Scattering processes relevant to the LHC and to formal investigations of quantum field theory will be computed within the new framework.","1954065","2015-10-01","2020-09-30"
"D-SynMA","Distributed Synthesis: from Single to Multiple Agents","Nir PITERMAN","UNIVERSITY OF LEICESTER","Computing is changing from living on our desktops and in dedicated devices to being everywhere. In phones, sensors, appliances, and robots – computers (from now on devices) are everywhere and affecting all aspects of our lives. The techniques to make them safe and reliable are investigated and are starting to emerge and consolidate. However, these techniques enable devices to work in isolation or co-exist. We currently do not have techniques that enable development of real autonomous collaboration between devices. Such techniques will revolutionize all usage of devices and, as consequence, our lives. Manufacturing, supply chain, transportation, infrastructures, and earth- and space exploration would all transform using techniques that enable development of collaborating devices. 
When considering isolated (and co-existing) devices, reactive synthesis – automatic production of plans from high level specification – is emerging as a viable tool for the development of robots and reactive software. This is especially important in the context of safety-critical systems, where assurances are required and systems need to have guarantees on performance. The techniques that are developed today to support robust, assured, reliable, and adaptive devices rely on a major change in focus of reactive synthesis. The revolution of correct-by-construction systems from specifications is occurring and is being pushed forward.
However, to take this approach forward to work also for real collaboration between devices the theoretical frameworks that will enable distributed synthesis are required. Such foundations will enable the correct-by-construction revolution to unleash its potential and allow a multiplicative increase of utility by cooperative computation. 
d-SynMA will take distributed synthesis to this new frontier by considering novel interaction and communication concepts that would create an adaptable framework of correct-by-construction application of collaborating devices.","1871272","2018-05-01","2023-04-30"
"D-TECT","Does dust triboelectrification affect our climate?","Vasileios AMOIRIDIS","NATIONAL OBSERVATORY OF ATHENS","The recent IPCC report identifies mineral dust and the associated uncertainties in climate projections as key topics for future research. Dust size distribution in climate models controls the dust-radiation-cloud interactions and is a major contributor to these uncertainties. Observations show that the coarse mode of dust can be sustained during long-range transport, while current understanding fails in explaining why the lifetime of large airborne dust particles is longer than expected from gravitational settling theories. This discrepancy between observations and theory suggests that other processes counterbalance the effect of gravity along transport. D-TECT envisages filling this knowledge gap by studying the contribution of the triboelectrification (contact electrification) on particle removal processes. Our hypothesis is that triboelectric charging generates adequate electric fields to hold large dust particles up in the atmosphere. D-TECT aims to (i) parameterize the physical mechanisms responsible for dust triboelectrification; (ii) assess the impact of electrification on dust settling; (iii) quantify the climatic impacts of the process, particularly the effect on the dust size evolution during transport, on dry deposition and on CCN/IN reservoirs, and the effect of the electric field on particle orientation and on radiative transfer. The approach involves the development of a novel specialized high-power lidar system to detect and characterize aerosol particle orientation and a large-scale field experiment in the Mediterranean Basin using unprecedented ground-based remote sensing and airborne in-situ observation synergies. Considering aerosol-electricity interactions, the observations will be used to improve theoretical understanding and simulations of dust lifecycle. The project will provide new fundamental understanding, able to open new horizons for weather and climate science, including biogeochemistry, volcanic ash and extraterrestrial dust research.","1968000","2017-09-01","2022-08-31"
"DarkComb","Dark-Soliton Engineering in Microresonator Frequency Combs","Victor TORRES COMPANY","CHALMERS TEKNISKA HOEGSKOLA AB","The continuing increase in Internet data traffic is pushing the capacity of single-mode fiber to its fundamental limits. Space division multiplexing (SDM) offers the only remaining physical degree of freedom – the space dimension in the transmission channel – to substantially increase the capacity in lightwave communication systems.

The microresonator comb is an emerging technology platform that enables the generation of an optical frequency comb in a micrometer-scale cavity. Its compact size and compatibility with established semiconductor fabrication techniques promises to revolutionize the fields of frequency synthesis and metrology, and create new mass-market applications.

I envision significant scaling advantages in future fiber-optic communications by merging SDM with microresonator frequency combs. One major obstacle to overcome here is the poor conversion efficiency that can be fundamentally obtained using the most stable and broadest combs generated in microresonators today. I propose to look into the generation of dark, as opposed to bright, temporal solitons in linearly coupled microresonators. The goal is to achieve reliable microresonator combs with exceptionally high power conversion efficiency, resulting in optimal characteristics for SDM applications. The scientific and technological possibilities of this achievement promise significant impact beyond the realm of fiber-optic communications.

My broad international experience, unique background in fiber communications, photonic waveguides and ultrafast photonics, the preliminary results of my group and the available infrastructure at my university place me in an outstanding position to pioneer this new direction of research.","2259523","2018-05-01","2023-04-30"
"DARKHORIZONS","Dark Matter and the Early Universe in the LHC Era","Malcolm Douglas Stephen Fairbairn","KING'S COLLEGE LONDON","The discovery of a Higgs like particle in its first science run shows that we are truly in the LHC era and when collisions resume we will learn more about the physics of the TeV scale.  

There are two main areas at the interface of particle physics and cosmology that the LHC will shed light on - If dark matter is a thermal relic then we naturally expect new particle physics close to this TeV energy range.  The LHC will also help us learn about the nature of the electroweak sector and its behaviour during the early Universe.

In this proposal we present a body of work which will combine information from the LHC with dark matter experiments and astronomical observations to understand both the nature of dark matter and the role of the Higgs sector in the first moments after the big bang.  

We will investigate dark matter by developing a new categorisation of interactions between the dark sector and the standard model.  This will enable us to perform detailed collider and direct detection phenomenology in a more comprehensive way than current approaches while avoiding the problems which occur when those methods breakdown.  Different schemes for mitigating against the upcoming problem of the neutrino floor in direct detection experiments will also be investigated.

Many of the keys to understanding the particle nature of dark matter lie in astrophysics, and we will develop new techniques to understand the distribution of dark matter in the Universe, its behaviour and density in distant galaxies and its velocity dispersion in the Solar system, critical to predict event rates in detectors.

We will use LHC and CMB data to answer important questions - Can the electroweak phase transition be first order?  What is the role of the Higgs field during inflation?  Can we use the electroweak sector to infer information about physics at high energy scale or the nature of inflation?

The interdisciplinary experience of the PI will ensure the ambitious project is a success.","1947665","2015-09-01","2020-08-31"
"DarkMix","Illuminating the dark side of surface meteorology: creating a novel framework to explain atmospheric transport and turbulent mixing in the weak-wind boundary layer","Christoph Karl THOMAS","UNIVERSITAET BAYREUTH","Surface meteorology impacts the abundance and quality of life on Earth through the transfer and mixing of light, heat, water, CO2, and other substances controlling the resources for humans, plants, and animals. However, current theories and models fail when airflows and turbulence are weak during calm nights leaving weather and climate forecasts uncertain. This ‘dark side’ occupies substantial fractions of time and our landscape, its physics are largely unknown, and has eluded proper experimental investigation.
DarkMix creates technological and theoretical innovations to observe and explain transport and mixing in the weak-wind boundary layer. Its ambitious goal is a radically new framework incorporating unexplored mechanisms such as submeso-scale motions, flow instationarities, and directional shear to effect a quantum leap in understanding the air-plant-soil exchange. DarkMix will build the ground-breaking first-ever fiber-optic distributed temperature sensing harp to fully resolve the 3-dimensional flow and air temperature fields and enable unprecedented computation of eddy covariance fluxes at scales of seconds over 4 orders of magnitude (deci- to hundreds of meters). Both key innovations bear significant risks of technical and fundamental nature, which are mitigated by pursuing alternatives. Measurements will inform cutting-edge large eddy simulations to test hypotheses. The interdisciplinary dimension takes DarkMix to a unique set of weak-wind sites including a valley-bottom grassland, a forest in complex terrain, and a city to investigate topographic effects, the forest carbon cycle, and the urban heat island.
DarkMix will open a new window for surface meteorology and its links to air quality, biogeochemistry, and climate change by giving physically meaningful and societally relevant answers to profound questions such as the exchange of greenhouse gases, hazards from ground fog, urban pollution, and agricultural losses through extreme cold air.","1898104","2017-05-01","2022-04-30"
"DarkSERS","Harvesting dark plasmons for surface-enhanced Raman scattering","Stephanie REICH","FREIE UNIVERSITAET BERLIN","Metal nanostructures show pronounced electromagnetic resonances that arise from localized surface plasmons. These collective oscillations of free electrons in the metal give rise to confined electromagnetic near fields. Surface-enhanced spectroscopy exploits the near-field intensity to enhance the optical response of nanomaterials by many orders of magnitude. 

Plasmons are classified as bright and dark depending on their interaction with far-field radiation. Bright modes are dipole-allowed excitations that absorb and scatter light. Dark modes are resonances of the electromagnetic near field only that do not couple to propagating modes. The suppressed photon emission of dark plasmons makes their resonances spectrally narrow and intense, which is highly desirable for enhanced spectroscopy as well as storing and transporting electromagnetic energy in nanostructures. The suppressed absorption, however, prevents us from routinely exploiting dark modes in nanoplasmonic systems.

I propose using spatially patterned light beams to excite dark plasmons with far-field radiation. By this I mean a beam profile with varying polarization and intensity that will be matched to the dark electromagnetic eigenmode. My approach activates the excitation of dark modes, while their radiative decay remains suppressed. I will show how to harvest dark modes for surface-enhanced Raman scattering providing superior intensity and an enhancement that is tailored to a specific vibration. Another feature of dark modes is their strong coupling to the vibrations of nanostructures. I will use this to amplify vibrational modes and, ultimately, induce phonon lasing. 

The proposed research aims at an enabling technology that unlocks a novel range of nanoplasmonic properties. It will put dark plasmons on par with the well-recognized bright modes to be used in fundamental science and for applications in analytics, optoelectronic, and nanoimaging.","2299506","2018-04-01","2023-03-31"
"DARKSURVEY","Using Galaxy Surveys to Understand the Dark Universe","William Percival","UNIVERSITY OF PORTSMOUTH HIGHER EDUCATION CORPORATION","Galaxy Surveys are a key resource for observational cosmology, with the potential to provide the answers to many fundamental questions in modern physics. The Darksurvey project will use the Dark Energy Survey (DES) and extended-Baryon Oscillation Spectroscopic Survey (eBOSS) within which Will Percival has key leadership positions, and future projects including MS-DESI to measure the cosmological expansion rate between redshifts 0.5 and 2, testing Dark Energy. Complimentary structure growth measurements will test Einstein's theory of Gravity on the largest scales possible. The large-scale clustering of galaxies will be used to constrain primordial non-Gaussianity, testing and constraining models of inflation. The scale-dependence of the clustering signal will be used to measure the masses of neutrinos through their early Universe effects, and to set constraints on the evolution of galaxies and structure over cosmological time-scales. Parallel development of innovative tests and measurement methods will be undertaken to enable and enhance these results, while joint analysis with CMB and weak-lensing data will be used to perform additional tests, and to break degeneracies present when cosmological models are tested.
This grant will consolidate the world-leading position of the group initiated by Will Percival at the University of Portsmouth, and developed over the last 4 years. Furthermore, it will train and develop a group of scientists within Europe with the key experimental skills required for the ESA Euclid mission.","2151192","2014-06-01","2020-05-31"
"DBA","Distributed Biological Algorithms","Amos Korman","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","This project proposes a new application for computational reasoning. More specifically, the purpose of this interdisciplinary project is to demonstrate the usefulness of an algorithmic perspective in studies of complex biological systems. We focus on the domain of collective behavior, and demonstrate the benefits of using techniques from the field of theoretical distributed computing in order to establish algorithmic insights regarding the behavior of biological ensembles. The project includes three related tasks, for which we have already obtained promising preliminary results. Each task contains a purely theoretical algorithmic component as well as one which integrates theoretical algorithmic studies with experiments. Most experiments are strategically designed by the PI based on computational insights, and are physically conducted by experimental biologists that have been carefully chosen by the PI. In turn, experimental outcomes will be theoretically analyzed via an algorithmic perspective. By this integration, we aim at deciphering how a biological individual (such as an ant) “thinks”, without having direct access to the neurological process within its brain, and how such limited individuals assemble into ensembles that appear to be far greater than the sum of their parts. The ultimate vision behind this project is to enable the formation of a new scientific field, called algorithmic biology, that bases biological studies on theoretical algorithmic insights.","1894947","2015-05-01","2020-04-30"
"DBSModel","Multiscale Modelling of the Neuromuscular System for Closed Loop Deep Brain Stimulation","Madeleine Mary Lowery","UNIVERSITY COLLEGE DUBLIN, NATIONAL UNIVERSITY OF IRELAND, DUBLIN","Deep brain stimulation (DBS) is an effective therapy for treating the symptoms of Parkinson’s disease (PD). Despite its success, the mechanisms of DBS are not understood and there is a need to improve DBS to improve long-term stimulation in a wider patient population, limit side-effects, and extend battery life. Currently DBS operates in ‘open-loop’, with stimulus parameters empirically set. Closed-loop DBS, which adjusts parameters based on the state of the system, has the potential to overcome current limitations to increase therapeutic efficacy while reducing side-effects, costs and energy. Several key questions need to be addressed before closed loop DBS can be implemented clinically. 
This research will develop a new multiscale model of the neuromuscular system for closed-loop DBS. The model will simulate neural sensing and stimulation on a scale not previously considered, encompassing the electric field around the electrode, the effect on individual neurons and neural networks, and generation of muscle force. This will involve integration across multiple temporal and spatial scales, in a complex system with incomplete knowledge of system variables. Experiments will be conducted to validate the model, and identify new biomarkers of neural activity that can used with signals from the brain to enable continuous symptom monitoring. The model will be used to design a new control strategy for closed-loop DBS that can accommodate the nonlinear nature of the system, and short- and long-term changes in system behavior. 
Though challenging, this research will provide new insights into the changes that take place in PD and the mechanisms by which DBS exerts its therapeutic influence. This knowledge will be used to design a new strategy for closed-loop DBS, ready for testing in patients, with the potential to significantly improve patient outcomes in PD and fundamentally change the way in which implanted devices utilise electrical stimulation to modulate neural activity.","1999474","2015-08-01","2020-07-31"
"DECAF","Deforestation – Climate –Atmospheric composition – Fire interactions and feedbacks","Dominick SPRACKLEN","UNIVERSITY OF LEEDS","Extensive and ongoing tropical deforestation and degradation have important environmental impacts. Smoke aerosol from deforestation fires degrades air quality, but the effects are poorly quantified. Deforestation alters rainfall through changes in the land surface and through changes to atmospheric aerosol. The magnitude and the sign of the rainfall response is not clear, because of poor process-level understanding and because previous attempts have studied land surface and aerosol responses separately. The impacts of deforestation on atmospheric composition and climate cause a complex set of biosphere interactions resulting in potential Earth system feedbacks. These feedbacks have not yet been quantified and so their importance is not known. The full impact of deforestation on air quality, climate and the Earth System may have been underestimated because there have been no integrated studies of the combined interactions and feedbacks between deforestation and the Earth system. DECAF is the first integrated study of the combined interactions and feedbacks between tropical deforestation, fire, atmospheric composition and climate. To address this important challenge, DECAF will exploit new information from in-situ and satellite observations in combination with state-of-the-art numerical models. DECAF will deliver improved process-level knowledge of the impacts of deforestation on atmospheric composition and climate and a step change in our understanding of the interactions and feedbacks between deforestation, atmospheric composition and climate. New understanding will inform the development of climate and Earth System Models and will facilitate new climate and Earth system assessments.","1965623","2018-03-01","2023-02-28"
"DeciGUT","A Grand Unified Theory of Decidability in Logic-Based Knowledge Representation","Sebastian Rudolph","TECHNISCHE UNIVERSITAET DRESDEN","""Logic-based knowledge representation (KR) constitutes a vital area of IT. The field  inspires and guides scientific and technological developments enabling intelligent management of large and complex knowledge resources. Elaborate languages for specifying knowledge (so-called ontology languages) and querying it have been defined and standardized. Algorithms for automated reasoning and intelligent querying over knowledge resources are being developed, implemented and practically deployed on a wide scale. 
Thereby, decidability investigations play a pivotal role to characterize what reasoning or querying tasks are at all computationally solvable. 
Past decades have seen a proliferation of new decidable formalisms for KR, dominated by two major paradigms: description logics and rule-based approaches, most notably existential rules. Recently, these research lines have started to converge and first progress has been made toward identifying commonalities among the various formalisms. Still, the underlying principles for establishing their decidability remain disparate, ranging from proof-theoretic notions to model-theoretic ones. 
DeciGUT will accomplish a major breakthrough in the field by establishing a """"Grand Unified Theory"""" of decidability. We will provide a novel, powerful model-theoretic criterion inspired by advanced graph-theoretic notions. We will prove that the criterion indeed ensures decidability and that it subsumes most of (if not all) currently known decidable formalisms in the KR field.
We will exploit our results toward the definition of novel decidable KR languages of unprecedented expressivity. We will ultimately extend our framework to encompass more advanced KR features beyond standard first order logic such as counting and non-monotonic aspects.
Our research will draw from and significantly impact the scientific fields of AI, Database Theory and Logic, but also give rise to drastically improved practical information management technology.""","1814937","2018-10-01","2023-09-30"
"DECRESIM","A Chemical Approach to Molecular Spin Qubits: Decoherence and Organisation of Rare Earth Single Ion Magnets","Alejandro Gaita Ariño","UNIVERSITAT DE VALENCIA","""Coordination Chemistry and Molecular Magnetism are in an ideal position for the rational design of Single-Molecule Magnets which can be used as molecular spin qubits, the irreducible components of any quantum technology. Indeed, a major advantage of molecular spin qubits over other candidates stems from the power of Chemistry for a tailored and inexpensive synthesis of systems for their experimental study. In particular, the so-called Lanthanoid-based Single-Ion Magnets, which are currently the hottest topic in Molecular Magnetism, have the potential to be chemically designed, tuning both their single-molecule properties and their crystalline environment. This will allow the independent study of the different quantum processes that cause the loss of quantum information, collectively known as decoherence. The study of quantum decoherence processes in the solid state is necessary both to lay the foundations for next-generation quantum technologies and to answer some fundamental questions.
The goals of this project are:
#1 To unravel the mechanistic details of decoherence in molecular spin qubits based on mononuclear lanthanoid complexes. This study will stablish criteria for the rational design of single spin qubits.
#2 To extend this study to the coupling between two or more spin qubits. This will allow us to explore the use of polynuclear lanthanoid complexes to achieve quantum gates or simple algorithms.
#3 To extrapolate to infinite systems formed by the complex organization of spin qubits. This exploratory goal will permit us to move beyond zero-dimensional systems, thus facilitating the advance towards complex quantum functions.
""","1827375","2015-08-01","2020-07-31"
"DeepFace","Understanding Deep Face Recognition","Lior Wolf","TEL AVIV UNIVERSITY","Face recognition is a fascinating domain: no other domain seems to present as much value when analysing casual photos; it is one of the few domains in machine learning in which millions of classes are routinely learned; and the trade-off between subtle inter-identity variations and pronounced intra-identity variations forms a unique challenge. 

The advent of deep learning has brought machines to what is considered a human level of performance. However, there are many research questions that are left open. At the top most level, we ask two questions: what is unique about faces in comparison to other recognition tasks that also employ deep networks and how can we make the next leap in performance of automatic face recognition? 

We consider three domains of research. The first is the study of methods that promote effective transfer learning. This is crucial since all state of the art face recognition methods rely on transfer learning. The second domain is the study of the tradeoffs that govern the optimal utilization of the training data and how the properties of the training data affect the optimal network design. The third domain is the post transfer utilization of the learned deep networks, where given the representations of a pair of face images, we seek to compare them in the most accurate way.

Throughout this proposal, we put an emphasis on theoretical reasoning. I aim to support the developed methods by a theoretical framework that would both justify their usage as well as provide concrete guidelines for using them. My goal of achieving a leap forward in performance through a level of theoretical analysis that is unparalleled in object recognition, makes our research agenda truly high-risk/ high-gains. I have been in the forefront of face recognition for the last 8 years and my lab's recent achievements in deep learning suggest that we will be able to carry out this research. To further support its feasibility, we present very promising initial results.","1696888","2017-05-01","2022-04-30"
"DeeViSe","Deep Learning for Dynamic 3D Visual Scene Understanding","Bastian LEIBE","RHEINISCH-WESTFAELISCHE TECHNISCHE HOCHSCHULE AACHEN","Over the past 5 years, deep learning has exercised a tremendous and transformational effect on the field of computer vision. However, deep neural networks (DNNs) can only realize their full potential when applied in an end-to-end manner, i.e., when every stage of the processing pipeline is differentiable with respect to the network’s parameters, such that all of those parameters can be optimized together. Such end-to-end learning solutions are still rare for computer vision problems, in particular for dynamic visual scene understanding tasks. Moreover, feed-forward processing, as done in most DNN-based vision approaches, is only a tiny fraction of what the human brain can do. Feedback processes, temporal information processing, and memory mechanisms form an important part of our human scene understanding capabilities. Those mechanisms are currently underexplored in computer vision.

The goal of this proposal is to remove this bottleneck and to design end-to-end deep learning approaches that can realize the full potential of DNNs for dynamic visual scene understanding. We will make use of the positive interactions and feedback processes between multiple vision modalities and combine them to work towards a common goal. In addition, we will impart deep learning approaches with a notion of what it means to move through a 3D world by incorporating temporal continuity constraints, as well as by developing novel deep associative and spatial memory mechanisms.

The results of this research will enable deep neural networks to reach significantly improved dynamic scene understanding capabilities compared to today’s methods. This will have an immediate positive effect for applications in need for such capabilities, most notably for mobile robotics and intelligent vehicles.","2000000","2018-04-01","2023-03-31"
"DeLiCAT","Death and Life of Catalysts: a Theory-Guided Unified Approach for Non-Critical Metal Catalyst Development","Evgeny Alexandrovich PIDKO","TECHNISCHE UNIVERSITEIT DELFT","Most of the developments in catalyst are still based on serendipitous and trial-and-error approaches, in which potential systems can be overlooked simply because of the sub-optimal conditions of the initial activity assessment. Mechanistic and kinetic studies could provide a framework for a more adequate assessment of new catalysts, but such rigorous experiments are not practical for general catalyst discovery. Modern chemical theory and computations hold a promise to be employed in new efficient theory-guided approaches for rational catalyst and process development.
 
The main aim of DeLiCat is to formulate a hierarchical computational strategy for the design and synthesis of new non-critical metal-based catalysts for sustainable chemical transformations. New, durable and cheap, yet, highly active and selective tailor-made catalyst for hydrogenation of carboxylic acids and their esters as well as for acceptorless dehydrogenation of alcohols will be developed. The research will follow an innovative strategy combining advanced chemical theory, computational screening and experimental approaches from the fields of homogeneous and heterogeneous catalysis in an efficient knowledge exchange loop. Computer simulations will reveal complex reaction networks that determine the “death” and the “life” of catalyst systems. These insights will be used in targeted design of novel multifunctional catalyst systems to direct the selectivity of the reaction network and to prevent deactivation paths. Complementary experimental studies will guide and validate the theoretical predictions. 

DeLiCAT represents a leap forward in unified first principles-guided catalyst design for liquid phase chemical transformations. The new theoretical concepts, methodological advances as well as the novel superior catalyst systems developed here will be applicable in various areas including biomass valorization, homogeneous and heterogeneous catalysis as well as hydrogen technology.","1999524","2017-05-01","2022-04-30"
"DEMIURGE","Automatic Design of Robot Swarms","Mauro Birattari","UNIVERSITE LIBRE DE BRUXELLES","The scope of this project is the automatic design of robot swarms. Swarm robotics is an appealing approach to the  coordination of large groups of robots. Up to now, robot swarms have been designed via some labor-intensive process.

My goal is to advance the state of the art in swarm robotics by developing the DEMIURGE: an intelligent system that is able to design and realize robot swarms in a totally integrated and automatic way

The DEMIURGE is a novel concept. Starting from requirements expressed in a specification language that I will define, the DEMIURGE will design all aspects of a robot swarm - hardware and control software.

The DEMIURGE will cast a design problem into an optimization problem and will tackle it in a computation-intensive way. In this project, I will study different control software structures, optimization algorithms, ways to specify requirements, validation protocols, on-line adaptation mechanisms and techniques for re-design at run time.","2000000","2016-10-01","2021-09-30"
"DEMOBLACK","Demography of black hole binaries in the era of gravitational wave astronomy","Michela MAPELLI","UNIVERSITA DEGLI STUDI DI PADOVA","The first direct detection of gravitational waves demonstrated that double black hole (BH) binaries exist, and can host surprisingly massive objects (> 20 solar masses). Most theoretical models do not predict the existence of such massive BHs, and the formation channels of BH binaries are essentially unconstrained. Dynamically formed BH binaries are the most elusive ones: current models either neglect them or study them in idealized systems. With DEMOBLACK, I will draw the first satisfactory picture of BH binary demography, by modeling realistic BH dynamics in a well-motivated cosmological context. I propose a novel approach for the study of BH dynamics: I will simulate the formation of BH binaries in star clusters self-consistently, starting from the hydrodynamics of the parent molecular cloud and accounting for the impact of stellar evolution, feedback, and dynamics on BH binaries. The key tool of DEMOBLACK is SEVN, my new population-synthesis code. With SEVN, I predicted the formation of massive BHs from metal-poor stars, before the first direct detection of gravitational waves. I will interface SEVN with a hydrodynamical code and with an N-body code, to study the formation of BH binaries self-consistently. I will then model the history of BH binaries across cosmic time, accounting for the evolution of metallicity. This novel approach is decisive to break degeneracies between dynamically formed and primordial BH binaries, and to make predictions for future observations by ground-based and space-borne gravitational wave interferometers.","1994764","2018-11-01","2023-10-31"
"DenseMatter","High-density QCD matter from first principles","Aleksi VUORINEN","HELSINGIN YLIOPISTO","Predicting the collective properties of strongly interacting matter at the highest densities reached within the present-day Universe is one of the most prominent challenges in modern nuclear theory. It is motivated by the desire to map out the complicated phase diagram of the theory, and perhaps even more importantly by the mystery surrounding the inner structure of neutron stars. The task is, however, severely complicated by the notorious Sign Problem of lattice QCD, due to which no nonperturbative first principles methods are available for tackling it.
 
The proposal at hand approaches the strong interaction challenge using a first principles toolbox containing most importantly the machinery of modern resummed perturbation theory and effective field theory. Our main technical goal is to determine three new orders in the weak coupling expansion of the Equation of State (EoS) of unpaired zero-temperature quark matter. Alongside this effort, we will investigate the derivation of a new type of effective description for cold and dense QCD, allowing us to include to the EoS contributions from quark pairing more accurately than what is possible at present. 

The highlight result of our work will be the derivation of the most accurate neutron star matter EoS to date, which will be obtained by combining insights from our work with those originating from the Chiral Effective Theory of nuclear interactions. We anticipate being able to reduce the current uncertainty in the EoS by nearly a factor of two, which will convert into a precise prediction for the Mass-Radius relation of the stars. This will be a milestone result in nuclear astrophysics, and in combination with emerging observational data on stellar masses and radii will contribute to solving one of the most intriguing puzzles in the field – the nature of the most compact stars in the Universe.","1342133","2017-07-01","2022-06-30"
"DerSympApp","Derived Symplectic Geometry and Applications","Damien CALAQUE","UNIVERSITE DE MONTPELLIER","We propose a program that aims at providing new developments and new applications of shifted symplectic and Poisson structures. It is formulated in the language and framework of derived algebraic geometry after Toën–Vezzosi and Lurie. 

On the foundational side, we will introduce the new notion of shifted symplectic groupoids and prove that they provide an alternative approach to shifted Poisson structures (as they were defined by the PI together with Tony Pantev, Bertrand Toën, Michel Vaquié and Gabriele Vezzosi). Along the way, we shall be able to prove several conjectures that have recently been formulated by the PI and other people. 

Applications are related to mathematical physics. For instance: 
- We will provide an interpretation of the Batalin–Vilkovisky formalism in terms of derived symplectic reduction. 
- We will show that the semi-classical topological field theories with values in derived Lagrangian correspondences that were previously introduced by the PI are actually fully extended topological field theories in the sense of Baez–Dolan and Lurie. 
- We will explain how one may use this formalism to rigorously construct a 2D topological field theory that has been discovered by Moore and Tachikawa. 

Quantization problems will also be discussed at the end of the proposal. 

This project proposal lies at the crossroads of algebraic geometry, mathematical physics (in its algebraic and geometric aspects) and higher algebra.","1385247","2018-09-01","2023-08-31"
"Des.solve","When solids become liquids: natural deep eutectic solvents for chemical process engineering","Ana Rita CRUZ DUARTE","NOVA ID FCT - ASSOCIACAO PARA A INOVACAO E DESENVOLVIMENTO DA FCT","Sugars, aminoacids or organic acids are typically solid at room temperature. Nonetheless when combined at a particular molar fraction they present a high melting point depression, becoming liquids at room temperature. These are called Natural Deep Eutectic Solvents – NADES. NADES are envisaged to play a major role on different chemical engineering processes in the future. Nonetheless, there is a significant lack of knowledge on fundamental and basic research on NADES, which is hindering their industrial applications. For this reason it is important to extend the knowledge on these systems, boosting their application development. NADES applications go beyond chemical or materials engineering and cover a wide range of fields from biocatalysis, extraction, electrochemistry, carbon dioxide capture or biomedical applications. Des.solve encompasses four major themes of research: 1 – Development of NADES and therapeutic deep eutectic solvents – THEDES; 2 – Characterization of the obtained mixtures and computer simulation of NADES/THEDES properties; 3 – Phase behaviour of binary/ternary systems NADES/THEDES + carbon dioxide and thermodynamic modelling 4 – Application development. Starting from the development of novel NADES/THEDES which, by different characterization techniques, will be deeply studied and characterized, the essential raw-materials will be produced for the subsequent research activities. The envisaged research involves modelling and molecular simulations. Des.solve will be deeply engaged in application development, particularly in extraction, biocatalysis and pharmaceutical/biomedical applications. The knowledge that will be created in this proposal is expected not only to have a major impact in the scientific community, but also in society, economy and industry.","1877006","2017-03-01","2022-02-28"
"Design2Heal","Rational design of scaffold architecture and functionalization to induce healing and tissue regeneration","Jürgen Groll","UNIVERSITAETSKLINIKUM WUERZBURG - KLINIKUM DER BAYERISCHEN JULIUS-MAXIMILIANS-UNIVERSITAT","When materials are implanted into the body they initiate an inflammatory response that is difficult to control. Consequently medical implants are tolerated by the body rather than fully integrated; the material is often sealed off from the body in a fibrotic capsule. Most recent research suggests that morphology is a decisive immunomodulatory trigger and may favor a healing-like reaction of the innate immune system, especially of macrophages.

I have pioneered a single-step method to generate non-woven fibrous scaffolds with surface chemistry control that allows specific cell adhesion. Additionally, my laboratory recently established melt electrospinning writing (MEW) that allows automated scaffold production by solvent-free electrostatic drawing with precise morphology control through rational deposition of polymer filaments in micrometer resolution.

Design2Heal is based on this world-wide unique combination of technologies and proposes to combine form (scaffold morphology) with function (surface chemistry) to generate biomaterials that are designed to heal and improve implant integration. Pioneering and ground breaking research within Design2Heal includes:

• A single-step procedure to fabricate MEW scaffolds with controlled surface functionalities for specific bioactivation.

• Unraveling the immunomodulatory potential of generic scaffold parameters (diameter, morphology) and surface functionalization (peptides, sugars, glycosaminoglycans) for rationally designed scaffolds in vitro with primary human innate immune cells.

• Resolve the immunomodulatory effects of cellular cross-talk and interaction between human immune cells, mesenchymal stem cells and endothelial progenitor cells in defined geometric confinements.

• In vivo proof-of-principle in the murine model
In case of success, Design2Heal will be a ground breaking first step towards actively healing implants independently of the affected tissue, with tremendous impact on healthcare worldwide.","1994200","2014-03-01","2019-02-28"
"DesignerPores","Understanding and Designing Novel NanoPores","Ulrich Felix Keyser","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Translocation of ions and molecules is ubiquitous in biology and technology. Despite the tremendous amount of technical development, biological systems are still much more sophisticated in exerting exquisite control over active and passive translocation through nanopores in membranes than their existing synthetic mimics. This proposal aims to build novel designer nanopores that can match naturally evolved systems. For this we have to control all three stages of translocation: 1) diffusion and entry into, 2) diffusion in, and 3) exit from the nanopore. To gain fundamental insight into the translocation process we will employ microfluidic channels combined with holographic optical tweezers. Results from the microscale model system will be directly translated to nanoscale pores built with DNA origami nanotechnology. Our microfluidic experiments will automatically track diffusing spherical and non-spherical particles in artificial channels. Facilitated membrane transport will be mimicked by holographic optical tweezers providing full control over the translocation process. We will clarify how translocation depends on particle-particle, particle-channel, and particle-channel-entrance interactions. 
The generic principles discovered on the microscale will guide the design of artificial nanopores made by DNA origami self-assembly. Our DNA origami based designer nanopores will lead to a novel class of transporters for molecules, ions, and water through solid-state and lipid membranes. The project will generate a quantitative understanding of membrane transport processes, test existing theoretical models with unprecedented experimental control, and introduce a novel approach to design active and passive nanopores built from DNA.","1936431","2015-07-01","2020-06-30"
"DIAPASoN","Differential Program Semantics","Ugo DAL LAGO","ALMA MATER STUDIORUM - UNIVERSITA DI BOLOGNA","Traditionally, program semantics is centered around the notion of program identity, that is to say of program equivalence: a program is identified with its meaning, and programs are considered as equal only if their meanings are the same. This view has been extremely fruitful in the past, allowing for a deep understanding of highly interactive forms of computation as embodied by higher-order or concurrent programs. The byproducts of all this lie everywhere in computer science, from programming language design to verification methodologies. The emphasis on equality — as opposed to differences — is not however in line with the way programs are written and structured in modern complex software systems.  Subtasks are delegated to pieces of code which behave as expected only up to a certain probability of error, and only if the environment in which they operate makes this possible deviation irrelevant.  These aspects have been almost neglected by the program semantics community until recently, and still have a marginal role. DIAPASON's goal is to study differences between programs as a constitutive and informative concept, rather than by way of relations between them.  This will be accomplished by generalizing four major frameworks of program semantics, traditionally used for giving semantics to programs, comparing them, proving properties of them, and controlling their usage of resources: logical relations, bisimulation, game semantics, and linear logic.","959562","2019-03-01","2024-02-29"
"DIDYMUS","MICROMACHINED OPTOMECHANICAL DEVICES: looking at cells, tissues, and organs ... with a gentle touch","Davide Iannuzzi","STICHTING VU","Every time we grab an object to look at its geometrical details or to feel if it is hard or soft, we are ineluctably confronted with the limits of our senses. Behind its appearances, the object may still hide information that, encrypted in its microscopic features, remains undetected to our macroscopic assessment. In life sciences, those limits are more than just frustrating: they are an obstacle to study and detect life threatening conditions. Many different instruments may overcome those limits, but the vast majority of them rely either on “sight” (optics) or “touch” (mechanics) separately. On the contrary, I believe that it is from the combination of those two “senses” that we have more chances to tackle the future challenges of cell biology, tissue engineering, and medical diagnosis.

Inspired by this tantalizing perspective, and supported by a technology that I have brought from blackboard to market, I have now designed a scientific program to breach into the microscopic scale via an unbeaten path. The program develops along three projects addressing the three most relevant scales in life sciences: cells, tissues, and organs. In the first project, I will design and test a new optomechanical probe to investigate how a prolonged mechanical load on a brain cell of a living animal may trigger alterations in its Central Nervous System. With the second project, I will develop an optomechanical tactile instrument that can assess how subsurface tissues deform in response to a mechanical stroke – a study that may change the way physicians look at tissue classification. For the third project, I will deliver an acousto-optical gas trace sensors so compact that can penetrate inside the lungs of an adult patient, where it could be used for early detection of pulmonary life threatening diseases. Each project represents an opportunity to open an entire new field, where optics and micromechanics are combined to extend our senses well beyond their natural limits.","1999221","2014-06-01","2019-05-31"
"DIFFINCL","Differential Inclusions and Fluid Mechanics","Laszlo SZEKELYHIDI","UNIVERSITAET LEIPZIG","Important problems in science often involve structures on several distinct length scales. Two typical examples are fine phase mixtures in solid-solid phase transitions and the complex mixing patterns in turbulent or multiphase flows. The microstructures in such situations influence in a crucial way the macroscopic behavior of the system, and understanding the formation, interaction and overall effect of these structures is a great scientific challenge. Although there is a large variety of models and descriptions for such phenomena, a recurring issue in the mathematical analysis is that one has to deal with very complex and highly non-smooth structures in solutions of the associated partial differential equations. 

A common ground is provided by the analysis of differential inclusions, a theory whose development was strongly influenced by the influx of ideas from the work of Gromov on partial differential relations, building on celebrated constructions of Nash for isometric immersions, and the work of Tartar in the study of oscillation phenomena in nonlinear partial differential equations. A recent success of this approach is provided by my work on the h-principle in fluid mechanics and Onsager's conjecture. Against this background my aim in this project is to go significantly beyond the state of the art, both in terms of the methods and in terms of applications of differential inclusions. One part of the project is to continue my work on fluid mechanics with the ultimate goal to address important challenges in the field: providing an analytic foundation for the K41 statistical theory of turbulence and for the behavior of turbulent flows near instabilities and boundaries. A further aim is to explore rigidity phenomena and to attack several outstanding open problems in the context of differential inclusions, most prominently Morrey's conjecture on quasiconvexity and rank-one convexity.","1860875","2017-04-01","2022-03-31"
"DIMENSION","Real-time Data-Informed Multi-scale Computational Methods for Material Design and Processing","Karen VEROY-GREPL","RHEINISCH-WESTFAELISCHE TECHNISCHE HOCHSCHULE AACHEN","The fundamental importance of materials to modern society is evidenced by the way new materials have revolutionized almost every aspect of our lives. Despite the many advances, dwindling resources and more stringent demands on product cost and performance demand increasingly better material designs and production processes, resulting in a heightened reliance on computational methods.
In the field of computational materials engineering, the recent emergence of data science into the mainstream is causing a paradigm shift in the way models and data are used. There is a shift from traditional simulation methods which use data mainly to calibrate parameters in models, to data-driven simulation methods which seek to bypass the use of models by extracting knowledge from large data sets. This project synergistically combines aspects of both – by developing advanced computational methods that permit multi-scale material models to be informed by available measurement data.
This project addresses this challenging problem through two main tasks. In the first part, we develop dimension reduction techniques for rapid multi-scale materials simulations. These methods must be capable of dealing with deterministic and stochastic microstructure parameters reflecting variations in loading, material, and morphological properties. In the second part, the reduced order models serve as an enabler for the development of computational methods for the selection of the most informative data and its assimilation into multi-scale material models. By enabling parameter estimation and model correction, this leads to increased accuracy and precision in the prediction of engineering quantities of interest.
The success of the project will give rise to a novel computational framework that enables real-time multi-scale materials simulations informed by optimally chosen data, thus permitting effective risk management and cost reduction in the design of materials and control of manufacturing processes.","1999632","2019-06-01","2024-05-31"
"DIMR","Data Intensive Modelling of the Rhizosphere Processes","Tiina Roose","UNIVERSITY OF SOUTHAMPTON","We rely on soil to support the crops on which we depend. Less obviously we also rely on soil for a host of 'free services' from which we benefit. For example, soil buffers the hydrological system greatly reducing the risk of flooding after heavy rain; soil contains very large quantities of carbon, which would otherwise be released into the atmosphere where it would contribute to climate change. Given its importance it is not surprising that soil, especially its interaction with plant roots, has been a focus of many researchers. However the complex and opaque nature of soil has always made it a difficult medium to study.
In this ERC research program I will develop a state of the art image based model of the physical and chemical properties of soil and soil-root interactions, i.e., a quantitative, model of the rhizosphere based on fundamental scientific laws. 
This will be realised by a combination of innovative, data rich fusion of structural and chemical imaging methods, integration of experimental efforts to both support and challenge modelling capabilities at the scale of underpinning bio-physical processes, and application of mathematically sound homogenisation/scale-up techniques to translate knowledge from rhizosphere to field scale. The specific science questions I will address with these techniques are: (1) how does the soil around the root, the rhizosphere, function and influence the soil ecosystems at multiple scales, (2) what is the role of root-soil interface micro morphology and mycorrhizae on plant nutrient uptake, (3) what is the effect of plant exuded mucilage on the soil morphology, mechanics and resulting field and ecosystem scale soil function and (4) how to translate this knowledge from the single root scale to root system, field and ecosystem scale in order to predict how the climate change, different soil management strategies and plant breeding will influence the soil fertility.","1996246","2015-09-01","2021-08-31"
"DiODe","Distributed Algorithms for Optimal Decision-Making","James Arthur Robert Marshall","THE UNIVERSITY OF SHEFFIELD","This grant will develop and translate a unifying framework for optimal decision-theory, and observations of natural systems, to design distributed algorithms for decentralised decision-making. This will enable a technological step-change in techniques for controlling distributed systems, primarily demonstrated during the grant by decentralised control of robot swarms. These algorithms and associated methodology will also provide hypotheses and tools to change the way scientists think about and interrogate natural decision mechanisms, from intracellular regulatory networks, via neural decision circuits, to decision-making populations of animals. Specific objectives are:

1. Distributed value-sensitive decision-making: undertake optimality analyses of the applicant’s existing decentralised decision-making algorithms based on observations of collective iterated voting-processes in honeybees, and extend these.

2. Distributed sampling and decision-making: design distributed mechanisms that implement optimal compromises between sampling information and making decisions based on that information.

3. Individual-confidence and distributed decision-making: translate machine learning theory to collective behaviour models, designing mechanisms in which weak decision-makers optimally combine their decisions to optimise group performance.

4. Optimal distributed decision-making in collective robotics: translate theory from objective 1 to 3 towards practical applications in artificial systems, demonstrated using collectively-deciding robots.

5. Development of tools for life scientists and validation of theoretical predictions in natural systems: interact with named collaborators to investigate identified decision mechanisms in single cells, in neural circuits, and in social groups. Develop accessible modelling tools to facilitate investigations by life scientists.","1413705","2015-08-01","2020-07-31"
"DISFILM","Fluorescent-based innovative measure in thin liquid films: A way to understand stability and energy dissipation in foams and emulsions","Isabelle Cantat","UNIVERSITE DE RENNES I","Nobody knows why a soap bubble collapses. When the liquid film forming the bubble, stabilised by surfactants, becomes too thin, it collapses. This seemingly simple problem, ruled by the classical laws of fluid mechanics and of statistical physics, is still a challenge for the physicist. The rupture criteria based on a stability analysis in the vicinity of the film equilibrium state fail to reproduce the observations. However the film ruptures in a foam obey some simple phenomenological laws, which suggest that underlying fundamental laws exist and wait to be determined. The state-of-the-art conjecture is that ruptures are related to hydrodynamical processes in the films, a field in which I have now an international leadership. Recent experimental data I obtained open the possibility to address this question using a fully non-linear approach in the far from equilibrium regime. In this aim, DISFILM will develop an innovative technique to measure the interface velocity and surfactant concentration, based on the use of fluorescent surfactants. The risk relies in the adaptation to dynamical conditions of advanced optical techniques. These quantities have never been measured on flowing interfaces yet, and my technique will be an important breakthrough in the field of free interface flows in presence of surfactants. A set-up will be designed to reproduce on few thin films the deformations occurring in a foam sample. The dynamical path leading to the rupture of the film will be identified and modelled. The results obtained on an isolated film will be implemented to predict the 3D foam stability and the approach will be extended to emulsions. Foams and emulsions are widely used in industry and most of the stability issues have been solved. Nevertheless, most of the industrial formulations must currently be modified in order to use green surfactants. This adaptation will be extremely more efficient and possible with the results of DISFILM as a guideline.","1415506","2017-09-01","2022-08-31"
"DISTRUCT","Structure Theory for Directed Graphs","Stephan Kreutzer","TECHNISCHE UNIVERSITAT BERLIN","Structural graph theory has proved to be a powerful tool for coping
with computational intractability. It provides a wealth of 
concepts and results that can be used to design efficient algorithms for
hard computational problems on specific classes of graphs that
occur naturally in applications.

In many applications in computer science, the natural mathematical
model are directed graphs. Unfortunately, research in
structural graph theory has so far almost exclusively focussed on
undirected graphs and no structure theory for directed graphs
comparable to the tree-width and graph minors based approach for
undirected graphs has been developed that would provide for a similar
set of tools and concepts to deal with computational problems on
directed graphs.  

The objective of this proposal is to develop such a structure
theory aimed specifically at algorithmic applications on directed
graphs. The novelty of our approach is that

a) it is based on directed minors which allows us to avoid
   the algorithmic problems faced by existing digraph width
   measures and has not been studied before in this context and 

b) it facilitates our recent proof of the excluded directed
   grid theorem which is likely to allow entirely new algorithmic
   techniques for directed graphs.

The focus of the project is on the development of the structural
foundations and algorithmic techniques for designing efficient algorithms
for a wide range of algorithmic digraph problems. In particular, we
will use an approach based on logical definability for developing such
algorithmic techniques. 

Furthermore, we will apply our methods to two specific application
areas, model-checking in computer-aided verification and inference
problems in Bayesian networks.","1826773","2015-07-01","2020-06-30"
"DIVI","Direct Visualization of Light-Driven Atomic-Scale Carrier Dynamics in Space and Time","Peter Gerhard Baum","UNIVERSITAT KONSTANZ","Electronics is rapidly speeding up. Ultimately, miniaturization will reach atomic dimensions and the switching speed will reach optical frequencies. This ultimate regime of lightwave electronics, where atomic-scale charges are controlled by few-cycle laser fields, holds promise to advance information processing technology from today’s microwave frequencies to the thousand times faster regime of optical light fields. All materials, including dielectrics, semiconductors and molecular crystals, react to such field oscillations with an intricate interplay between atomic-scale charge displacements (polarizations)  and collective carrier motion on the nanometer scale (currents). This entanglement provides a rich set of potential mechanisms for switching and control. However, our ability to eventually realize lightwave electronics, or even to make first steps, will critically depend on our ability to actually measure electronic motion in the relevant environment: within/around atoms. The most fundamental approach would be a direct visualization in space and time. This project, if realized, will offer that: a spatiotemporal recording of electronic motion with sub-atomic spatial resolution and sub-optical-cycle time resolution, i.e. picometers and few-femtoseconds/attoseconds. Drawing on our unique combination of expertise covering electron diffraction and few-cycle laser optics likewise, we will replace the photon pulses of conventional attosecond spectroscopy with freely propagating single-electron pulses at picometer de Broglie wavelength, compressed in time by sculpted laser fields. Stroboscopic diffraction/microscopy will provide, after playback of the image sequence, a direct visualization of fundamental electronic activity in space and time. Profound study of atomic-scale light-matter interaction in simple and complex materials will provide a comprehensive picture of the fundamental physics allowing or limiting the high-speed electronics of the future.","1992083","2015-08-01","2020-07-31"
"DNA Funs","DNA-based functional lattices","Tim LIEDL","LUDWIG-MAXIMILIANS-UNIVERSITAET MUENCHEN","Nature has evolved astonishingly diverse structures where the nanoscale assembly of components is key to their functionality. Such nanostructures self-assemble at massive scales and at spatial resolutions surpassing top-down production techniques. The leaves of a single tree, e.g., can cover the area of 10.000 m^2 while every mm^2 contains more than 10^8 highly efficient light-harvesting complexes. For future photovoltaic devices, light-managing surfaces and photonic devices it will thus be beneficial to adopt principles of self-assembly. Advances in design and low-cost production of DNA nanostructures allow us to challenge nature. By combining the assembly power of bottom-up DNA origami with top-down lithography it will be possible to fabricate functional nanostructured materials designed on the molecular level while reaching macroscopic dimensions.
With the goal to boost energy conversion rates, I will design DNA structures that grow from pre-patterned surfaces and assemble into interpenetrating 3D networks that exhibit the highest possible contact area for electron donor and acceptor molecules in organic photovoltaic devices. Spectral tuning through carefully designed dye arrangements will complement these efforts.
Custom-tailored photonic crystals built from lattices of DNA origami structures will control the flow of light. By incorporating dynamic DNA reconfigurability and colloidal nanoparticles at freely chosen positions, intelligent materials that respond to external cues such as light or heat are projected.
Positioning accuracy of 1 nm renders possible the emergence of so-called “Dirac plasmons” in DNA-assembled particle lattices. Such topologically protected states are sought after for the coherent and loss-less propagation of energy and information in next-generation all-optical circuits.
These approaches have the potential to reduce production costs and increase efficiencies of light-harvesting devices, intelligent surfaces and future computing devices.","1997500","2019-04-01","2024-03-31"
"DNA ORIGAMI MOTORS","Constructing and powering nanoscale DNA origami motors","Hendrik DIETZ","TECHNISCHE UNIVERSITAET MUENCHEN","Our goal is to advance the field of DNA nanotechnology by achieving directed transport on the nanoscale using robustly functioning synthetic motor units. To do so, we propose to construct spatially periodic, diffusive mechanisms that have broken inversion symmetry and to subject these mechanisms to conditions away from thermal equilibrium. We will build on recent progress in creating complex DNA-based structures and construct various nanoscale rotary and translational Brownian ratchet mechanisms that have well- defined degrees of freedom for motion within periodic and asymmetric energy landscapes. The mechanisms will be self-assembled from DNA origami components. We will use cryo-Transmission Electron Microscopy (TEM) to evaluate and iteratively refine our structures. Conventional video-rate fluorescence microscopy, in addition to super-resolution microscopy, will be employed to study in solution and in real time the diffusive motion of the mechanisms on the single particle level. We will introduce various deterministic or stochastic thermal, mechanical, or chemical perturbations to drive the systems away from thermal equilibrium. We will use laser heating and cooling to experimentally test thermal and flashing ratcheting mechanisms; we will employ dissipative asymmetric fluxes arising in active matter as realized in high-density ATP-hydrolysing motility assays; and we will couple out-of-equilibrium chemical reactions to the motion of our mechanisms. The ultimate goal of our work is to take insights from these experiments and create robustly functioning nanoscale motor units that can drive directed motion against external load and perform at levels comparable to those of natural macromolecular motor proteins. Achieving this goal will create unprecedented technological opportunities, for example, to drive chemical synthesis, actively propel nanoscale drug- delivery vehicles, pump and separate molecules across barriers or package molecules into cargo components.","2000000","2017-05-01","2022-04-30"
"DNAFOLDIMS","Advanced mass spectrometry approaches to reveal nucleic acid folding energy landscapes","Valérie Gabelica","INSTITUT NATIONAL DE LA SANTE ET DE LA RECHERCHE MEDICALE","""50 years after the discovery of the DNA double helix, the variety of structures that nucleic acids can adopt continues to surprise the scientific community. Specific structures and conformational changes are linked to important functions in cell regulation. Understanding the principles that govern how small molecules such as natural metabolites or synthetic drugs modulate the nucleic acid structures is of prime importance for molecular biology and pharmacology. The field however suffers from the lack of suitable experimental tools to monitor all assemblies and structures formed when a small molecule encounters its targets.

The goal of my project is to develop unique mass spectrometry-based approaches to detect, quantify and characterize all these assemblies and structures. Our team’s strength will be to integrate a multidisciplinary approach, from physical and analytical chemistry to molecular biology. We will address the fundamentals of nucleic acid ionization and transfer in the gas phase, develop a unique instrumental setup combining mass spectrometry, ion mobility and circular dichroism ion spectroscopy, and apply these new approaches to biologically important nucleic acids, in order to reveal the mechanisms of ligand-induced conformational changes in important regulatory structures such as G-quadruplex or riboswitches.

This research will also have broader impact, as the approaches and concepts developed here for nucleic acids will contribute fundamental advances in mass spectrometry, and will be transferrable to other supramolecular or biological complexes.""","2021755","2014-06-01","2019-05-31"
"DOiCV","Discrete Optimization in Computer Vision: Theory and Practice","Vladimir Kolmogorov","INSTITUTE OF SCIENCE AND TECHNOLOGYAUSTRIA","This proposal aims at developing new inference algorithms for graphical models with discrete variables, with a focus on the MAP estimation task. MAP estimation algorithms such as graph cuts have transformed computer vision in the last decade; they are now routinely used and are also utilized in commercial systems.
Topics of this project fall into 3 categories.
Theoretically-oriented: Graph cut techniques come from combinatorial optimization. They can minimize a certain class of functions, namely submodular functions with unary and pairwise terms. Larger classes of functions can be minimized in polynomial time. A complete characterization of such classes has been established. They include k-submodular functions for an integer k _ 1.
I investigate whether such tools from discrete optimization can lead to more efficient inference algorithms for practical problems. I have already found an important application of k-submodular functions for minimizing Potts energy functions that are frequently used in computer vision. The concept of submodularity also recently appeared in the context of the task of computing marginals in graphical models, here discrete optimization tools could be used.
Practically-oriented: Modern techniques such as graph cuts and tree-reweighted message passing give excellent results for some graphical models such as with the Potts energies. However, they fail for more complicated models. I aim to develop new tools for tackling such hard energies. This will include exploring tighter convex relaxations of the problem.
Applications, sequence tagging problems: Recently, we developed new algorithms for inference in pattern-based Conditional Random Fields (CRFs) on a chain. This model can naturally be applied to sequence tagging problems; it generalizes the popular CRF model by giving it more flexibility. I will investigate (i) applications to specific tasks, such as the protein secondary structure prediction, and (ii) ways to extend the model.","1641585","2014-06-01","2019-05-31"
"DOQS","Many-Body Physics with Driven Open Quantum Systems of Atoms, Light and Solids","Sebastian Ludwig Diehl","UNIVERSITAET ZU KOELN","Understanding the quantum many-particle problem is one of the grand challenges of modern physics. While tremendous progresses have been made over the past decades in thermodynamic equilibrium, nonequilibrium many-body quantum physics is still in its infancy. Strong motivation for addressing this challenge comes from recent experimental developments in diverse areas, ranging from cold atomic gases over light-driven semiconductors to microcavity arrays. This moves systems into the focus, which are located on the interface of quantum optics, many-body physics and statistical mechanics. They share in common that coherent and driven-dissipative quantum dynamics occur on an equal footing, creating scenarios without immediate counterpart in traditional condensed matter systems. This project has the goal of pushing forward the understanding of such driven open quantum systems. To this end, we follow a combined approach structured around three key challenges. (i) We aim to identify novel macroscopic phenomena, which manifestly witness microscopic non-equilibrium conditions. This concerns non-thermal stationary states, where we will shape an understanding of non-equilibrium phase diagrams and the associated phase transitions, in particular constructing a notion of driven quantum criticality. But it also encompasses the identification of new universal regimes in open system time evolution. Finally, we will extend the concept of topological order to a broader non-equilibrium context, motivated by quantum information applications. (ii) We will create new theoretical tools, in particular advancing a flexible Keldysh dynamical quantum field theory for driven open quantum systems. (iii) We will address a broad spectrum of cutting edge experimental platforms in view of exploring our theoretical scenarios, and to foster mutual cross-fertilization. With an emphasis on cold atomic gases, this program also comprises exciton-polariton condensates and coupled circuit QED architectures.","1676424","2016-02-01","2021-01-31"
"DROUGHT-HEAT","Land-Climate Interactions: Constraints for Droughts and Heatwaves in a Changing Climate","Sonia Isabelle Seneviratne","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","""Land-climate interactions mediated through soil moisture and vegetation play a critical role in the climate system, in particular for the occurrence of extreme events such as droughts and heatwaves. They are, however, poorly constrained in current Earth System Models (ESMs), leading to large uncertainties in climate projections. These uncertainties affect the quality and accuracy of projections of temperature, water availability, and carbon concentrations, as well as that of projected impacts on agriculture, ecosystems, and health.

In the past years, in-situ and remote sensing-based datasets of soil moisture, evapotranspiration, and energy and carbon fluxes have become increasingly available, providing untapped potential for reducing associated uncertainties in current climate models. The DROUGHT-HEAT project aims at innovatively exploiting these new information sources in order to 1) derive observations-based diagnostics to quantify and isolate the role of land-climate interactions in past extreme events (""""Diagnostic Atlas""""), 2) evaluate and improve current ESMs and constrain climate-change projections using the derived diagnostics, and 3) apply the newly gained knowledge to frontier developments in the attribution of climate extremes to land processes and their mitigation through """"land geoengineering"""".

The DROUGHT-HEAT project integrates the newest land observational datasets with the latest stream of ESMs. Novel methodologies will be applied to extract functional relationships from the data, and identify key gaps in the ESMs' representation of underlying processes. These will build on physically-based relationships, machine learning tools, and model calibration. In addition, they will encompass the mapping and merging of derived diagnostics in space and time to reduce """"blank spaces"""" in the datasets. The project is unprecedented in its breadth and scope and will allow a major breakthrough in our understanding of the processes leading to heatwaves and droughts.""","1952285","2014-09-01","2019-08-31"
"DUALITY","Theoretical Foundations of Memory Micro-Insertions in Wireless Communications","Petros ELIA","EURECOM","We propose to develop the theoretical foundations of transforming memory into data rates, and to explore their practical ramifications in wireless communication networks.

Motivated by the long-lasting open challenge to invent a communication technology that scales with the network size, we have recently discovered early indications of how preemptive use of distributed data-storage at the receiving communication nodes (well before transmission), can offer unprecedented throughput gains by surprisingly bypassing the dreaded bottleneck of real-time channel-feedback. For an exploratory downlink configuration, we unearthed a hidden duality between feedback and preemptive use of memory, which managed to doubly-exponentially reduce the needed memory size, and consequently offered unbounded throughput gains compared to all existing solutions with the same resources. This was surprising because feedback and memory were thought to be mostly disconnected; one is used on the wireless PHY layer, the other on the wired MAC.

This development prompts our key scientific challenge which is to pursue the mathematical convergence between feedback-information-theory and preemptive distributed data-storage, and to then design ultra-fast memory-aided communication algorithms that pass real-life testing.
This is a structurally new approach, which promises to reveal deep links between feedback information theory and memory, for a variety of envisioned wireless-network architectures of exceptional promise. In doing so, our new proposed theory stands to identify the basic principles of how a splash of memory can surgically alter the informational-structure of these networks, rendering them faster, simpler and more efficient. In the end, this study has the potential to directly translate the continuously increasing data-storage capabilities, into gains of wireless network capacity, and to ultimately avert the looming network-overload caused by these same indefinite increases of data volumes.","1978778","2017-04-01","2022-03-31"
"DURACELL","Cell Migration under Mechanical Constraints","Benoît Ladoux","UNIVERSITE PARIS DIDEROT - PARIS 7","Control of cell migration is crucial for many biological processes. Cells sense mechanical cues to guide their migration. As opposed to passive materials, living cells actively respond to the mechanical stimuli of their environment through the transduction of mechanical information into biochemical signaling events. These responses, particularly to rigidity, include differentiation, migration and alterations in cell-matrix and cell-cell adhesion and thus occur over a wide range of time and length scales. I propose to address the effect of substrate mechanical properties on cell migration using quantitative in vitro methods based on micro-fabrication and micro-mechanical techniques. My main objectives are to:
1/ Discover specific mechanisms that guide single cells toward stiffer substrates (a process known as durotaxis), investigate the range of stiffness-sensitive responses and determine the molecular mechanisms based on actin dynamics and cell adhesion assembly. 2/ Characterize the emergence of coordinated cell movements and thus how cells move in concert under external mechanical constraints. In addition to cell-substrate interactions, the role of cell-cell junctions is crucial in the transmission of mechanical signals over the cell population. By analyzing tissue dynamics at both mesoscopic and molecular scales, we hope to unravel how epithelial cell sheets mechanically integrate multiple adhesive cues to drive collective cell migration.3/ Elucidate the role of 3D mechanical environments in collective cell migration. In contrast to migration in 2D, cells in 3D must overcome the biophysical resistance of their surrounding milieu. Based on optical and innovative micro-fabrication techniques to modify the stiffness of 3D scaffolds, we will study its influence on cell migration modes and invasion. The goal of this interdisciplinary project is to understand how cells integrate mechanical adhesive signals to adapt their internal organization and ensure tissue integrity","1762734","2014-06-01","2019-05-31"
"DYNACQM","Dynamics of Correlated Quantum Matter: From Dynamical Probes to Novel Phases of Matter","Frank POLLMANN","TECHNISCHE UNIVERSITAET MUENCHEN","The interplay of quantum fluctuations and correlation effects in condensed matter can yield emergent phases with fascinating properties. Understanding these challenging quantum-many body systems is a problem of central importance in theoretical physics and the basis for the development of new materials for future technologies. Dynamical properties can provide characteristic fingerprints that allow to identify novel phases in newly synthesized materials and optical lattice systems. Moreover, when brought out of equilibrium, correlated quantum matter can exhibit dynamical phases that cannot occur in equilibrium settings. 

DYNACQM will develop new theoretical and numerical frameworks to study dynamical properties of correlated quantum matter. On the theoretical side, we will investigate how many-body entanglement affects dynamical properties and predict universal features that can be measured in experiments. For example, dynamical spin correlation functions, measured in neutron scattering experiments, provide signatures of topologically ordered spin liquids. Furthermore, we will study the role of disorder and many-body localization in static as well as in driven quantum systems. On the numerical side, we will develop efficient tensor-product state based algorithms to simulate the dynamics of quantum many-body systems. These will allow us to study realistic microscopic model systems and to understand their dynamical properties.

Recent developments in the creation of synthetic quantum systems and advances in high resolution spectroscopy allow for an unprecedented precision with which the dynamics of quantum systems can be studied and manipulated experimentally. In this light, it is particularly important to theoretically understand the dynamics of correlated quantum systems and to make testable predictions. DYNACQM will bridge between the fundamental understanding of many-body entanglement in correlated quantum matter and experiments.","1998750","2018-06-01","2023-05-31"
"DYNAFLUORS","Dynamic Activatable Fluorophores","Marc VENDRELL ESCOBAR","THE UNIVERSITY OF EDINBURGH","In DYNAFLUORS I will develop the first chemical toolbox for imaging in real time the activity of immune cells in tumours.
Although the management of cancer has improved over the years, the cure rates for patients with metastasis and advanced tumours remain low due to lack of appropriate therapies. Recent studies suggest that drugs empowering host immune cells (i.e. immunotherapies) are promising approaches for intractable tumours. However, there are no tools to visualise and understand how host immune cells stop cancer progression in vivo. This important unmet challenge drives the ambitious targets of this proposal.

Over the past 10 years, I have pioneered the development of chemical fluorophores that allow unparalleled analysis of biological systems. In this project, I will implement an innovative approach to unify cutting-edge methodologies in chemistry and biology and develop Dynamic Activatable Fluorophores (DYNAFLUORS) as a chemical toolbox with enhanced imaging capabilities over current technologies. 

The cross-disciplinary and ambitious nature of this project will open multiple avenues for broad impact in many areas of chemistry as well as in basic biology, imaging and medicine. DYNAFLUORS will allow us to image, from the molecular level to human tissue, the activity of immune cells in tumours and the response to therapy in real time. This ground-breaking chemical platform will represent a step forward in the forefront of chemical imaging and will create new opportunities in the personalised management of cancer.

In the long term, DYNAFLUORS will become a transformative toolbox for monitoring disease in humans. The integration of functional fluorophores into imaging technologies to perform ‘optical biopsies’ in vivo and to create patient-specific drug-response assays has the potential to revolutionise the diagnosis, stratification and personalised treatment of disease.","1986650","2018-06-01","2023-05-31"
"DYNAMO","Energy and charge transfer nonadiabatic dynamics in light-harvesting molecules and nanostructures","Roland Mitric","JULIUS-MAXIMILIANS UNIVERSITAET WUERZBURG","The goal of DYNAMO is to develop an efficient mixed quantum-classical methodology for the simulation of light-induced nonadiabatic processes in multichromophoric light-harvesting assemblies and to apply it to explore energy and charge transport dynamics in novel classes of light-harvesting systems. There is growing evidence that nonadiabatic relaxation processes play a fundamental role in determining the efficiency of the excitonic transfer or charge injection. In addition to the intramolecular nonradiative transitions through conical intersections, well known from photochemistry, the coupling between the chromophores in multichromophoric assemblies gives rise to novel intermolecular nonadiabatic relaxation channels through funnels between the delocalized excitonic and/or charge transfer states. In order to simulate coupled electron-nuclear dynamics in multichromophoric nanostructures we will develop and implement light-induced surface hopping methods and combine them with efficient electronic structure methods. For a unified description of excitonic and charge transfer states we will combine constrained density functional theory (CDFT) and linear response time-resolved density functional theory (TDDFT) within the configuration interaction framework. The direct link with the experiment will be provided through the simulation of time-resolved multidimensional spectra in the mixed quantum-classical framework. We will apply the new methodology to investigate energy and charge transport in nanostructures of self-assembled organic molecules (e.g. tubular J-aggregates), in low band-gap organic polymers (e.g. squaraines) and in hybrid plasmon-exciton architectures, where the photon capture and charge injection efficiency can be enhanced by the interaction with plasmonic fields. The ultimate goal is to reveal mechanisms of efficient energy and charge transfer using a first principles methodology, providing guidance for the design of efficient light-harvesting systems.","1501188","2015-06-01","2020-05-31"
"DYNAPOL","Modeling approaches toward bioinspired dynamic materials","Giovanni Maria PAVAN","SCUOLA UNIVERSITARIA PROFESSIONALE DELLA SVIZZERA ITALIANA","Nature uses self-assembly to build fascinating supramolecular materials, such as microtubules and protein filaments, that can self-heal, reconfigure, adapt or respond to specific stimuli in dynamic way. Building synthetic (polymeric) supramolecular materials possessing similar bioinspired properties via the same self-assembly principles is interesting for many applications. But their rational design requires a detailed comprehension of the molecular determinants controlling the assembly (structure, dynamics and properties) that is typically very difficult to reach experimentally.
The aim of this project is to obtain structure-dynamics-property relationships to learn how to control the dynamic bioinspired properties of supramolecular polymers. I propose to unravel the molecular origin of the bioinspired behavior through massive multiscale modeling, advanced simulations and machine learning. First, we will develop ad hoc molecular models to study monomer assembly and the supramolecular structure of various types of self-assembled materials on multiple scales. Second, using advanced simulation approaches we will characterize the supramolecular dynamics of these materials (dynamic exchange of monomers) at high (submolecular) resolution. We will then study bioinspired properties such as the ability of various supramolecular materials to self-heal, adapt or reconfigure dynamically in response to specific stimuli. Our models will be systematically validated by comparison with the experimental evidence from our collaborators. Finally, we will use machine learning approaches to analyze our high-resolution simulations and to identify the key monomer features that control and determine the structure, dynamics and dynamic properties of a supramolecular material (i.e., structure-dynamics-property relationships). This research will produce unprecedented insight and fundamental models for the rational design of artificial dynamic materials with controllable bioinspired properties.","1999623","2019-06-01","2024-05-31"
"Dynasore","Dynamical magnetic excitations with spin-orbit interaction in realistic nanostructures","Samir Lounis","FORSCHUNGSZENTRUM JULICH GMBH","Nano-spin-orbitronics is an emerging and fast growing field that aims at combining three degrees of freedom − spin, charge and spin-orbit interaction − to explore new nanotechnologies stemming from fundamental physics. New magnetic phases of matter are investigated using, in particular, atomic design to tailor beneficial physical properties down to the atomic level. Storage, transport and manipulation of magnetic information within a small set of atoms does not only require a fundamental understanding of their ground-state properties from the perspective of quantum mechanics, but crucially also their dynamical excited states. We propose to go beyond the state of the art by investigating from first-principles the dynamical properties of chiral spin textures in nanostructures from 2-dimensions to 0-dimension with these nanostructures being deposited on different substrates where spin-orbit interaction plays a major role. Understanding their response to external dynamical fields (electric/magnetic) or currents will impact on the burgeoning field of nano-spin-orbitronics. Indeed, to achieve efficient manipulation of nano-sized functional spin textures, it is imperative to exploit and understand their resonant motion, analogous to the role of ferromagnetic resonance in spintronics. A magnetic skyrmion is an example of a spin-swirling texture characterized by a topological number that will be explored. This spin state has huge potential in nanotechnologies thanks to the low spin currents needed to manipulate it. Based on time-dependent density functional theory and many-body perturbation theory, our innovative scheme will deliver a paradigm shift with respect to existing theoretical methodologies and will provide a fundamental understanding of: (i) the occurrence of chiral spin textures in reduced dimensions, (ii) their dynamical spin-excitation spectra and the coupling of the different excitation degrees of freedom and (iii) their impact on the electronic structure.","1994879","2016-06-01","2021-05-31"
"DyNET","Dynamical river NETworks: climatic controls and biogeochemical function","Gianluca BOTTER","UNIVERSITA DEGLI STUDI DI PADOVA","Despite the ubiquity of expansion and retraction dynamics of flowing streams, the large majority of biogeochemical and hydrological studies conceive river networks as static elements of the landscape, and a coherent framework to quantify nature and extent of drainage network dynamics is lacking. The implications of this phenomenon extend far beyond hydrology and involve key ecological and biogeochemical function of riparian corridors. The proposed research project will move beyond the traditional paradigm of static river networks by unravelling, for the first time, physical causes and biogeochemical consequences of stream dynamics. In particular, the project will undertake the following overarching scientific questions: 1) what are the climatic and geomorphic controls on the expansion/contraction of river networks? 2) what is the length of temporary streams and what is their impact on catchment-scale biogeochemical processes and stream water quality across scales? These challenging issues will be addressed by developing a novel theoretical framework complemented by extensive field observations within four representative sites along a climatic gradient in the EU. Field measurements will include long-term weekly mapping of the active drainage network and daily hydro-chemical data across scales. The experimental dataset will be used to develop and inform a set of innovative modelling tools, including an analytical framework for the description of spatially explicit hydrologic dynamics driven by stochastic rainfall and a modular hydro-chemical model based on the concept of water age, able to account for the variable connectivity among soil, groundwater and channels as induced by stream network dynamics. The project will open new avenues to quantify freshwater carbon emissions - crucially dependent on the extent of ephemeral streams - and it will provide a robust basis to identify temporary rivers and maintain their biogeochemical function in times of global change.","1999758","2018-05-01","2023-04-30"
"DYNPOR","First principle molecular dynamics simulations for complex chemical transformations in nanoporous materials","Véronique Van Speybroeck","UNIVERSITEIT GENT","Chemical transformations in nanoporous materials are vital in many application domains, such as catalysis, molecular separations, sustainable chemistry,….  Model-guided design is indispensable to tailoring materials at the nanometer scale level.    
At real operating conditions, chemical transformations taking place at the nanometer scale have a very complex nature, due to the interplay of several factors such as the number of particles present in the pores of the material, framework flexibility, competitive pathways, entropy effects,…  The textbook concept of a single transition state is far too simplistic in such cases.  A restricted number of configurations of the potential energy surface is not sufficient to capture the complexity of the transformation.    

My objective is to simulate complex chemical transformations in nanoporous materials using first principle molecular dynamics methods at real operating conditions, capturing the full complexity of the free energy surface.  To achieve these goals advanced sampling methods will be used to explore the interesting regions of the free energy surface. The number of guest molecules at real operating conditions will be derived and the diffusion of small molecules through pores with blocking molecules will be studied.  New theoretical models will be developed to keep track of both the framework flexibility and entropy of the lattice.  

The selected applications are timely and rely on an extensive network with prominent experimental partners.  The applications will encompass contemporary catalytic conversions in zeolites, active site engineering in metal organic frameworks and structural transitions in nanoporous materials, and the expected outcomes will have the potential to yield groundbreaking new insights.  

The results  are expected to have impact far beyond the horizon of the current project as they will contribute to the transition from static to dynamically based modeling tools within heterogeneous catalysis","1993750","2015-08-01","2020-07-31"
"E-motion","Electro-motion for the sustainable recovery of high-value nutrients from waste water","Louis Cornelia Patrick Maria de Smet","WAGENINGEN UNIVERSITY","Current water treatment technologies are mainly aimed to improve the quality of water. High-value nutrients, like nitrate and phosphate ions, often remain present in waste streams. Electro-driven separation processes offer a sustainable way to recover these nutrients. Ion-selective polymer membranes are a strong candidate to achieve selectivity in such processes.

The aim of E-motion is to chemically modify porous electrodes with membranes to introduce selectivity in electro-driven separation processes. New, ultrathin ion-selective films will be designed, synthesized and characterized. The films will be made by successively adsorbing polycations and polyanions onto the electrodes. Selectivity will be introduced by the incorporation of ion-selective receptors. The adsorbed multilayer films will be studied in detail regarding their stability, selectivity and transport properties under varying experimental conditions of salinity, pH and applied electrical field, both under adsorption and desorption conditions.

The first main challenge is to optimize and to understand the film architecture in terms of 1) stability towards an electrical field, 2) ability to facilitate ion transport. Also the influence of ion charge and ion size on the transport dynamics will be addressed. The focus of E-motion is set on phosphate ions, which is rather complex due to their large size, pH-dependent speciation and the development of phosphate-selective materials. Theoretical modelling of the solubility equilibria and electrical double layers will be pursued to frame the details of the electrosorption of phosphate.

E-motion represents a major step forward in the selective recovery of nutrients from water in a cost-effective, chemical-free way at high removal efficiency. The proposed surface modification strategies and the increased understanding of ion transport and ionic interactions in membrane media offer also applications in the areas of batteries, fuel cells and solar fuel devices.","1950000","2016-11-01","2021-10-31"
"e-Sequence","e-Sequence: a sequential approach to engineer heteroatom doped graphene nanoribbons for electronic applications","Aurelio MATEO ALONSO","UNIVERSIDAD DEL PAIS VASCO/ EUSKAL HERRIKO UNIBERTSITATEA","Graphene nanoribbons (NR) are quasi-1D nanostructures with discrete band gaps, ballistic conduction, and one-atom thickness. Such properties make them ideal candidates to develop low-dimensional semiconductors, which are essential components in nanoelectronics. Atomically-precise control over the structure of NR (width, length, edge, doping) is crucial to fully exploit their potential. However, current approaches for the synthesis of NR suffer from several drawbacks that do not allow attaining such level of precision, therefore alternative methods need to be sought.

e-Sequence will develop an unprecedented approach that assembles stepwise small molecular building blocks into NR to specifically target the most important challenges in NR synthesis. Such approach will enable the preparation of an unlimited number of NR with atomically-precise control over their structure and with almost no synthetic and purification effort, exceeding the limits of existing methods.

The impact of e-Sequence will not be limited to NR synthesis but it will also extend to other disciplines, since NR are promising candidates to develop new technologies with applications in electronics, sensing, photonics, energy storage and conversion, spintronics, etc.

e-Sequence ambitious research programme will be orchestrated by an independent scientist with an excellent track record of achievements in low-dimensional carbon nanostructures, and who has already established a fledgling and internationally competitive research group. Building on this and on his recent permanent appointment as Research Professor, the award of this ERC project will enable him to consolidate his group, build a portfolio of excellent research, and produce results that compete on the world stage.","2000000","2017-11-01","2022-10-31"
"Earth core","Exploring Thermodynamic Properties of Earth’s Core-Forming Materials","Tetsuya Komabayashi","THE UNIVERSITY OF EDINBURGH","It is known that the Earth’s core is less dense than pure iron by about 7%, which is due to the presence of a light element(s) such as Si, S, C, O, and H. The goal of this project is to construct a thermodynamic model of the Earth’s central core. A particular focus is on the identification of the light element because the inclusion of these elements in iron liquid depends on the pressure (P), temperature (T), and chemical environment and hence provides us invaluable information about the origin and evolution of the solid Earth. We will examine phase relations and density of phases in Fe-light element systems by conducting high-P-T experiments and employing thermodynamic calculations based on the experimental data. 
High-P-T experiments will be conducted in a diamond anvil cell with three different kinds of heating techniques: laser heating, external-resistive heating, and internal-resistive heating. Of the three, the internal-resistive heating system is a special technique that I have developed and employed and I am currently generating 5000 K at 200 GPa with it. Structure of phases will be analysed by in-situ X-ray diffraction. Chemical analysis will also be employed on samples to determine element partitioning between the phases. 
I will also employ thermodynamic calculations based on the experimental data to fully understand the thermodynamic properties of the materials and obtain physical properties which are difficult to directly determine by experiment such as sound velocity of liquids. 
From the thermodynamic models, I will calculate the physical properties of light element-bearing iron liquids and compare them with seismologically constrained values of the Earth’s core to find out the best matching composition. From these results, I will discuss the physical and chemical environments during the core formation and implicate in the origin and evolution of the Earth. Also the results will be applied to other terrestrial planets which have metallic cores.","1891765","2015-06-01","2020-05-31"
"EARTHSEQUENCING","A new approach to sequence Earth history at high resolution over the past 66 million years","Heiko Pälike","UNIVERSITAET BREMEN","""One major challenge to be addressed by this proposal is to overcome fundamental obstacles to generate a first high-resolution and continuous fully integrated record of geological events, ages and durations
(a ‘sequence of Earth history’) for the past 66 million years, anchored to the present, to extract properties of Earth’s and solar system orbital motion, and then to apply this time scale to solve first order questions about Earth’s climate system and Earth System sensitivity. The project will bridge the long-standing ‘Eocene tuning gap’, primarily using spectacular new data recovered during Integrated Ocean Drilling Expedition 342 and integrated with a new consistent and integrated approach with existing data that currently only provide time sequences floating in time, not anchored to the present. The proposal will extract astronomical parameters (tidal dissipation, dynamical ellipticity) and verify astronomical models to provide long term amplitude modulation patterns of Earth’s orbital variations (obliquity and short eccentricity) beyond 40 million years before present.  It will also search for the fingerprint of chaotic transitions in the solar system that will allow astronomical models to be tested. The improved geologic time scale will then be applied, exploited, and combined with modern Earth System Models of Intermediate Complexity to quantify Earth System sensitivity to orbital forcing during a world of elevated carbon-dioxide concentrations during the ‘greenhouse’ Paleogene. Using novel new pattern matching and recognition algorithms as well as time series analysis methods, the full record of Earth history will be fully integrated and analysed with a consistent and documented workflow. This development will have the ground-breaking potential to take ‘Earth sequencing’ to the next level.""","1998343","2014-04-01","2019-03-31"
"eAXON","Electronic AXONs: wireless microstimulators based on electronic rectification of epidermically applied currents","Antonio IVORRA Cano","UNIVERSIDAD POMPEU FABRA","To build interfaces between the electronic domain and the human nervous system is one of the most demanding challenges of nowadays engineering. Fascinating developments have already been performed such as visual cortical implants for the blind and cochlear implants for the deaf. Yet implantation of most electrical stimulation systems requires complex surgeries which hamper their use for the development of so-called electroceuticals. More importantly, previously developed systems based on central stimulation units are not adequate for applications in which a large number of sites must be individually stimulated over large and mobile body parts, thus hindering neuroprosthetic solutions for patients suffering paralysis due to spinal cord injury or other neurological disorders. A solution to these challenges could consist in developing addressable single-channel wireless microstimulators which could be implanted with simple procedures such as injection. And, indeed, such solution was proposed and tried in the past. However, previous attempts did not achieve satisfactory success because the developed implants were stiff and too large. Further miniaturization was prevented because of the use of inductive coupling and batteries as energy sources. Here I propose to explore an innovative method for performing electrical stimulation in which the implanted microstimulators will operate as rectifiers of bursts of innocuous high frequency current supplied through skin electrodes shaped as garments. This approach has the potential to reduce the diameter of the implants to one-fifth the diameter of current microstimulators and, more significantly, to allow that most of the implants’ volume consists of materials whose density and flexibility match those of neighbouring living tissues for minimizing invasiveness. In fact, implants based on the proposed method will look like short pieces of flexible thread.","1999813","2017-05-01","2022-04-30"
"ECHO","Extending Coherence for Hardware-Driven Optimizations in Multicore Architectures","Alberto ROS","UNIVERSIDAD DE MURCIA","Multicore processors are present nowadays in most digital devices, from smartphones to high-performance servers. The increasing computational power of these processors is essential for enabling many important emerging application domains such as big-data, media, medical, or scientific modeling. A fundamental technique to improve performance is speculation, a technique that consists in executing work before it is known if it is actually needed. In hardware, speculation significantly increases energy consumption by performing unnecessary operations, while speculation in software (e.g., compilers) is not the default thus preventing performance optimizations. Since performance in current multicores is limited by their power budget, it is imperative to make multicores as energy-efficient as possible to increase performance even further.
In a multicore architecture, the cache coherence protocol is an essential component since its unique but challenging role is to offer a simple and unified view of the memory hierarchy. This project envisions that extending the role of the coherence protocol to simplify other system components will be the key to overcome the performance and energy limitations of current multicores. In particular, ECHO proposes to add simple but effective extensions to the cache coherence protocol in order to (i) reduce and even eliminate misspeculations at the processing cores and synchronization mechanisms and to (ii) enable speculative optimizations at compile time. The goal of this innovative approach is to improve the performance and energy efficiency of future multicore architectures. To accomplish the objectives proposed in this project, I will build on my 14 years expertise in cache coherence, documented in over 40 publications of high impact.","1999955","2019-09-01","2024-08-31"
"ECLAIR","Emulation of subgrid-scale aerosol-cloud interactions in climate models: towards a realistic representation of aerosol indirect effect","Sari Hannele Korhonen","ILMATIETEEN LAITOS","I propose to develop an innovative interdisciplinary model framework to refine the estimate of aerosol indirect effect (i.e. influence of atmospheric aerosol particles on cloud properties), which remains the single largest uncertainty in the current drivers of climate change. 

A major reason for this uncertainty is that current climate models are unable to resolve the spatial scales for aerosol-cloud interactions. We will resolve this scale problem by using statistical emulation to build computationally fast surrogate models (i.e. emulators) that can reproduce the effective output of a detailed high-resolution cloud-resolving model. By incorporating these emulators into a state-of-the-science climate model, we will for the first time achieve the accuracy of a limited-area high-resolution model on a global scale with negligible computational cost.

The main scientific outcome of the project will be a highly refined and physically sound estimate of the aerosol indirect effect that enables more accurate projections of future climate change, and thus has high societal relevance. In addition, the developed emulators will help to quantify how the remaining uncertainties in aerosol properties propagate to predictions of aerosol indirect effect. This information will be used, together with an extensive set of remote sensing, in-situ and laboratory data from our collaborators, to improve the process-level understanding of aerosol-cloud interactions. 

The comprehensive uncertainty analyses performed during this project will be highly valuable for future research efforts as they point to processes and interactions that most urgently need to be experimentally constrained. Furthermore, our pioneering model framework that incorporates emulators to represent subgrid- scale processes will open up completely new research opportunities also in other fields that deal with heterogeneous spatial scales.","1999511","2015-09-01","2020-08-31"
"ECM_INK","Cells-self Extracellular Matrices-based Bioinks to create accurate 3D diseased skin tissue models","Alexandra Margarida PINTO MARQUES","UNIVERSIDADE DO MINHO","It has been recognized that growing cells within 3D structures reduces the gap between 2D in vitro cell cultures and native tissue physiology. This has been paving the way for the development of reliable 3D in vitro cell-based platforms with major impact in the reduction/elimination of animal experimentation, diseases modelling and drug development. So far, the many strategies that have been followed to bioengineer in vitro 3D human tissue models mostly rely on the random culture of cells within a 3D structure without reflecting the compositional and structural complexity of the native tissues. Recently proposed bioprinting technologies that allow accurate and high speed deposition of various cells and matrices at high resolution, have therefore great potential in the development of physiologically reliable 3D in vitro tissue models by recreating the different microenvironments/microfunctionalities found in each tissue. Nonetheless, among the components required for bioprinting, bioinks in particular have demanding requirements and much has still to be done regarding their intrinsic formulation to lead cell behaviour and support specific functionalities.
ECM_INK intends to tackle this issue by developing cells-self extracellular matrices-based bioinks to create accurate and pathophysiological relevant 3D in vitro diseased skin tissue models. The development of cell phenotype-driven bioinks will generate complex microenvironments comprising varied cell types within matrices that were specifically designed to attain a particular response from each one of those cell types. The use of cells from patients suffering from chronic, genetic and neoplastic skin diseases represents a major advantage that will be reflected in the accuracy and functionality of the respective 3D in vitro models. The ultimate confirmation of their potential will be complete after validation using animal-free approaches reinforcing the intrinsic relationship of ECM_INK with the 3Rs policy.","1998939","2017-05-01","2022-04-30"
"ECO-ZEN","Enabling Catalytic Cross Couplings with only Zinc Electrophiles, Nucleophiles and Boranes","Michael James INGLESON","THE UNIVERSITY OF MANCHESTER","This high-impact, challenging CoG Proposal integrates multiple novel ideas in boron and zinc chemistry into an overarching project to open up new horizons across synthesis and catalysis. The Applicant’s successful ERC StG has opened up new avenues of pioneering research in main group element mediated transformations that were not conceivable before the work was done. Components of this proposal extend out from the StG into new, exciting research areas that are completely different. Developing low toxicity earth abundant catalysts for important transformations is vital to the EU with the focus herein being on; (i) the Suzuki-Miyaura (S-M) cross coupling reaction which is ubiquitous in industry and academia, and (ii) the formation of organoboranes that are essential synthetic intermediates. Both of these are currently dominated by toxic, expensive and low abundance precious metal catalysts (e.g. Pd, Ir). This project will deliver innovation through utilising combinations of main group Lewis acids and nucleophilic anions that do not react with each other, i.e. are frustrated pairs. This “frustration” enables the two species to concertedly transform substrates to achieve:

(i) Precious metal-free S-M cross coupling reactions of sp3C electrophiles catalysed by zinc and boron compounds, including stereospecific couplings and one pot two step cross electrophile couplings.

(ii) Trans-elementoboration of alkynes, including the unprecedented fluoroboration of alkynes.

Other new approaches will be developed to access novel (hetero)arylboronic acid derivatives using only simple boranes and without requiring noble metal catalysts, specifically: (i) boron directed C-H borylation and (ii) directed ortho borylation to enable subsequent meta selective SEAr C-H functionalisation. 

This CoG will afford the freedom and impetus via consolidated funding to undertake fundamental research to deliver high impact results, including developing a new area of cross coupling catalysis research.","2070093","2018-05-01","2023-04-30"
"ECOHERB","Drivers and impacts of invertebrate herbivores across forest ecosystems globally.","Daniel Metcalfe","LUNDS UNIVERSITET","Forests slow global climate change by absorbing atmospheric carbon dioxide but this ecosystem service is limited by soil nutrients. Herbivores potentially alter soil nutrients in a range of ways, but these have mostly only been recorded for large mammals. By comparison, the impacts of the abundant invertebrates in forests have largely been ignored and are not included in current models used to generate the climate predictions so vital for designing governmental policies
The proposed project will use a pioneering new interdisciplinary approach to provide the most complete picture yet available of the rates, underlying drivers and ultimate impacts of key nutrient inputs from invertebrate herbivores across forest ecosystems worldwide. Specifically, we will:

(1) Establish a network of herbivory monitoring stations across all major forest types, and across key environmental gradients (temperature, rainfall, ecosystem development).
(2) Perform laboratory experiments to examine the effects of herbivore excreta on soil processes under different temperature and moisture conditions.
(3) Integrate this information into a cutting-edge ecosystem model, to generate more accurate predictions of forest carbon sequestration under future climate change.

The network established will form the foundation for a unique long-term global monitoring effort which we intend to continue long after the current funding time scale. This work represents a powerful blend of several disciplines harnessing an array of cutting edge tools to provide fundamentally novel insights into an area of direct and urgent importance for the society.","1750000","2016-03-01","2021-02-28"
"ELECNANO","Electrically Tunable Functional Lanthanide Nanoarchitectures on Surfaces","DAVID ECIJA FERNANDEZ","FUNDACION IMDEA NANOCIENCIA","Lanthanide metals are ubiquitous nowadays, finding use in luminescent materials, optical amplifiers and waveguides, lasers, photovoltaics, rechargeable batteries, catalysts, alloys, magnets, bio-probes, and therapeutic agents. In addition, they bear potential for high temperature superconductivity, magnetic refrigeration, molecular magnetic storage, spintronics and quantum information. 

Surprisingly, the study of lanthanide physico-chemical properties on surfaces is at its infancy, particularly at the nanoscale. To address this extraordinary scientific opportunity, I will research the foundations and prospects of lanthanide elements to design functional nanoarchitectures on surfaces and I will study their inherent physico-chemical phenomena in distinct coordination environments, targeting novel approaches for sensing, nanomagnetism and electroluminescence. Importantly, our studies will encompass both metal substrates and decoupling surfaces including ultra-thin film insulators and graphene. Nurturing from these studies and in parallel, we will focus on graphene voltage back-gated supports, thus surpassing the seminal knowledge on electrically-inert substrates and enhancing the scope of our research to address the overarching objective of the proposal, i.e., the design of electrically tunable functional lanthanide nanomaterials.

The culmination of ELECNANO project will provide strategies for:
1.-Design of functional nanomaterials on high-technological supports.
2.-Development of advanced coordination chemistry on surfaces.
3.-Rationale of the physico-chemical properties of lanthanide-coordination environments.
4.-Engineering of lanthanide nanoarchitectures for ultimate sensing, nanomagnetism and electroluminescence.
5.-In-situ atomistic views of electrically tunable materials and unprecedented fundamental studies of charge-molecule/metal physics on devices.","1994713","2018-09-01","2023-08-31"
"eLightning","Lightning propagation and high-energy emissions within coupled multi-model simulations","Alejandro Luque Estepa","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","More than 250 years after establishing the electrical nature of the lightning flash, we still do not understand how a lightning channel advances. Most of these channels progress not continuously but in a series of sudden jumps and, as they jump, they emit bursts of energetic radiation.  Despite increasingly accurate observations, there is no accepted explanation for this stepped progression.

This proposal addresses this open question.  First, we propose a methodological breakthrough that will allow us to tackle the main bottleneck in the theoretical understanding of lightning: the wide disparity between length-scales within a lightning flash.  We plan to apply techniques that have succeeded in other fields, such as multi-model coupled simulations and moving-mesh finite elements methods.  Acting as a computational microscope, these techniques will reveal the small-scale electrodynamics around a lightning channel.

We will then apply these techniques to elucidate the intertwined problems of lightning channel stepping and thunderstorm-related high-energy emissions.   The main hypothesis that we will test is that stepping is due to the formation of low-conductivity spots within the filamentary-discharge region that surrounds a lightning channel.  This idea is motivated by observations from high-altitude atmospheric discharges.  By resolving the small-scale dynamics, with our numerical method, we will also test hypothesis for high-energy emissions from the lighting channel, which crucially depend on the microscopic distribution of electric fields.

This interdisciplinary proposal, straddling between geophysics and gas discharge physics, seeks a double breakthrough: the methodological one of building multi-scale lightning simulations and the hypothesis-driven one of finding out the reason for stepping.  If it succeeds, it will achieve a leap forward in our knowledge of lightning, undoubtedly one of the greatest spectacles in our planet's repertoire.","1960826","2016-06-01","2021-05-31"
"ElIonT","Electron- and Ion Transfer at the Interface: a Hyphenated Dynamic Multi-Frequency Approach","Fabio LA MANTIA","UNIVERSITAET BREMEN","It is undisputed that electrochemistry has a central role in our contemporary society. This is demonstrated by its profound involvement in many aspects of everyday life: from powering portable electronic devices to personal electro-mobility, passing through recycling, waste water treatment, clean energy production, water desalination, personal care, and others. It appears that we have reached the limits of the technological development and no further revolutionary progresses can be achieved without a deeper understanding of the electron- and ion-transfer process at the interface. The objective of this proposal is to achieve a phenomenological modeling of the electron- and ion-transfer processes, by extending the Marcus-Hush theory of the electron transfer to a general kinetic equation based on experimental data. The extended kinetic equation should include and clarify the role of the excess free Gibbs energy on the kinetics of electron- and ion-transfer, as well as the role of the double layer charge (Frumkin effect). A unified theory of charge transfer and transport will be proposed in the frame of the phenomenological theory of transport and of classic and extended irreversible thermodynamics. Since the investigated phenomena are complex and inter-linked, the investigation techniques must seize snapshots of the system during its evolution; this will be done by hyphenating the electrochemical techniques with quartz crystal microbalance, able to measure in real time nanogram mass changes. In order to cover the time-scales necessary to develop the phenomenological theory, we will measure dynamic impedance and differential immitance spectra with a dynamic multi-frequency approach. This is based on perturbing the system with a multi-sine signal and extracting the linear and non-linear current response and mass change. The evaluation of the phenomenological parameters will rely on novel analysis algorithms and on precise modeling of the interface.","1943600","2018-05-01","2023-04-30"
"Emergence","Emergence of wild differentiable dynamical systems","pierre berger","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Many physical or biological systems display time-dependent states which can be mathematically modelled by a differentiable dynamical system. The state of the system consists of a finite number of variables, and the short time evolution is given by a differentiable equation or the iteration of a differentiable map. The evolution of a state is called an orbit of the system. The theory of dynamical systems studies the long time evolution of the orbits.
For some systems, called chaotic, it is impossible to predict the state of an orbit after a long period of time. However, in some cases, one may predict the probability of an orbit to have a certain state. A paradigm is given by the Boltzmann ergodic hypothesis in thermodynamics: over long periods of time, the time spent by a typical orbit in some region of the phase space is proportional to the “measure” of this region. The concept of Ergodicity has been mathematically formalized by Birkhoff. Then it has been successfully applied (in particular) by the schools of Kolmogorov and Anosov in the USSR, and Smale in the USA to describe the statistical behaviours of typical orbits of many differentiable dynamical systems.
For some systems, called wild, infinitely many possible statistical behaviour coexist. Those are spread all over a huge space of different ergodic measures, as initially discovered by Newhouse in the 70's. Such systems are completely misunderstood. In 2016, contrarily to the general belief, it has been discovered that wild systems form a rather typical set of systems (in some categories).
This project proposes the first global, ergodic study of wild dynamics, by focusing on dynamics which are too complex to be well described by means of finitely many statistics, as recently quantified by the notion of Emergence. Paradigmatic examples will be investigated and shown to be typical in many senses and among many categories. They will be used to construct a theory on wild dynamics around the concept of Emergence.","1070343","2019-09-01","2024-08-31"
"EMPIRE","Galaxy Evolution in the ALMA Era - The Baryon Cycle and Star Formation in Nearby Galaxies","Frank BIGIEL","RHEINISCHE FRIEDRICH-WILHELMS-UNIVERSITAT BONN","A thorough understanding of the processes regulating the conversion of gas into stars is key to understand structure formation in the universe and the evolution of galaxies through cosmic time. Despite significant progress over the past years, the properties of the actual dense, star forming gas across normal disk galaxies remain largely unknown. This will be changed with EMPIRE, a comprehensive 500hr large program led by the PI at the IRAM 30m mm-wave telescope. EMPIRE will provide for the first time extended maps of a suite of dense gas tracers (e.g., HCN, HCO+, HNC) for a sample of nearby, star-forming, disk galaxies.

By means of detailed analysis, including radiative transfer and chemical modelling, we will constrain a variety of physical quantities (in particular gas densities). We will relate these directly to the local star formation efficiency and to a variety of other dynamical, stellar and local ISM properties from existing pan-chromatic mapping of these galaxies (HI, IR, CO, UV, optical) to answer the question: ``how is star formation regulated across galaxy disks?''. By determining true abundance variations, we will contribute key constraints to the nascent field of galaxy-scale astrochemistry. Detailed comparisons to data for star forming regions in the Milky Way will link core, cloud and galactic scales towards a coherent view of dense gas and star formation. These results will provide an essential anchor point to Milky Way and high redshift observations alike.

Analysis, interpretation and modelling of this complex data set requires a team of two postdocs and two PhD students. The PI has demonstrated his ability to successfully lead a research group through his current position as a DFG funded Emmy-Noether group leader. In combination with his widely recognized previous work and his expertise in mm-wave astronomy and ISM/star formation studies, the PI and the proposed group are uniquely positioned to make significant impact during this ERC grant.","1659451","2017-07-01","2022-06-30"
"EMPOWER","Medium Voltage Direct Current Electronic Transformer","Drazen DUJIC","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","More than a century ago, the invention of alternating current (AC) transformer has made AC the preferred choice over the direct current (DC) technologies. Line AC transformers are bulky but simple and reliable devices, made out of copper and iron, providing voltage adaptation and galvanic isolation in AC power systems. 

Currently, DC technology is increasing its presence in AC power systems, enabled by progress in semiconductor devices and power electronics based energy conversion. DC power distribution networks can effectively support energy transformation and high penetration of distributed energy resources and energy storage integration (both increasingly being DC by nature) in future energy systems. Despite this shift towards the DC power distribution networks, DC Transformer, offering AC transformer like features (and beyond) does not exist, either conceptually or practically.

To enable the next (r)evolution in power systems, the EMPOWER project will develop the DC Transformer, a novel, flexible, highly efficient, compact, and reliable conversion principle for seamless energy routing in high-power DC distribution networks. Through a holistic approach, novel concepts, integration and optimization, we will demonstrate new design paradigms for galvanically-isolated power conversion. Our approach relies on resonant conversion utilizing high-voltage semiconductor devices in combination with high-frequency magnetic materials. We propose a new approach for the DC Transformer, avoiding active power flow control and instead utilizing control effort for the safety and protection. The DC Transformer will unify functions of a power converter and a protection device into a single power electronics system, improving drastically the conversion efficiency, reliability and power density in future DC power distribution networks. The success of this project will place Europe at the edge of reliable, efficient and safe energy distribution and transmission technologies.","2198145","2019-06-01","2024-05-31"
"ENCOMOLE-2i","Endoscopic Comprehensive Optical Multimodal Molecular Intelligent Imaging","Robert Huber","UNIVERSITAT ZU LUBECK","Optical imaging has exceptional potential for medical diagnosis, because it can provide high spatial resolution and molecular contrast. However, for in vivo imaging in humans, the poor penetration of only a few millimetres is a major obstacle. Optical endoscopes solve this problem, but currently most of them only perform non-advanced, classical white light imaging. Also, the speed of current devices is not sufficient to comprehensively scan entire organs at microscopic resolution. Hence, medical imaging is still dominated by non-optical techniques like X-ray, ultrasound and magnetic resonance imaging.
The objective of ENCOMOLE-2i is to push the performance of advanced optical in vivo imaging techniques to cross the application threshold for clinical research and practice. An endoscopic multi-modal molecular imaging platform will be developed with unprecedented capabilities for the diagnosis of disease.
The hardware technology development includes three novel imaging modalities. Optical coherence tomography with line rates of several Megahertz will be used for comprehensive structural imaging over large areas. Time encoded stimulated Raman sensing, supported by a new type of two photon microscopy, will be used for guided and referenced molecular imaging. Combining these techniques into one system and interfacing it with a newly developed endoscope will generate great synergy. Moreover, the unique synchronization capabilities of these modalities enable a radically new strategy for more efficient data acquisition: The concept of adaptive “Intelligent Imaging”.
The goal is to develop a universal endoscopy platform which can then be specifically tailored to the individual application. In the project the focus is on gastrointestinal imaging. The synergy between technological and algorithmic advances in ENCOMOLE-2i will break ground for more optical in vivo imaging in clinical research and routine, which can finally lead to improved diagnosis of many types of disease.","1998530","2016-01-01","2020-12-31"
"ENERCAPSULE","Nanoencapsulation for Energy Storage and Controlled Release","Dzmitry Shchukin","THE UNIVERSITY OF LIVERPOOL","The main vision of the project ENERCAPSULE is the development of nanoencapsulation technologies based on switchable nanoscale barriers for novel generation of controlled energy storage and delivery systems. These systems will be based on the “smart” nanocontainers (size below 200 nm) loaded with the energy-enriched active components: materials for thermal energy (both latent and based on chemical reactions) storage and substances for bioenergy (ATP or its components) storage for synthetic biology platforms. First novelty of the proposed project is the protection of the nanoscaled energy-enriched materials against environment during storage and controlled release of the encapsulated energy on demand only using both inherent properties of nanocontainer shell or biomimetic nanovalves introduced as shell components. Another main objective of the project is to study the structure and surface-to-volume properties of the energy enriched materials dispersed and encapsulated on nanoscale. The questions of stability of energy nanomaterials, influence of the nanocontainer shell on their energy capacity, homogeneity and operation lifetime will be investigated. Polymer organic nanocapsules with hollow interior and mesoporous carbon nanoparticles are chosen in the project as main types of the nanocontainer scaffolds for energy-enriched materials due to their high loading capacity and potential to design their shells to attain them controlled permeability properties. At the end of the project, developed novel energy storage and delivery systems will be combined within one network having several mechanisms for release and uptake of energy, which can be activated depending on type and intensity of the external impact (demand). The potential applications of such multienergy storage systems will be tested by industrial companies supporting the project.","2004500","2015-09-01","2020-08-31"
"ENFORCE","ENgineering FrustratiOn in aRtificial Colloidal icEs:degeneracy, exotic lattices and 3D states","pietro TIERNO","UNIVERSITAT DE BARCELONA","Geometric frustration, namely the impossibility of satisfying competing interactions on a lattice, has recently
become a topic of considerable interest as it engenders emergent, fundamentally new phenomena and holds
the exciting promise of delivering a new class of nanoscale devices based on the motion of magnetic charges.
With ENFORCE, I propose to realize two and three dimensional artificial colloidal ices and investigate the
fascinating manybody physics of geometric frustration in these mesoscopic structures. I will use these soft
matter systems to engineer novel frustrated states through independent control of the single particle
positions, lattice topology and collective magnetic coupling. The three project work packages (WPs) will
present increasing levels of complexity, challenge and ambition:
(i) In WP1, I will demonstrate a way to restore the residual entropy in the square ice, a fundamental longstanding
problem in the field. Furthermore, I will miniaturize the square and the honeycomb geometries and investigate the dynamics of thermally excited topological defects and the formation of grain boundaries.
(ii) In WP2, I will decimate both lattices and realize mixed coordination geometries, where the similarity
between the colloidal and spin ice systems breaks down. I will then develop a novel annealing protocol based
on the simultaneous system visualization and magnetic actuation control.
(iii) In WP3, I will realize a three dimensional artificial colloidal ice, in which interacting ferromagnetic
inclusions will be located in the voids of an inverse opal, and arranged to form the FCC or the pyrochlore
lattices. External fields will be used to align, bias and stir these magnetic inclusions while monitoring in situ
their orientation and dynamics via laser scanning confocal microscopy.
ENFORCE will exploit the accessible time and length scales of the colloidal ice to shed new light on the
exciting and interdisciplinary field of geometric frustration.","1850298","2020-01-01","2024-12-31"
"ENGAGES","Next generation algorithms for grabbing and exploiting symmetry","Pascal Schweitzer","TECHNISCHE UNIVERSITAET KAISERSLAUTERN","Symmetry is a phenomenon that appears in many different contexts. 
Algorithmic symmetry detection and exploitation is the concept of finding intrinsic symmetries of a given object and then using these symmetries to our advantage. Application areas of algorithmic symmetry detection and exploitation range from convolutional neural networks in machine learning to computer graphics, chemical data bases and beyond. 
In contrast to this widespread use, our understanding of the theoretical foundation (namely the graph isomorphism problem) is incomplete and current algorithmic symmetry tools are inadequate for big data applications. Hence, EngageS addresses these key challenges in the field using a systematic approach to the theory and practice of symmetry detection. It thereby also fixes the existing lack of interplay between theory and practice, which is part of the problem.

EngageS' main aims are to tackle the classical and descriptive complexity of the graph isomorphism problem and to design the next generation of symmetry detection algorithms. As key ideas to resolve the complexity, EngageS offers three  new approaches on how to prove lower bounds and a new method to settle the descriptive complexity.

EngageS will also develop practical symmetry detection algorithms for big data, exploiting parallelism and memory hierarchies of modern machines, and will introduce the concept of and a road map to exploiting absence of symmetry. Overall EngageS will establish a comprehensive software library that will serve as a  platform for integrated research on the algorithmic treatment of symmetry.

In summary, EngageS will develop fast, efficient and accessible symmetry detection tools that will be used to solve complex algorithmic problems in a range of fields including combinatorial algorithms, generation problems, and canonization.","1999094","2019-03-01","2024-02-29"
"ENLIGHTENED","Nanophotonic Nanomechanical Mass Spectrometry for Biology and Health","Sébastien Claude Hentz","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","« Mass Spectrometry has become a routine analytical tool in modern biological research, and has gained in recent years a foothold in the realm of clinical diagnostic and screening. However, it is still costly, complex and because its principle relies on ionization, it is incapable of analyzing biomolecules with masses greater than a few MDa. Averaging more than 100 million particles per measurement, it is also incapable of characterizing the diversity of such heavy entities. ENLIGHTENED aims at demonstrating a breakthrough concept based on Photonic Nano-Mechanical Mass Spectrometry, able to perform analysis of bioparticles of high biomedical significance, of ultra-high mass, never so far characterized, with single-molecule sensitivity and unprecedented resolution. The long-term vision beyond the current proposal is to provide the biologists with a tool which will be transformative for fundamental knowledge, and to make possible cheap, handheld devices for personalized medicine.
ENLIGHTENED proposes to use photons to shed light on unexplored species at the individual level, which is of high biomedical significance and will expand our understanding of simple life forms.”","1999090","2014-06-01","2020-05-31"
"ENSURE","Exploring the New Science and engineering unveiled by Ultraintense ultrashort Radiation interaction with mattEr","Matteo Passoni","POLITECNICO DI MILANO","With the ENSURE project I aim at attaining ground-breaking results in the field of superintense laser-driven ion acceleration, proposing a multidisciplinary research program in which theoretical, numerical and experimental research will be coherently developed in a team integrating in an unprecedented way advanced expertise from materials engineering and nanotechnology, laser-plasma physics, computational science. The aim will be to bring this topic from the realm of fundamental basic science into a subject having realistic engineering applications.
The discovery in 2000 of brilliant, multi-MeV, collimated ion sources from targets irradiated by intense laser pulses stimulated great interest worldwide, due to the ultra-compact spatial scale of the accelerator and ion beam properties. The laser-target system provides unique appealing features to fundamental physics which can be studied in a small lab. At the same time, laser-ion beams could have future potential in many technological areas. This is boosting the development of new labs and facilities all over Europe, but to support these efforts, crucial challenges need to be faced to make these applications a reality.
The goals of ENSURE are: i) design and production of nanoengineered targets, with properties tailored to achieve optimized ion acceleration regimes. This will be pursued exploiting advanced techniques of material science & nanotechnology ii) design of laser-ion beams for novel, key applications in nuclear and materials engineering iii) realization of engineering-oriented ion acceleration experiments, in advanced facilities iv) synergic development of all the required theoretical support for i,ii,iii).
The results of the project can determine a unique impact in the research on laser-driven ion acceleration in Europe, providing new directions to support the attainment, in the next future, of concrete applications of great societal relevance, in medical, energy and materials areas.","1887500","2015-09-01","2020-08-31"
"ENUBET","Enhanced NeUtrino BEams from kaon Tagging","Andrea Longhin","ISTITUTO NAZIONALE DI FISICA NUCLEARE","ENUBET has been designed to open a new window of opportunities in accelerator neutrino physics.  

The proposed project enables for the first time the measurement of the positrons produced in the decay tunnel of conventional neutrino beams: these particles signal uniquely the generation of an electron neutrino at source. 
Neutrino facilities enhanced by the ENUBET technique will have an unprecedented control of the neutrino flux. This will allow to reduce by one order of magnitude the uncertainties on neutrino cross sections: a leap that has been sought after since decades and that is needed to address the challenges of discovering matter-antimatter asymmetries in the leptonic sector.

The apparatus is a highly specialized electromagnetic calorimeter with fast response, sustaining particle rates as high as 0.5 MHz/cm^2, having excellent electron/pion separation capabilities with a reduced number of read-out channels. ENUBET will boost technologies that have been envisaged for high energy colliders to address this new challenge. On the other hand it will operate in a substantially different configuration. The experiment will be performed at the CERN Neutrino Platform, a recently approved facility where innovative neutrino detectors will be developed exploiting dedicated hadron beam-lines from the SPS accelerator. In the first phase of the project, ENUBET will address the challenges of particle identification from extended sources, developing innovative optical readout systems and cost-effective solutions for radiation imaging. This approach is based on cutting-edge technologies for single photon sensitive devices. During the second phase, the detector will be assembled and characterized at CERN with particle beams. Finally, it will be operated in time coincidence with Liquid Argon neutrino detectors, achieving a major step towards the realization of the concept of tagging individual neutrinos both at production and interaction level, on an event-by-event basis.","2000000","2016-06-01","2021-05-31"
"EPGR","The Evolution Problem in General Relativity","Jérémie Szeftel","SORBONNE UNIVERSITE","General relativity has been introduced by A. Einstein in 1915. It is a major theory of modern physics and at the same time has led to fascinating mathematical problems. The present proposal focusses on two aspects of the evolution problem for the Einstein equations which has been initiated by the pioneering work of Y. Choquet-Bruhat in 1952.

The Einstein equations form a nonlinear system of partial differential equations of hyperbolic type whose complexity raises significant challenges to its mathematical analysis. The goal of this project is to strengthen our understanding of two important themes concerning the evolution problem in general relativity. On the one hand, the control of low regularity solutions of the Einstein equations, a topic which is intimately linked with the celebrated cosmic censorship conjectures of R. Penrose, a major open problem in the field. On the other hand, the question of the stability of particular solutions of the Einstein equations in the wake of the groundbreaking proof of the stability of the Minkowski space-time due to D. Christodoulou and S. Klainerman. These directions are extremely active and have recently led to impressive results. More specifically, this project proposes to consider the following two work packages

-Going beyond the bounded L2 curvature theorem. This result has been recently obtained by the PI in collaboration with S. Klainerman and I. Rodnianski and is the sharpest result in so far as low regularity solutions of the Einstein equations are concerned. Yet, the fundamental quest towards a scale invariant well-posedness criterion for the Einstein equations remains wide open.

-The black hole stability problem. This problem concerns the stability of the Kerr metrics which form a 2-parameter family of solutions to  the Einstein vacuum equations. Many results have been obtained concerning various versions of linear stability, but significant challenges remain in order to tackle the nonlinear stability result.","1455000","2017-05-01","2022-04-30"
"EPIC","Earth-like Planet Imaging with Cognitive computing","Olivier ABSIL","UNIVERSITE DE LIEGE","One of the most ambitious goals of modern astrophysics is to characterise the physical and chemical properties of rocky planets orbiting in the habitable zone of nearby Sun-like stars. Although the observation of planetary transits could in a few limited cases be used to reach such a goal, it is widely recognised that only direct imaging techniques will enable such a feat on a statistically significant sample of planetary systems. Direct imaging of Earth-like exoplanets is however a formidable challenge due to the huge contrast and minute angular separation between such planets and their host star. The proposed EPIC project aims to enable the direct detection and characterisation of terrestrial planets located in the habitable zone of nearby stars using ground-based high-contrast imaging in the thermal infrared domain. To reach that ambitious goal, the project will focus on two main research directions: (i) the development and implementation of high-contrast imaging techniques and technologies addressing the smallest possible angular separations from bright, nearby stars, and (ii) the adaptation of state-of-the-art machine learning techniques to the problem of image processing in high-contrast imaging. While the ultimate goal of this research can likely only be reached with the advent of giant telescopes such as the Extremely Large Telescope (ELT) around 2025, the EPIC project will lay the stepping stones towards that goal and produce several high-impact results along the way, e.g. by re-assessing the occurrence rate of giant planets in direct imaging surveys at the most relevant angular separations (i.e., close to the snow line), by conducting the deepest high-contrast imaging search for rocky planets in the alpha Centauri system, by preparing the scientific exploitation of the ELT, and by providing the first open-source high-contrast image processing toolbox relying on supervised machine learning techniques.","2178125","2019-05-01","2024-04-30"
"EPICODE","Programmable Readers, Writers, and Erasers of the Epigenetic Cytosine Code","Daniel SUMMERER","TECHNISCHE UNIVERSITAT DORTMUND","Human DNA contains two types of biologically instructive information: the canonical nucleobases A, G, T, C, and the epigenetic nucleobases mC, hmC, fC, and caC. Canonical nucleobases encode the identity of all RNAs and proteins that are synthesized by a cell, whereas epigenetic nucleobases regulate this synthesis. This regulation shapes the phenotype of cells, and its perturbation is a key trigger of cancer.
Canonical nucleobases can be decoded in a programmable manner by nucleic acids and their analogs via Watson-Crick-base pairing, and the simplicity of this recognition has enabled revolutionary developments in the biological sciences. In contrast, comparable developments in epigenetics have not yet been possible, since a molecular scaffold with  programmable recognition of epigenetic nucleobases does not exist. 
We will establish the first class of molecules capable of the expanded programmable recognition of both canonical and epigenetic DNA nucleobases in vitro and in vivo. This is based on transcription-activator-like effectors (TALEs) that consist of four types of concatenated modules, each of which recognizes a canonical nucleobase. We have recently reported the detection of single epigenetic nucleobases by TALEs. 
In this project, we will 
1. engineer a toolbox of TALE modules with selectivity for C, mC, hmC, fC, and caC,
2. employ them for TALE-based in vitro typing and profiling (reading) of cancer biomarker mC/hmC, and 
3. design photoactivatable TALE-fusions that enable the writing and erasing of mC at user-defined genomic loci in vivo with spatiotemporal resolution. This will provide the first insights into the dynamic effects of de novo editing on chromatin regulation, and enables the imprinting of regulatory states.
Given the central role of epigenetic nucleobases in cancer and the universality of our approach, this project will provide enabling and broadly applicable methodology for cancer epigenetics research, diagnosis and therapy.","1979679","2017-11-01","2022-10-31"
"EpiMech","Epithelial cell sheets as engineering materials: mechanics, resilience and malleability","Marino Arroyo Balaguer","UNIVERSITAT POLITECNICA DE CATALUNYA","The epithelium is a cohesive two-dimensional layer of cells attached to a fluid-filled  fibrous matrix, which lines most free surfaces and cavities of the body. It serves as a protective barrier with tunable permeability, which must retain integrity in a mechanically active environment. Paradoxically, it must also be malleable enough to self-heal and remodel into functional 3D structures such as villi in our guts or tubular networks. Intrigued by these conflicting material properties, the main idea of this proposal is to view epithelial monolayers as living engineering materials. Unlike lipid bilayers or hydrogels, widely used in biotechnology, cultured epithelia are only starting to be integrated in organ-on-chip microdevices. As for any complex inert material, this program requires a fundamental understanding of the structure-property relationships. (1) Regarding their effective in-plane rheology, at short time-scales epithelia exhibit solid-like behavior while at longer times they flow as a consequence of the only qualitatively understood dynamics of the cell-cell junctional network. (2) As for material failure, excessive tension can lead to epithelial fracture, but as we have recently shown, matrix poroelasticity can also cause hydraulic fracture under stretch. However, it is largely unknown how adhesion molecules, membrane, cytoskeleton and matrix interact to give epithelia their robust and flaw-tolerant resilience. (3) Regarding shaping 3D epithelial structures, besides the classical view of chemical patterning, mechanical buckling is emerging as a major morphogenetic driving force, suggesting that it may be possible design 3D epithelial structures in vitro by mechanical self-assembly. Towards understanding (1,2,3), we will combine a broad range of theoretical, computational and experimental methods. Besides providing fundamental mechanobiological understanding, this project will provide a framework to manipulate epithelia in bioinspired technologies.","1989875","2016-09-01","2021-08-31"
"EQEC","Engineering Quantum Error Correction","Barbara Terhal","TECHNISCHE UNIVERSITEIT DELFT","This proposal will advance the theory of quantum error correction towards its application in real physical devices, in particular superconducting transmon qubit systems. The research will result in proposals for experiments: how to use physical qubits to redundantly represent logical quantum information and how error information can be obtained and classically processed. The research will consider novel ways of using transmon qubits to achieve a universal fault-tolerant surface code architecture. The research will produce a design of a universal fault-tolerant architecture in which qubits are encoded in the electromagnetic field of a (microwave) cavity. Research will also focus on mathematical and numerical studies in quantum error correction which are technology-independent, but shed light on coding overhead, decoding efficiency and logical universality.","1786563","2016-04-01","2021-03-31"
"EQuO","Electron Quantum optics in quantum Hall edge channels","Gwendal Feve","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Quantum effects have been studied on photon propagation in the context of quantum optics since the second half of the last century. In particular, using single photon emitters, fundamental tests of quantum mechanics were explored by manipulating single to few photons in Hanbury-Brown and Twiss and Hong Ou Mandel experiments. 
 In nanophysics, there is a growing interest to translate these concepts of quantum optics to electrons propagating in nanostructures. Single electron emitters have been realized such that single elementary electronic excitations can now be manipulated in the analog of pioneer quantum optics experiments.
 Electron quantum optics goes beyond the mere reproduction of optical setups using electron beams, as electrons, being interacting fermions, differ strongly from photons. Contrary to optics, understanding the propagation of an elementary excitation requires replacing the single body description by a many body one. 
 The purpose of this proposal is to specifically explore the emergence of many body physics and its effects on electronic propagation using the setups and concepts of electron quantum optics. The motivations are numerous: firstly single particle emission initializes a simple and well controlled state. I will take this unique opportunity to test birth, life and death scenarii of Landau quasiparticles and observe the emergence of many-body physics. Secondly, I will address the generation of entangled few electrons quantum coherent states and study how they are affected by interactions. Finally, I will attempt to apply electron quantum optics concepts to a regime where the ground state itself is a strongly correlated state of matter. In such a situation, elementary excitations are no longer electrons but carry a fractional charge and obey fractional statistics. No manipulation of single quasiparticles has been reported yet and the determination of some quasiparticle characteristics, such as the fractional statistics remains elusive.","1997878","2015-10-01","2020-09-30"
"ERCC","Efficient Resource Constrained Cryptography","Eike Kiltz","RUHR-UNIVERSITAET BOCHUM","""Traditionally, cryptographic protocols were run on servers or personal computers which have large and easily scalable computational resources. For these applications there exist a large variety of well-established cryptographic systems. Right now, we are in the midst of the shift toward ubiquitous computing on resource constrained devices (RCDs): small devices with severe constraints in terms of computing power, code size, and network capacities. RCDs are used virtually everywhere: smart phones, bank cards, electronic ID-cards, medical implants, cars, RFIDs as bar code replacement, etc. Due to their computational constraints, many current cryptographic security solutions are no longer applicable to RCDs. Existing solutions are often “ad-hoc” and do not come with a formal security treatment.

The central objective of the ERCC project is to initiate an overarching formal treatment of cryptographic solutions for RCDs, particularly focusing on efficiency. The main conceptual novelty is to follow the concept of provable security. We intend to design new cryptographic protocols that have a mathematical proof of security (assuming the hardness of some mathematical problem) and are still competitive with constructions currently used on RCDs. While we certainly cannot hope that all our new provably secure constructions will be superior to existing ad-hoc constructions, recent preliminary research
results give rise to optimism. Concretely, we will base our new protocols on hard problems in ideal and structures lattices and we will study weaker (yet still realistic) security models for RCDs allowing for efficient instantiations.""","1874960","2014-11-01","2019-10-31"
"ErgComNum","Ergodic theory and additive combinatorics","Tamar Ziegler","THE HEBREW UNIVERSITY OF JERUSALEM","The last decade has witnessed a new spring for dynamical systems. The field - initiated by Poincare in the study of the N-body problem - has become essential in the understanding of seemingly far off fields such as combinatorics, number theory and theoretical computer science. In particular, ideas from ergodic theory played an important role in the resolution of long standing open problems in combinatorics and number theory. A striking example is the role of dynamics on nilmanifolds in the recent proof of Hardy-Littlewood estimates for the number of solutions to systems of linear equations of finite complexity in the prime numbers. The interplay between ergodic theory, number theory and additive combinatorics has proved very fruitful; it is a fast growing area in mathematics attracting many young researchers. We propose to tackle central open problems in the area.","1342500","2016-05-01","2021-04-30"
"EspLORE","Extending the science perspectives of linear wires of carbon atoms from fundamental research to emerging materials","Carlo Spartaco CASARI","POLITECNICO DI MILANO","EspLORE aims at addressing the potential of carbon-atom wires for developing novel functional coatings in an application-oriented approach. Carbon-atom wires, based on sp-hybridization, are the ultimate 1-dimensional carbon nanostructure (1-atom diameter) with functional properties strongly dependent on the wire length and termination. The design and control of the wire structure opens the way to build materials with tunable properties, which is at present a largely unexplored topic. The core concept of EspLORE is to exploit the present fundamental knowledge of carbon-atom wires as isolated molecules/nanostructures to explore the applied science and engineering of new materials in the form of thin film assemblies and nanocomposites, so to fill the large existing gap between basic science and engineering. To this aim the main challenging goals are: 
1) the controlled synthesis of wires; 
2) the development of strategies to assemble wires in thin films and nanocomposites; 
3) the exploration of potential use of wire-based materials in direct energy conversion devices (e.g. photovoltaics, water splitting, fuel cells).
The proposed methodology includes fabrication of wires by physical methods, their deposition/assembling on surfaces, and the experimental study of structural, electronic and optical properties. Structure-property relationship is investigated at a multiscale level, moving from the single wire level (atomic scale) to multi-wire interactions (nanoscale) and up to extended systems (macroscale). 
The outcomes of the project will put the foundations for the materials engineering of wire-based systems and their realistic implementation in advanced technological applications. These materials, able to provide complementary properties to graphene, will synergistically contribute to open new perspectives for an innovative ‘all-carbon’ approach to present and future challenges in many fields of engineering and technology.","1981875","2017-05-01","2022-04-30"
"ESTUARIES","Estuaries shaped by biomorphodynamics, inherited landscape conditions and human interference","Maarten Gabriel Kleinhans","UNIVERSITEIT UTRECHT","ESTUARIES are shallow coastal water bodies with river inflow shaped by biomorphological processes, with patterns of channels and shoals, sand/mud flats, tidal marshes, vegetated banks and peat. Development was influenced by early Holocene landscape that drowned under sealevel rise, and by human interference. 
Estuaries harbour highly productive natural habitats and are of pivotal economic importance for food production, access to harbours and urban safety. Accelerating sealevel rise, changing river discharge and interference threaten these functions, but we lack fundamental understanding and models to predict combined effects of biomorphological interactions, inherited landscape and changing drivers.
We do not understand to what extent present estuary planform shape and shoal patterns resulted from biomorphological processes interacting with inherited conditions and interference. Ecology suggests dominant effects of flow-resisting and sediment de/stabilising eco-engineering species. Yet abiotic physics-based models reproduce channel-shoal patterns surprisingly well, but must assume a fixed planform estuary shape. Holocene reconstructions emphasise inherited landscape- and agricultural effects on this planform shape, yet fossil shells and peat also imply eco-engineering effects.
My aims are to develop models for large-scale planform shape and size of sandy estuaries and predict past and future, large-scale effects of biomorphological interactions and inherited conditions.
We will significantly advance our understanding by our state-of-the-art eco-morphological model, my unique analogue landscape models with eco-engineers and a new, automated paleogeographic reconstruction of 10 data-rich Holocene estuaries on the south-east North Sea coast. We will systematically compare these to modelled scenarios with biomorphological processes, historic interference and inherited valley geometry and substrate. Outcomes will benefit ecology, archeology, oceanography and engineering","2000000","2015-12-01","2020-11-30"
"ESTYMA","Excited state quantum dynamics in molecular aggregates: a unified description from biology to devices","Alessandro Troisi","THE UNIVERSITY OF LIVERPOOL","The coherent dynamics of excitons in systems of biological interest and in organic materials can now be studied with advanced experimental techniques, including two dimensional electronic spectroscopy, with time resolution of few femtoseconds. The theory of open quantum systems, that should support the interpretation of these new experiments, has been developed in different contexts over the past 60 years but seems now very inadequate for the problems of current interest.  First of all, the systems under investigation are extremely complex and the most common approach, based on the development of phenomenological models, is often not very informative.  Many different models yield results in agreement with the experiments and there is no systematic way to derive these models or to select the best model among many.  Secondly, the quantum dynamics of excitons is so fast that one cannot assume that the dynamics of environment is much faster than the dynamics of the system, an assumption crucial for most theories.  A remedy to the current limitation is proposed here through the following research objectives.
(1) A general and automatic protocol will be developed to generate simple treatable models of the system from an accurate atomistic description of the same system based on computational chemistry methods.
(2) A professionally-written software will be developed to study the quantum dynamics of model Hamiltonians for excitons in molecular aggregates. This software will incorporate different methodologies and will be designed to be usable also by non-specialists in the theory of quantum open systems (e.g. spectroscopists, computational chemists).
(3) A broad number of problems will be studied with this methodology including (i) exciton dynamics in light harvesting complexes and artificial proteins and (ii) exciton dynamics in molecular aggregates of relevance for organic electronics devices.","1512873","2014-04-01","2019-03-31"
"ETASECS","Extremely Thin Absorbers for Solar Energy Conversion and Storage","Avner Rothschild","TECHNION - ISRAEL INSTITUTE OF TECHNOLOGY","ETASECS aims at making a breakthrough in the development of photoelectrochemical (PEC) cells for solar-powered water splitting that can be readily integrated with PV cells to provide storage capacity in the form of hydrogen. It builds upon our recent invention for resonant light trapping in ultrathin films of iron oxide (a-Fe2O3), which enables overcoming the deleterious trade-off between light absorption and charge carrier collection efficiency. Although we recently broke the water photo-oxidation record by any a-Fe2O3 photoanode reported to date, the losses are still high and there is plenty of room for further improvements that will lead to a remakable enhancement in the performance of our photoanodes, reaching quantum efficiency level similar to state-of-the-art PV cells. ETASECS aims at reaching this ambitious goal, which is essential for demonstrating the competitiveness of PEC+PV tandem systems for solar energy conversion and storage. Towards this end WP1 will combine theory, modelling and simulations, state-of-the-art experimental methods and advanced diagnostic techniques in order to identify and quantify the different losses in our devices. This work will guide the optimization work in WP2 that will suppress the losses at the photoanode and insure optimal electrical and optical coupling of the PEC and PV cells. We will also explore advanced photon management schemes that will go beyond our current light trapping scheme by combining synergic optical and nanophotonics effects. WP3 will integrate the PEC and PV cells and test their properties and performance. WP4 will disseminate our progress and achievements in professional and public forums. The innovations that will emerge from this frontier research will be further pursued in proof of concept follow up investigations that will demonstrate the feasibility of this technology. Success along these lines holds exciting promises for ground breaking progress towards large scale deployment of solar energy.","2150000","2014-09-01","2019-08-31"
"Euler systems","Euler systems and the Birch--Swinnerton-Dyer conjecture","Sarah Zerbes","UNIVERSITY COLLEGE LONDON","The Birch--Swinnerton-Dyer conjecture, one of the Millennium Prize Problems, is one of the central unsolved problems in mathematics. It predicts a relation between the arithmetic of an elliptic curve and the properties of the L-function of the elliptic curve. Some special cases of the conjecture were proven by Kolyvagin; the main ingredient in his proof is an algebraic construction called an Euler system. Even though Euler systems are extremely powerful tools, so far only five examples are known to exist. I propose to construct several new examples of Euler systems, in order to prove new cases of the Birch--Swinnerton-Dyer conjecture. In particular, I believe the following theorem to be within reach:

Let A be either a modular elliptic curve over a (real or imaginary) quadratic number field, or a modular abelian surface over the rational numbers. If the L-value L(A, 1) is non-zero, then the Mordell--Weil group of A is finite (i.e. the Birch--Swinnerton-Dyer conjecture holds for A).","1070473","2015-07-01","2020-06-30"
"EvoStruc","The physics of antibiotic resistance evolution in spatially-structured multicellular assemblies","Rosalind Allen","THE UNIVERSITY OF EDINBURGH","The rise in bacterial infections that are resistant to antibiotic treatment poses a major global health challenge. Addressing this challenge is not just a clinical issue: understanding bacterial resistance evolution calls for an interdisciplinary approach, in which the development of new physics, in coordination with biology, chemistry and engineering, has a central role to play. In particular, statistical physics, to predict the stochastic emergence of drug-resistant mutants, must be integrated with soft matter and chemical physics, to understand the spatial organization of the bacterial populations within which this happens.

Bacterial infections are very often spatially heterogeneous. This is known to influence the outcome of antibiotic treatment – for example bacterial biofilms, which form on the surfaces of medical implants, are notoriously hard to remove. However, much less attention has been paid to the role of spatial structure in the evolution of drug resistance, i.e. the emergence and spread of genetically drug-resistant bacterial strains. 

I will lead a research programme which will for the first time uncover the two-way link between the emergence of spatial structure in bacterial multicellular assemblies and the evolution of drug resistance. The programme builds on my current theoretical, simulation and experimental work. I will first determine the basic principles of evolution in drug gradients using theoretical models, combined with experiments in a controlled, 1D geometry. I will then explore how these principles translate to the more realistic scenario of bacterial biofilms, where spatial structure and drug gradients are emergent properties, using advanced computer simulation methods and both confocal microscopy and evolution experiments. In the final part of the programme, I will use these insights to reveal optimization principles for the design of evolution-resistant surface coatings for applications in medical devices.","1826984","2016-06-01","2022-05-31"
"EXCITERS","Extreme Ultraviolet Circular Time-Resolved Spectroscopy","Yann Mairesse","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Chiral molecules exist as two forms, so-called enantiomers, which have essentially the same physical and chemical properties and can only be distinguished via their interaction with a chiral system, such as circularly polarized light. Many biological processes are chiral-sensitive and unraveling the dynamical aspects of chirality is of prime importance for chemistry, biology and pharmacology. Studying the ultrafast electron dynamics of chiral processes requires characterization techniques at the attosecond (10−18 s) time-scale.
Molecular attosecond spectroscopy has the potential to resolve the couplings between electronic and nuclear degrees of freedom in such chiral chemical processes. There are, however, two major challenges: the generation of chiral attosecond light pulse, and the development of highly sensitive chiral discrimination techniques for time-resolved spectroscopy in the gas phase.
This ERC research project aims at developing vectorial attosecond spectroscopy using elliptical strong fields and circular attosecond pulses, and to apply it for the investigation of chiral molecules. To achieve this, I will (1) establish a new type of highly sensitive chiroptical spectroscopy using high-order harmonic generation by elliptical laser fields; (2) create and characterize sources of circular attosecond pulses; (3) use trains of circularly polarized attosecond pulses to probe the dynamics of photoionization of chiral molecules and (4) deploy ultrafast dynamical measurements to address the link between nuclear geometry and electronic chirality.
The developments from this project will set a landmark in the field of chiral recognition. They will also completely change the way ellipticity is considered in attosecond science and have an impact far beyond the study of chiral compounds, opening new perspectives for the resolution of the fastest dynamics occurring in polyatomic molecules and solid state physics.","1691865","2016-09-01","2021-08-31"
"EXMAG","Excitonic Magnetism in Strongly Correlated Materials","Jan Kunes","TECHNISCHE UNIVERSITAET WIEN","Spontaneous symmetry breaking leading to states of matter with long-range order is one of the central topics in condensed matter physics. Common types of order, such as ferro- and anti-ferromagnetic, are characterized by spin or charge densities modulated on inter-atomic scale, therefore well studied thanks to various scattering experiments. Order parameters that are not of this type are much more difficult to detect, giving rise to names such as hidden order or electronic nematicity. Their impact on transport or thermodynamic properties may, nevertheless, be substantial. In the EXMAG project we will investigate excitonic condensation in systems with strongly correlated electrons as a new mechanism leading to unconventional ordered states. The objective of the project is to characterize the physical properties of various excitonic phases and to find their realization in real materials. We will focus on intermediate coupling strength and doped systems where the interaction between the excitonic order and the charge carriers is expected to lead to new physics. In particular, we want to explore the potential of the excitonic order to induce instabilities, e.g. magnetic or superconducting, that are not present in the normal phase. We will also address the possibility of topologically non-trivial quasi-particle band-structures in the excitonic phase. Our main tool will be numerical simulations based on the dynamical mean-field theory and ab initio band-structure methods. We will pursue two main lines of research: investigation of simple models allowing access to many physical observables and studies of real materials capturing the chemical complexities at the cost of more severe approximations. Ultimately, we want to understand in detail the properties of the excitonic magnets and their potential functionalities,and to identify the main control parameters and promising materials.","1382500","2015-06-01","2020-05-31"
"EXOKLEIN","The Climates and Habitability of Small Exoplanets Around Red Stars","Kevin HENG","UNIVERSITAET BERN","The detection of life beyond our Solar System is possible only via the remote sensing of the atmospheres of exoplanets.  The recent discovery that small exoplanets are common around cool, red stars offers an exciting opportunity to study the atmospheres of Earth-like worlds.  Motivated by this revelation, the EXOKLEIN project proposes to construct a holistic climate framework to understand astronomical observations in the context of the atmosphere, geochemistry and biosignatures of the exoplanet.  The proposed research is divided into three major themes.  Research Theme 1 aims to construct a virtual laboratory of an atmosphere that considers atmospheric dynamics, chemistry and radiation, as well as how they interact.  This virtual laboratory enables us to understand the physical and chemical mechanisms involved, as well as predict the observed properties of an exoplanet.  Research Theme 2 aims to generalize the carbonate-silicate cycle (also known as the long-term carbon cycle) by considering variations in rock composition, water acidity and atmospheric conditions.  The carbonate-silicate cycle is important because it regulates the long-term presence of carbon dioxide (a vital greenhouse gas) in atmospheres.  We also aim to investigate the role of the cycle in determining the fates of ocean-dominated exoplanets called “water worlds”.  Research Theme 3 aims to investigate the long-term stability of biosignature gases in the context of the climate.  Whether a gas uniquely indicates the presence of biology on an exoplanet depends on the atmospheric properties and ultraviolet radiation environment.  We investigate three prime candidates for biosignature gases: methyl chloride, dimethylsulfide and ammonia.  Overall, the EXOKLEIN project will significantly advance our understanding of whether the environments of rocky exoplanets around red stars are stable and conducive for life, and whether the tell-tale signatures of life may be detected by astronomers.","1984729","2018-02-01","2023-01-31"
"ExoLights","Decoding Lights from Exotic Worlds","Giovanna Tinetti","UNIVERSITY COLLEGE LONDON","It is now accepted that exoplanets are ubiquitous. However little is known about those planets we have detected beyond the fact they exist and their location. For a minority, we know their weight, size and orbital parameters. For less than twenty, we have some clues about their atmospheric temperature and composition. How do we progress from here?
We are still far from a hypothetical Hertzsprung–Russell diagram for planets and we do not even know whether there ever will be such classification for planets. The planetary parameters mass, radius and temperature alone do not explain the diversity revealed by current observations. The chemical composition of these planets is needed to trace back their formation history and evolution, as was the case for the Solar System.
Pioneering results were obtained through transit spectroscopy with Hubble, Spitzer and ground-based facilities, enabling the detection of ionic, atomic and molecular species and of the planet’s thermal structure. With the arrival of improved or dedicated instruments in the coming decade, planetary science will expand beyond the narrow boundaries of our Solar System to encompass our whole Galaxy.
In the next five years, ExoLights will address the following fundamental questions:
– Why are exoplanets as they are?
– What are the causes for the observed diversity?
– Can their formation history be traced back from their current composition and evolution?
New spectroscopic observations of a select sample of exoplanets’ atmospheres (~ 20 out of the 150 observable today) will be analysed with state-of-the art statistical techniques and interpreted through a comprehensive set of spectral retrieval models, developed by the PI and her team. This programme, together with the homogeneous re-analysis of archive observations of a larger sample of exoplanets, will allow us to use the chemical composition as a powerful diagnostic of the history, formation mechanisms and evolution of gaseous and rocky exoplanets.","2080502","2014-05-01","2019-04-30"
"EXONMR","""Exploiting 17O NMR Spectroscopy: Atomic-Scale Structure, Disorder and Dynamics in Solids""","Sharon Elizabeth Marie Ashbrook","THE UNIVERSITY COURT OF THE UNIVERSITY OF ST ANDREWS","""The fundamental importance of oxide-based systems in technology, energy materials, geochemistry and catalysis, and the presence of oxygen in many biomaterials, should have resulted in oxygen nuclear magnetic resonance (NMR) spectroscopy emerging as a vital tool for materials characterization. NMR offers an element-specific, atomic-scale probe of the local environment, providing a potentially powerful probe of local structure, disorder and dynamics in solids. However, despite the almost ubiquitous presence of oxygen in inorganic solids, oxygen NMR studies have been relatively scarce in comparison to other nuclei, owing primarily to the low natural abundance of the  NMR-active isotope, 17O (0.037%). Hence, isotopic enrichment is necessary, often at considerable cost and effort. Furthermore, the presence of anisotropic quadrupolar broadening (and the need for complex high-resolution experiments) has also limited the development and application of 17O NMR to date. Here, we propose to develop an internationally-leading research programme to exploit the largely untapped potential of 17O spectroscopy. This wide-ranging programme will involve (i) the exploration of novel synthetic approaches for cost-efficient isotopic enrichment, (ii) the development of new solid-state NMR methodology, specific for 17O, (iii) the application of state-of-the-art first-principles calculations of 17O NMR parameters and (iv) the application of these methods to three different areas of investigation: high-pressure silicate minerals, microporous materials and ceramics for waste encapsulation. The ultimate long-term aim is to change the way in which solid-state chemists characterise materials; so that solid-state NMR (and 17O NMR in particular) is viewed as a necessary and important step in the refinement of a detailed structural model.""","1902188","2014-04-01","2019-03-31"
"EXPLORINGMATTER","Exploring Matter with Precision Charm and Beauty Production Measurements in Heavy Nuclei Collisions at LHCb","Giulia Manca","UNIVERSITA DEGLI STUDI DI CAGLIARI","Collisions of ultra relativistic nuclei are a tool to reach huge energy densities and to form a new state of matter called Quark-Gluon Plasma (QGP), where quarks and gluons can move freely. A number of experiments have studied the possible formation of QGP, but the behaviour of heavy particles such as charm (c) and beauty (b) quarks when they traverse this medium is largely unknown and is the most powerful tool to prove the creation of the QGP and to characterise it. I will perform novel measurements using the LHCb detector at CERN, which covers an unique kinematic region, essential for a full understanding of QGP and nuclear matter in general. LHCb has been optimised to perform c and b quark physics measurements in proton-proton collisions. In EXPLORINGMATTER I propose to extend the LHCb programme to collect for the first time data in heavy ion collisions. Three experimental scenarios are foreseen: (1) Collisions of protons, benchmark to understand the behaviour of the c and b particles in other more complicated environments, as well as providing the final answers to the mechanism of heavy quarkonium production; (2) Collisions of protons with heavy nuclei, where cold nuclear matter effects in high-energy collisions can be studied in detail to understand lead nuclei collisions, where QGP is expected to be formed. (3) Collisions of heavy nuclei, pursued (a) by analysing heavy nuclei interactions through a dedicated setup in which gas will be injected in the LHCb interaction region, reaching energy densities typical of dedicated fixed target experiments; (b) by collecting heavy ion collision data at the LHC. This second setup, which has not been envisaged by LHCb up to now will revolutionise the measurements in this area thanks to the LHCb coverage and precision not achievable by any other experiment. My measurements will furthermore indicate the route to new experiments that could be designed on the basis of these findings.","1849957","2015-04-01","2020-03-31"
"EXQUISITE","External Quantum Control of Photonic Semiconductor Nanostructures","Stephan Erich Reitzenstein","TECHNISCHE UNIVERSITAT BERLIN","In this project, we will control photonic nanostructures by external feedback, optical injection and synchronization. This will allow us to study nonlinear dynamics in quantum systems and to externally manipulate and stabilize light-matter interaction in the regime of quantum electrodynamics (cQED). We will experimentally and theoretically address a) optical injection and feedback control of quantum dot (QD)–microlasers, b) quantum control cQED systems via delayed single photon feedback, and c) mutually coupled and synchronized chaotic microcavity systems. In a) we will advance the concepts of time-delayed coupling in standard semiconductor laser diodes to few photon states, where quantum fluctuations contribute to or even dominate over the usual classical dynamics. Feedback-coupling in microlasers will allow us to explore the limits of a classical description of chaotic laser dynamics via the Lang-Kobayashi rate equations and to develop an advanced model taking cQED- and QD-specific effects into account. This subject will be complemented by the study of optical injection of coherent light and non-classical light into microlasers to influence and study mode-locking, chaos and stimulated emission down to the quantum level. Single photon feedback in b) will be applied to stabilize coherent coupling of light and matter and to act against decoherence which constitutes a major bottleneck for application of semiconductor nanostructures in quantum information technology. In c) the mutual coupling of microlasers will be used to study synchronization of chaotic quantum devices at the single photon limit and to explore the underlying physics of isochronal synchronization. Our work will have important impact at an interdisciplinary level on the development of nonlinear dynamical systems towards the quantum limit and the understanding of fundamental light-matter interaction in the presence of time delayed single photon feedback.","1999800","2014-04-01","2019-03-31"
"EXSEED","Extreme-Light Seeded Control of Ultrafast Laser Material Modifications","David GROJO","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","High-peak power compact femtosecond lasers allow strong-field interactions that are the basis for high-precision laser micro-fabrication. They also create extreme conditions within the matter, leading to the generation of rainbow light used to produce even shorter pulses and new frequencies that can extend from the X-ray to the TeraHertz domain. However, due to the low conversion efficiencies, these attractive light pulses remain unexploited in the context of laser nano-/micro-fabrication.
The main objective of this project is to exceed the intrinsic limits of ultrafast laser material processing by developing novel seeded-control technologies with extreme light pulses. In the proposed concept, seed free carriers are injected into materials from extreme light and then avalanched with perfectly synchronized infrared pulses to extract all potential benefits from modest energy new types of radiation.
The project includes the study of interactions seeded with deep-ultraviolet, few-optical-cycle and mid-infrared ultrashort pulses. The expected nonlinear processes with these radiations open new and exciting opportunities to tailor material properties with nanometer-scale spatial resolutions and in the three dimensions (3D) for materials inside which the occurrence of breakdown is, today, inaccessible (e.g. semiconductors). This will lead to the first demonstrations of rapid 3D prototyping by laser of silicon photonics microdevices.
A long term objective is to open the door to the use of the most extreme ultrashort laser-induced radiations, including extreme-ultraviolet attosecond pulses that hold promises to reach the highest degree of control in the time and space of the interactions.
These and other ideas require investigations on ionization physics by ultrashort pulses at extreme wavelengths. They also require tight control of the ultrafast pulses, broadband manipulations and novel interaction diagnostics technologies that will be developed as parts of the project.","1833406","2017-05-01","2022-04-30"
"EXTREME","EXtreme Tectonics and Rapid Erosion in Mountain Environments","Todd Alan Ehlers","EBERHARD KARLS UNIVERSITAET TUEBINGEN","""Tectonic plate corners are hotspots for high rates of continental deformation and erosion, and associated with human-relevant hazards including poorly understood earthquakes, destructive landslides, and extreme climate. A better understanding of continental deformation can mitigate these hazards. However, the coupling between climate and tectonic interactions at plate corners is a key unknown and the focus of this study. My recent work, published in international journals including Science and Nature, quantifies mountain building and climate change and provides a baseline for an innovative study of plate corner dynamics.
This proposal challenges the geoscience ‘tectonic aneurysm’ paradigm that rapid deformation and erosion at plate corners is initiated from the “top down” by localized precipitation, and erosion. Rather, I hypothesize that these processes are: 1) initiated from the “bottom up” by the 3D geometry of the subducting plate; and 2) require a threshold rate of both “bottom up” deformation and surface erosion to initiate a feedback between climate and tectonics.
I propose, for the first time, a holistic modeling and data collection approach that quantifies the temporal and spatial evolution of all aspects of plate corner evolution, including: 3D thermomechanical modeling of plate corner deformation and uplift for different plate geometries; Atmospheric modeling to quantify the climate response to evolving topography, a topic spearheaded by my research group; And surface process modeling to close the loop and couple the atmospheric and mechanical models. Model predictions will be vetted against observed deformation and erosion histories from existing and new cosmogenic isotope and thermochronometer data from end-member locations including the Himalaya, Alaskan, Olympic, and Andean plate corners. EXTREME will produce a globally integrated atmospheric and solid Earth understanding of continental deformation, a task only possible at the scale of an ERC grant.""","1999956","2014-04-01","2019-03-31"
"ExtremeQuantum","Quantum materials under extreme conditions","Paul Andrew Goddard","THE UNIVERSITY OF WARWICK","New states of matter offer an unparalleled testing ground for studying fundamental physics, particularly interacting quantum systems. The EXTREMEQUANTUM project will significantly advance our knowledge of these states by using extreme conditions of magnetic field and pressure to enable a continuous, clean and reversible tuning of quantum interactions, thereby shedding light on the building blocks of exotic magnetism and unconventional superconductivity. By developing the materials and methodology to achieve this, we will push our understanding of quantum systems beyond current limitations and open a route for exploiting the untapped potential of these materials to underpin future technology in fields as diverse as electrical power networks, quantum computation and healthcare.

EXTREMEQUANTUM takes as its starting point recent theoretical and experimental discoveries in the area of quantum materials and will capitalize on a novel measurement technique developed in my research group over the past few years. By utilizing both atomic and molecular substitution, the project will focus on a series of materials that are on the verge of a phase instability. Ultra-high fields and applied pressure will push these systems through the critical region where the state of matter changes and inherently quantum effects dominate. Electronic, magnetic and structural properties will be measured as the tipping point is breached and the resulting data compared with predictions of theoretical models. The results will provide answers to questions of deep concern to modern physics, such how quantum fluctuations, topology and disorder can be used to create states of matter with novel and functional properties.","1840513","2016-09-01","2021-08-31"
"EyeCode","Perceptual encoding of high fidelity light fields","Rafal Konrad MANTIUK","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","One of the grand challenges of computer graphics has been to generate images indistinguishable from photographs for a naïve observer. As this challenge is mostly completed and computer generated imagery starts to replace photographs (product catalogues, special effects in cinema), the next grand challenge is to produce imagery that is indistinguishable from the real-world.

Tremendous progress in capture, manipulation and display technologies opens the potential to achieve this new challenge (at the research stage) in the next 5-10 years. Electronic displays offer sufficient resolution, frame rate, dynamic range, colour gamut and, in some configurations, can produce binocular and focal depth cues. However, most of the work done in this area ignores or does not sufficiently address one of the key aspects of this problem - the performance and limitations of the human visual system.

The objective of this project is to characterise and model the performance and limitations of the human visual system when observing complex dynamic 3D scenes. The scene will span a high dynamic range (HDR) of luminance and provide binocular and focal depth cues. In technical terms, the project aims to create a visual model and difference metric for high dynamic range light fields (HDR-LFs). The visual metric will replace tedious subjective testing and provide the first automated method that can optimize encoding and processing of HDR-LF data. 

Perceptually realistic video will impose enormous storage and processing requirements compared to traditional video. The bandwidth of such rich visual content will be the main bottleneck for new imaging and display technologies. Therefore, the final objective of this project is to use the new visual metric to derive an efficient and approximately perceptually uniform encoding of HDR-LFs. Such encoding will radically reduce storage and bandwidth requirements and will pave the way for future highly realistic image and video content.","1868855","2017-07-01","2022-06-30"
"F-BioIce","Fundamentals of Biological Ice Nucleation","Tobias WEIDNER","AARHUS UNIVERSITET","Ice active bacteria can promote the growth of ice more effectively than any other material known. Using specialized ice nucleating proteins (INPs), they attack plants by frost damage and, when airborne in the atmosphere, they drive ice nucleation within clouds and control global precipitation patterns. The control INPs exert over water phase transitions has relevance for disciplines as diverse as climatology, plant pathology, biomedicine and material science. Despite the apparent importance, the molecular mechanisms behind INP freezing have remained largely elusive. This lack of our knowledge can be traced back to the challenges in studying protein and water structure and dynamics at the very interface between monolayers of proteins and water.
With F-BioIce my team and I want to reveal the molecular details of INP function. We ask the questions: What is the structural basis for protein control of freezing? What structural motifs do proteins use to interact with water, and what is the configuration of water molecules that INPs imprint into interfacial water layers? What is the role of structural dynamics and for surface freezing? We will develop new methods based on sum frequency generation (SFG) spectroscopy to determine mode of action by which INPs interact with and manipulate water. The INPs and water structure will be obtained by combining three rising methods in the field: SFG techniques that I have been spearheading, computer simulations and cryo-electron microscopy. We will study model water surfaces and, for the first time, realistic water aerosols interacting with INPs. These new strategies could lead to a paradigm shift in the entire field of ice nucleation and a search for similar processes in ice active fungi and pollen and abiotic ice nucleators – feldspar, silica and soot. The obtained information will provide critical input for climate models and revolutionary new freezing technologies for food preservation, cryomedicine and cloud seeding.","1999936","2019-04-01","2024-03-31"
"F-ELEMENT_ARCHITECT","Building Precise Molecular Architectures to Unlock Remarkable f-Element Properties","David MILLS","THE UNIVERSITY OF MANCHESTER","The astonishing properties of the f-elements have been exploited in numerous consumer technologies, despite their fundamental chemistry being poorly developed. It is now crucial to address this issue to provide the necessary insights to develop future applications. Design criteria exist to build f-element complexes with maximised physical attributes. This adventurous proposal targets the synthesis and thorough analysis of two complementary molecular f-element architectures that 1) optimise magnetic properties and 2) stabilise unusual oxidation states.

In Part 1, we target highly axial f-element complexes that lack equatorial ligand interactions. These molecules can exhibit maximised single-molecule magnet properties, including magnetic hysteresis, a memory effect and as a prerequisite of data storage, at liquid nitrogen temperatures. This is the necessary first step towards achieving high-density molecular data storage without expensive liquid helium cooling and future commercial applications.

In Part 2, we target trigonal f-element complexes that lack axial ligand interactions. These are optimal ligand fields for the stabilisation of low oxidation states, thus we aim for rare lanthanide/actinide(II) and unprecedented lanthanide/actinide(I) complexes. These compounds are ideal candidates for unique measurements of covalency by pulsed electron paramagnetic resonance spectroscopy, which will provide textbook data that can be transferable to nuclear fuel cycles.

An ERC CoG will provide the necessary resources to build a world-leading research team that will deliver landmark synthetic results and fresh insights into f-element electronic structure, whilst opening up new chemical space for future exploitation. These findings will underpin current technologies and will facilitate the discovery of future applications, supporting key Horizon 2020 priority areas including the Flagship on Quantum Technologies, and enhancing the scientific reputation and economy of the EU.","1990801","2019-09-01","2024-08-31"
"FACTORY","New paradigms for latent factor estimation","Cédric Févotte","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Data is often available in matrix form, in which columns are samples, and processing of such data often entails finding an approximate factorisation of the matrix in two factors. The first factor yields recurring patterns characteristic of the data. The second factor describes in which proportions each data sample is made of these patterns. Latent factor estimation (LFE) is the problem of finding such a factorisation, usually under given constraints. LFE appears under other domain-specific names such as dictionary learning, low-rank approximation, factor analysis or latent semantic analysis. It is used for tasks such as dimensionality reduction, unmixing, soft clustering, coding or matrix completion in very diverse fields.

In this project, I propose to explore three new paradigms that push the frontiers of traditional LFE. First, I want to break beyond the ubiquitous Gaussian assumption, a practical choice that too rarely complies with the nature and geometry of the data. Estimation in non-Gaussian models is more difficult, but recent work in audio and text processing has shown that it pays off in practice. Second, in traditional settings the data matrix is often a collection of features computed from raw data. These features are computed with generic off-the-shelf transforms that loosely preprocess the data, setting a limit to performance. I propose a new paradigm in which an optimal low-rank inducing transform is learnt together with the factors in a single step. Thirdly, I show that the dominant deterministic approach to LFE should be reconsidered and I propose a novel statistical estimation paradigm, based on the marginal likelihood, with enhanced capabilities. The new methodology is applied to real-world problems with societal impact in audio signal processing (speech enhancement, music remastering), remote sensing (Earth observation, cosmic object discovery) and data mining (multimodal information retrieval, user recommendation).","1931776","2016-09-01","2021-08-31"
"FADAMS","Foundations of Factorized Data Management Systems","Dan Olteanu","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","The objective of this project is to investigate scalability questions arising with a new wave of smart relational data management systems that integrate analytics and query processing. These questions will be addressed by a fundamental shift from centralized processing on tabular data representation, as supported by traditional systems and analytics software packages, to distributed and approximate processing on factorized data representation.

Factorized representations exploit algebraic properties of relational algebra and the structure of queries and analytics to achieve radically better data compression than generic compression schemes, while at the same time allowing processing in the compressed domain. They can effectively boost the performance of relational processing by avoiding redundant computation in the one-server setting, yet they can also be naturally exploited for approximate and distributed processing. Large relations can be approximated by their subsets and supersets, i.e., lower and upper bounds, that factorize much better than the relations themselves. Factorizing relations, which represent intermediate results shuffled between servers in distributed processing, can effectively reduce the communication cost and improve the latency of the system.

The key deliverables will be novel algorithms that combine distribution, approximation, and factorization for computing mixed loads of queries and predictive and descriptive analytics on large-scale data. This research will result in fundamental theoretical contributions, such as complexity results for large-scale processing and tractable algorithms, and also in a scalable factorized data management system that will exploit these theoretical insights. We will collaborate with industrial partners, who are committed to assist in providing datasets and realistic workloads, infrastructure for large-scale distributed systems, and support for transferring the products of the research to industrial users.","1980966","2016-06-01","2021-05-31"
"FanCY","Flow and Deformation of Cancer tumours near Yielding","Pouyan BOUKANY","TECHNISCHE UNIVERSITEIT DELFT","The aim of this proposal is to understand when, how and why metastatic tumour cells detach from a tumour. 

Often, primary tumours do not kill patients, but secondary tumours do. These so-called metastatic tumour cells disassociate from a primary tumour and, ultimately, prove fatal. Currently, we do not understand the fundamentals of the biophysical pathways and mechanisms of the metastasis of cancer, hampering medical intervention. I propose a multidisciplinary approach, combining engineering, chemistry, biophysics and cell biology to identify the mechanical pathways for the creation of metastatic cancer cells.

Biological cells in tissue are very densely packed, which locks them in place relative to their neighbours, a state referred to as jammed. The collective system of cells can become fluidised locally and flow when pushed or deformed. Even greater forces can make the entire tissue fluid-like, referred to as yielding. The crucial open questions are: how does tissue yield, and what universal physics underlies yielding? 

I will develop a novel fundamental and predictive description of yielding in jammed living tissue to show: 
1. How and when jammed living cells are driven to fluid-like state. 
2. How confinement tunes the migration mode of cancer cells. 
3. How yielding is related to the structural evolution of detached cells.
4. How critical scaling controls deformation and flow of living cells near yielding.

I will demonstrate that the distance to yielding governs the mechanical response in collective cell motion inside a tumour, and that exploiting critical scaling allows predicting the dynamics of cell detachment near yielding. The outcomes will significantly aid the treatment of cancer in the near future by bridging the gap between chemical and mechanical pathways of cancer metastasis. I have the required multidisciplinary track record. Moreover, preliminary experiments show highly promising results.","2000000","2019-04-01","2024-03-31"
"FANOEC","Fundamentals and Applications of Inorganic Oxygen Evolution Catalysts","Xile Hu","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","The oxygen evolution reaction (OER) is the key reaction to enable the storage of solar energy in the form of hydrogen fuel through water splitting. Efficient, Earth-abundant, and robust OER catalysts are required for a large-scale and cost-effective production of solar hydrogen. While OER catalysts based on metal oxides exhibit promising activity and stability, their rational design and developments are challenging due to the heterogeneous nature of the catalysts. Here I propose a project to (i) understand OER on metal oxides at the molecular level and engineer catalytic sites at the atomic scale; (ii) develop and apply practical OER catalysts for high-efficiency water splitting in electrochemical and photoelectrochemical devices. The first general objective will be obtained by using 2-dimensional metal oxide nanosheets as a platform to probe the intrinsic activity and active sites of metal oxide OER catalysts, as well as by developing sub-nanocluster and single-atom metal oxide OER catalysis. The second general objective will be obtained by establishing new and better synthetic methods, developing new classes of catalysts, and applying catalysts in innovative water splitting devices. 
The project employs methodologies from many different disciplines in chemistry and materials science. Synthesis is the starting point and the backbone of the project, and the synthetic efforts are complemented and valorised by state-of-the-art characterization and catalytic tests. The project will not only yield significant fundamental insights and knowledge in heterogeneous OER catalysis, but also produce functional and economically viable catalysts for solar fuel production.","2199983","2016-07-01","2021-06-30"
"FastMat","Fast determination of fatigue properties of materials beyond one billion cycles","Nicolas RANC","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Many mechanical structures are submitted to repeated loadings and can break under stress lower than the ultimate tensile stress. This phenomenon is called the fatigue of materials and can be found in many industrial sectors, such as the transport industry, aeronautic industry and energy production. Fatigue design is thus crucial in engineering and it requires the precise characterization of material behavior under cyclic loadings to ensure the safety and reliability of structures throughout their life. An increase in the life span of a structure or a reduction in the number of maintenance phases leads to an increases in the number of cycles applied to this structure. It is presently common to find mechanical systems subjected to several billion cycles, in what is called the gigacycle fatigue domain. The characterization of the fatigue behavior of materials requires fatigue tests to be conducted until fracture for different stress amplitudes. One problem with this method is the test duration, which becomes excessive and beyond possible, particularly for a very high number of cycles. The goal of FastMat is to develop a new method that reduces considerably the duration of fatigue characterization. This method involves the use of only short interrupted tests coupled with a self-heating measurement to characterize the fatigue behavior for very low stress amplitudes. The scientific objective is to develop simultaneously experimental and numerical tools for the fast determination of fatigue behavior. The experimental approach will be developed to estimate simultaneously the dissipation and the stored energy, which directly reflect fatigue damage. For the numerical approach, discrete dislocation dynamics simulations will be developed to establish links between the fatigue damage associated with the evolution of dislocation structures, the stored energy and the dissipated energy.","1860963","2017-07-01","2022-06-30"
"FaultScan","Passive seismic scanning of the preparation phase of damaging earthquakes","Florent BRENGUIER","UNIVERSITE GRENOBLE ALPES","The recent September 2017, magnitude 7.1, central Mexico earthquake that caused 370 casualties reminds us that earthquakes are among the most dramatic natural disasters worldwide. Causal physical processes are not instantaneous and laboratory and numerical experiments predict that earthquakes should be preceded by a detectable slow preparation phase. Despite considerable efforts, however, robust geophysical precursors have not yet been observed before damaging earthquakes. 
My FaultScan project will revolutionize our ability to directly observe transient deformation within the core of active faults and provide unprecedented accuracy in the detection of earthquake precursors. My ambition is to develop a new, noise-based, high resolution, seismic monitoring approach. I intend to grasp the opportunity of a recent step change in seismic instrumentation and data processing capabilities to achieve a dream for seismologists: reproduce repeatable, daily, virtual seismic sources that can probe the core of active faults at seismogenic depths using only passive seismic records. 
I plan to target the San Jacinto Fault (a branch of the San Andreas Fault system) that is currently believed to pose one of the largest seismic risks in California. It is an ideal fault for this project because it is very active, already extensively studied and easily accessible for the pilot field data acquisition work.
This project is in collaboration with the Univ. of South. California, the Univ. of Cal. San Diego and specialists in earthquake mechanics and will include earthquake preparation processes and seismic modeling that will guide us for our long-term (3 years), breakthrough, passive seismic experiment and further data analysis and interpretation.
I strongly believe that this project has a very high potential for providing fundamental results on the physics of earthquakes and faults and that it will have a major impact on earthquake prediction worldwide in the near future.","2524630","2019-06-01","2024-05-31"
"Feel your Reach","Non-invasive decoding of cortical patterns induced by goal directed movement intentions and artificial sensory feedback in humans","Gernot Rudolf Mueller-Putz","TECHNISCHE UNIVERSITAET GRAZ","In Europe estimated 300.000 people are suffering from a spinal cord injury (SCI) with 11.000 new injuries per year. The consequences of spinal cord injury are tremendous for these individuals. The loss of motor functions especially of the arm and grasping function – 40% are tetraplegics – leads to a life-long dependency on care givers and therefore to a dramatic decrease in quality of life in these often young individuals. With the help of neuroprostheses, grasp and elbow function can be substantially improved. However, remaining body movements often do not provide enough degrees of freedom to control the neuroprosthesis.
The ideal solution for voluntary control of an upper extremity neuroprosthesis would be to directly record motor commands from the corresponding cortical areas and convert them into control signals. This would realize a technical bypass around the interrupted nerve fiber tracts in the spinal cord.
A Brain-Computer Interface (BCI) transform mentally induced changes of brain signals into control signals and serve as an alternative human-machine interface. We showed first results in EEG-based control of a neuroprosthesis in several persons with SCI in the last decade, however, the control is still unnatural and cumbersome. 
The objective of FEEL YOUR REACH is to develop a novel control framework that incorporates goal directed movement intention, movement decoding, error processing, processing of sensory feedback to allow a more natural control of a neuroprosthesis. To achieve this aim a goal directed movement decoder will be realized, and continuous error potential decoding will be included. Both will be finally joined together with an artificial kinesthetic sensory feedback display attached to the user. We hypothesize that with these mechanisms a user will be able to naturally control an neuroprosthesis with his/ her mind only.","1994161","2016-05-01","2021-04-30"
"FeMiT","Ferrites-by-design for Millimeter-wave and Terahertz Technologies","Martí GICH","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Robust disruptive materials will be essential for the “wireless everywhere” to become a reality.  This is because we need a paradigm shift in mobile communications to meet the challenges of such an ambitious evolution. In particular, some of these emerging technologies will trigger the replacement of the magnetic microwave ferrites in use today. This will namely occur with the forecasted shift to high frequency mm-wave and THz bands and in novel antennas that can simultaneously transmit and receive data on the same frequency. In both cases, operating with state-of-the-art ferrites would require large external magnetic fields incompatible with future needs of smaller, power-efficient devices. 
To overcome these issues, we target ferrites featuring the so far unmet combinations of low magnetic loss and large values of magnetocrystalline anisotropy, magnetostriction or magnetoelectric coupling.  
The objective of FeMiT is developing a novel family of orthorhombic ferrites based on ε-Fe2O3, a room-temperature multiferroic with large magnetocrystalline anisotropy. Those properties and unique structural features make it an excellent platform to develop the sought-after functional materials for future compact and energy-efficient wireless devices. 
In the first part of FeMiT we will explore the limits and diversity of this new family by exploiting rational chemical substitutions, high pressures and strain engineering. Soft chemistry and physical deposition methods will be both considered at this stage.
The second part of FeMiT entails a characterization of functional properties and selection of the best candidates to be integrated in composite and epitaxial films suitable for application. The expected outcomes will provide proof-of-concept self-biased or voltage-controlled signal-processing devices with low losses in the mm-wave to THz bands, with high potential impact in the development of future wireless technologies.","1989967","2019-05-01","2024-04-30"
"FeREDCOUPLS","FeREDCOUPLS - Reduced Iron Catalysts for Reduction and Coupling Reactions","Axel Jacobi von Wangelin","UNIVERSITAET HAMBURG","The aerobic conditions on our planet enable the accumulation of oxidized matter whereas reduced chemicals are the most valuable energy carriers. Future shortages of energy-rich resources make efficient reductive transformations one of the greatest scientific challenges. To address this societal, economic and environmental demand, we propose new approaches to the design and application of stabilized iron catalysts. Our endeavour exploits the higher reducing power of Fe (vs. noble metals) in challenging reductive transformations and capitalizes on the high sustainability of Fe catalysis over noble metal technologies. 
The use of low-valent Fe catalysts, the realization of new catalytic reactions and their mechanistic understanding will only be possible through the controlled generation and effective stabilization of reduced Fe species and active nanoparticles. Major emphasis will be placed on coordinative ligand/solvent systems which accommodate electron-rich Fe centers (olefins, arenes, Lewis acids, redox-ligands, ionic liquids). We address new approaches to the synthesis of low-valent Fe complexes and bottom-up/top-down preparations of Fe(0) nanoparticles. Catalytic reactions of high relevance to the manufacture of chemicals and materials will be studied (reduction, cross-coupling, hydrogenation, defunctionalization) with special emphasis on cheap abundant substrates. Mechanistic studies aim at understanding Fe-centered reductive bond activations and ligand co-operation. The proposed use of the most abundant transition metal for challenging reductive processes under practical conditions extends beyond the realm of synthesis, catalysis, and materials into spectroscopy, solvent technologies and reaction processing with direct relevance to sustainable chemicals and energy production. Our multidisciplinary program will provide new sets of active iron catalysts for reductive processes and is a major puzzle piece toward a greener chemical synthesis.","1995400","2016-10-01","2021-09-30"
"FermiSurfaceFlavours","FLAVOURS OF FERMI SURFACE IN THE ABSENCE OF A CONVENTIONAL FERMI LIQUID","Suchitra SEBASTIAN","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Quantum oscillations have revealed signature Fermi surfaces in a diverse range of materials families, with breakthrough advances made by a synthesis of theoretical modelling, experimental vision, materials preparation, and advances in measurement technique. Traditionally, the very observation of a Fermi surface has been taken to imply an underlying Fermi liquid. In this proposal, we seek to transcend this traditional paradigm in the field of correlated electron systems and define a new framework for the observation of quantum oscillations associated with a novel Fermi surface in the absence of a conventional Fermi liquid. Guided by a selection of theoretical proposals, we identify for study materials families starting from the more readily modellable correlated Mott insulators and Kondo insulators without the complication of mobile electrons. We progress to regions where mobile electrons are introduced – where we select for study the doped Mott insulating cuprate superconductors. Eventually we access the intervening region of unconventional quantum critical physics where a Fermi surface in the absence of a conventional Fermi liquid transitions to a Fermi surface underpinned by a conventional Fermi liquid, by lattice-density tuning of selected materials. We propose to investigate the Fermi surface of these regimes of correlated materials phase space that defy conventional Fermi liquid behaviour by the use of advanced quantum oscillation techniques in selected high purity correlated materials, under either ambient pressure conditions or under lattice-density tuning, and using high magnetic fields. We expect the project outcome to have a substantive impact on our understanding of correlated electron systems, especially in hitherto opaque regions of phase space where Fermi liquid behaviour breaks down. We thus anticipate a new era where quantum oscillations serve as a diagnostic for novel phases of correlated matter that lack a conventional Fermi liquid description.","2127851","2019-04-01","2024-03-31"
"FHiCuNCAG","Foundations for Higher and Curved Noncommutative Algebraic Geometry","Wendy LOWEN","UNIVERSITEIT ANTWERPEN","With this research programme, inspired by open problems within noncommutative algebraic geometry (NCAG) as well as by actual developments in algebraic topology, it is our aim to lay out new foundations for NCAG. On the one hand, the categorical approach to geometry put forth in NCAG has seen a wide range of applications both in mathematics and in theoretical physics. On the other hand, algebraic topology has received a vast impetus from the development of higher topos theory by Lurie and others. The current project is aimed at cross-fertilisation between the two subjects, in particular through the development of “higher linear topos theory”. We will approach the higher structure on Hochschild type complexes from two angles. Firstly, focusing on intrinsic incarnations of spaces as large categories, we will use the tensor products developed jointly with Ramos González and Shoikhet to obtain a “large version” of the Deligne conjecture. Secondly, focusing on concrete representations, we will develop new operadic techniques in order to endow complexes like the Gerstenhaber-Schack complex for prestacks (due to Dinh Van-Lowen) and the deformation complexes for monoidal categories and pasting diagrams (due to Shrestha and Yetter) with new combinatorial structure. In another direction, we will move from Hochschild cohomology of abelian categories (in the sense of Lowen-Van den Bergh) to Mac Lane cohomology for exact categories (in the sense of Kaledin-Lowen), extending the scope of NCAG to “non-linear deformations”. One of the mysteries in algebraic deformation theory is the curvature problem: in the process of deformation we are brought to the boundaries of NCAG territory through the introduction of a curvature component which disables the standard approaches to cohomology. Eventually, it is our goal to set up a new framework for NCAG which incorporates curved objects, drawing inspiration from the realm of higher categories.","1171360","2019-06-01","2024-05-31"
"FICOMOL","Field Control of Cold Molecular Collisions","Sebastiaan Y T VAN DE MEERAKKER","STICHTING KATHOLIEKE UNIVERSITEIT","It is a long held dream of chemical physicists to study (and to control!) the interactions between individual molecules in completely specified collisions. This project brings this goal within reach. I will develop novel methods to study collisions between individual molecules at temperatures between 10 mK and 10 K, and to manipulate their interaction using electric and magnetic fields. Under these cold conditions, the collisions are dominated by quantum effects such as interference and tunneling. Scattering resonances occur that respond sensitively to external electric or magnetic fields, yielding the thrilling perspective to provide “control knobs” to steer the outcome of a collision. Building on my unique experience with state-of-the-art molecular beam deceleration methods, I will study scattering resonances for chemically relevant systems involving molecules such as OH, NO, NH3 and H2CO in crossed beam experiments. Using external electric or magnetic fields, we will tune the positions and widths of resonances, such that collision rates can be changed by orders of magnitude. This type of “collision engineering” will be used to induce and study hitherto unexplored quantum phenomena, such as the merging of individual resonances, and resonant energy transfer in bimolecular collisions. Measurements of exotic collision phenomena under yet unexplored conditions as proposed here provide excellent tests for quantum theories of molecular interactions, and pave the way towards the engineering of novel quantum structures, or the collective properties of interacting molecular systems. The proposed research program will transform this field from merely “probing nature” with the highest possible detail to “manipulating nature” with the highest possible level of control. It will open up a new and intellectually rich research field in chemical physics and physical chemistry, and will be a major breakthrough in the emerging research field of cold molecules.","2000000","2019-03-01","2024-02-29"
"Fields4CAT","Force Fields in Redox Enzymatic Catalysis","Ismael DÍEZ PÉREZ","KING'S COLLEGE LONDON","Fields4CAT aims to identify the nature and directionality of the driving forces in a redox enzyme that govern the catalytic chemical process.
Industrial bio-manufacturing is one of the pillars of today’s world economy making its way to a sustainable development. Redox enzymes catalyze the most demanding chemical reactions under mild conditions, such as the oxy-functionalization of non-activated hydrocarbons, which usually requires harsh reaction conditions. Enzyme Biotechnology has greatly progressed thanks to rational mutagenesis schemes that draw upon the static X-ray structural information. The high complexity of enzymatic catalysis has, however, hampered its development because a single point mutation near the active site can affect several relevant parameters at the same time, obscuring the interpretation and constraining the rational design of technological biocatalysts.
Fields4CAT proposes dissecting the relevant forces exerted over an individual catalytic active site in its wild-type state, and then using the resulting forces map to design enzyme/metal platforms with enhanced capabilities. To this aim, it develops in 3 blocks organized in a step-wise fashion: (i) block 1 sets up a electrochemical multi-stimuli single-protein toolbox (Ec-SPT) with capabilities to trap individual proteins in a nanoscale tunnelling junction and subject them to a variety of force stimuli, i.e. mechanical, electrostatic and magnetic. (ii) Block 2 designs the chemical electrical plugs that will specifically connect the enzyme to the junction electrodes with precise controlled orientation. (iii) Block 3 characterizes the single-protein electrical signatures of the enzyme activity and quantifies the catalytic effect of the different force stimuli along the vertical junction axis.
Fields4CAT will identify new guidelines to bioengineer a redox enzyme/metal platform with tuned catalytic activity, bringing about new breakthroughs in the future of Bio-Catalysis.","1998700","2019-03-01","2024-02-29"
"Fireworks","Celestial fireworks: revealing the physics of the time-variable sky","Avishay Gal-Yam","WEIZMANN INSTITUTE OF SCIENCE LTD","Experimental time-domain astrophysics is on the verge of a new era as technological, computational, and operational progress combine to revolutionise the manner in which we study the time-variable sky. This proposal consolidates previous breakthrough work on wide-field surveys into a coherent program to advance our study of the variable sky on ever decreasing time-scales: from days, through hours, to minutes. We will watch how stars explode in real time in order to study the complex physics of stellar death, build new tools to handle and analyse the uniquely new data sets we are collecting, and shed light on some of the most fundamental questions in modern astrophysics: from the origin of the elements, via the explosions mechanism of supernova explosions, to the feedback processes that drive star formation and galaxy evolution.","2461111","2017-09-01","2022-08-31"
"FLAMENCO","A Fully-Implantable MEMS-Based Autonomous Cochlear Implant","Kulah Haluk","MIDDLE EAST TECHNICAL UNIVERSITY","Sensorineural impairment, representing the majority of the profound deafness, can be restored using cochlear implants (CIs), which electrically stimulates the auditory nerve to repair hearing in people with severe-to-profound hearing loss. A conventional CI consists of an external microphone, a sound processor, a battery, an RF transceiver pair, and a cochlear electrode. The major drawback of conventional CIs is that, they replace the entire natural hearing mechanism with electronic hearing, even though most parts of the middle ear are operational. Also, the power hungry units such as microphone and RF transceiver cause limitations in continuous access to sound due to battery problems. Besides, damage risk of external components especially if exposed to water and aesthetic concerns are other critical problems. Limited volume of the middle ear is the main obstacle for developing fully implantable CIs.
FLAMENCO proposes a fully implantable, autonomous, and low-power CI, exploiting the functional parts of the middle ear and mimicking the hair cells via a set of piezoelectric cantilevers to cover the daily acoustic band. FLAMENCO has a groundbreaking nature as it revolutionizes the operation principle of CIs. The implant has five main units: i) piezoelectric transducers for sound detection and energy harvesting, ii) electronics for signal processing and battery charging, iii) an RF coil for tuning the electronics to allow customization, iv) rechargeable battery, and v) cochlear electrode for neural stimulation. The utilization of internal energy harvesting together with the elimination of continuous RF transmission, microphone, and front-end filters makes this system a perfect candidate for next generation autonomous CIs. In this project, a multi-frequency self-powered implant for in vivo operation will be implemented, and the feasibility will be proven through animal tests.","1993750","2016-07-01","2021-06-30"
"FLATLAND","Electron-lattice-spin correlations and many-body phenomena in 2D semiconductors and related heterostructures","Ralph Bernhard Ernstorfer","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Two-dimensional crystalline materials exhibit exceptional physical properties and offer fascinating potential as fundamental building blocks for future two-dimensional electronic and optoelectronic devices.  Transition metal dichalcogenides (TMDCs) are of particular interest as they show a variety of many-body phenomena and correlation effects. Key properties are: i) additional internal degrees of freedom of the electrons, described as valley pseudospin and layer pseudospin, ii) electronic many-body effects like strongly-bound excitons and trions, and iii) electron-lattice correlations like polarons. While these phenomena represent intriguing fundamental solid state physics problems, they are of great practical importance in view of the envisioned nanoscopic devices based on two-dimensional materials. 

The experimental research project FLATLAND will address the exotic spin-valley-layer correlations in few-layer thick TMDC crystals and TMDC-based heterostructures. The latter comprise other 2D materials, organic crystals, metals and phase change materials as second constituent. Microscopic coupling and correlation effects, both within pure materials as well as across the interface of heterostructures, will be accessed by time- and angle-resolved extreme ultraviolet-photoelectron spectroscopy, femtosecond electron diffraction, and time-resolved optical spectroscopies. The project promises unprecedented insight into the microscopic coupling mechanisms governing the performance of van der Waals-bonded devices.","2640633","2016-10-01","2021-09-30"
"FlexNets","Quantifying Flexibility in Communication Networks","Wolfgang Leonhard Kellerer","TECHNISCHE UNIVERSITAET MUENCHEN","Communication networks have emerged to become the basic infrastructure for all areas of our society with application areas ranging from social media to industrial production and healthcare. New requirements include the need for dynamic changes of the required resources, for example, to react to social events or to shifts of demands. Existing networks and, in particular, the Internet cannot meet those requirements mainly due to their ossification and hence limitation in resource allocation, i.e., lack of flexibility to adapt the available resources to changes of demands on a small time-scale and in an efficient way. In recent years, several concepts have emerged in networking research to provide more flexibility in networks through virtualization and control plane programmability. In particular, the split between data plane and a centralized control plane as defined by Software Defined Networking (SDN) is regarded as the basic concept to allow flexibility in networks. However, a deeper understanding of what flexibility means remains open. In this project, flexibility focuses on the dynamic changes in time and size of a network that is characterized by its resources (link rate and node capacities) and connectivity (network graph). It is the objective of this research to analyse the fundamental design space for flexibility in SDN-based networks with respect to cost such as resource usage, traffic overhead and delay. The outcome will be a set of quantitative arguments pro and contra certain design choices. An analytical cost model to quantitatively assess the trade-off for flexibility vs. cost will be developed. To assess flexibility with respect to general graph properties a graph model will be designed. The detailed analysis is based on three use cases: dynamic resource allocation, QoS control, and resilience. In the state of the art, selected aspects of flexibility have been explored for certain network scenarios, a fundamental and comprehensive analysis is missing.","1931250","2015-09-01","2020-08-31"
"FLUDYCO","Fluid dynamics of planetary cores: formation, heterogeneous convection and rotational dynamics","Michael Le Bars","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Understanding the flows in planetary cores from their formation to their current dynamics is a tremendous interdisciplinary challenge. Beyond the challenge in fundamental fluid dynamics to understand these extraordinary flows involving turbulence, rotation and buoyancy at typical scales well beyond our day-to-day experience, a global knowledge of the involved processes is fundamental to a better understanding of the initial state of planets, of their thermal and orbital evolution, and of magnetic field generation, all key ingredients for habitability. The purpose of the present project is to go beyond the state-of-the-art in tackling three barriers at the current frontier of knowledge. It combines groundbreaking laboratory experiments, complementary pioneering numerical simulations, and fruitful collaborations with leaders in various fields of planetary sciences. Improving on the latest advances in the field, I will address the fluid dynamics of iron fragmentation during the later stages of planetary accretion, in order to produce innovative, dynamically reliable models of planet formation. Considering the latest published data for Earth, I will investigate the flows driven in a stratified layer at the top of a liquid core and their influence on the global convective dynamics and related dynamo. Finally, building upon the recent emergence of alternative models for core dynamics, I will quantitatively examine the non-linear saturation and turbulent state of the flows driven by libration, as well as the shape and intensity of the corresponding dynamo. In the context of an international competition, the originality of my work comes from its multi-method and interdisciplinary character, building upon my successful past researches. Beyond scientific advances, this high-risk/high-gain project will benefit to a larger community through the dissemination of experimental and numerical improvements, and allow promoting science through an original outreach program.","1992602","2016-07-01","2021-06-30"
"FNPMLS","Fundamental nuclear properties measured with laser spectroscopy","Kieran Thomas Joseph Flanagan","THE UNIVERSITY OF MANCHESTER","The prime research theme of this project is the study of short-lived exotic nuclei with laser spectroscopy. Over the next 5 years my team will study the role of three-nucleon forces and their associated influence on nuclear structure and the limits of nuclear existence. This work will investigate the interplay between tensor and central forces and the associated effect on quantum shells in exotic nuclear systems. This proposal will study how the shape of the nucleus is modified at the limits of nuclear existence. We will use innovative laser spectroscopy methods to achieve these goals. The project will be carried out at the ISOLDE facility, CERN, which is the premier radioactive beam facility at the precision frontier. The proposed research activity closely matches the NuPECC (Nuclear Physics European Collaboration Committee) 2010 Long Range Plan. The wider scientific impact of this research will influence modelling explosive stellar processes and nuclear synthesis, understanding the structure of astrophysical compact-objects such as neutron stars and predicting regions of enhanced stability in the super heavy elements. The FNPMLS project will develop ultra-sensitive methodologies that set a new paradigm in laser spectroscopy. It builds on the cutting edge technology of collinear resonance ionization spectroscopy (CRIS) that I have developed during my STFC Advanced Fellowship.  The CRIS technique combines the high resolution nature of collinear laser spectroscopy with the high sensitivity of resonance ionization spectroscopy. The research programme and investment outlined in this proposal will place my team in a unique and world leading position. This work will happen in advance of the next generation of radioactive beam facility such as SPIRAL2, FAIR and FRIB and will provide the essential ingredients for future fundamental questions.","1846542","2015-04-01","2020-03-31"
"FOGHORN","FOG-aided wireless networks for communication, cacHing and cOmputing: theoRetical and algorithmic fouNdations","Osvaldo SIMEONE","KING'S COLLEGE LONDON","""The FOGHORN project aims at developing the theoretical and algorithmic foundations of fog-aided wireless networks. This is an emerging class of wireless systems that leverages the synergy and complementarity of cloudification and edge processing, two key technologies in the evolution towards 5G systems and beyond. Fog-aided wireless networks can reap the bene 
fits of centralization via cloud processing, in terms of capital and operating cost reductions, greening, and
enhanced spectral e fficiency, while, at the same time, being able to cater to low-latency applications, such as the """"tactile"""" internet, by means of localized intelligence at the network edge. The operation of fog-aided wireless networks poses novel fundamental research problems pertaining to the optimal management of the communication, caching and computing resources at the
cloud and at the edge, as well as to the transmission on the fronthaul network connecting cloud and edge. The solution of these problems challenges the theoretical principles and engineering insights which have underpinned the design of existing networks. The initial research activity on the topic, of which the EU is at the forefront, focuses, by and large, on ad hoc solutions and technologies. In contrast, the goal of this project is to develop fundamental theoretical insights
and algorithmic principles with the main aim of guiding engineering choices, unlocking new academic opportunities and disclosing new technologies. The theoretical framework is grounded in network information theory, which enables the distillation of design principles, along with signal processing, (non-convex) optimization, queuing and distributed computing to develop and analyse algorithmic solutions.""","2318719","2017-06-01","2022-05-31"
"FORCASTER","Force, Motion and Positioning of Microtubule Asters","Nicolas David Minc","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Cells must move and position internal components to perform their function. We here focus on the physical designs which allow microtubule (MT) asters to exert forces in order to move and position themselves in vivo. These are arrays of MTs radiating from the centrosome, which fill up large portions of cells. They orchestrate nuclear positioning and spindle orientation for polarity, division and development. Forces that move asters are generated at nanometer and second scales by MT-associated motors from sites in the cytoplasm or at the cell surface. How MTs and force-generators self-organize to control aster motion and position at millimeter and hour scales is not known. We will use a suit of biophysical experiments and models to address how aster micro-mechanics contribute to aster migration, centration, de-centration and orientation in a single in vivo system, using the early stages of Sea urchin development as a quantitative model. 
We aim to: 1) Elucidate mechanisms that drive aster large-scale motion, using sperm aster migration after fertilization during which asters grow and move rapidly and persistently to the large-egg center. We will investigate how speeds and trajectories depend on boundary conditions and on the dynamic spatial organization of force-generators.
 2) Implement magnetic-based subcellular force measurements of MT asters. We will use this to understand how single force-events are integrated at the scale of asters, how global forces may evolve will aster size, shape, in centration and de-centration processes, using various stages of development, and cell manipulation; and to compute aster friction. 
 3) Couple computational models and 3D imaging to understand and predict stereotyped division patterns driven by subsequent aster positioning and aster-pairs orientation in the early divisions of Sea urchin embryos and in other tissues. 
This framework bridging multiple scales will bring unprecedented insights on the physics of living active matter.","2199310","2015-07-01","2020-06-30"
"FOREFRONT","Frontiers of Extended Formulations","Samuel Fiorini","UNIVERSITE LIBRE DE BRUXELLES","""Linear programming has proved to be an invaluable tool both in theory and practice. Semidefinite programming  surpasses linear programming in terms of expressivity while remaining tractable. This project proposal investigates the modeling power of linear and semidefinite programming, in the context of combinatorial optimization. Within the emerging framework of extended formulations (EFs), I seek a decisive answer to the following question: Which problems can be modeled by a linear or semidefinite program, when the number of constraints and variables are limited? EFs are based on the idea that one should choose the """"right"""" variables to model a problem. By extending the set of variables of a problem by a few carefully chosen variables, the number of constraints can in some cases dramatically decrease, making the problem easier to solve. Despite previous high-quality research, the theory of EFs is still on square one. This project proposal aims at (i) transforming our current zero-dimensional state of knowledge to a truly three-dimensional state of knowledge by pushing the boundaries of EFs in three directions (models, types and problems); (ii) using EFs as a lens on complexity by proving strong consequences of important conjectures such as P != NP, and leveraging strong connections to geometry to make progress on the log-rank conjecture. The proposed  methodology is: (i) experiment-aided; (ii) interdisciplinary; (iii) constructive.""","1455479","2014-09-01","2019-08-31"
"FOREMAT","Finding a needle in a haystack: efficient identification of high performing organic energy materials","Mariano Campoy Quiles","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Following promising early breakthroughs, progress in the development of high-performance multicomponent organic energy materials has stalled due to a bottleneck in device optimization. FOREMAT will develop a breakthrough technology to overcome this bottleneck by shifting from fabrication-intense to measurement-intense assessment methods, enabling rapid multi-parameter optimization of novel systems. Our goal is to deliver organic material systems with a step-change in performance, bringing them close to the expected market turn point, including panchromatic organic photovoltaics with ca 15% efficiencies and thermoelectric devices that could revolutionize waste heat recovery by their flexibility, lightweight and high power factor.

The development of multicomponent materials promises to dramatically improve the cost, efficiency and stability of organic energy devices. For example, they allow to engineer broad-band absorption in photovoltaics matched to the sun’s spectrum, or to create composites that conduct electricity like metals while thermally insulate like cotton yielding thermoelectric devices beyond the state-of-the-art. Despite these advantages, the long time required to evaluate promising organic multinaries currently limits their development. 

We will circumvent this problem by developing a high-throughput technology that will allow evaluation times up to two orders of magnitude faster saving, at the same time, around 90% of material. To meet these ambitious goals, we will advance novel fabrication tools and create samples bearing a high density of information arising from 2-dimensional gradual variations in relevant parameters that will be sequentially tested with increasing resolution in order to determine optimum values with high precision. This quantitative step will enable a disruptive qualitative change as in depth multidimensional studies will lead to design rationales for multicomponent systems with step-change performance in energy applications.","2423894","2015-10-01","2020-09-30"
"FORSIED","Formalizing Subjective Interestingness in Exploratory Data Mining","Tijl De Bie","UNIVERSITEIT GENT","""The rate at which research labs, enterprises and governments accumulate data is high and fast increasing. Often, these data are collected for no specific purpose, or they turn out to be useful for unanticipated purposes: Companies constantly look for new ways to monetize their customer databases; Governments mine various databases to detect tax fraud; Security agencies mine and cross-associate numerous heterogeneous information streams from publicly accessible and classified databases to understand and detect security threats. The objective in such Exploratory Data Mining (EDM) tasks is typically ill-defined, i.e. it is unclear how to formalize how interesting a pattern extracted from the data is. As a result, EDM is often a slow process of trial and error.

During this fellowship we aim to develop the mathematical principles of what makes a pattern interesting in a very subjective sense. Crucial in this endeavour will be research into automatic mechanisms to model and duly consider the prior beliefs and expectations of the user for whom the EDM patterns are intended, thus relieving the users of the complex task to attempt to formalize themselves what makes a pattern interesting to them.

This project will represent a radical change in how EDM research is done. Currently, researchers typically imagine a specific purpose for the patterns, try to formalize interestingness of such patterns given that purpose, and design an algorithm to mine them. However, given the variety of users, this strategy has led to a multitude of algorithms. As a result, users need to be data mining experts to understand which algorithm applies to their situation. To resolve this, we will develop a theoretically solid framework for the design of EDM systems that model the user's beliefs and expectations as much as the data itself, so as to maximize the amount of useful information transmitted to the user. This will ultimately bring the power of EDM within reach of the non-expert.""","1549315","2014-05-01","2019-04-30"
"FORWARD","New Frontiers for Optoelectronics with Artificial Media","ALOYSE MARIE CHARLES DEGIRON","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","To detect or generate complex light beams that are increasingly needed in biology and photonics (light with non-zero angular momentum and non-classical light), it is necessary to rely on bulky and sophisticated setups, considerably limiting their potential. The FORWARD project aims at obtaining the same functionalities with a new generation of optoelectronic components of submicron thickness in the near infrared range. This ambitious objective implies to devise radically new ways of creating and manipulating complex light at the nanoscale. In FORWARD, this tremendous challenge will be addressed by hybridizing two classes of artificial media-colloidal quantum dots (CQDs) and metamaterials-and leveraging advanced cooperative behaviours within the hybrids. In the new devices, which will be pumped electrically, the active layers will be made of a film of CQDs interwoven with the metallic inclusions of an optical metamaterial.
FORWARD has a strong multidisciplinary character as it lies at the crossroads of nanocrystal processing, nanofabrication, nanophotonics, condensed matter physics and optoelectronics. First, we will hybridize metallic metamaterials and CQDs, study the transport properties in these devices and develop metamaterial/CQD photodetectors demonstrating the advantage of the hybridization. Second, we will induce classical cooperative effects between the different metamaterial inclusions and utilize this approach to fabricate hybrids LEDs capable of emitting optical vortices. Last, we will induce quantum synchronizations among the CQDs and demonstrate hybrids LEDs that produce coherent and non-classical light.
Each demonstrator of the project will be a world first in terms of functionalities, miniaturization and operation principle. Besides, this initiative can be seen as the first of its kind that takes a unified and multidisciplinary view at artificial media, opening new horizons for synthetic composite materials in optics, electronics and optoelectronics.","1965045","2018-11-01","2023-10-31"
"FoTran","Found in Translation – Natural Language Understanding with Cross-Lingual Grounding","Jörg TIEDEMANN","HELSINGIN YLIOPISTO","""Natural language understanding is the """"holy grail"""" of computational linguistics and a long-term goal in research on artificial intelligence. Understanding human communication is difficult due to the various ambiguities in natural languages and the wide range of contextual dependencies required to resolve them.  Discovering the semantics behind language input is necessary for proper interpretation in interactive tools, which requires an abstraction from language-specific forms to language-independent meaning representations.  With this project, I propose a line of research that will focus on the development of novel data-driven models that can learn such meaning representations from indirect supervision provided by human translations covering a substantial proportion of the linguistic diversity in the world. A guiding principle is cross-lingual grounding, the effect of resolving ambiguities through translation. The beauty of that idea is the use of naturally occurring data instead of artificially created resources and costly manual annotations. The framework is based on deep learning and neural machine translation and my hypothesis is that training on increasing amounts of linguistically diverse data improves the abstractions found by the model. Eventually, this will lead to universal sentence-level meaning representations and we will test our ideas with multilingual machine translation and tasks that require semantic reasoning and inference.""","1817622","2018-09-01","2023-08-31"
"FOUR ACES","Future of upper atmospheric characterisation of exoplanets with spectroscopy","David René Bernard EHRENREICH","UNIVERSITE DE GENEVE","This project will open a new path to characterise the atmospheres of exoplanets down to Earth-size objects, using the spatial extension of upper atmospheres as a magnifying glass to access the atmospheric properties. The tremendous energy received by exoplanets close to their stars leads to dramatic atmospheric expansion and escape, which could result in the formation of hot rocky super-Earths seen in recent years. While the escape mechanisms and evolutionary impact on planets and atmospheres remain debated, the atmospheric expansion gives rise to spectacular spectroscopic signatures in the UV, only detectable with the Hubble Space Telescope (HST). In 2015, I discovered a huge extended atmosphere escaping from a “warm Neptune”, which represents a milestone on the road to the atmospheres of lower-mass, more temperate planets. Using HARPS spectroscopy from the ground, I revealed the extreme conditions in the upper atmosphere of a “hot Jupiter”, probing the onset of atmospheric escape in the optical, linking the upper and lower atmospheres. I propose to consolidate these breakthroughs via a thorough exploitation of the vast amount of observations I obtained for ~20 planets (100+ hours on HST and 250+ hours on HARPS and HARPS-N) in the wake of my results. I will use those data to bind theories describing the lower and upper atmospheres of exoplanets, and determine how these are impacted by stellar activity. In a second step, I will build and deliver a legacy archive of UV observations by the end of HST in ~2020. In an era where new transit surveys will provide hundreds of easier-to-study exoplanets transiting bright stars, I will use my priviledged access to the reconnaissance capabilities of the ESA CHEOPS mission (2018–2022) to cherry-pick the very best planets for atmospheric characterisation. I will combine the space-borne and ground-based high-resolution spectroscopic follow-ups of these planets to deliver a novel, comprehensive view of exoplanetary atmospheres.","1999475","2017-06-01","2022-05-31"
"FRAGMENT","FRontiers in dust minerAloGical coMposition and its Effects upoN climaTe","Carlos Perez Garcia-Pando","BARCELONA SUPERCOMPUTING CENTER - CENTRO NACIONAL DE SUPERCOMPUTACION","Soil dust aerosols are mixtures of different minerals, whose relative abundances, particle size distribution (PSD), shape, surface topography and mixing state influence their effect upon climate. However, Earth System Models typically assume that dust aerosols have a globally uniform composition, neglecting the known regional variations in the mineralogy of the sources. The goal of FRAGMENT is to understand and constrain the global mineralogical composition of dust along with its effects upon climate. The representation of the global dust mineralogy is hindered by our limited knowledge of the global soil mineral content and our incomplete understanding of the emitted dust PSD in terms of its constituent minerals that results from the fragmentation of soil aggregates during wind erosion. The emitted PSD affects the duration of particle transport and thus each mineral’s global distribution, along with its specific effect upon climate. Coincident observations of the emitted dust and soil PSD are scarce and do not characterize the mineralogy. In addition, the existing theoretical paradigms disagree fundamentally on multiple aspects. We will contribute new fundamental understanding of the size-resolved mineralogy of dust at emission and its relationship with the parent soil, based on an unprecedented ensemble of measurement campaigns that have been designed to thoroughly test our theoretical hypotheses. To improve knowledge of the global soil mineral content, we will evaluate and use available remote hyperspectral imaging, which is unprecedented in the context of dust modelling. Our new methods will anticipate the coming innovation of retrieving soil mineralogy through high-quality spaceborne hyperspectral measurements. Finally, we will generate integrated and quantitative knowledge of the role of dust mineralogy in dust-radiation, dust-chemistry and dust-cloud interactions based on modeling experiments constrained with our theoretical innovations and field measurements.","2000000","2018-10-01","2023-09-30"
"FRECOM","Nonlinear-Distortion Free Communication over the Optical Fibre Channel","Darko ZIBAR","DANMARKS TEKNISKE UNIVERSITET","Motivation
The enormous growth in the Internet of Things and server farms for cloud services has increased the strain on the optical communication infrastructure. By 2025, our society will require data rates that are physically impossible to implement using current state-of-the-art optical communication technologies. This is because fibre-optic communication systems are rapidly approaching their fundamental capacity limits imposed by the Kerr nonlinearity of the fibre. Nonlinear distortion limits the ability to transport and detect the information stream. This is a very critical problem for increasing the data rates of any optical fibre communication system. 

Proposed research 
The only physical quantities not affected by the nonlinearity are eigenvalues, associated with the optical fibre propagation equation. Eigenvalues are thereby ideal candidates for information transport. The concept of eigenvalues is derived under the assumption that the fibre is lossless and that there is no noise in the system which is not strictly correct. Therefore, novel methodologies and concepts for the design of a noise mitigating receiver and a noise robust transmitter are needed to reap the full benefits of optical communication systems employing eigenvalues. This proposal will develop such strategies. This will be achieved by combining, for the first time, the fields of nonlinear optics, optical communication and nonlinear digital signal processing. The results from the project will be verified experimentally, and will form the basis for a new generation of commercial optical communication systems.

Preliminary results
Our proof-of-concept results demonstrate, for the first time, that noise can be handled by employing novel receiver concepts. An order of magnitude improvement compared to the state-of-the-art is demonstrated.

Environment 
The research will be carried out in close cooperation with leading groups at Stanford University and Technical University of Munich.","2000000","2018-03-01","2023-02-28"
"FRICatANIONS","Frontiers in Catalytic Anion-Binding Chemistry","Olga GARCIA MANCHENO","WESTFAELISCHE WILHELMS-UNIVERSITAET MUENSTER","Chemical transformations comprise the polarization of the reacting species. As a consequence, partially or fully charged reagents and intermediates are omnipresent in chemistry. Although anion-binding processes are well-known for their crucial role in molecular recognition, this type of phenomenon has only recently been utilized for catalysis. Since catalytic reactions are of utmost relevance to construct valuable chemicals and materials, this mode of catalytic chemical activation might be the key for the future design of original and more efficient synthetic transformations. However, the effects of anions in catalytic processes are still largely unknown. 
Aiming at providing a novel general synthetic toolbox, in this project I propose several anion-binding activation concepts to solve current challenging catalytic synthetic problems. To achieve this goal, structurally different chiral anion-binding catalysts will be developed and incorporated into the existing limited palette of catalyst library. Furthermore, I propose a significant expansion of the application scope of anion-binding catalysis based on the activation and modulation of anionic nucleophiles and oxidants to develop organocatalytic reactions such as halogenations and oxidations, including the asymmetric functionalization of C-H bonds. In addition, anion-binding processes will be used to facilitate key steps in cross-coupling reactions such as the transmetallation, as well as the photoactivity modulation of readily available photosensitizers and the introduction of asymmetric photocatalysis involving radical-anions.
The proposed groundbreaking approaches will revolutionize not only anion-binding catalysis but also all the scientific areas relying on catalytic synthetic methods. Thus, the results derived from this project will have a tremendous impact in diverse fields such as catalysis, organic synthesis and material sciences, as well as in economical, environmental and industrial issues.","1997763","2017-06-01","2022-05-31"
"FricLess","A seamless multi-scale model for contact, friction, and solid lubrication","Lucia Nicola","UNIVERSITA DEGLI STUDI DI PADOVA","Friction and wear are liable for enormous losses in terms of energy and  resources in modern society. Costs related to unwanted friction in industrialised countries are estimated to be about 3% of the gross domestic product. Urgency is even greater nowadays as friction between micro-components has become the bottleneck of several applications for which miniaturisation is critical.

Lubrication is a commonly adopted solution to reduce friction. Graphite is a broadly used solid lubricant for large scale applications, while the lubricating properties of a few-layers graphene hold great promise especially for smaller scale applications. At present, our knowledge of the friction and lubrication of rough surfaces is essentially phenomenological. This is because friction is only deceivingly a simple mechanisms, which instead requires understanding of physical phenomena simultaneously acting at different length scales. The change in contact size, which controls the friction stress, depends on nano-scale phenomena such as atomic de-adhesion, sliding, dislocation nucleation in metals, but also on micro- and macro-scale phenomena as (size-dependent) plastic deformation.

The objective of this proposal is to reach an unprecedented understanding of metal friction and lubrication by accounting, for the first time, for all relevant phenomena occurring from the atomic to the macro-scale, and their interplay.
To this end, a seamless concurrent multi-scale model will be developed. The power of this new model lies in its capability of describing three-dimensional bodies with realistic roughness in sliding lubricated contact, with the accuracy of an atomistic simulation.

This research builds towards a complete picture of metal friction and lubrication. The materials chosen for the proposed research are copper and  multi-layer graphene. However, the model that will be developed is general and can be used to study different materials, lubricants and environmental conditions.","1999985","2016-06-01","2022-11-30"
"FTHPC","Fault Tolerant High Performance Computing","Oded Schwartz","THE HEBREW UNIVERSITY OF JERUSALEM","Supercomputers are strategically crucial for facilitating advances in science and technology: in climate change research, accelerated genome sequencing towards cancer treatments, cutting edge physics, devising engineering innovative solutions, and many other compute intensive problems. However, the future of super-computing depends on our ability to cope with the ever increasing rate of faults (bit flips and component failure), resulting from the steadily increasing machine size and decreasing operating voltage. Indeed, hardware trends predict at least two faults per minute for next generation (exascale) supercomputers.

The challenge of ascertaining fault tolerance for high-performance computing is not new, and has been the focus of extensive research for over two decades.  However, most solutions are either (i) general purpose, requiring little to no algorithmic effort, but severely degrading performance (e.g., checkpoint-restart), or (ii) tailored to specific applications and very efficient, but requiring high expertise and significantly increasing programmers' workload. We seek the best of both worlds: high performance and general purpose fault resilience.

Efficient general purpose solutions (e.g., via error correcting codes) have revolutionized memory and communication devices over two decades ago, enabling programmers to effectively disregard the very
likely memory and communication errors. The time has come for a similar paradigm shift in the computing regimen. I argue that exciting recent advances in error correcting codes, and in short probabilistically checkable proofs, make this goal feasible. Success along these lines will eliminate the bottleneck of required fault-tolerance expertise, and open exascale computing to all algorithm designers and programmers, for the benefit of the scientific, engineering, and industrial communities.","1824467","2019-06-01","2024-05-31"
"FUN POLYSTORE","FUNctionalized POLYmer electrolytes for energy STORagE","Daniel BRANDELL","UPPSALA UNIVERSITET","Besides the need for large-scale implementation of renewable energy sources, there is an equivalent need for new energy storage solutions. This is not least true for the transport sector, where electric vehicles are expanding rapidly. The rich flora of battery chemistries – today crowned by the Li-ion battery – is likewise expected to expand in upcoming years. Novel types of batteries, “post-lithium ion”, will challenge the Li-ion chemistries by advantages in cost, sustainability, elemental abundance or energy density. This requires significant improvements of the materials, not least regarding the electrolyte. The conventional liquid battery electrolytes pose a problem already for the mature Li-ion chemistries due to safety and cost, but are particularly destructive for future battery types such as Li-metal, organic electrodes, Li-S, Li-O2, Na- or Mg-batteries, where rapid degradation and loss of material are associated with incompatibilities with the electrolytes. In this context, solid state polymer electrolytes (SPEs) could provide a considerable improvement.

The field of solid polymer electrolytes (SPEs) is dominated by polyethers, particularly poly(ethylene oxide) (PEO). This application regards moving out of the established PEO-paradigm and exploring alternative polymer hosts for SPEs, primarily polycarbonates and polyesters. These ‘alternative’ polymers are comparatively easy to work with synthetically, and their possible functionalization is straightforward. The work aims at exploring functionalized alternative polymer host for mechanically robust block-copolymer systems, for alternative cation chemistries (Na, Mg, etc.), for extremely high and low electrochemical potentials, and for unstable and easily dissolved electrode materials (sulfur, organic). Moreover, since the ion transport processes in the host materials are fundamentally different from polyethers, there is a need for investigating the conduction mechanisms using simulations.","1950732","2018-09-01","2023-08-31"
"FunctionalP4","Metal-Mediated Methods for the Functionalization of White Phosphorus (P4)","Robert Matthias WOLF","UNIVERSITAET REGENSBURG","Organophosphorus compounds are an important and industrially relevant class of molecules with numerous uses, e.g. as reagents in organic synthesis, ligands in catalytically active metal complexes, and in pest control. State-of-the-art synthesis methods for all these valuable and useful compounds rely on an atom inefficient and hazardous multi-step procedure involving the oxidation of white phosphorus (P4) with toxic chlorine gas. Less wasteful and more environmentally benign methods are highly desirable, but transformations of white phosphorus directly into organophosphorus compounds are hardly developed.
This project explores new methods for the activation and functionalization of white phosphorus. The metal-mediated stepwise transformation of P4 into organophosphorus compounds is a key objective. Novel transition metal compounds are designed and synthesized, which can generate reactive phosphorus units. The concept of heterobimetallic P4 activation, where two electronically different metal complexes interact with P4 cooperatively, is introduced for this purpose. Reactions of the phosphorus fragments in these new, reactive complexes with electrophiles will produce novel, fundamentally interesting organophosphorus compounds avoiding chlorinated intermediates. Catalytic methods for P4 functionalization are currently unknown, and developing such methods using transition metal and photoredox catalysts is an additional objective of this proposal.
By providing novel synthetically useful and even catalytic procedures for converting P4 into organophosphorus compounds, this project will significantly contribute to the development of phosphorus chemistry and more sustainable synthesis methods.","1955846","2018-09-01","2023-08-31"
"GAINBYSTRAIN","Gain by Strain: Precise Cuts of Cyclopropanes as Key to Molecular Complexity","Daniel Bodo Werz","TECHNISCHE UNIVERSITAET BRAUNSCHWEIG","A central discipline of chemistry is the design und creation of molecules with defined structural and chemical properties. Stretching synthetic horizons is a never-ending endeavor to inspirit the chemist’ s creativity in preparing compounds and materials yet to be discovered. Relying on their high strain energy cyclopropanes, as carriers of the most fundamental ring geometry, offer a unique reactivity which allows for a multitude of transformations being grouped in ring-opening reactions, cycloadditions and rearrangements. Major advantage of all these processes is the cyclopropane-derived intrinsic atom-economy.
In this research project, we propose a number of uncommon and challenging reactions making use of donor-acceptor cyclopropanes. Introducing a distinctively controlled bond cleavage we seek to develop novel modes of 1,3-bifunctionalization by σ-bond metathesis, by using hypervalent iodine reagents and by merging organocatalysis with photoredox catalysis. Unprecedented ring-enlargements to four-membered rings by [3+1]-cycloadditions employing isonitriles, carbenes and nitrenes are envisioned, aryne insertions into the three-membered ring leading to indane systems are planned and a general concept for [3+3]-cycloadditions with 1,3-dipoles is presented paving the way to unusual syntheses of heterocycles.
A distinct class of compounds obtainable by our methodology will set the stage to access completely unexplored heterocyclic π-systems being of interest for material science and molecular electronics.
Besides our central goals of advancing organic methodology and to demonstrating the synthetic utility of these novel reactions, we anticipate that mechanistic insights gained by experimental and computational means will be of high impact for the chemistry of this fundamental structural unit in general.","1994250","2015-07-01","2021-06-30"
"GALACTICNUCLEUS","The Fingerprint of a Galactic Nucleus: A Multi-Wavelength, High-Angular Resolution, Near-Infrared Study of the Centre of the Milky Way","Rainer Schödel","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Galactic stellar nuclei are very common in all types of galaxies and are marked by the presence of nuclear star clusters, the densest and most massive star clusters in the present-day Universe. Their formation is still an unresolved puzzle. The centre of the Milky Way contains a massive black hole and a stellar nucleus and is orders of magnitude closer than any comparable target. It is the only galactic nucleus and the most extreme astrophysical environment that we can examine on scales of milli-parsecs. It is therefore a crucial laboratory for studying galactic nuclei and their role in the context of galaxy evolution. Yet, suitable data that would allow us to examine the stellar component of the Galactic Centre exist for less than 1% of its projected area. Moreover, the well-explored regions are extraordinary, like the central parsec around the massive black hole, and therefore probably not representative for the overall environment. Fundamental questions on the stellar population, structure and assembly history of the Galactic Centre remain therefore unanswered. This project aims at addressing the open questions by obtaining accurate, high-angular resolution, multi-wavelength near-infrared photometry for an area of several 100 pc^2, a more than ten-fold increase compared to the current state of affairs. The Galactic Centre presents unique observational challenges because of a combination of high extinction and extreme stellar crowding. It is therefore not adequately covered by existing or upcoming imaging surveys. I present a project that is specifically tailored to overcome these observational challenges. In particular, I have developed a key technique to obtain the necessary sensitive, high-angular resolution images with a stable point spread function over large, crowded fields. It works with a range of existing ground-based instruments and will serve to complement existing data to provide a global and detailed picture of the stellar nucleus of the Milky Way.","1547657","2014-02-01","2019-01-31"
"GALOP","Galois theory of periods and applications.","Francis Clément Sais BROWN","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","A period is a complex number defined by the integral of an algebraic differential form over a region defined by polynomial inequalities. Examples include: algebraic numbers, elliptic integrals, and Feynman integrals in high-energy physics. Many problems in mathematics can be cast as a statement involving periods. A deep idea, based on Grothendieck's philosophy of motives, is that there should be a Galois theory of periods, generalising classical Galois theory for algebraic numbers. This reposes on inaccessible conjectures in transcendence theory, but these can be circumvented in many important cases using an elementary notion of motivic periods. This allows one to set up a working Galois theory of periods in many  situations of arithmetic and physical interest.

These ideas grew out of the PI's recent proof of the Deligne-Ihara conjecture, in which the Galois theory of multiple zeta values  was worked out. Multiple zeta values are one of the most fundamental families of periods, and  their Galois group plays an important role in mathematics: it is conjecturally equal to  Drinfeld's Grothendieck-Teichmuller group, the stable derivation algebra on moduli spaces of curves, and the Galois group of mixed Tate motives over the integers. It occurs in deformation quantization, the homology of the graph complex, and the Kashiwara-Vergne problem, as well as having numerous connections to string theory, and quantum field theory.

The goal of this proposal is to generalise this picture.  Periods of moduli spaces of curves, multiple L-functions of modular forms, and Feynman amplitudes in quantum field and string theory should each have their own Galois theory which is yet to be worked out. 

This is completely uncharted territory, and will have numerous applications to number theory, algebraic geometry and physics.","1997959","2017-03-01","2022-02-28"
"GAPS","Spectral gaps in interacting quantum systems","David Perez Garcia","UNIVERSIDAD COMPLUTENSE DE MADRID","Interactions in a many body quantum system are encoded in a Hamiltonian, where the physical intuition that particles can only interact with those which are closeby is formally imposed as a local structure in the Hamiltonian, and homogeneity in space is imposed by a translational invariant structure on a given regular lattice in one, two or three dimensions. The first main aim of this proposal is to characterize the existence of a uniform (with the system size) lower bound on the gap between the two lowest eigenvalues of a given local translational invariant Hamiltonian.

There are many reasons which motivate this study, coming from different fields, and hence many potential applications. We will concentrate here on those coming from quantum information theory and from condensed matter physics and mainly, as the second main aim of this proposal, on classifying the different possible quantum phases arising in this type of models.","1462750","2015-09-01","2020-08-31"
"GATIPOR","Guaranteed fully adaptive algorithms with tailored inexact solvers for complex porous media flows","Martin Vohralik","INSTITUT NATIONAL DE RECHERCHE ENINFORMATIQUE ET AUTOMATIQUE","Efficient use of computational resources with a reliable outcome is a definite target in numerical simulations of partial differential equations (PDEs). Although this has been an important subject of numerical analysis and scientific computing for decades, still, surprisingly, often more than 90% of the CPU time in numerical simulations is literally wasted and the accuracy of the final outcome is not guaranteed. The reason is that addressing this complex issue rigorously is extremely challenging, as it stems from linking several rather disconnected domains like modeling, analysis of PDEs, numerical analysis, numerical linear algebra, and scientific computing. The goal of this project is to design novel inexact algebraic and linearization solvers, with each step being adaptively steered by optimal (guaranteed and robust) a posteriori error estimates, thus online interconnecting all parts of the numerical simulation of complex environmental porous media flows. The key novel ingredients will be multilevel algebraic solvers, tailored to porous media simulations, with problem- and discretization-dependent restriction, prolongation, and smoothing, yielding mass balance on all grid levels, accompanied by local adaptive stopping criteria. We shall theoretically prove the convergence of the new algorithms and justify their optimality, with in particular guaranteed (without any unknown constant) error reduction and overall computational load. Implementation into established numerical simulation codes and assessment on renowned academic and industrial benchmarks will consolidate the theoretical results. As a final outcome, the total simulation error will be certified and current computational burden cut by orders of magnitude. This would represent a cardinal technological advance both theoretically as well as practically in urgent environmental applications, namely the nuclear waste storage and the geological sequestration of CO2.","1283088","2015-09-01","2020-08-31"
"GaugeGravSym","Extended Symmetries in Gauge and Gravity Theories","Niklas Frederik Beisert","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","In the recent couple of years, we have achieved an incredibly deep understanding of N=4 maximally supersymmetric gauge theory and the AdS/CFT correspondence which relates this model to string theory. The main reason for this progress consists in the apparent exact integrability of the models in the planar limit. Integrability is a hidden symmetry which allows to establish very efficient tools for performing calculations. Remarkably, these tools not only conveniently compute observables at very high orders in the coupling constant, both at weak and at strong coupling, but they also make quantitative predictions at finite coupling strength. A similar amount of progress is due to the development of novel on-shell techniques which allow to construct scattering amplitudes at several loop orders. They become especially powerful when combined with the extended symmetries related to integrability.

The aim of the project is to put the recent rapid progress in integrability and scattering amplitudes on a solid foundation. By enhancing the encountered symmetries and applications towards more realistic gauge and gravity theories we hope to obtain new tools for QFT in general as well as new clues for the problem of quantum gravity.

More concretely, we will work out a precise formulation for the algebra underlying integrability. This is a crucial step towards proving integrability in AdS/CFT and to justify and develop efficient methods. Furthermore, we plan to develop applications of integrability away from the planar limit and for non-integrable gauge theories. Finally, we will extend these methods and considerations to gravity models. We will also take a fresh look at alternative models with a view to solving the puzzle of quantum gravity.

We plan to address these important objectives with the common framework of extended symmetries and powerful calculational techniques for scattering amplitudes.","1660804","2014-06-01","2019-05-31"
"GCGXC","GenoChemetics: Gene eXpression enabling selective Chemical functionalisation of natural products","Rebecca Jane Miriam Goss","THE UNIVERSITY COURT OF THE UNIVERSITY OF ST ANDREWS","""We aim to consolidate a trans-disciplinary research programme in which synthetic biology is harnessed to enable synthetic chemistry. We will utilise this approach to expeditiously access series of previously intractable natural product analogues.

There is an urgent need for the discovery and development of new drugs and in particular new antibiotics. More than 13 million lives worldwide are currently claimed each year due to infectious diseases. Natural products provide an unparalleled starting point for drug discovery, with over 60% of anticancer agents and over 70% of antibiotics entering clinical trials in the last three decades being based on such compounds.  In order to gain a full understanding as to how a drug works and in order to be able to generate compounds with improved biological activity and physicochemical properties the generation of analogues is essential. In recent years pharmaceutical industries have shied away from natural products due to the perceived synthetic intractability of libraries of natural product analogues and the misperception that it is not possible to carry out thorough structure activity relationship (SAR) assessment on such compounds. As a result of largely abandoning natural products, industries’ drug discovery pipelines are beginning to run dry; this is a particular concern when faced with the need to combat the ever-increasing problem of drug resistance and infectious disease.

We aim to challenge the misperception that natural products are not “med chemable” We are developing a new approach to natural product analogue synthesis. By introducing a gene from a foreign organism to complement existing natural product biosynthetic machinery we are able to introduce a chemically orthogonal, reactive and selectably chemically functionalisable handle into the natural product (the antithesis of a protecting group) - this reactive handle will enable us to carry out chemical modifications only at the site at which it is located.""","1981272","2014-06-01","2019-05-31"
"GEMS","General Embedding Models for Spectroscopy","Chiara CAPPELLI","SCUOLA NORMALE SUPERIORE","Recently, there has been a paradigmatic shift in experimental molecular spectroscopy, with new methods focusing on the study of molecules embedded within complex supramolecular/nanostructured aggregates. In the past, molecular spectroscopy has benefitted from the synergistic developments of accurate and cost-effective computational protocols for the simulation of a wide variety of spectroscopies. These methods, however, have been limited to isolated molecules or systems in solution, therefore are inadequate to describe the spectroscopy of complex nanostructured systems. The aim of GEMS is to bridge this gap, and to provide a coherent theoretical description and cost-effective computational tools for the simulation of spectra of molecules interacting with metal nano-particles, metal nanoaggregates and graphene sheets.
To this end, I will develop a novel frequency-dependent multilayer Quantum Mechanical (QM)/Molecular Mechanics (MM) embedding approach, general enough to be extendable to spectroscopic signals by using the machinery of quantum chemistry and able to treat any kind of plasmonic external environment by resorting to the same theoretical framework, but introducing its specificities through an accurate modelling and parametrization of the classical portion. The model will be interfaced with widely used computational chemistry software packages, so to maximize its use by the scientific community, and especially by non-specialists. 
As pilot applications, GEMS will study the Surface-Enhanced Raman (SERS) spectra of systems that have found applications in the biosensor field, SERS of organic molecules in subnanometre junctions, enhanced infrared (IR) spectra of oligopeptides adsorbed on graphene, Graphene Enhanced Raman Scattering (GERS) of organic dyes, and the transmission of stereochemical response from a chiral analyte to an achiral molecule in the vicinity of a plasmon resonance of an achiral metallic nanostructure, as measured by Raman Optical Activity-ROA","1609500","2019-06-01","2024-05-31"
"GEOMETRICSTRUCTURES","Deformation Spaces of Geometric Structures","Anna Wienhard","RUPRECHT-KARLS-UNIVERSITAET HEIDELBERG","""Moduli spaces of flat bundles and representation varieties play a prominent role in various areas of mathematics. Historically such spaces first arose in the study of systems of analytic differential equations. Closely related, and in fact locally homeomorphic, are deformation spaces of locally homogeneous geometric structures. Such deformation spaces often arise as solutions to basic geometric problems, and their global properties provide powerful topological invariants, in particular for three- and four-dimensional manifolds.
Due to the ubiquity of these spaces, methods and viewpoints from various areas of mathematics such as dynamical systems, algebraic geometry, gauge theory, representation theory, partial differential equations, number theory and complex analysis can be combined, and their interplay gives rise to the richness of this subject. In recent year there has also been an increasing interaction with theoretical physics, which has been fruitful for both sides.
In recent years the deformation theory of geometric structures has received revived attention due to new developments, which involve in a deeper way the connections to Lie theory and gauge theory. Unexpectedly, many new examples of deformation spaces of geometric structures appeared. Two such developments are Higher Teichmueller theory and Anosov representations of hyperbolic groups, which generalize classical Teichmueller theory and the theory of quasi-Fuchsian representations to the context of Lie groups of higher rank.
The goal of the proposal is to understand the fine structure and internal geometry of deformation spaces of geometric structures, and to further develop the structure theory of discrete subgroups in higher rank Lie groups. Of particular interest are deformation spaces with appear in the connection with higher Teichmueller theory, because they are expected to be of similar mathematical significance as classical Teichmueller space.""","1570327","2014-01-01","2018-12-31"
"GEOSTICK","Morphodynamic Stickiness: the influence of physical and biological cohesion in sedimentary systems","Daniel Roy PARSONS","UNIVERSITY OF HULL","Our coasts, estuaries, & low-land river environments are some of the most sensitive systems to sea-level rise & environmental change. In order to manage these systems, & adapt to future changes, we desperately need to be able to predict how they will alter under various scenarios. However, our models for these environments are not yet robust enough to predict, with confidence, very far into the future. Moreover, we also need to improve how we use our understanding of modern environments in reconstructing paleo-environments, where significant assumptions have been made in the way in which relationships derived from the modern have been applied to ancient rocks.
 
One of the main reasons our models, & geological interpretations, of these environments, are not yet good enough is because these models have formulations that are based on assumptions that these systems are composed of only non-cohesive sands. However, mud is the most common sediment on Earth & many of these systems are actually dominated by biologically-active muds & complex sediment mixtures. We need to therefore find ways to incorporate the effect of sticky mud & sticky biological components into our predictions. Recent work my colleagues & I have published show just how important such abiotic-biotic interactions can be: inclusion of only relatively small (<0.1% by mass) quantities of biological material into sediment mixtures can reduce alluvial bedform size by an order of magnitude.
 
However, this is just a start & there is much to do in order to advance our fundamental understanding & develop robust models that predict the combined effects of abiotic & biotic processes on morphological evolution of these environments under changing drivers & conditions. GEOSTICK will deliver this advance allowing us to test how sensitive these environments are, assess if there are tipping points in their resilience & examine evidence for the evolution of life in the ancient sediments of early Earth and Mars.","2581155","2017-05-01","2022-04-30"
"GETEMO","Geometry, Groups and Model Theory","Emmanuel, François, Jean Breuillard","WESTFAELISCHE WILHELMS-UNIVERSITAET MUENSTER","Our proposed research lies at the interface of Geometry, Group Theory, Number Theory and Combinatorics. In recent years, striking results were obtained in those disciplines with the help of a surprise newcomer at the border between mathematics and logic: Model Theory. Bringing its unique point of view and its powerful formalism, Model Theory made a resounding entry into several different fields of mathematics. Here shedding new light on a classical phenomenon, there solving a long-standing open problem via a completely new method.

Recent examples of concrete mathematical problems where Model Theory interacted in a fruitful manner abound: the local version of Hilbert's 5th problem by Goldbring and van den Dries, Szemeredi's theorems in combinatorics and graph theory, the André-Oort conjecture in diophantine geometry (Pila, Wilkie, Zannier), etc. In this vein, and building on Hrushovski's model-theoretic work, Green, Tao and myself recently settled a conjecture of Lindenstrauss pertaining to the structure of approximate groups.

Our plan in this project is to put these methods into further use, to collaborate with model theorists, and to start looking through this prism at a small collection of familiar problems coming from combinatorics, group theory, analysis and spectral geometry of metric spaces, or from arithmetic geometry. Among them: extend our study of approximate groups to the general setting of locally compact groups, obtain uniform estimates on the spectrum of Cayley graphs of large finite groups, prove an analogue for character varieties of the Pink-Zilber conjectures in relation with rigidity theory for discrete subgroups of Lie groups, and clarify the links between uniform spectral gaps and height lower bounds in diophantine geometry with a view towards Lehmer's conjecture.","1284000","2014-06-01","2019-05-31"
"GIANTCLIMES","Giants through Time:  Towards a Comprehensive Giant Planet Climatology","Leigh Nicholas FLETCHER","UNIVERSITY OF LEICESTER","Giant planets serve as natural laboratories to explore the processes shaping planetary climate.  The next five years will likely transform our understanding of the extreme environments of the outer Solar System, with the culmination of the Juno and Cassini missions to Jupiter and Saturn and the arrival of a new capability for ice giant science (James Webb Space Telescope, JWST).  GIANTCLIMES will capitalise on this chance of a generation by assembling the first comprehensive climatology of all four giants.  My programme will provide insights that no single mission can:  exploring atmospheric variability over long time spans using an unprecedented multi-decade archive of ground-based observations; new data from space telescopes and planetary missions; combined with world-leading spectral analysis techniques and interpretive models.  GIANTCLIMES consists of three objectives:

1. CLIMATE CYCLES: Assemble the first quasi-continuous record of Jovian climate over three decades to identify natural patterns of atmospheric variability to predict spectacular storm eruptions and global-scale transformations of its banded structure.
2. STRATOSPHERES: Explore the changing stratospheres of seasonal Saturn and non-seasonal Jupiter over long timescales to develop a new paradigm for the radiative, chemical and transport processes shaping these poorly-understood atmospheric regimes.
3. ICE GIANTS:  Provide the benchmark for understanding the fundamental differences between Ice Giant and Gas Giant climate via existing Spitzer and Herschel observations of Uranus and Neptune, and produce the highly-anticipated first spatial maps of their stratospheres using JWST.

These projects will explore planetary climates in all their guises, using comparative remote sensing studies to understand the forces defining their natural variability.  New insights and discoveries from GIANTCLIMES will reinforce my leading role in the next generation of ambitious missions to explore the giant planets.","1999815","2017-04-01","2022-03-31"
"GlacialLegacy","Glacial Legacy on the establishment of evergreen vs. summergreen boreal forests","Ulrike Herzschuh","ALFRED-WEGENER-INSTITUT HELMHOLTZ-ZENTRUM FUR POLAR- UND MEERESFORSCHUNG","Boreal forests provide critical ecosystem services to humanity, including timber supplies, cli-mate-regulation, and permafrost-stabilization. However, these forests differ markedly between Asia, which is dominated by summergreen larch forests, and North America, where boreal for-ests are exclusively evergreen. The basic mechanisms controlling the distributions of these bo-real biomes remain poorly understood. 
My new hypothesis is that summergreen and evergreen needle-leaf forests represent alterna-tive quasi-stable states that occur today under similar climatic conditions, but were triggered by different environmental conditions and gene pools during the Last Glacial.
GlacialLegacy will use coherent empirical and modelling approaches to investigate this hypoth-esis across the entire Northern Hemisphere, also collecting new data from northern Asia, where both forests types occur today. 
Work package (WP) A will explore the dependency of post-glacial forest establishment on the glacial climate and genetic characteristics of northern tree refugia. We will use ancient DNA analysis of sediments, complemented by results from pollen data synthesis. For a mechanistic understanding of the empirical evidence obtained, we will simulate post-glacial forest migra-tion using the LAVESI individual-based vegetation model, into which long-term genetic process-es will be incorporated. 
WP-B will further refine the LAVESI model using results from vegetation and biophysical field surveys. This will enable us to quantify the vegetation–fire–permafrost–climate feedbacks that are likely to facilitate boreal forest bi-stability. 
Such a model configuration is the only way that reliable predictions of the future of boreal for-ests can be made, which will be the objective of WP-C. These predictions will aim to anticipate potentially critical future ecosystem service changes on a continental scale, thus providing the knowledge base required for adaptation strategies to be prepared.","1979052","2018-11-01","2023-10-31"
"GlassUniversality","Universal explanation of low-temperature glass anomalies","Francesco, Ascanio Mario Marcello ZAMPONI","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","While amorphous solids constitute most of the solid matter found in Nature, their understanding is much poorer than for crystalline solids, at the point that most solid state textbooks are entirely focused on crystals. The reason underlying this uncomfortable situation is that amorphous solids display all kind of anomalies with respect to a simple description in terms of phonon excitations around a perfect lattice. In particular, they display an excess of low-frequency vibrational modes, their thermodynamic and transport coefficients behave differently from crystals, they respond non-linearly to arbitrarily small strains, and have highly cooperative dynamics. Traditionally, each of these aspects has been studied independently of the others, by almost distinct communities, and in terms of microscopic elements that are specific to a given material.

The objective of this proposal is to take a different approach and seek a universal explanation of all the anomalies of amorphous solids, in terms of criticality associated with a new phase transition between two distinct glass phases.

This goal is both ambitious and reachable. It is reachable because such a phase transition has just been theoretically predicted to exist on rigorous grounds, in an abstract limit of infinite spatial dimensions; its existence allows one to compute the critical exponents of jamming, in strikingly good agreement with numerical simulations; and the transition has been observed numerically in a realistic model of glass. It is ambitious because it requires to firmly establish the universal nature of the transition, and connect it to the experimentally observed anomalies through concrete analytical and numerical calculations, which will open the way to a direct experimental test. Both tasks require solving a number of difficult conceptual and technical problems. But, if successful, this project could lead to a revolution in our understanding of amorphous solid matter.","1362125","2017-09-01","2022-08-31"
"GLOBE","Global Lensing Observations to go Beyond Einstein","Catherine Elizabeth Cox Heymans","THE UNIVERSITY OF EDINBURGH","This ERC Consolidator grant will push forward the boundaries in our understanding of gravity by confronting the most advanced theoretical framework for modified gravity models with this decade’s ultimate set of observations.  Using three state-of-the-art, same-sky lensing spectroscopy surveys, which are the only deep surveys currently in existence to have this unique complementarity, we will undertake a ground-breaking gravity experiment on some of the largest scales observed in the Universe.  Our findings could show that we need to go beyond Einstein to bring about a revolution in our understanding of gravity on cosmological scales, transforming our understanding of the dark universe.  

My analysis will combine two gravity probes; the non-relativistic motion of galaxies detected through redshift-space distortions, and the relativistic motion of light detected through the weak gravitational lensing of distant galaxies.  The same-sky combination of these probes provides the best long-term prospect for observing if matter bends space differently to time, and if the gravitational constant G evolves.  

As the main objective of this research could be so far reaching, it is imperative that it is approached with care, using a meticulous analysis.    Using novel techniques that exploit the same-sky nature of these surveys, we will improve the accuracy and precision of our results, understanding and removing sources of systematic errors inherent in both gravity probes.  This will enable my ERC team to carry out pioneering dark universe science, confident that our results are truly probing fundamental physics rather than residual systematic subtleties of the data.","1995797","2015-11-01","2020-10-31"
"GLYCO-TOOLS","Bio-Inspired Tools for Glycoscience","Maria Carmen Galan","UNIVERSITY OF BRISTOL","Cell surface carbohydrates play key roles in cell recognition mechanisms. O-glycosylation is a ubiquitous post-translational modification that is highly dynamic and responsive to cellular stimuli through the action of cycling enzymes. Expression of specific O-glycans is linked to changes in gene expression in, for example, inflammatory bowel disease, cystic fibrosis and several types of cancer. 


Protein-carbohydrate interactions typically exhibit high specificity and weak affinities toward their carbohydrate ligand. This low affinity is compensated in nature by the architecture of the protein, the host presenting the carbohydrate ligands in a multivalent manner or as clusters on the cell or mucosal surface. This effect is known as the multivalency or “cluster–glycoside effect” and has been well documented for lectin–carbohydrate interactions as increasing ligand affinity and selectivity. The fundamental understanding of these glycosylation patterns at molecular and functional levels will allow mechanisms associated with bacterial-host interactions, bowel disease and several cancers to be defined, which will facilitate the identification of effective treatments and diagnostics for these conditions in due course. 

This is a multidisciplinary project involving synthetic organic and inorganic chemistry, enzymology and glycobiology. The proposal centres on the development of expedient synthetic and chemo-enzymatic methodologies for the preparation of novel  multivalent O-glycan probes that will be used in the screening of O-glycosylation-linked interactions in health and in disease. These studies will help us understand the parameters controlling the combinatorial diversity of O-glycans and the implications of such diversity on receptor binding and subsequent intracellular signalling, which in turn  will lead us to the development of new glycan-based diagnostic tools and therapeutics.","1986356","2015-07-01","2020-06-30"
"GLYCONTROL","Understanding and Controlling Glycosylation Reactions","Jeroen Dirk Cornelis CODÉE","UNIVERSITEIT LEIDEN","This proposal aims to understand and control glycosylation reactions. In a glycosylation reaction a “donor” glycoside and an “acceptor” (the nucleophile) are united to form an oligosaccharide. Although it is the central reaction in carbohydrate chemistry, our understanding of this reaction, in terms of stereoselectivity and productivity is still limited. The structural variation in the building blocks leads to a complex continuum of SN2-SN1 mechanisms that operates and it is currently impossible to predict where in the continuum the reaction exactly takes place. This proposal provides fundamental insight into the outcome of glycosylations by studying both the activated donor glycoside and the acceptor nucleophile. Activation of a donor glycoside leads to different reactive intermediates, covalent anomeric species (most often triflates) and oxocarbenium ion-like species. The relative reactivity of these species is quantified to generate novel reactivity charts. The covalent species are studied by innovative competition experiments, kinetic studies and NMR spectroscopy. The (fleeting) oxocarbenium ion-like intermediates are probed by a computational approach and by “super-acid NMR” studies in which stable glycosyl cations are generated and studied in super-acid media. The reactivity of glycosyl acceptors is systematically studied in a set of SN2 or SN1-type glycosylations. Using kinetic studies and competition reactions charts of acceptor nucleophilicity are compiled. The reactivity of the donors and acceptors is matched using a family of tailor made “reactivity modulators”, spanning a broad reactivity window bridging the reactivity gap between the building blocks leading to predictable glycosylations. The developed methodology is employed in automated solid phase syntheses of libraries of oligosaccharides featuring multiple cis-glycosidic linkages. The proposal is a major step forward in the development of a general glycosylation procedure.","2000000","2017-05-01","2022-04-30"
"GLYCOSURF","Surface-Based Molecular Imprinting for Glycoprotein Recognition","Paula Maria Da Silva Mendes","THE UNIVERSITY OF BIRMINGHAM","""There is now overwhelming evidence that glycosylation changes during the development and progression of various malignancies. Altered glycosylation has been implicated in cancer, immune deficiencies, neurodegenerative diseases, hereditary disorders and cardiovascular diseases. Currently, antibodies are playing a central role in enabling the detection of glycoprotein biomarkers using a variety of immunodiagnostic tests. Nonetheless, antibodies do have their own set of drawbacks that limit the commercialization of antibody sensing technology. They suffer from poor stability, need special handling and require a complicated, costly production procedure. More importantly, they lack specificity because they bind only to a small site on the biomarker and are not able to discriminate, for instance, among different glycosylated proteins. The current antibody diagnostic technology has well recognized limitations regarding their accuracy and timeliness of diagnose of disease. This project will focus on research into the means of developing a generic, robust, reliable and cost-effective alternative to monoclonal antibody technology. The project aims to exploit concepts and tools from nanochemistry, supramolecular chemistry and molecular imprinting to provide highly innovative synthetic recognition platforms with high sensitivity and specificity for glycoproteins. Such novel type of platforms will make a profound and significant impact in the broad fields of biosensors and protein separation devices with applications in many areas such as biomedical diagnostics, pharmaceutical industry, defense and environmental monitoring. The proposed technology may open an untraveled path in the successful diagnosis, prognosis and monitoring of therapeutic treatment for major diseases such as cancer, immune deficiencies, neurodegenerative diseases, hereditary disorders and cardiovascular diseases.""","1894046","2014-12-01","2019-11-30"
"GMGalaxies","Understanding the diversity of galaxy morphology in the era of large spectroscopic surveys","Andrew PONTZEN","UNIVERSITY COLLEGE LONDON","Galaxies are the building blocks of structure in the Universe; this proposal seeks to understand how their shapes, colours and dynamics are determined. For example, what happened in the history of some galaxies to transform them into passive ellipticals while others, seemingly of the same mass and in the same environment, are star-forming spirals? Even such a basic question about the link between morphology and star formation has not yet been answered, revealing our theories of galaxy formation are inadequate. This is a major concern in an era where understanding the shapes of galaxies and how they relate to the underlying dark matter is essential for progress in precision cosmology.  

This project will build the missing link between the history of a galaxy and its observational properties (i.e. between cause and effect) by using numerical simulations.  Current research in this area rightly gives significant attention to the crucial problem of how feedback – energy input from supernovae, active galactic nuclei, and more – affect observable properties.  But as well as investigating this avenue, GM Galaxies will uniquely make use of my new technique (“genetic modification”) to systematically investigate the role of the galaxy’s merging and accretion history at high resolution.

To distinguish the fingerprints of history from the effects of feedback, we will compare to rich new data from integral field unit surveys; these reveal, for example, galactic metallicity and velocity maps. My pilot study for this project shows that such measures of a galaxy disambiguate between alternative formation routes to galaxies which would appear similar by photometric measures alone. Similarly, we will make predictions for the observable properties of the gas reservoir surrounding galaxies and for integral field observations at high redshift. In this way we will make a predictive account of how galactic structure is determined by the interaction of the accretion history with feedback.","1741230","2019-10-01","2024-09-30"
"GOCART","Gauging Ocean organic Carbon fluxes using Autonomous Robotic Technologies","Stephanie Anne HENSON","NATURAL ENVIRONMENT RESEARCH COUNCIL","Climate change driven by CO2 emissions from human activities is a significant challenge facing mankind. An important component of Earth’s carbon (C) cycle is the ocean’s biological C pump; without it atmospheric CO2 would be ~50% higher than it is now. The pump consists of sinking organic matter which is remineralised back into CO2 in the deep ocean. The depth at which remineralisation occurs is the main factor affecting the amount of organic C stored in the ocean. Currently we do not understand how or why remineralisation depth varies in time, which limits our ability to make robust predictions of how the future C cycle, and hence our climate, will change into the future. This is mainly due to the challenges of measuring remineralisation depth using conventional methods– a barrier which autonomous underwater vehicles are poised to overcome by providing high frequency data over long periods. This technological innovation will revolutionise our understanding of this important planetary C flux.
I propose an ambitious project to address current uncertainties in remineralisation depth. GOCART encompasses new observations, obtained using cutting-edge technology and novel methodology, through to global climate modelling. Underwater glider deployments will be used to establish the characteristics and significance of temporal variability in organic C flux and remineralisation depth during the most dynamic period of the year. This will enable new insights into the factors driving variability in remineralisation depth, ultimately leading to development of a new model parameterisation incorporating temporal variability. Using an innovative modelling framework, this parameterisation will be tested for its potential to improve predictions of ocean C storage. GOCART represents a significant advance in quantifying temporal variability in remineralisation depth, which is key to reducing uncertainty in model predictions of ocean C storage, and yet currently almost entirely unknown.","1999110","2017-09-01","2022-08-31"
"GPSART","Geometric aspects in pathwise stochastic analysis and related topics","Peter Karl Friz","TECHNISCHE UNIVERSITAT BERLIN","""Recent years have seen an explosion of applications of geometric and pathwise ideas in probability theory, with motivations from fields as diverse as quantitative finance, statistics, filtering, control theory and statistical physics. Much can be traced back to Bismut, Malliavin (1970s) on the one-hand and then Doss, Sussman (1970s), Foellmer (1980s) on the other hand, with substantial new input from Lyons (from '94 on), followed by a number of workers, including Gubinelli (from '04 on) and the writer of these lines (also from '04 on). Most recently, the theory of such ``rough paths"""" has been extended to ``rough fields"""", notably in the astounding works of M. Hairer (from '13 on). The purpose of this project is to study a number of important problems in this field, going beyond the rough path setting, and with emphasis on geometric ideas. 

(i) The transfer of concepts from rough path theory to the new world of Hairer's regularity structures.

(ii) Applications of geometric and pathwise ideas  in quantitative finance.

(iii) Obtain a pathwise understanding of the geometry of Loewner evolution and more generally explore the use of rough path-inspired ideas in the world of Schramm-Loewner evolution.

(iv) Investigate the role of geometry in the pathwise analysis of non-linear evolution equations.""","1465000","2016-09-01","2021-08-31"
"GraM3","Surface-grafted metallofullerene molecular magnets with controllable alignment of magnetic moments","Alexey Alexandrovich Popov","LEIBNIZ-INSTITUT FUER FESTKOERPER- UND WERKSTOFFFORSCHUNG DRESDEN E.V.","The molecules retaining their magnetization in the absence of magnetic field are known as single molecule magnets (SMMs). Important problems to be solved on the way to the applications of SMMs in molecular spintronics is their deposition on surfaces and addressing their spins on the single molecular level. In this project we will address these problems by designing SMMs based on endohedral metallofullerenes (EMFs) derivatized with anchoring groups. SMM behaviour recently discovered for DySc2N@C80 and Dy2ScN@C80 in PI’s group is governed by a strong magnetic anisotropy (magnetic moments of Dy ions are aligned along the Dy–N bonds) and ferromagnetic exchange interactions between Dy ions within the clusters. Protected by the carbon cages, these SMMs exhibit uniquely long zero-field relaxation times of several hours at 2 K and provide an ideal system for addressing the individual spin states. Spatial orientation of magnetic moments in EMF-SMMs is determined by the endohedral cluster and is therefore influenced by the orientation of the EMFs molecules and their internal dynamics. We will apply three strategies to control the spatial arrangement of the magnetic moments in EMF-SMMs: (i) deposition of EMF molecules via sublimation; (ii) exohedral modification of EMFs with anchoring groups for grafting of EMFs on surfaces; (iii) introducing photoswitchable units into the anchoring groups which can reversibly change their geometry upon impact of light and will allow switching direction of the magnetic moment in a fully controllable way. Magnetic behaviour of the surface-grafted SMMs will be studied by bulk- and surface-sensitive techniques including X-ray magnetic circular dichroism and especially spin-polarized scanning tunneling microscopy. Successful fulfillment of the objectives of this interdisciplinary high-risk/high-gain project will revolutionize the field of the surface molecular magnetism by allowing the study and control of the SMMs on a single spin level.","1912181","2015-06-01","2020-05-31"
"GRAMS","GRavity from Astrophysical to Microscopic Scales","Enrico BARAUSSE","SCUOLA INTERNAZIONALE SUPERIORE DI STUDI AVANZATI DI TRIESTE","General Relativity (GR) describes gravity on a huge range of scales, field strengths and velocities. However, despite its successes, GR has been showing its age. Cosmological data support the existence of a Dark Sector, but may also be interpreted as a breakdown of our understanding of gravity. Also, GR is intrinsically incompatible with quantum field theory, and should be replaced, at high energies, by a (still unknown) quantum theory of gravity.

This deadlock may prelude to a paradigm change in our understanding of gravity, possibly triggered by the direct observations of neutron stars and black holes by gravitational-wave interferometers. The recent LIGO/Virgo observations, and in particular the coincident detection of electromagnetic and gravitational signals from neutron-star binaries, have already made a huge impact on our theoretical understanding of gravity, by severely constraining several extensions of GR.

GRAMS is a high-risk/high-gain project seeking to push the implications of these observations even further, by exploring whether the existing LIGO/Virgo data, and in particular their absence of non-perturbative deviations from GR, are consistent with gravitational theories built to reproduce the large-scale behaviour of the Universe (i.e. the existence of Dark Energy and/or Dark Matter), while at the same time passing local tests of gravity thanks to non-perturbative screening mechanisms. I will prove that the very fact of screening local scales makes gravitational emission in these theories much more involved than in GR, and also intrinsically unlikely to yield results in agreement with existing (and future) gravitational-wave observations. This would be a huge step forward for our understanding of cosmology, as it would rule out a modified gravity origin for the Dark Sector. Even if this conjecture is incorrect, GRAMS will provide the first numerical-relativity simulations of compact binaries ever in gravitational theories of interest for cosmology.","1993920","2019-04-01","2024-03-31"
"GRANN","Graphene Coated Nanoparticles and Nanograins","Liv Haahr Hornekaer","AARHUS UNIVERSITET","In a truly cross-disciplinary research project encompassing surface science, optics, nano-science, astrophysics and chemistry we will synthesize a novel family of high quality mono-layer graphene coated nanoparticles and graphene nanograins with new chemical and optical properties and investigate their catalytic activity, chemical stability and optical characteristics to gauge their relevance for and applicability in industrial catalysis, solar cells, and interstellar chemistry. 

This will be accomplished by extending existing expertise, knowledge and methods developed by us and by international colleagues for graphene synthesis, graphene reactivity and chemical functionalization, graphene coatings on industrially relevant samples and interstellar surface astrochemistry on carbonaceous materials, into the nanoparticle regime. Combined with state-of-the-art surface science characterization methods with emphasis on scanning tunnelling microscopy and spectroscopy, high resolution transmission electron microscopy, X-ray photoelectron spectroscopy, and thermal desorption mass spectrometry, complemented by Raman and transmission spectroscopy, this will enable us to design, characterize, and understand the properties of this new family of particles at the atomic level. 

The vision is to harness and combine the remarkable properties of graphene and nanoparticles to create systems with entirely new and unexplored characteristics, to tune these characteristics to be useful for real-world applications, and to exploit the new systems as the first realistic laboratory models of catalytic nanoparticles for interstellar surface chemistry.

This ambitious and cross-disciplinary research program will predominantly take place at the Surface Dynamics Laboratory at Aarhus University which is headed by the applicant, but will also involve local, national and international collaborators.","1996147","2015-07-01","2020-06-30"
"GRANT","Groups, Representations and Analysis in Number Theory","Harald Andres Helfgott Seier","GEORG-AUGUST-UNIVERSITAT GOTTINGENSTIFTUNG OFFENTLICHEN RECHTS","The last decade has seen remarkable progress in the study of growth in infinite families of groups. The main approach has its roots in additive combinatorics, but has truly given fruit in a non-commutative context. It is becoming clear that the central role is played not by groups in isolation, but by actions of groups. It is from this perspective that my plan addresses, at the same time, questions on growth in groups as such and hard problems in analytic number theory.

While this line of research on growth started with the study of matrix groups, it has now given strong results on permutation groups as well. Two outstanding matters are the control of dependence on rank in matrix groups, and the removal of the need for the Classification Theorem in permutation groups. Going beyond these questions on diameter and expansion, there are at least three new directions I propose to follow: towards algorithms, towards geometric group theory, and towards number theory.

Some of the main recent results in the area take the form of diameter bounds. Bounding a diameter amounts to showing that one can express any element of a group as a short product of generators. One of the main algorithmic questions consists in actually finding such an expression, and doing so rapidly. Links between geometric group theory (which studies growth in infinite groups) and the new combinatorial techniques ought to become stronger. Sofic and hyperlinear groups -- which arose in part from geometric group theory -- seem to invite a combinatorial approach.

Additive combinatorics has already shown its relevance to exponential sums, a key subject in analytic number theory. Can a newer perspective based on actions of groups give more general results? Short Kloosterman sums, which are particularly hard to bound, can be framed as a test case.

I also plan to pursue related interests in automorphic forms - which are a classical example of the relevance of group actions to number theory - and model theory.","1374250","2015-09-01","2020-08-31"
"GRAPHICS","GRAphene nonlinear PHotonic Integrated CircuitS","Christelle Brigitte Isabelle Monat","ECOLE CENTRALE DE LYON","""GRAPHICS aims at developing novel chip-based photonic devices for all-optical signal processing in graphene/ semiconductor hybrid platforms. The resulting architectures will be the cornerstone of a disruptive optical routing and processing technology on silicon chips for communications as well as Datacom and interconnect applications. These will also pave the way towards the photonic-microelectronic convergence, through the realization of CMOS compatible platforms. 
Our research program will focus on two main classes of nonlinear optical devices: (1) integrated pulsed III-V/ Si microlasers, and (2) all-optical signal processing devices, relying on two distinct nonlinear features of graphene, i.e. its saturable absorption and its nonlinear Kerr response, respectively. In addition, the capability of tuning graphene properties electrically will allow us to create fundamentally flexible and reconfigurable intelligent optical devices.
The two classes of nonlinear devices targeted in the project represent significant achievements in their own right. However, they share some scientific and technological challenges. For instance, relevant strategies must be found for enhancing the typically low interaction of light with the monolayer of carbon atoms, as needed for the device miniaturization. Here, we will combine graphene with the nanophotonic toolbox  -microcavities, or slow light photonic crystals-  to enhance the light-graphene interaction and realize compact chip-scale devices. More fundamentally, these two classes of nonlinear devices will jointly contribute to shape the long-term vision of a fully integrated photonic platform, in which the pulsed microlaser delivers directly on-chip the optical peak power necessary to trigger all other """"intelligent"""" devices onto the same circuit. GRAPHICS will therefore help to """"draw"""" a novel generation of photonic integrated circuits and architectures, with graphene playing a key role, to be used for managing high-speed optical data.""","1999257","2015-09-01","2020-08-31"
"GraphInt","Principles of Graph Data Integration","Philippe Cudre-mauroux","UNIVERSITE DE FRIBOURG","The present proposal tackles fundamental problems in data management, leveraging expressive, large-scale and heterogeneous graph structures in order to integrate both unstructured (e.g., text) and structured (e.g., relational) content. Integrating heterogeneous content has become a key hurdle in the deployment of Big Data applications, due to the meteoric rise of both machine and user-generated data storing information in a variety of formats. Traditional integration techniques cleaning up, fusing and then mapping heterogeneous data onto rigid abstractions fall short of accurately capturing the complexity and wild heterogeneity of today’s information. Having closely followed the emergence of heterogeneous information sources online, I am convinced that only an interdisciplinary approach drawing both from classical data management and from large-scale Web information processing techniques can solve the formidable data integration challenges that they pose. The following project proposes an ambitious overhaul of information integration techniques embracing the scale and heterogeneity of today’s data. I propose the use of expressive and heterogeneous graphs of entities to continuously and dynamically interrelate disparate pieces of content while capturing their idiosyncrasies. The following project focuses on three core issues related to large-scale and heterogeneous information graphs: i) the effective extraction of fined-grained information from unstructured sources and their proper integration into large-scale heterogeneous and probabilistic graphs, ii) the creation of novel physical storage structures and primitives to durably and efficiently manage the profusion of data considered by such graphs using clusters of commodity machines, and iii) the development of logical data abstraction mechanisms facilitating the effective and efficient resolution of complex analytic and data integration queries on top of the physical layer.","1998339","2016-08-01","2021-07-31"
"GrDyAp","Groups, Dynamics, and Approximation","Andreas Thom","TECHNISCHE UNIVERSITAET DRESDEN","Eversince, the study of symmetry in mathematics and mathematical physics has been fundamental
to a thourough understanding of most of the fundamental notions. Group theory in all its forms
is the theory of symmetry and thus an indispensible tool in many of the basic theoretical sciences.
The study of infinite symmetry groups is especially challenging, since most of the tools from the
sophisticated theory of finite groups break down and new global methods of study have to be found.
In that respect, the interaction of group theory and the study of group rings with methods from ring
theory, probability, Riemannian geometry, functional analyis, and the theory of dynamical systems
has been extremely fruitful in a variety of situations. In this proposal, I want to extend this line of
approach and introduce novel approaches to longstanding and fundamental problems.
There are four main interacting themes that I want to pursue:
(i) Groups and their study using ergodic theory of group actions
(ii) Approximation theorems for totally disconnected groups
(iii) Kaplansky’s Direct Finiteness Conjecture and p-adic analysis
(iv) Kervaire-Laudenbach Conjecture and topological methods in combinatorial group theory
The theory of `2-homology and `2-torsion of groups has provided a fruitful context to study global
properties of infinite groups. The relationship of these homological invariants with ergodic theory
of group actions will be part of the content of Part (i). In Part (ii) we seek for generalizations of
`2-methods to a context of locally compact groups and study the asymptotic invariants of sequences
of lattices (or more generally invariant random subgroups). Part (iii) tries to lay the foundation of a padic
analogue of the `2-theory, where we study novel aspects of p-adic functional analysis which help
to clarify the approximation properties of (Z/pZ)-Betti numbers. Finally, in Part (iv), we try to attack
various longstanding combinatorial problems in group theory with tools from algebraic topology and
p-local homotopy theory.","2000000","2016-10-01","2021-09-30"
"GREENLIGHT_REDCAT","Towards a Greener Reduction Chemistry by Using Cobalt Coordination Complexes as Catalysts and Light-driven Water Reduction as a Source of Reductive Equivalents","Julio Lloret Fillol","FUNDACIO PRIVADA INSTITUT CATALA D'INVESTIGACIO QUIMICA","The development of alternative greener synthetic methods to transform renewable feedstocks into elaborated chemical structures mediated by solar light is a prerequisite for a future sustainable society. In this regard, this project entails the use of visible light as driving force and water as a source of hydrides for the synthesis of high-value chemicals.
The project merges photoredox catalysis with 1st row transition coordination complexes catalysis to open a new avenue for greener selective catalytic reduction processes for organic substrates. The ground-breaking nature of the project is:
 A) Develop light-driven region- and/or enantioselective catalytic reductions using well-defined cobalt coordination complexes with aminopyridine ligands, initially developed for water reduction. Sterics, electronics and supramolecular interactions (apolar cavities and chiral pockets) will be studied to proper control of the selectivity in the reduction of i) C=E and C=C bonds and ii) in the C-C inter- and intramolecular reductive homo- or heterocouplings.
 B) Fundamental understanding of the light-driven cobalt catalysed reductions characterizing intermediates that are involved in the reactivity, kinetics and labelling studies as well as performing computational modelling of reaction mechanisms. The basic understanding of operative mechanisms will expedite a new methodology for electrophile-electrophile umpolung couplings.
 C) Enhance catalytic performance of the light-driven cobalt catalysed reductions by self-assembling of catalyst-photosensitizer into carbon based pi-conjugated materials through noncovalent supramolecular interactions. Likewise, it will allow electrode immobilization for electrocatalysed reductions using water as a source of protons and electrons.
 As a proof of concept, cobalt catalysts based on aminopyridine ligands have been shown highly active in the light-driven reduction of ketones and aldehydes to alcohols, using water as the source of hydrogen atom.","1999063","2015-07-01","2020-06-30"
"GREinGC","General Relativistic Effect in Galaxy Clustering as a Novel Probe of Inflationary Cosmology","Jaiyul Yoo","UNIVERSITAT ZURICH","Substantial advances in cosmology over the past decades have firmly established the standard model of cosmology. However, the physical nature of the early Universe and dark energy (or inflationary cosmology) remains  poorly understood. To resolve these issues, a large number of galaxy surveys are planned to measure millions of galaxies in the sky, promising precision measurements of galaxy clustering with enormous statistical power. Despite these advances in observation, the standard theoretical description of galaxy clustering is based on the Newtonian description, inadequate for measuring the relativistic effects from the early Universe and the deviations of modified gravity from general relativity. In recent years, the applicant, for the first time, developed the linear-order general relativistic description of galaxy clustering and showed that the relativistic effect in galaxy clustering is already measurable at a few-sigma level in current surveys like the Sloan survey
and significant detections (>10 sigma) are possible in upcoming surveys.

This research proposal will aim to use the subtle relativistic effect in galaxy clustering to develop novel probes of inflationary cosmology. In particular, the applicant will 1) formulate the higher-order relativistic description of galaxy clustering, an essential tool for computing the bispectrum, and 2) investigate the unique relativistic signatures (linear-order and higher-order) in galaxy clustering from the early Universe and dark energy to develop novel probes of isolating those signatures and to quantify their detectabilities in future galaxy surveys. Biases in cosmological parameter estimation, if the standard Newtonian description is used, will be quantified. A comprehensive understanding of inflationary cosmology will have far-reaching consequences, shedding light on new physics beyond the standard model.","1991721","2016-03-01","2021-02-28"
"GroIsRan","Growth, Isoperimetry and Random walks on Groups","ANNA ERSHLER","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The goal of the project is to develop new techniques for estimation and evaluation of well-known asymptotic invariants of groups, including growth of groups, isoperimetric profiles,  entropy and probability to return to the origin of random walks as well as of some more recent invariants related to the geometric criteria for construction of quotients of groups, which appeared in the joint work of PI with A.Karlsson (2010), and in a recent work of Ozawa (2015) giving a short functional analytic proof of the Polynomial Growth Theorem. We plan to work on the Gap conjecture of Grigorchuk, which states that any group of growth asymptotically strictly less than exp(n1/2) has polynomial growth, the question about the forms of Foelner sets in groups of intermediate and exponential growth and Kaimanovich and Vershik conjecture about characterisation of groups of exponential growth in terms of non-triviality of the Poisson boundary of some symmetric random walks. We plan to develop methods sharpening previous results of PI about isoperimetric inequalities for wreath products and relation between growth of groups and isoperimetry, and apply them for growth estimates and the description of the boundary.
 A further goal of the project is to introduce new constructions of non-elementary amenable groups which can show that necessary conditions in growth conjecture and isoperimetric inequalities cannot be weakened.","1789438","2017-09-01","2022-08-31"
"GROWMOF","Modelling of MOF self-assembly, crystal growth and thin film formation","Tina Düren","UNIVERSITY OF BATH","Metal-organic frameworks (MOFs) constitute one of the most exciting developments in recent nanoporous material science. Synthesised in a self-assembly process from metal corners and organic linkers, a near infinite number of materials can be created by combining different building blocks allowing to fine tune host guest interactions. MOFs are therefore considered promising materials for many applications such as gas separation, drug delivery or sensors for which MOFs in form of nanoparticles, composite materials or thin films are required. For MOFs to realise their potential and to become more than just promising materials, a degree of predictability in the synthesis and the properties of the resulting material is paramount and the full multiscale pathway from molecular assembly to crystal growth and thin film formation needs to be better understood.

Molecular simulation has greatly contributed to developing adsorption applications of MOFs and now works hand-in-hand with experimental methods to characterise MOFs, predict their performance and study molecular level phenomena. In contrast, hardly any simulation studies exist about the formation of MOFs, their crystal growth or the formation of thin films. Yet such studies are essential for understanding the fundamentals which will ultimately lead to a better control of the material properties. Building on my expertise in molecular modelling including the development of methods to model the synthesis of porous solids, we will develop new methods to study:
 
1. the self-assembly process of MOFs under synthesis conditions 
2. the formation of nanoparticles 
3. the integration of MOF nanoparticles into composite materials and the self-assembly into extended structures 
4. the layer-by-layer growth of thin films 

At the end of the project we will have transformed our understanding of how MOFs form at a variety of length scales and opened up new research directions for the targeted synthesis of MOFs fit for applications.","1738715","2015-08-01","2020-07-31"
"GWT","Gromov-Witten Theory: Mirror Symmetry, Birational Geometry, and the Classification of Fano Manifolds","Thomas Henry Coates","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","The classification of Fano manifolds is a long-standing and important open problem.  Fano manifolds are basic building blocks in geometry: they are `atomic pieces' of mathematical shapes.  We will take a radically new approach to Fano classification, combining Mirror Symmetry (a circle of ideas which originated in string theory) with new methods in geometry and massively-parallel computational algebra.  

Our main geometric tool will be Gromov-Witten invariants.   The Gromov-Witten invariants of a space X record the number of curves in X of a given genus and degree which meet a given collection of cycles in X; they have important applications in algebraic geometry, symplectic topology, and theoretical physics.  We will develop powerful new methods for computing Gromov-Witten invariants, and will apply these methods to Fano classification and to questions in birational geometry.","1999995","2016-10-01","2021-09-30"
"Habitat-OASIS","Habitability of Oceans and Aqueous Systems on Icy Satellites","Frank Heinz POSTBERG","FREIE UNIVERSITAET BERLIN","Icy moons in the outer solar system are prime candidates for harbouring alien life within their sub-surface oceans. Among them Enceladus and Europa are considered to have the largest astrobiological potential. Habitat-OASIS aims to explore the habitability of the ocean worlds of Enceladus, Europa, and other icy satellites using in situ mass spectrometry from on-going and future space missions. At Enceladus (and probably Europa) the ice grains expelled by active plumes carry matter previously dissolved and suspended in the subsurface oceans, allowing constraining their geochemistry. The mass spectrometers aboard the Cassini-Huygens spacecraft currently orbiting Saturn are analysing this material and already delivered spectacular science results. Project 1 of this proposal is the refined data analysis of the Enceladus plume material using novel techniques and is the first ever opportunity to explore in detail a potential ocean habitat outside Earth. Newly developed laser-assisted dispersion experiments will be used to acquire mass spectra on a wide variety of analogue materials, enabling the identification and quantification of inorganic, organic and possibly biogenic compounds embedded in the ice grains. Geochemical aqueous alteration experiments and numerical modelling will support further constraining the habitability of Enceladus and extrapolating the results to other ocean moons. Project 2 will leverage the laboratory capabilities from Project 1 to create a comprehensive library of mass spectra in preparation for the upcoming missions visiting Jupiter’s icy moons: ESA’s JUICE Mission and NASA’s Europa Mission. Even if no plume is present both spacecraft will encounter surface material residing in ejecta clouds around the moons that can be connected to subsurface processes. Having analogue measurements available early in the missions will be critical for exploiting their full potential and will maintain the leading edge of ocean world exploration in Europe.","1995250","2017-02-01","2022-01-31"
"HAPDEGMT","Harmonic Analysis, Partial Differential Equations and Geometric Measure Theory","Jose Maria Martell Berrocal","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","The origin of Harmonic Analysis goes back to the study of the heat diffusion, modeled by a differential equation, and the claim made by Fourier that every periodic function can be represented as a series of sines and cosines. In this statement we can find the motivation to many of the advances that have been made in this field. Partial Differential Equations model many phenomena from the natural, economic and social sciences. Existence, uniqueness, convergence to the boundary data, regularity of solutions, a priori estimates, etc.,  can be studied for a given PDE.  Often, Harmonic Analysis plays an important role in such problems and, when the scenarios are not very friendly, Harmonic Analysis turns out to be fundamental. Not very friendly scenarios are those where one lacks of smoothness either in the coefficients of the PDE and/or in the domains where the PDE is solved. Some of these problems lead to obtain the boundedness of certain singular integral operators and this drives one to the classical and modern Calderón-Zygmund theory, the paradigm of Harmonic Analysis. When studying the behavior of the solutions of the given PDE near the boundary, one needs to understand the geometrical features of the domains and then Geometric Measure Theory jumps into the picture.

This ambitious project lies between the interface of three areas: Harmonic Analysis, PDE and Geometric Measure theory. It seeks  deep results motivated by elliptic  PDE using techniques from Harmonic Analysis and Geometric Measure Theory.This project is built upon results obtained by the applicant in these three areas. Some of them are very recent and have gone significantly beyond the state of the art. The methods to be used have been shown to be very robust and therefore they might be useful towards its applicability in other regimes. Crucial to this project is the use of Harmonic Analysis where the applicant has already obtained important contributions.","1429790","2014-01-01","2018-12-31"
"HAZE","Reducing the Burden of Smouldering Megafires: an Earth-Scale Challenge","Guillermo Jose Rein","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","Smouldering megafires are the largest and longest-burning fires on Earth. They destroy essential peatland ecosystems, and are responsible for 15% of annual global greenhouse gas emissions. This is the same amount attributed to the whole of the European Union, and yet it is not accounted for in global carbon budgets. Peat fires also induce surges of respiratory emergencies in the population and disrupt shipping and aviation routes for long periods, weeks even months. The ambition of HAZE is to advance the science and create the technology that will reduce the burden of smouldering fires. Despite their importance, we do not understand how smouldering fires ignite, spread or extinguish, which impedes the development of any successful mitigation strategy. Megafires are routinely fought across the globe with techniques that were developed for flaming fires, and are thus ineffective for smouldering. Moreover, the burning of deep peat affects older soil carbon that has not been part of the active carbon cycle for centuries to millennia, and thus creates a positive feedback to the climate system. HAZE wants to turn the challenges faced by smouldering research into opportunities and has the following three novel aims: 
1) To conduct controlled laboratory experiments and discover how peat fires ignite, spread and extinguish.
2) To develop multidimensional computational models for the field scale (~1 km) and simulate the real phenomena.
3) To create pathways for novel mitigation technologies in accurate prevention, quick detection systems, and simulation-driven suppression strategies.
With my proposal, Europe has the chance to lead the way and pioneer technologies against this Earth-scale and important but unconventional source of emissions. I am confident that with the support of ERC, I can deliver the science and excellence needed to tackle this global challenge, and in doing so, I will advance the knowledge frontier, foster innovation and develop new young talent for Europe","1958900","2016-05-01","2021-04-30"
"HEART","""The Highly Efficient And Reliable smart Transformer (HEART), a new Heart for the Electric Distribution System""","Marco Liserre","CHRISTIAN-ALBRECHTS-UNIVERSITAET  ZU KIEL","""In the last 10 years, power electronics has moved significantly towards the electric grid, making it more flexible and decentralized. Still important challenges remain. One of the most thrilling is re-inventing the distribution transformer after more than 125 years since its first use in the electrification of a city. In fact, actual distribution transformers can no longer fulfill the requirements of a modern electric grid highly dominated by distributed sources and new sizable loads, like heat pumps and electric vehicles.
This project proposes the invention of a novel “Smart Transformer” (ST), based on a modular architecture of units made by power electronics converters, that will be able to manage the energy and the information flows among sources and loads in the distribution area with the goal of decoupling it from the rest of the bulk power system. Actual proposals of Smart Transformers cannot compete in terms of cost, efficiency and reliability with traditional transformers.
This project has decided to take this challenge with a paradigm shift in how to approach it and a new set of methodologies. The breakthrough results of this research will be obtained taking the following high-risk high-gain bet: significantly influence the efficiency and the reliability of the Smart Transformer by routing the energy flows among its power converter units. A new understanding of how the energy flows are managed by the modular connection of power converter units will guide the design of new architectures for the ST allowing different routes for the energy. Graph theory will be used to find optimal paths for the energy flows with the goal of maximizing efficiency and reliability. The energy flows will be managed by relying on information coming from the electric distribution system sensors (requirements) and from the power module sensors (constraints).
The holy grail of this research is to provide a new durable heart to the electric distribution system.""","1996720","2014-05-01","2019-04-30"
"HEINSOL","Hierarchically Engineered Inorganic Nanomaterials from the atomic to supra-nanocrystalline level as a novel platform for SOLution Processed SOLar cells","Gerasimos Konstantatos","FUNDACIO INSTITUT DE CIENCIES FOTONIQUES","Solution processed inorganic nanocrystal (NC) materials have received enormous attention as an emerging technology to address the TW challenge in solar cells. These nanomaterials offer a unique opportunity for low-cost high efficiency all-inorganic solar cells. Despite the great efforts though, only a limited number of colloidal NC compounds has been successfully employed, which either rely on costly and scarce elements or toxic materials. HEINSOL´s mission is to develop the first highly efficient, robust solution processed solar cell platform based on environmentally friendly, Earth abundant materials. To achieve this, HEINSOL undertakes a hierarchical approach to tailor the opto-electronic properties of inorganic NCs, starting from the control of composition and their properties at the atomic level and following up with further tailoring their optoelectronic properties via interactions at the supra-nanocrystalline level. HEINSOL, at the atomic level, will develop novel doping schemes for colloidal NCs to tailor their electronic character as well as passivation schemes to reduce the density of unfavourable trap states. At the supra-nanocrystalline level, HEINSOL will explore novel nano-heterojunctions that cater for efficient charge separation and suppressed recombination, elements of paramount importance in high performance solar cells. The microscopic properties of the NCs will be correlated with the macroscopic properties of the NC composites in operating devices, a methodology that will provide new insights on the underlying mechanisms at the nanoscale that govern the properties of those devices. The final goal is to introduce a new architectural platform for solution processed solar cells that will truly expand the material availability for the Photovoltaic Industry.","2486865","2017-02-01","2022-01-31"
"HELENA","Heavy-Element Nanowires","Erik Petrus Antonius Maria Bakkers","TECHNISCHE UNIVERSITEIT DELFT","""Nanowires are a powerful and versatile platform for a broad range of applications. Among all semiconductors, the heavy-elements materials exhibit the highest electron mobilities, strongest spin-orbit coupling and best thermoelectric properties. Nonetheless, heavy-element nanowires have been unexplored. With this proposal we unite the unique advantages of design freedom of nanowires with the special properties of heavy-element semiconductors. We specifically reveal the potential of heavy-element nanowires in the areas of thermoelectrics, and topological insulators. Using our strong track record in this area, we will pioneer the synthesis of this new class of materials and study their intrinsic materials properties. Starting point are nanowires of InSb and PbTe grown using the vapor-liquid-solid mechanism. Our aims are 1) to obtain highest-possible electron mobilities for these bottom-up fabricated materials by investigating new materials combinations of different semiconductor classes to effectively passivate the nanowire surface and we will eliminate impurities; 2) to investigate and optimize thermoelectric properties by developing advanced superlattice and core/shell nanowire structures where electronic and phononic transport is decoupled; and 3) to fabricate high-quality planar nanowire networks, which enable four-point electronic transport measurements and allow precisely determining carrier concentration and mobility. Besides the fundamentally interesting materials science, the heavy-element nanowires will have major impact on the fields of renewable energy, new (quasi) particles and quantum information processing. Recently, the first signatures of Majorana fermions have been observed in our InSb nanowires. With the proposed nanowire networks the special properties of this recently discovered particle can be tested for the first time.""","2698447","2014-09-01","2019-08-31"
"HeteroIce","Towards a molecular-level understanding of heterogeneous ice nucleation","Angelos Michaelides","UNIVERSITY COLLEGE LONDON","Ice formation is one of the most common phase transitions on Earth. It is relevant to an enormous variety of phenomena such as weathering, cloud formation, airline safety, agriculture, and energy. However, despite having been studied since antiquity, our molecular level understanding of ice formation is largely incomplete. In particular, almost all ice formation in nature is aided by impurities or the surfaces of foreign materials, yet how surfaces act to facilitate ice formation (heterogeneous ice nucleation) is unclear. Given the ubiquity of ice nucleation, this is arguably one of the biggest unsolved problems in the physical sciences.

Experiment provides insight into crystal nucleation and growth, but most nucleation events happen too quickly and involve too few particles to be rationalised purely by experiment. As a result, computer simulations play an important role and I believe we are now on the verge of using simulation to bring about major breakthroughs in understanding ice formation. Specifically, in this project we aim to perform the first full-on attack on heterogeneous ice nucleation so as to elucidate how the physiochemical properties of materials control their ability to nucleate ice. We will focus on nucleation on solid inorganic substrates and our approach will be to couple systematic studies on model systems with in-depth explorations of more realistic (and experimentally realisable) surfaces. We will improve existing computer simulation methods and develop new ones for accurate large- scale simulations of phase transitions in complex heterogeneous environments. In so doing we will help to make simulations of ice nucleation more routine, enabling us to establish what makes a good ice nucleating agent. The results from this multi-disciplinary project will not only shed light on an important everyday process but may also help to improve climate models and develop improved cloud seeding materials, or inhibitor coatings for industrial purposes.","1915083","2014-04-01","2019-03-31"
"HICCUP","High Impact Cross-section Calculations for Unprecedented Precision","Giulia Zanderighi","EUROPEAN ORGANIZATION FOR NUCLEAR RESEARCH","""The first runs of the Large Hadron Collider (LHC) experiment just finished. The LHC was successful in discovering a particle compatible with the Higgs boson of the Standard Model (SM). However expectations to discover New Physics have not been met so far.

In order to establish whether the new resonance is the SM Higgs boson, or not, precise measurements of its properties are mandatory. These require accurate predictions for cross-sections involving the Higgs boson, as well as for SM backgrounds, that need to be subtracted accurately. Furthermore, since so far New Physics has been elusive, it will be even more important to extend the range of these searches as much as possible. This requires a solid control of SM backgrounds.

This project aims at pushing the frontier of precision QCD calculations to reach an unprecedented precision for collider
processes. The project is divided into two main parts.

In the first part the PI will formulate a general procedure to merge different calculations at next-to-leading order (NLO) level. This will lead to the construction of an event generator for two-to-one and two-to-two scattering processes at next-to-next-to-leading order (NNLO), including parton shower corrections, essentially upgrading the POWHEG NLO generator to the NNLO level. Depending on the process considered, a significant reduction of the theoretical errors, by a factor 2-4, will be achieved.

The second part focuses on extending the accuracy of resummed predictions for important QCD observables from next-to-leading logarithmic to next-to-next-to-leading logarithmic level, again achieving a substantial reduction of the theoretical error. The observables considered include, besides event-shapes and jet-rates, also jet-veto predictions in Higgs + 1 or 2 jet events.

Besides the groundbreaking impact on present LHC physics measurements, these results will also be essential to match the high accuracy of measurements at a future linear collider.""","1514798","2014-04-01","2019-03-31"
"HiCoShiVa","Higher coherent coholomogy of Shimura varieties","Vincent Pilloni","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","One can attach certain complex analytic functions to algebraic varieties defined over the rational numbers, called Zeta functions. They are a vast generalization of Riemann’s zeta function. The Hasse-Weil conjecture predicts that these Zeta functions satisfy a functional equation and admit a meromorphic continuation to the whole complex plane. This follows from the conjectural Langlands program, which aims in particular at proving that Zeta functions of algebraic varieties are products of automorphic L-functions.
Automorphic forms belong to the representation theory of reductive groups but certain automorphic forms actually appear in the cohomology of locally symmetric spaces, and in particular the cohomology of automorphic vector bundles over Shimura varieties. This is a bridge towards arithmetic geometry.
There has been tremendous activity in this subject and the Hasse-Weil conjecture is known for proper smooth algebraic varieties over totally real number fields with regular Hodge numbers. This covers in particular the case of genus one curves. Nevertheless, lots of basic examples fail to have this regularity property : higher genus curves, Artin motives...
The project HiCoShiVa is focused on this irregular situation. On the Shimura Variety side we will have to deal with higher cohomology groups and torsion. The main innovation of the project is to construct p-adic variations of the coherent cohomology. We are able to consider higher coherent cohomology classes, while previous works in this area have been concerned with degree 0 cohomology.
The applications will be the construction of automorphic Galois representations, the modularity of irregular motives and new cases of the Hasse-Weil conjecture, and the construction of p-adic L-functions.","1288750","2019-02-01","2024-01-31"
"HIGCC","Search for Higgs bosons decaying to charm quarks","Alexander SCHMIDT","RHEINISCH-WESTFAELISCHE TECHNISCHE HOCHSCHULE AACHEN","In the standard model of particle physics (SM), the Higgs boson explains the existence of mass of the elementary particles. However, the model suffers from severe weaknesses: radiative corrections drive the theoretical mass of the Higgs boson to extremely high, unnatural values, while the observed mass is rather low (the famous hierarchy problem). Unknown mechanisms of physics beyond the standard model (BSM) must exist to avoid this unnatural situation. Such BSM mechanisms modify the predicted properties and decay patterns of the Higgs boson. The experimental collaborations at the LHC are measuring these decay patterns as precisely as possible.

The decay of the Higgs boson into bottom quarks is dominant with a predicted decay fraction of 57%. Neither this nor the subdominant decay into charm quarks of 2.9% have ever been observed. The small decay fraction into charm quarks makes it susceptible to BSM modifications, if they exist. A measurement of this charm decay fraction would either unravel new physics that has been sought for more than 60 years, or constrain BSM scenarios to enhance the understanding of the fundamental theory of matter.

However, the decay of the Higgs boson into charm quarks has been considered to be experimentally inaccessible at the LHC, because of the difficulties to distinguish charm quarks from other quarks. In this proposal I will show how to overcome these experimental obstacles with new methods for the detection of charm quarks in the CMS detector. The new methods will be based on decay vertex reconstruction algorithms that make use of modern pattern recognition concepts. In combination with new techniques for data analysis and interpretation, this will facilitate the first observation of the Higgs to charm decay, and the measurement of its branching fraction, if it is anomalously enhanced through BSM contributions. With this strategy the first indication for physics beyond the standard model may be found.","1973875","2017-09-01","2022-08-31"
"HIGEOM","Highly accurate Isogeometric Method","Giancarlo Sangalli","UNIVERSITA DEGLI STUDI DI PAVIA","""Partial Differential Equations (PDEs) are widely used  in science and engineering simulations, often in tight connection with  Computer Aided Design (CAD). The Finite Element Method (FEM) is one of  the most popular technique for the discretization of PDEs. The IsoGeometric Method (IGM), proposed in 2005 by T.J.R. Hughes et al.,  aims at improving the interoperability between CAD and FEMs. This is achieved by adopting the CAD mathematical primitives, i.e. Splines and Non-Uniform Rational B-Splines (NURBS), both for geometry  and unknown fields representation. The IGM has gained an incredible momentum especially in the engineering community. The use of high-degree, highly smooth NURBS is extremely successful and the IGM outperforms the FEM in most academic benchmarks.

However, we are far from having a satisfactory mathematical understanding of the IGM and, even more importantly, from exploiting its full potential. Until now, the IGM theory and practice have been deeply influenced by finite element analysis. For example, the IGM is implemented resorting to a FEM code design,  which is  very inefficient for high-degree and high-smoothness NURBS. This has made possible a fast spreading of the IGM, but also limited it to quadratic or cubic NURBS  in complex simulations.

The use of higher degree IGM for real-world applications asks for new tools allowing for the efficient construction and solution of the linear system, time integration, flexible local mesh refinement,  and so on. These questions need to be approached beyond the FEM framework. This is possible  only on solid mathematical grounds,  on a new theory of splines and NURBS able to comply with the needs of the IGM.

This project will provide the crucial knowledge and will re-design  the IGM to make it a superior, highly accurate and stable methodology, having a significant impact in the field of numerical simulation of PDEs, particularly when accuracy is essential both in geometry and fields representation.""","928188","2014-06-01","2019-05-31"
"HIGGSBNDL","Higgs bundles: Supersymmetric Gauge Theories and Geometry","Sakura Schafer-Nameki","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","String theory provides a unified description of particle physics and gravity, within a consistent theory of quantum gravity. The goal of this research is to develop both the phenomenological implications as well as conceptual foundations of string theory and its non-perturbative completions, M- and F-theory. Both, seemingly independent, questions are deeply connected to a mathematical structure, the Higgs bundle, which characterizes supersymmetric vacua of dimensionally reduced gauge theories, and insights into the moduli space of Higgs bundles will result in a fruitful cross-connection between these subjects.
For string theory to engage in a meaningful dialog with particle physics, it is paramount to gain a universal understanding of the low energy effective theories that can arise from it. Building on the success of studying F-theory vacua in terms of Higgs bundles, we propose to develop the Higgs bundle approach for M-theory on G2-manifolds, leading to a universal characterization of the low energy physics. Methods developed for Higgs bundles of d = 3 N = 2 theories obtained from M5-branes on three-manifolds will be used in this process. Associated to each Higgs bundle is a local G2 manifold and we propose a way (using new results in geometry) to construct compact G2 spaces associated to these, which manifestly ensure the phenomenological soundness of the compactifications.
Higgs bundles have recently also played a key role in studying the compactifications of the M5-brane in M-theory. We propose and develop a new duality between a d = 4 theory on a four-manifold X4 and a d = 2, N = (2,0) supersymmetric gauge theory on a two-sphere S2, obtained by considering the M5-brane theory on X4xS2. The supersymmetric vacua have a characterization in terms of Higgs bundles, which can be studied with tools developed for F- theory Higgs bundles on four-manifolds. Furthermore we propose a concrete approach to derive this duality from first principles.","1794562","2016-09-01","2021-08-31"
"HIGH-GEAR","High-valent protein-coordinated catalytic metal sites: Geometric and Electronic ARchitecture","Martin Ivar HÖGBOM","STOCKHOLMS UNIVERSITET","It is estimated that almost half of all enzymes utilize metal cofactors for their function, for example the respiratory complexes and the oxygen-evolving photosystem II, the most fundamental requirements for aerobic life as we know it. If we could mimic nature’s use of metals for harvesting sunlight, energy conversion and chemical synthesis it would eliminate the need for fossil fuels and greatly increase the possibilities of chemical industry while reducing the environmental impact. Achieving this type of chemistry is an outstanding testament to evolution and understanding it is a glaring challenge to mankind.

These types of reactions are based on very challenging redox chemistry (involving one or several electrons). The key catalytic species are generally high-valent metal clusters with a varying ligand environment, provided by the protein and other bound molecules, that directly controls the reactivity of the inorganic core. To be able to understand and mimic this chemistry it is of central importance to know the geometric and electronic structures of the metal core as well as the entire ligand environment for these usually short-lived and very reactive intermediates. It has, for a number of reasons, proven extremely challenging to obtain these for protein-coordinated catalysts.

The central goal of this project is to determine true and accurate geometric and electronic structures of high-valent di-nuclear Fe/Fe and Mn/Fe metal sites coordinated in protein matrices known to direct these for varied and important chemistry. By combining new X-ray diffraction based techniques with advanced spectroscopy we aim to define how the protein controls the entatic state as well as reactivity and mechanism for some of the most potent catalysts in nature. The results will serve as a basis for design of oxygen-activating catalysts with novel properties.","1968375","2017-06-01","2022-05-31"
"highECS","Reining in the upper bound on Earth’s Climate Sensitivities","Thorsten MAURITSEN","STOCKHOLMS UNIVERSITET","One of the greatest recent advances in climate science is that it is now beyond reasonable doubt that human activity is warming the Earth. The next natural question is by how much the Earth will warm for a given emission – a quantity that will be essential to regulating global warming. Yet, the likely range of 1.5-4.5 K for equilibrium climate sensitivity (ECS) for a doubling of the atmospheric CO2 concentration has not been reduced for decades. In particular the risk of ECS being high is concerning, but also represents a scientifically intriguing challenge.

In this project I will conduct unconventional and innovative research designed to limit the upper bound of ECS: I will confront leading hypotheses of extreme cloud feedbacks – the primary potential source of a high ECS – with observations from the full instrumental- and satellite records, and proxies from warm- and cold past climates. I will investigate how ocean- and atmospheric circulations impact cloud feedbacks, and seek the limits for how much past greenhouse warming could have been masked by aerosol cooling.

The highECS project builds on my developments of climate modeling, diagnostics and statistical methods, the strengths of the host institution and developments in national and international projects. The effort is timely in that the World Climate Research Programme (WCRP) has identified uncertainty in ECS as one of the grand challenges of climate science, while the capacity to observe ongoing climate change, key cloud processes, extracting new proxy evidence of past change and computing power is greater than ever before. 

If successful in my objective of reining in the upper bound on climate sensitivity this will be a major breakthrough upon a nearly 40-year scientific deadlock and reduce the risk of catastrophic climate change – if not, it will indicate that extreme policy measures may be needed to curb future global warming. Either way, the economic value of knowing is tremendous.","1998654","2018-09-01","2023-08-31"
"HighPotOx","Exploring the Limits of High Potential OxidizersPrediction, Validation and Preparation of Unusual Molecules at the Edge of Stability","Sebastian HASENSTAB-RIEDEL","FREIE UNIVERSITAET BERLIN","The very well-known concept of formal oxidation states, used e. g. for redox reactions is one of the most fundamental ones in general chemistry. However, in the area of very strong oxidizers even the familiar oxido(-II) ligand becomes redox-innocent and assigning oxidation states becomes ambiguous. Very strong (super-) oxidizers are compounds whose oxidizing strength exceeds that of elemental F2. Anyhow, not only molecular oxidizer but also their interaction with the environment in different media needs to be considered, as these dramatically affect their intrinsic oxidizing strength. Here we propose novel conjugate oxidizer/Lewis or Brønsted acid systems with extremely high ox. power. These new ox. media make use of the alliance of high ox. strength and Lewis /Brønsted super acidity. The investigation and development of oxidizers is of essential interest in all areas of chemistry and beyond. Unfortunately a detailed understanding of this fundamental chemistry is still lacking. Here we describe based on three work strands PV, MI, and BP, how we aim at a more fundamental understanding of such systems. The undertaken research, which includes qc investigations, molecular characterizations in matrices and synthetic fluorine chemistry as well as oxido complexes is summarized in five work packages describing different prototype areas (organigram). Based on the gained knowledge, the project will rank and specify such oxidizers and the mechanism leading to ox. media. By using the threefold work strand approach, our project will guide us in a systematic discovery of the systems with high application potential in terms of selectivity and disposability, and oxidizing systems with high to ultrahigh oxidation potentials, and into the chemical terra incognita of fragile molecules at the edge of stability. We envision to highlight that the outcome of the project will be extremely useful for scientists from almost all fields of chemistry and related disciplines.","1988280","2020-01-01","2024-12-31"
"HINBOTS","Highly Integrated Nanoscale Robots for Targeted Delivery to the Central Nervous System","Salvador Pané Vidal","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","Over the past two decades researchers have been working to create synthetic small-scale machines ranging from molecular entities or miniaturized structures, to more complex assemblies of micro- and nanomaterials. These machines are able to navigate in complex environments by harvesting fuel from the surrounding media or from external power sources. One of the most sought-after applications for these miniaturized machines is to perform minimally invasive interventions, in which these devices will ultimately reduce risk, cost, and discomfort compared to conventional interventions. This has driven researchers to produce a myriad of small-scale robots loaded with therapeutic cargo. While recent research has demonstrated the potential of these devices in animal models, a number of challenges remain in moving small-scale robots into the operating theatre. Here, we propose highly integrated nanorobots capable of realizing several functions on-demand by capitalizing on recent developments in small-scale robotics, multiferroics, supramolecular chemistry, and gated materials. These nanorobots will integrate a porous inorganic active chassis made of a piezoelectric or a magnetoelectric multiferroic that will host therapeutic agents, with redox or electroresponsive supramolecular gates that will control the release of payloads. We will demonstrate for the first time that redox- and electroresponsive supramolecular machinery grafted onto the surface of piezoelectric or multiferroic platforms can be remotely controlled by means of a piezoelectrochemical potential triggered by acoustic and magnetic fields. The ultimate goal of this research consists of creating smart multifunctional nanorobots, which will act on affected sites of the central nervous system by delivering therapeutic agents and electrostimulating the rewiring of neural circuitry.","1998720","2018-09-01","2023-08-31"
"HiPhore","High-temperature Thermophoresis using advanced optical microscopies","Guillaume Frédéric Marcel BAFFOU","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Thermophoresis denotes the motion of dissolved species in fluids created by temperature gradients. In water, the origin of thermophoresis is multiple, complex and still a matter of active research activities for solutes such as proteins, DNA or colloids.

Thermophoresis at small scales (sub-100 µm) aroused a strong interest this last decade because it makes the process faster and because of the development of important applications in life sciences, e.g. in bioanalytics. However, reducing the spatial scale makes quantitative and non-invasive measurements of temperature and molecular concentration more challenging.

In the HiPhore project, using gold nanoparticles under illumination as nanosources of heat, I wish to achieve major breakthroughs in the field of microscale thermophoresis in liquids (MTL): (i) We will develop new microscopy tools and pioneer their use in the context of MTL: we will implement the possibility to shape arbitrarily complex microscale temperature profiles and to quantitatively image in parallel the resulting fields of temperature and molecular concentration using label-free advanced optical tools. (ii) Thanks to these tools, we will study the enigmatic origin of protein thermophoresis with a new glance. We will also explore a new regime, that I coin super-thermophoresis, consisting in thermophoresis in superheated liquid water up to 200°C. We have shown that such a metastable state can be achieved at ambient pressure using gold nanoparticles under illumination at their plasmonic resonance. (iii) Based on this gain of knowledge and know-how, we will develop two new applications of MTL. The first one consists in studying the thermal stability of proteins by thermophoresis with a label-free approach. The second one consists in using a superthermophoretic trap to enable for the first time the culture and the real-time observation of hyperthermophilic microorganisms (living up to 113°C) in vivo at ambient pressure under optical microscopy means.","1922973","2018-03-01","2023-02-28"
"HIPS","High-Performance Secure Computation with Applications to Privacy and Cloud Security","Yehuda Lindell","BAR ILAN UNIVERSITY","""Secure two-party and multiparty computation has long stood at the center of the foundations of theoretical cryptography. However, in the last five years there has been blistering progress on the question of efficient secure computation. We are close to the stage that secure computation can be applied to real-world privacy and security problems. There is thus considerable interest in secure computation solutions from governments, military and security organisations, and industry. However, in order to answer the needs of secure computation in practice, there is still a need to make secure computation protocols much faster.

Until now, research in efficient cryptographic protocols has typically been in two different directions. The first direction, and the major one, is to construct more efficient protocols and prove them secure, where efficiency is measured by the amount of communication sent, the number of heavy cryptographic operations carried out (e.g., exponentiations), and so on. The second direction is to take the state-of-the-art protocols and implement them while optimising the implementation based on systems concerns. This latter direction has proven to improve the efficiency of existing protocols significantly, but is limited since it remains within the constraints of existing cryptographic approaches.

We propose a synergetic approach towards achieving high-performance secure computation. We will design new protocols while combining research from cryptography, algorithms and systems. In this way, issues like load balancing, memory management, cache-awareness, bandwidth bottlenecks, utilisation of parallel computing resources, and more, will be built into the cryptographic protocol and not considered merely as an afterthought. If successful, HIPS will enable the application of the beautiful theory of secure computation to the problems of privacy in the digital era, cloud security and more.""","1999175","2014-10-01","2019-09-30"
"HOLI","Deep Learning for Holistic Inference","Amir Globerson","TEL AVIV UNIVERSITY","Machine learning has rapidly evolved in the last decade, significantly improving accuracy on tasks such as image classification. Much of this success can be attributed to the re-emergence of neural nets. However, learning algorithms are still far from achieving the capabilities of human cognition. In particular, humans can rapidly organize an input stream (e.g., textual or visual) into a set of entities, and understand the complex relations between those. In this project I aim to create a general methodology for semantic interpretation of input streams. Such problems fall under the structured-prediction framework, to which I have made numerous contributions. The proposal identifies and addresses three key components required for a comprehensive and empirically effective approach to the problem.
 First, we consider the holistic nature of semantic interpretations, where a top-down process chooses a coherent interpretation among the vast number of options. We argue that deep-learning architectures are ideally suited for modeling such coherence scores, and propose to develop the corresponding theory and algorithms. Second, we address the complexity of the semantic representation, where a stream is mapped into a variable number of entities, each having multiple attributes and relations to other entities. We characterize the properties a model should satisfy in order to produce such interpretations, and propose novel models that achieve this. Third, we develop a theory for understanding when such models can be learned efficiently, and how well they can generalize. To achieve this, we address key questions of non-convex optimization, inductive bias and generalization. We expect these contributions to have a dramatic impact on AI systems, from machine reading of text to image analysis. More broadly, they will help bridge the gap between machine learning as an engineering field, and the study of human cognition.","1932500","2019-02-01","2024-01-31"
"HoloQosmos","Holographic Quantum Cosmology","Thomas Hertog","KATHOLIEKE UNIVERSITEIT LEUVEN","The current theory of cosmic inflation is largely based on classical physics. This undermines its predictivity in a world that is fundamentally quantum mechanical. With this project we will develop a novel approach towards a quantum theory of inflation. We will do this by introducing holographic techniques in cosmology. The notion of holography is the most profound conceptual breakthrough that has emerged form fundamental high-energy physics in recent years. It postulates that (quantum) gravitational systems such as the universe as a whole have a precise `holographic’ description in terms of quantum field theories defined on their boundary. Our aim is to develop a holographic framework for quantum cosmology. We will then apply this to three areas of theoretical cosmology where a quantum approach is of critical importance. First, we will put forward a holographic description of inflation that clarifies its microphysical origin and is rigorously predictive. Using this we will derive the distinct observational signatures of novel, truly holographic models of the early universe where inflation has no description in terms of classical cosmic evolution. Second, we will apply holographic cosmology to improve our understanding of eternal inflation. This is a phase deep into inflation where quantum effects dominate the evolution and affect the universe’s global structure. Finally we will work towards generalizing our holographic models of the primordial universe to include the radiation, matter and vacuum eras. The resulting unification of cosmic history in terms of a single holographic boundary theory may lead to intriguing predictions of correlations between early and late time observables, tying together the universe’s origin with its ultimate fate. Our project has the potential to revolutionize our perspective on cosmology and to further deepen the fruitful interaction between cosmology and high-energy physics.","1995900","2014-08-01","2019-07-31"
"HQMAT","New Horizons in Quantum Matter: From Critical Fluids to High Temperature Superconductivity","Erez BERG","WEIZMANN INSTITUTE OF SCIENCE LTD","Understanding the low-temperature behavior of quantum correlated materials has long been one of the central challenges in condensed matter physics. Such materials exhibit a number of interesting phenomena, such as anomalous transport behavior, complex phase diagrams, and high-temperature superconductivity. However, their understanding has been hindered by the lack of suitable theoretical tools to handle such strongly interacting quantum ``liquids.'' 
Recent years have witnessed a wave of renewed interest in this long-standing, deep problem, both from condensed matter, high energy, and quantum information physicists. The goal of this research program is to exploit the recent progress on these problems to open new ways of understanding strongly-coupled unconventional quantum fluids. We will perform large-scale, sign problem-free QMC simulations of metals close to quantum critical points, focusing on new regimes beyond the traditional paradigms. New ways to diagnose transport from QMC data will be developed. Exotic phase transitions between an ordinary and a topologically-ordered, fractionalized metal will be studied. In addition, insights will be gained from analytical studies of strongly coupled lattice models, starting from the tractable limit of a large number of degrees of freedom per unit cell. The thermodynamic and transport properties of these models will be studied. These solvable examples will be used to provide a new window into the properties of strongly coupled quantum matter. We will seek ``organizing principles'' to describe such matter, such as emergent local quantum critical behavior and a hydrodynamic description of electron flow. Connections will be made with the ideas of universal bounds on transport and on the rate of spread of quantum information, as well as with insights from other techniques. While our study will mostly focus on generic, universal features of quantum fluids, implications for specific materials will also be studied.","1515400","2019-01-01","2023-12-31"
"HyBurn","Enabling Hydrogen-enriched burner technology for gas turbines through advanced measurement and simulation","Isaac Boxx","DEUTSCHES ZENTRUM FUER LUFT - UND RAUMFAHRT EV","A major impediment to the economic viability of carbon-free renewable energy sources such as wind and solar power is an inability to effectively utilize the power they generate if it is not immediately needed. One option to address this is to use excess generator capacity during off-peak demand periods to produce hydrogen (H2), a high energy-content, carbon-free fuel that can be mixed with natural gas and distributed to end-users via existing natural gas pipeline infrastructure, where its energy content is recovered via combustion in conventional gas-turbine (GT) power plants. H2-enrichment, however, dramatically alters the combustion dynamics of natural-gas and its effect on turbulent flame dynamics, combustion stability and pollutant formation in GT combustors is not well enough understood today for this scenario to be safely implemented with existing power plants.

The objective of this study is to facilitate Europe’s transition to a reliable and cost-effective energy system based on carbon-free renewable power generation. It will accomplish this by developing advanced laser measurement techniques for use in high-pressure combustion test facilities and using them to acquire the data necessary to develop robust predictive analysis tools for hydrogen-enriched natural gas combustor technology. This data will analyzed in close collaboration with the simulation and modelling teams and used to rigorously test and validate combustion models and predictive analysis tools currently under development.","1996135","2016-06-01","2021-05-31"
"hyControl","Coherent optical control of multi-functional nano-scale hybrid units","Mirko Cinchetti","TECHNISCHE UNIVERSITAT DORTMUND","In the physics and chemistry of materials science, an intense focus of forefront research is the search for ever-smaller and ever-faster building blocks for information and communication technology (ICT) applications. The realization of next-generation devices, in ICT fields such as spintronics, spin-orbitronics and plasmonics, will depend decisively on our ability to generate new functionalities that can be actively controlled on the shortest length and time scales.

The groundbreaking idea of hyControl is to develop a conceptually new class of active ICT nano-scale materials by building functionality into the nano-scale object that naturally forms when an organic molecule is hybridized on a metallic surface: a nano-scale hybrid unit (NHyU). NHyUs will be realized by depositing selected organic molecules onto three classes of inorganic systems: transition metals; spin-textured materials such as Rashba systems and topological insulators; and magneto-plasmonic nano-structures. By tuning optical excitation to specific resonances, we will control the hybridization strength with ultrashort laser pulses, and thereby induce a coherent response in the spin, orbit, and/or electron degrees of freedom of the NHyU. Thereby we will achieve coherent control - at the molecular scale - of technologically important parameters, such as magnetization, plasmonic resonances, and spin texture. This hyControl concept will be implemented using a novel experimental method, spin- and phase-resolved orbital mapping, that is capable of resolving the transient spin-dependent electronic structure of precisely those valence band electrons which mediate the hybridization in a single NHyU.

While inspired by the latest achievements in molecular spintronics, hyControl will open the way to new technologies in various ICT applications, three of which - spintronics, spin-orbitronics, and plasmonics - have been selected to demonstrate the ability and versatility of optically controlled NHyUs.","1994791","2017-09-01","2022-08-31"
"HydraMechanics","Mechanical Aspects of Hydra Morphogenesis","Kinneret KEREN","TECHNION - ISRAEL INSTITUTE OF TECHNOLOGY","Morphogenesis is one of the most remarkable examples of biological pattern formation. Despite substantial progress in the field, we still do not understand the organizational principles responsible for the robust convergence of the morphogenesis process, across scales, to form viable organisms under variable conditions. We focus here on the less-studied mechanical aspects of this problem, and aim to uncover how mechanical forces and feedback contribute to the formation and stabilization of the body plan. Regenerating Hydra offer a powerful platform to explore this direction, thanks to their simple body plan, extraordinary regeneration capabilities, and the accessibility and flexibility of their tissues. We propose to follow the regeneration of excised tissue segments, which inherit an aligned supra-cellular cytoskeletal organization from the parent Hydra, as well as cell aggregates, which lack any prior organization. We will employ advanced microscopy techniques and develop elaborate image analysis tools to track cytoskeletal organization and collective cell migration and correlate them with global tissue morphology, from the onset of regeneration all the way to the formation of complete animals. Furthermore, to directly probe the influence of mechanics on Hydra morphogenesis, we propose to apply various mechanical perturbations, and intervene with the axis formation process using external forces and mechanical constraints. Overall, the proposed work seeks to develop an effective phenomenological description of morphogenesis during Hydra regeneration, at the level of cells and tissues, and reveal the mechanical basis of this process. More generally, our research will shed light on the role of mechanics in animal morphogenesis, and inspire new approaches for using external forces to direct tissue engineering and advance regenerative medicine.","2000000","2019-02-01","2024-01-31"
"HYDROCARB","Hydrogen isotopes in plant-derived organic compounds as new tool to identify changes in the carbon metabolism of plants and ecosystems during the anthropocene","Ansgar KAHMEN","UNIVERSITAT BASEL","HYDROCARB is motivated by the enormous potential that stable hydrogen isotope ratios (δ2H values) in plant compounds have as hydrological proxy, but in particular as new proxy for the carbon metabolism in plants. Current conceptual models suggest that δ2H values in plant organic compounds are composed of (i) hydrological and (ii) metabolic signals. The hydrological information that is contained in δ2H values of plant material is now well understood and is often applied in (paleo-) hydrological research. In contrast, the metabolic information that is contained in plant δ2H values is mostly unknown. Intriguing recent research suggests, however, that metabolic signals in the δ2H values of plant organic compounds reflect the balance of autotrophic and heterotrophic processes in plants. This suggests that exciting and previously unknown opportunities exist to exploit δ2H values in plant compounds for information on the carbohydrate metabolism of plants, which would be relevant for a broad range of biological and biogeochemical disciplines.
The goal of HYDROCARB is to perform the experimental work that is now needed to identify the key biochemical and physiological processes that determine the metabolic information that is recorded in the δ2H values of plant organic compounds such as leaf wax lipids, lignin and cellulose. With this HYDROCARB will provide the basis for semi-mechanistic models that will allow (i) disentangling hydrological from metabolic signals in plant δ2H values and (ii) identifying the precise physiological processes with respect to a plants carbohydrate metabolism that can be deducted from the δ2H values of different plant compounds. If successful, HYDROCARB will establish with this research δ2H values in plant organic compounds as a powerful new proxy that will allow ground-breaking and innovative research on plant and ecosystem carbon cycling, which has implications for plant biology, biogeochemistry and the earth system sciences.","1999941","2017-11-01","2022-10-31"
"HYDROMA","Origin and evolution of organic matter in carbonaceous chondrites: influence of hydrothermal processes","Laurent REMUSAT","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Carbonaceous chondrites (CC) are believed to be fragments of carbonaceous asteroids from the asteroidal belt. They contain up to 4wt% of organic compounds, showing a huge diversity and extremely variable H and N isotope compositions. These isotope compositions can relate to synthesis environments but the exact nature of the processes that influenced the formation of organic compounds in CC remains unresolved. Part of the issue comes from the occurrence of hydrothermal alteration on the chondrites that exhibit the largest content in organic matter. Hydrothermalism may have modified the chemical and isotopic signature of organic molecules, but the extent of these modifications is not yet constrained, leaving a lot of uncertainties on the interpretation of H and N isotope ratios. 

 The HYDROMA project aims at determining the effects of hydrothermalism on the D/H and 15N/14N ratios of organic molecules in CC. This project will rely on an innovative experimental approach to quantify isotopic exchange of hydrogen and nitrogen between organic compounds and the hydrothermal fluid. HYDROMA will provide a self-consistent determination of the extent and kinetics of the modification of the isotopic signatures recorded in organic molecules. Hence, it will improve the understanding of H and N-isotope systematics of organic matter in CC. HYDROMA will permit using isotope composition of organic compounds to constrain the hydrothermal events (duration, temperature) on carbonaceous asteroids. This multidisciplinary research will shed new light on the origin and reprocessing of organic matter in the early solar system, and its delivery to rocky planets, including the Earth, thus disclosing the origin of prebiotic molecules on our planet.","1994351","2019-09-01","2024-08-31"
"HydroSync","Hydrodynamic Synchronisation in Model and Biological Systems","Pietro Cicuta","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Cilia and flagella beating in synchronised patterns give rise to metachronal waves, beautiful examples of emergent behaviour in biology. These collective dynamical states are essential in life, transporting nutrients and clearing pathogens; they arise from the mechanical interaction of individual cilia mediated by the viscous fluid.
Severe pathologies are associated with cilia malfunction in humans. The current analysis of ciliated tissues in the clinic is focused purely on the frequency of beating: this is insufficient to discriminate between different pathologies. Much more information is present in the cilia dynamics video data that is recorded from patients; it is not being extracted because the correct theoretical framework for analysis is not in place.
We will develop our current work on actively driven colloidal systems to selectively test aspects of the biological scenarios, and start a new line of investigation in our lab, with cell culture experiments to validate these findings; we will understand the onset of collective dynamics (new physics), and how cilia waves are robust against fluctuations in cilia beat frequency, spatial arrangement and fluid rheology. New video analysis tools will be developed based on this full understanding of mechanical synchronisation, enabling the collective dynamics to be related back to the behaviour of individual cilia and to the physical properties of the fluid.
The team will be of two Post-docs, responsible for the two parts of the project: model and biological systems. A PhD student will contribute to the biological experiments, which present multiple lines of investigation, and will develop the video-analysis code to obtain the full degree of information from biological experiments.
The new analysis tool that results from this project will be deployed in the clinical setting through an established collaboration; enabling diagnosis of airway disorders represents a broad impact on physiology and clinical practice.","1261572","2014-05-01","2018-04-30"
"HyMAP","Hybrid Materials for Artificial Photosynthesis","Víctor Antonio De La Peña O'shea","Fundacion IMDEA Energia","HyMAP aims to develop a new generation of multifunctional hybrid photocatalysts and solar photoreactor which would allow the exploitation of at least the 1 % of the sunlight energy for the CO2 photoreduction using water as electron donor. This will imply a CO2 conversion in the range of 12 to 35 Ton/y•ha, depending on product distribution, which represents at least a 20-fold improvement over the state of the art. To achieve this goal, I propose an interdisciplinary research program through which several breakthroughs at different scales will be achieved:
Development of efficient multifunctional organic/inorganic semiconductors and metal-organic frameworks photocatalysts with separated reduction/oxidation active sites. The fact of having independent multiple redox sites combined in a single material would maximize charge separation and transport processes, as well as sunlight harvesting.
Characterization and modelling of the structural and opto-electronic properties of the proposed materials.
Evaluation of the materials in artificial photosynthesis devices. At this stage, a solar photoreactor that would allow good transmission, uniform light distribution and maximize the energy harvesting in the overall spectra will be developed.
HYMAP will provide me with an excellent opportunity to lead a consolidated research group. During my scientific career I have demonstrated creative thinking, autonomy and an excellent capacity to carry out state of the art research in heterogeneous catalysis, characterization, modelling and reactor engineering. I have a meritorious research track reflected by a good number of scientific publications, broad professional expertise, innovative project conception and a consolidate network of international collaboration. This, along with my leadership and management abilities, will assure the successful achievement of the mentioned goals of this project.
HyMAP is a revised version of a proposal scored with A (2nd stage) of last ERC-CoG call.","2506738","2015-07-01","2020-06-30"
"HYMNS","High-sensitivitY Measurements of key stellar Nucleo-Synthesis reactions","Cesar Domingo Pardo","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","The origin of the heavy elements in the Universe is one of the main open questions in modern science. Beyond iron the two main mechanisms of nucleosynthesis are the slow (s) and rapid (r) neutron capture processes operating in giant stars and explosive stellar environments, respectively. Modern s-nucleosynthesis studies are based on the combination of i) stellar models, ii) observed abundances and iii) neutron capture rates measured over many years using several techniques. HYMNS is aimed at a paradigm shift in the sensitivity of s-process neutron capture measurements; The most advanced and accurate methods allow one to measure the neutron capture rate as a function of the neutron energy by combining the time-of-flight technique with radiation detectors, either calorimeters or total energy detectors. These systems are sensitive only to the radiation energy, which ultimately limits the attainable detection sensitivity. State-of-the-art detection systems require drastic innovation if we are to access the stellar (n,g) rates of several key radioactive nuclei, where only small amounts of sample material are available. Such unstable nuclides are of pivotal importance for nucleosynthesis studies because they act as branching points in the s-path and are thus extremely sensitive to the stellar physical conditions. The aim of HYMNS is to develop and apply a novel detection system in the field of (n,g) measurements called total-energy detector with imaging capability (i-TED), which is capable of measuring both the energy and the trajectory of the g-rays, thus enabling a superior level of background discrimination. HYMNS is structured to enable the first measurements for key s-process branching nuclei over the stellar energy range. The first application will be to determine the neutron capture cross section of  79Se, which will provide the most stringent constraint for the thermal conditions and their time-dependence in state-of-the-art evolution models of massive stars.","1886558","2016-06-01","2021-05-31"
"HyperMu","Hyperfine splittings in muonic atoms and laser technology","Aldo Sady ANTOGNINI","PAUL SCHERRER INSTITUT","The proton radius extracted from the measurements of the 2S-2P energy splitting in muonic hydrogen
(μp) has attracted great attention because of a 7σ discrepancy with the values extracted from
electron scattering and hydrogen (H) spectroscopy. Hundreds of publications have been devoted to the
so called “proton radius puzzle” ranging from studies of physics beyond the standard model, to reanalysis
of electron scattering data, refinements of bound-state QED calculations, new theories describing
the proton structure, and proposals for new scattering and H spectroscopy experiments.
As next step, I plan two new (i.e., never before attempted) measurements: the ground-state hyperfine
splitting (1S-HFS) in both μp and μ3He+ with 1 ppm relative accuracy by means of pulsed laser
spectroscopy. From these measurements the nuclear-structure contributions (two-photon-exchange)
can be extracted with a relative accuracy of 100 ppm which in turn can be used to extract the corresponding
Zemach radii (with a relative accuracy of 0.1%) and polarizability contributions. The Zemach radii
can provide magnetic radii when form-factor data or models are assumed.
These radii are benchmarks for lattice QCD and few-nucleon theories. With the polarizability contribution
they impact our models of the proton and of the 3He nucleus. Moreover, the μp measurement
can be used to solve the discrepancy between the magnetic radii values as extracted from polarized and
unpolarized electron scattering and to further test bound-state QED predictions of the 1S-HFS in H.
These two experiments require a muon beam line, a target with an optical cavity, detector, and laser
systems. As weak M1 transitions must be probed, large laser-pulse energies are needed, thus cutting-edge
laser technologies (mainly thin-disk laser and parametric down-conversion) need to be developed.
Laser schemes of potentially high industrial impact that I have just patented will be implemented and
refined.","1999926","2017-10-01","2022-09-30"
"HyperQC","Hyper Quantum Criticality","Christian Rueegg","PAUL SCHERRER INSTITUT","Hyper Quantum Criticality – HyperQC is a major initiative with the aim of generating and controlling novel phases of correlated magnetic quantum matter, and of exploring them in high-precision experiments. A combination of new capabilities enabled by the development of instrumentation, pioneering ultra-fast studies and experiments on magnetic model materials will allow both the exploration of fundamental Hamiltonians and fully quantitative tests of quantum criticality in hyper-parameter space: temperature, magnetic field, pressure, energy, momentum and time.  
 
HyperQC - Challenge. Direct control of the dimensionality, symmetry, chemical potential and interactions in magnetic materials is achieved by a new experimental set-up combining high magnetic fields and pressures with ultra-low temperatures, which will be installed on neutron scattering instruments at the Swiss Spallation Neutron Source SINQ. Experiments on a number of magnetic model materials allow the realization and high-precision measurements of the multi-dimensional quantum critical properties of systems including magnon Bose-Einstein Condensates, spin Luttinger liquids and renormalized classical ordered phases, as well as of other many-body phenomena in quantum spin systems. 

HyperQC – Vision. Experiments on the time-dependent, non-equilibrium properties of quantum magnets and quantum critical points are new. Ultra-short laser and X-ray pulses are able to alter and measure the lattice, spin, orbital and electronic properties of solids, which has been demonstrated in recent experiments on multiferroic materials and superconductors. The effects of such pulses on a number of well-characterized model quantum magnets will be investigated with the aim of studying the time-dependent dynamics of quantum critical systems for the first time.","2328649","2016-12-01","2021-11-30"
"HYPNOTIC","Hybrid Indium Phosphide on Silicon nanophotonics for ultimate laser diodes, flip-flops and memories","Fabrice, Denis RAINERI","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The HYPNOTIC project aims at achieving a breakthrough in Silicon laser science and technology by taking forward the III-V semiconductors on Silicon hybrid technology into the nanophotonic world to make the dream of the convergence of microelectronics and photonics on a chip come true. This project intends to take up the challenge of bringing to reality electrically powered photonic crystal nanolasers as reference sources for dense integration and logical processing in a Silicon-based optical platform by accomplishing: (i) power efficiency with extremely low activation energies of few fJ, (ii) high bandwidth beyond 40Gbits/s, (iii) compactness with footprints less than 100µm² for high integration density of 103-104 of devices per mm2.
A paradigm change will be brought to Silicon photonics by laying down 3 corner stones which consist firstly in the realisation of ultimate nanolaser diode sources at telecom wavelengths using an optimised single hybrid active nanocavity. Secondly, the groundbreaking atomic physics concepts of superradiance and lasing without inversion of population resonators will be transposed to nanophotonics by coupling several active nanocavities. Besides studying them for their fundamental interest, the project will capitalise on them to drastically augment the power efficiency and the modulation bandwidth of the nanosources. Finally, the fabricated nanolaser diodes using these novel concepts will be exploited to demonstrate cutting-edge flip-flop and memory devices able to surpass current off-chip electronic random access memories in access times and bandwidth which could enable unprecedented computational power.","1981721","2017-04-01","2022-03-31"
"i-CaD","Innovative Catalyst Design for Large-Scale, Sustainable Processes","Joris Wilfried Maria Cornelius Thybaut","UNIVERSITEIT GENT","A systematic and novel, multi-scale model based catalyst design methodology will be developed. The fundamental nature of the models used is unprecedented and will represent a breakthrough compared to the more commonly applied statistical, correlative relationships. The methodology will focus on the intrinsic kinetics of (potentially) large-scale processes for the conversion of renewable feeds into fuels and chemicals. Non-ideal behaviour, caused by mass and heat transfer limitations or particular reactor hydrodynamics, will be explicitly accounted for when simulating or optimizing industrial-scale applications. The selected model reactions are situated in the area of biomass upgrading to fuels and chemicals: fast pyrolysis oil stabilization, glycerol hydrogenolysis and selective oxidation of (bio)ethanol to acetaldehyde.

For the first time, a systematic microkinetic modelling methodology will be developed for oxygenates conversion. In particular, stereochemistry in catalysis will be assessed. Two types of descriptors will be quantified: kinetic descriptors that are catalyst independent and catalyst descriptors that specifically account for the effect of the catalyst properties on the reaction kinetics. The latter will be optimized in terms of reactant conversion, product yield or selectivity. Fundamental relationships will be established between the catalyst descriptors as determined by microkinetic modelling and independently measured catalyst properties or synthesis parameters. These innovative relationships allow providing the desired, rational feedback in from optimal descriptor values towards synthesis parameters for a new catalyst generation. Their fundamental character will guarantee adequate extrapolative properties that can be exploited for the identification of a groundbreaking next catalyst generation.","1999877","2014-06-01","2019-05-31"
"I-SURF","Inorganic surfactants with multifunctional heads","Sebastian Polarz","UNIVERSITAT KONSTANZ","""Surfactants are molecules of enormous scientific and technological importance, which are widely used as detergents, emulsifiers or for the preparation of diverse nanostructures. Fascinating abilities regarding the formation of self-organized structures, like micelles or liquid crystals, originate from their amphiphilic architecture, which comprises a polar head group linked to a hydrophobic chain. While almost all known surfactants are organic, a new family of surfactants is now emerging, which combine amphiphilic properties with the advanced functionality of transition metal building blocks. The current project aims at the synthesis of unique inorganic surfactants (I-SURFs), which contain multinuclear, charged metal-oxo entities as heads, and their exploration with regard to additional redox, catalytic or magnetic functionalities. A particular challenge is the creation of smart surfactant systems that can be controlled via external stimuli. While thermotropic liquid crystals and their adjustment in electric fields (enabling LCDs) have been studied in depth, very limited research concerns the control of self-assembled amphiphilic structures by use of magnetic fields. It is obvious that exposure to a magnetic field has inherent advantages over electric fields for controlling structures in water. I-SURFs with single-molecule magnets as heads will be thus prepared and studied. Another groundbreaking task is the creation of I-SURFs with additional catalytic activities. Since catalytic heads can be positioned via self-organization, for instance on the surface of micellar aggregates, catalytic relay systems can be assembled with a second catalytic species in proximity to the first. Thus, cooperative effects in catalytic tandem reactions will ultimately be observed. These examples show that frontier research on I-SURFs is of outstanding relevance for supramolecular science and will certainly pave the way toward new technological applications with great benefits to society.""","1863546","2014-03-01","2019-02-28"
"IChaos","Intermediate Chaos","Alexander Bufetov","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","""The transition from order to chaos has been a central theme of investigation in dynamical systems in the last two decades. Structures that exhibit a mix of deterministic and chaotic properties, for example, quasi-crystals, naturally arise in problems of geometry and mathematical physics. Despite intense study, key questions about these structures remain wide open.
The proposed research is an investigation of intermediate chaos in ergodic theory of dynamical systems. Specific examples include systems of geometric origin such as interval exchange maps, translation and Hamiltonian flows on surfaces of higher genus, symbolic substitution systems important in the study of quasi-crystals as well as dynamical systems arising in asymptotic combinatorics and mathematical physics such as determinantal and Pfaffian point processes. Specific tasks include computation of the Hausdorff dimension for the spectral measure of interval exchange maps (problem posed by Ya. Sinai), limit theorems for Hamiltonian flows on surfaces of higher genus (question of A. Katok), development of entropy theory and functional limit theorems for determinantal point processes and a description of the ergodic decomposition for infinite orthogonally-invariant measures on the space of infinite real matrices (the real case of the problem, posed in 2000 by A. Borodin and G. Olshanski, of harmonic analysis on the infinite-dimensional analogue of the Grassmann manifold). The project consolidates the proposer's past work, in particular, his limit theorems for translation flows (Annals of Math. 2014), his proof of the 1985 Vershik-Kerov entropy conjecture (GAFA 2012) and his solution of the complex case of the Borodin-Olshanski problem (preprint 2013). The proposer is currently PI of project ANR-11-IDEX-0001-02 (1.11.2013--30.10.2015; budget 360000 euro) under the Programme ""Investissements d'avenir"" of the Government of the French Republic.""","1696937","2016-01-01","2020-12-31"
"ICON-BIO","Integrated Connectedness for a New Representation of Biology","Natasa PRZULJ","BARCELONA SUPERCOMPUTING CENTER - CENTRO NACIONAL DE SUPERCOMPUTACION","The aim of the project is to develop a comprehensive framework for generalizing network analytics and fusion paradigms of non-negative matrix factorization to medical data. Heterogeneous, interconnected, systems-level omics data are becoming increasingly available and important in precision medicine. We are seeking to better stratify and subtype patients into risk groups, discover new biomarkers for complex and rare diseases, personalize medical treatment based on genomics and exposures of an individual, and repurpose known drugs to different patient groups. Existing methodologies for dealing with these big data are limited and a paradigm shift is needed to achieve quantitatively and qualitatively better results.
 
The project is motivated by the recent success of non-negative matrix tri-factorization (NMTF) based methods for fusion of heterogeneous data in biomedicine. Though these methods have been known for some time, the availability of large datasets, coupled with modern computational power and efficient optimization methods, allowed for creation and efficient training of complex models that can make a qualitative breakthrough. For example, NMTF has recently achieved unprecedented performance on exceptionally hard problems of simultaneously utilizing the wealth of diverse molecular and clinical data in precision medicine. However, research thus far has been limited to special variants of this problem and used only fixed point methods to address these exciting examples of hard non-convex high-dimensional non-linear optimization problems.

The ambition of the project is to develop general data fusion methods, from mathematical models to efficient and scalable software implementation, and apply them to the domain of biomedical informatics. The project will lead to a paradigm shift in biomedical and computational understanding of data and diseases that will open up ways to solving some of the major bottlenecks in precision medicine and other domains.","2000000","2018-04-01","2023-03-31"
"ICONICAL","In control of exciton and charge dynamics in molecular crystals","Ferdinand Cornelius Grozema","TECHNISCHE UNIVERSITEIT DELFT","The aim of the work proposed here is to achieve control over charge and excited state dynamics in organic crystalline materials and in this way to come to solid state materials with explicit built-in functionality. The charge and excited state dynamics do not only depend on the properties of individual molecules but are to a large extent determined by the interactions between multiple molecules. By careful engineering of the properties of individual molecules and of the way they aggregate in the solid crystalline state it is in principle possible to design materials that exhibit a specific functionality. Examples of this are materials that are optimized to give high charge carrier mobilities and high exciton diffusion coefficients. It is also possible to design more complex functionality. An example of this is singlet exciton fission, a process by which one singlet excited state transforms into a combination of two triplet states. This spin-allowed process can in principle increase the efficiency of organic solar cells by a factor 1.5. A second example is upconversion of low energy photons into higher energy photons. This is possible by combining two low-energy triplet excited states into a single singlet excited state by triplet-triplet annihilation. Finally, it is possible gain control over charge separation on the interface of two different materials to increase the charge separation efficiency in photovoltaic cells.

In this work, we will explore ways to achieve control of charge and exciton dynamics in a combined effort including organic synthesis, computational chemistry and time-resolved spectroscopy and conductivity experiments. This research represents a major step forward in the understanding of the relation between molecular and solid state structure and the electronic properties of organic crystalline materials. This is of considerable fundamental interest but also has direct implications for the utilization of these materials in electronic devices.","2000000","2015-06-01","2020-05-31"
"ICOPT","Fundamental Problems at the Interface of Combinatorial Optimization with Integer Programming and Online Optimization","Rico Zenklusen","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","The goal of this proposal is to leverage and significantly extend techniques from the field of Combinatorial Optimization to  address some fundamental open algorithmic questions in other, related areas, namely Integer Programming and Online Optimization. More precisely, we focus on the following three thrusts, which share many combinatorial features:

- Integer programming with bounded subdeterminants.
- Expressive power of mixed-integer linear formulations.
- The matroid secretary conjecture, a key online selection problem.

Recent significant progress, in which the PI played a central role, combined with new ideas, give hope to obtain breakthrough results in these fields. Many of the questions we consider are long-standing open problems in their respective area, and any progress is thus likely to be a significant contribution to Mathematical Optimization and Theoretical Computer Science. However, equally importantly, if progress can be achieved through the suggested methodologies, then this would create intriguing new links between different fields, which was a key driver in the selection of the above research thrusts.","1443422","2019-11-01","2024-10-31"
"ICORDA","Ice CORe DAting tools revisited to infer the dynamic of glacial – interglacial transitions over the last 1.5 million years","Amaelle LANDAIS ISRAEL","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The Quaternary period (last 2600 thousands of years, hereafter ka) is the ideal period to evaluate our understanding of climate processes with general circulation models (GCM) used for prediction of future climate. During this period, the largest climate changes are glacial – interglacial transitions, hereafter terminations, the last termination being a classical benchmark for GCM. The rhythm of terminations changed from a world associated with a 40 ka periodicity to a world associated with a 100 ka glacial – interglacial periodicity between 1250 and 700 ka. The cause for this transition is a long debated question highlighting that the causes and mechanisms of terminations are still poorly understood. The timing and amplitudes of terminations indeed result from multiple influences of insolation forcing, ice sheet size, atmospheric greenhouse gases (GHG) concentration as well as shorter (millennial) scale climate variability. The big challenge of ICORDA consists in solving major puzzles on the mechanisms of terminations by deciphering these different influences using two key Antarctic ice core records: EPICA Dome C covering the last 800 ka and an ice core to be drilled in the coming years and covering the last 1500 ka. While ice cores provide unique continuous and high resolution climatic and GHG records, they are still too poorly dated on long timescales to address the aforementioned challenge. ICORDA aims at rethinking the way ice core chronology is built for decreasing drastically the associated uncertainties. This will be done by (1) developing a mechanistic approach for the interpretation of isotopic tracers used for ice core dating and (2) combining numerous low to mid latitude ice core tracers to provide a global picture of climate change during terminations. The strategy involves interdisciplinarity between climate, geochemistry, ecophysiology and innovative instrumental developments as well as field, laboratory experiments and modeling.","1994100","2019-09-01","2024-08-31"
"ICYBOB","Initial Conditions of YMCs, Birth of OB associations and long term evolution of stellar clusters","clare DOBBS","THE UNIVERSITY OF EXETER","The goal of this proposal is to establish a new era of stellar cluster evolution research by performing numerical simulations on different scales, and of different stages of a cluster’s life, from the formation of YMCs, the formation and evolution of OB associations, to the evolution of clusters and associations in galaxies. The PI is one of the pioneers of galactic simulations of GMC and star formation was one of the first numericists to perform galactic scale simulations of molecular cloud formation and evolution, and has produced some of the most realistic and sophisticated isolated simulations of galaxies in this field to date. The next challenge is to follow cluster evolution, something which has not yet been attempted numerically. And, with the GaiaAIA instrument set to transform stellar astronomy in our Galaxy, our work will provide a fundamental theoretical counterpart. Key questions we will address include i) how does gas disperse from new clusters and what happens to that gas, ii) how do YMCs form, iii) how do new clustersGiant Molecular Clouds (GMCs) evolve into OB associations, and ivii) how long can clusters survive for as they orbit a galaxy and what causes their destruction.","1980385","2019-06-01","2024-05-31"
"Ig-QPD","Ion-gated Interfaces for Quantum Phase Devices","Jianting Ye","RIJKSUNIVERSITEIT GRONINGEN","The aim of this ERC proposal is to develop a highly efficient tunable interface with ion-movement-mediated gating as a rich platform for novel electronic devices by using field effect controlling of quantum phase transitions. Working beyond conventional FETs, the new transistors will be build by combining novel layered semiconductor films grown by the CVD method: newly synthesized ionic material; and a well-defined interface optimized by surface analysis techniques; which jointly are able to boost the field effect control of carrier doping to the range required for switching quantum phases such as superconductivity in electrical transport, ferromagnetism in magnetization, and chiral or coherent light sources in optical applications.
The sub-topics are designed to cover sufficiently broad disciplines of material sciences, new device technologies based on electrochemical principles, and condensed-matter physics. Such a design will make the project high adaptable for success at different levels with clear defined objectives to: 1) develop new materials and material combinations for ion gated interfaces to establish a rich platform of quantum phases; 2) utilize these quantum phases for device functionalities enjoying the characteristic abrupt response in phase transitions and to establish control of magnetism by field effect; and 3) create light emitting devices for effectively correlating light emission with quantum phases.
The project represents an exciting new research field that is attracting the attention of many research groups around the world. The applicant is a well-established pioneer in developing this rapid growing and highly competitive field, where he achieved major milestones in design, fabrication and operation of quantum phase devices. Embedded in the strong material researches environment of the host institute and in his new group, it is the perfect timing for the applicant to fulfil the dream of creating a new paradigm of electronic devices.","2000000","2015-06-01","2020-05-31"
"IGOC","Interactions between Groups, Orbits, and Cartans","Xin Li","QUEEN MARY UNIVERSITY OF LONDON","Recently, we discovered that the notion of Cartan subalgebras builds bridges between C*-algebras, topological dynamics, and geometric group theory. The goal of this research project is to develop our understanding of this concept in order to attack the following major open questions:

I. The UCT question
II. The Baum-Connes conjecture
III. The conjugacy problem for topological shifts
IV. Quasi-isometry rigidity for polycyclic groups

UCT stands for Universal Coefficient Theorem and is a crucial ingredient in classification. I want to make progress on the open question whether sufficiently regular C*-algebras satisfy the UCT, taking my joint work with Barlak as a starting point.
The Baum-Connes conjecture predicts a K-theory formula for group C*-algebras which has far-reaching applications in geometry and algebra as it implies open conjectures of Novikov and Kaplansky. My new approach to II will be based on Cartan subalgebras and the notion of independent resolutions due to Norling and myself.
Problem III asks for algorithms deciding which shifts are topologically conjugate. It has driven a lot of research in symbolic dynamics.
Conjecture IV asserts that every group quasi-isometric to a polycyclic group must already be virtually polycyclic. A solution would be a milestone in our understanding of solvable Lie groups.
To attack III and IV, I want to develop the new notion of continuous orbit equivalence which (as I recently showed) is closely related to Cartan subalgebras.

Problems I to IV address important challenges, so that any progress will result in a major breakthrough. On top of that, my project will initiate new interactions between several mathematical areas. It is exactly the right time to develop the proposed research programme as it takes up recent breakthroughs in classification of C*-algebras, orbit equivalence for Cantor minimal systems, and measured group theory, where measure-theoretic analogues of our key concepts have been highly successful.","1296966","2019-09-01","2024-08-31"
"IL-E-CAT","Enhancing electrocatalysis in low temperature fuel cells by ionic liquid modification","Bastian Joachim Max Etzold","TECHNISCHE UNIVERSITAT DARMSTADT","The commercialization of low temperature fuel cells is restricted by the high cost and low durability of cathode catalysts. Intense efforts have been devoted to tackle this issue by engineering the structure of Pt-based catalysts. Herein, a novel concept towards enhancing the performance of low temperature fuel cell catalysts is proposed, namely by tuning the local active site microenvironment with an immobilized ionic liquid (IL) phase. As demonstrated by the applicant in preliminary work, a suitable IL layer strongly influences the active catalytic site in a very promising manner, apparently via a highly complex interplay of solvent-, ligand- and electrostatic-stabilization effects. As the structural versatility of ILs allows for rational engineering of this modification at molecular level, the proposed project aims for a full scientific exploration of the remarkable activation and stabilization effects in ORR, to enable the realization of an innovative fuel cell cathode with dramatically enhanced performance. To achieve this ambitious goal, a sound fundamental understanding of the interaction of ILs with electrocatalytic sites will be derived by making use of the excellent research infrastructure and longstanding experience in ionic liquid design and catalytic materials at our institute. To demonstrate the general applicability, the deduced principals will also be applied to CO2 electrochemical reduction. The approach will not stop at the design of novel catalyst systems, but will address solutions to ensure long-term stability of the IL modification. To avoid IL leaching from the catalyst over time, the recent success of the applicant in the synthesis of novel core/shell carbon materials will be employed. The IL will be synthesized in situ within a mesoporous core and the steric demanding ions fixed through a molecular sieving shell surrounding each catalyst particle. A model-assisted strategy will be applied for optimization of the core/shell pore structures.","1999465","2016-05-01","2021-04-30"
"illumizymes","Illuminating aptamers and ribozymes for biomolecular tagging and fluorogen activation","Claudia Höbartner","JULIUS-MAXIMILIANS-UNIVERSITAT WURZBURG","RNAs are linear biopolymers that consist of only four types of building blocks, but can fold into complex three-dimensional structures that are endowed with selective, high-affinity ligand-binding abilities known as aptamers, and catalytic activities known as ribozymes. Genome projects have brought the surprising insight that a large part of the human genome is transcribed into RNAs, but only a very small fraction is translated into proteins. The actual number of noncoding RNAs with specific functions is currently unknown, but many are considered as prominent regulators of cellular functions. Posttranscriptional modifications of RNA add an extra layer of complexity, but their regulatory roles in RNA metabolism are only poorly understood. Despite the relative simplicity in molecular composition, the available methodological repertoire for manipulation, interrogation and visualization of RNA is rather limited. This project aims to solve the challenge of RNA labeling in both fixed and living cells, using aptamers and ribozymes for RNA imaging and functional characterization. We introduce the term illumizymes for novel tools that attach bio-orthogonal tags and fluorophores to specific RNA sequences, in vitro and in vivo. Ribozymes and aptamers for small, stable, and specific labels will be identified by in vitro selection and systematic evolution of ligands by exponential enrichment (SELEX) to activate the fluorescence of latent chromophores by restricting their conformational flexibility and/or formation of covalent bonds by new bio-orthogonal reactions. Using naturally inspired, cell-permeable and non-toxic ligands, we will specifically select for increased brightness and photostability, and evolve illumizymes into color-switching probes for RNA microscopy. The new genetically encodable RNA devices will find widespread applications in diverse disciplines to enlighten our understanding of cellular RNA functions in health and disease.","2061250","2016-07-01","2021-06-30"
"IMAGINE","Non-Invasive Imaging of Nanoscale Electronic Transport","Christian Degen","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","Electronic transport in nanostructures and thin films shows a rich variety of physical effects that have been fundamental to the development of modern electronics and communication devices. The standard method for investigating electronic transport – resistance measurements – does not provide any information on the nanoscale current distribution in such structures. The lack of spatial information is unfortunate, because the current distribution plays a key role in many intriguing physical phenomena. Having a technique at hand that could simply look at nanoscale current flow would be immensely valuable.

In this project we propose to exploit sensitive magnetic microscopy to directly access the current distribution in nanostructures with ~15nm spatial resolution. Our approach is based on the recent technique of scanning diamond magnetometry (SDM), a scanned-probe method that utilizes a single spin in a diamond tip as a high-resolution sensor of magnetic field. Conceived in 2008 by the PI, SDM exploits quantum metrology to achieve very high sensitivities, and has recently enabled a breakthrough in the passive analysis of magnetic surfaces. Our proposal has three objectives: (i) Lay the instrumental and conceptual groundwork required for imaging tiny (<10nA) current variations in two-dimensional conductors. (ii) Demonstrate imaging of a variety of mesoscopic transport features on a well-established model system: Mono- and bilayer graphene. (iii) Explore the potential of our technique for probing electronic properties beyond transport, like phase transitions and photoexcitation.

Together, our experiments are designed to establish a powerful new technology for imaging current distributions non-invasively and with nanometer spatial resolution. This capability will provide the unique opportunity for directly looking at electronic transport in nanostructures, with a potentially transformative impact on condensed matter physics, materials science and electrical engineering.","2491490","2019-10-01","2024-09-30"
"imbh","Do intermediate-mass black holes exist?","Peter Gustaaf Jonker","STICHTING NEDERLANDSE WETENSCHAPPELIJK ONDERZOEK INSTITUTEN","With this proposed project I will determine whether intermediate-mass black holes (IMBHs) exist. I propose to use ESA's new Gaia mission, the rich Hubble Space Telescope data archive, and state-of-the-art techniques to investigate systems predicted to exist but not yet found hitherto, such as recoiled hyper-compact stellar systems, red-supergiant mass donors to ultra-luminous X-ray sources, and white dwarf tidal disruption events. The latter can only be detected if black holes with masses less than 1E5 Msun are involved. Using these systems and events we can probe the sphere of influence of the IMBH and determine the black hole mass dynamically.
Currently, there are strong indications for the existence of IMBHs, but dynamical evidence, the irrefutable proof of their existence, is still lacking. Whereas the unequivocal detection of an IMBH will be a breakthrough discovery in itself, it has also important consequences for searches of dark matter annihilation signals, it will provide a baseline for the rate predictions of gravitational wave radiation events involving IMBHs, and the properties of a population of IMBHs provides important constraints on the growth of supermassive black holes and galaxies. Finally, if we discover IMBHs in hyper-compact star clusters it validates numerical relativity simulations that predict that merging black holes receive a recoil kick.
My membership of Gaia's Data Processing and Analysis Consortium gives me a distinct advantage in analysing and interpreting Gaia data that, through the superb angular resolution, immediate spectroscopic observations and all-sky coverage, provides unique capabilities ideally suited for answering the question whether IMBHs exist.
My proposed project is the first to recognize the potential of Gaia (WP1&2) as well as the implications of having red supergiant mass donors in some ultra-luminous X-ray sources (WP3) for answering the question on the existence of IMBHs.","1999975","2015-09-01","2020-08-31"
"IMBIBE","Innovative technology solutions to explore effects of the microbiome on intestine and brain pathophysiology","Róisín Meabh OWENS","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","The human gut is host to over 100 trillion bacteria that are known to be essential for human health. Intestinal microbes can affect the function of the gastrointestinal (GI) tract, via immunity, nutrient absorption, energy metabolism and intestinal barrier function. Alterations in the microbiome have been linked with many disease phenotypes including colorectal cancer, Crohn’s disease, obesity, diabetes as well as neuropathologies such as autism spectrum disorder (ASD), stress and anxiety. Animal studies remain one of the sole means of assessing the importance of microbiota on development and well-being, however the use of animals to study human systems is increasingly questioned due to ethics, cost and relevance concerns. In vitro models have developed at an accelerated pace in the past decade, benefitting from advances in cell culture (in particular 3D cell culture and use of human cell types), increasing the viability of these systems as alternatives to traditional cell culture methods. This in turn will allow refinement and replacement of animal use. In particular in basic science, or high throughput approaches where animal models are under significant pressure to be replaced, in vitro human models can be singularly appropriate. The development of in vitro models with microbiota has not yet been demonstrated even though the transformative role of the microbiota appears unquestionable. The IMBIBE project will focus on using engineering and materials science approaches to develop complete (i.e. human and microbe) in vitro models to truly capture the human situation. IMBIBE will benefit from cutting edge organic electronic technology which will allow real-time monitoring thus enabling iterative improvements in the models employed. The result from this project will be a platform to study host-microbiome interactions and consequences for pathophysiology, in particular, of the GI tract and brain.","1992578","2017-10-01","2022-09-30"
"iMPACT","innovative Medical Protons Achromatic Calorimeter and Tracker","Piero Giubilato","UNIVERSITA DEGLI STUDI DI PADOVA","The iMPACT project focuses on the realization of a proton Computed Tomography (pCT) scanner capable of acquiring a target full 3D image with 1s exposure, therefore opening the way to the practical application of proton imaging technique in medical radiotherapy treatments. Such cutting-edge particles scanner combines innovative ideas devised for the future High Energy Physics experiments together with original developments in the microelectronic field to enable charged particles imaging at the GHz scale.
     
In recent years the use of hadrons (1H and 12C ions) for cancer radiation treatment has become an established technique and many facilities are currently operational or under construction worldwide. To fully exploit the therapeutic advantages offered by hadron therapy, precise target (body) imaging for accurate beam delivery is decisive. pCT systems, currently in their R&D phase, provide the ultimate in low dose (< 2 mGy), 3D imaging for hadrons treatment guidance. Key components of a pCT system are the detectors used to track the protons and measure their residual energy.

The iMPACT scanner, composed by a proprietary monolithic pixels tracking detector and an innovative achromatic calorimeter, will improve current pCT imaging speed by more than a factor 100, leading to potential recording times of about 1 second for a full 3D target image (compared to present ≈ 10 minutes). The iMPACT detector will also have higher spatial resolution (equal or better than 10 µm) and lower material budget (by a factor 10) respect to state of the art systems, further enhancing 3D imaging accuracy. 

Not least when considering actual industrial application, production costs will be far lower than existent systems, because all sensors will be designed with commercially available technologies, making it possible to move pCT from the academic research realm to that of viable medical equipment.","1810000","2016-01-01","2019-12-31"
"IMPACT","The giant impact and the Earth and Moon formation","Razvan Caracas","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Very little is understood of the physics governing the Giant Impact and the subsequent formation of the Moon. According to this model an impactor hit the proto-Earth; the resulting energy was enough to melt and partially vaporize the two bodies generating a large protolunar disk, from which the Earth-Moon couple formed. Hydrodynamic simulations of the impact and the subsequent evolution of the protolunar disk are currently based on models of equations of state and phase diagrams that are unconstrained by experiments or calculations. Estimates of the positions of critical points, when available at all, vary by one order of magnitude in both temperature and density. Here we propose to compute the thermodynamics of the major rock-forming minerals and rock aggregates, and use it to study the formation and evolution of the protolunar disk. For this we employ a unique combination of atomistic state-of-the-art ab initio simulations. We use large-scale density-functional theory (DFT) molecular dynamics to study bulk fluids, coupled with Green functions (GW) and time-dependent DFT techniques to analyze atomic clusters and molecular species. We compute the vaporization curves, position the supercritical points, and characterize the sub-critical and supercritical regimes. We construct equations of state of the rocks at the conditions of the giant impact that are beyond current experimental capabilities. We employ a multiscale approach to bridge the gap between atomic, geological sample, and planetary scales via thermodynamics; we simulate the thermal profile through the disk, the ratio between liquid and vapor, and the speciation. From speciation we predict elemental and isotopic partitioning during condensation. Plausible impact scenarios, features of the impactor and of the proto-Earth will be constrained with a feedback loop, until convergence between predictions of final Earth-Moon compositions and observations is reached.","1900000","2016-09-01","2021-08-31"
"iNanoEOR","In-situ produced nanoparticles for enhanced oil recovery","Dongsheng Wen","UNIVERSITY OF LEEDS","The era of finding “easy oil” is coming to an end, and future supply will become more reliant on fossil fuels produced from enhanced oil recovery (EOR) process. Many EoR methods have been used, including mechanical, chemical, thermal and biological approaches, but there are still 50~70% of the original oil trapped in reservoir rocks after the primary and secondary recovery. NanoEOR, i.e, injecting nanoparticles (NPs) together with flooding fluids, is an emerging field. However all proposed applications are based on pre-fabricated NPs, which encountered enormous problems in NP stabilization and transport under reservoir conditions. This project proposes a revolutionary concept, iNanoEOR: in-situ production of NPs inside the reservoir for enhanced oil recovery. Rather than pre-manufacturing, dispersing and stabilizing NPs in advance, NPs will be produced in the reservoir by controlled hydrothermal reactions, acting as sensors to improve reservoir characterisation, or as property modifiers to effectively mobilize the trapped oil. This project will validate the innovative iNanoEOR concept by answering three questions: i) how the concept works? ii) what kind of NPs should be produced that can effectively mobilize trapped oil? iii) what are desired NP properties to allow them flow through a reservoir? Three work programs are designed, and a number of breakthroughs beyond state-of-art research are expected, which include i) proof-of-concept of the innovative iNanoEOR, ii) developing a new methodology for temperature measurement inside a reservoir, iii) revelation of the influence of NPs on EOR under reservoir-like conditions, iv) understanding the controlling factors in  NP transport at different scales. The project will not only contribute directly to iNanoEOR,  but also transfers the PI’s expertise in nanomaterials and multiphase flow into oil and gas sector and underpin many NP-related subsurface applications, which currently is non-existing in the Europe.","1958733","2015-08-01","2020-07-31"
"InanoMOF","Multifunctional micro- and nanostructures assembled from nanoscale metal-organic frameworks and inorganic nanoparticles","Daniel Maspoch Comamala","FUNDACIO INSTITUT CATALA DE NANOCIENCIA I NANOTECNOLOGIA","In InanoMOF, we aim to develop frontier Supramolecular and Nanochemistry methodologies for the synthesis of a novel class of structures via controlled assembly of nanoscale metal-organic frameworks (nanoMOFs) and inorganic nanoparticles (INPs). These methods will embody the premise that “controlled object-by-object nano-assembly is a ground-breaking approach to explore for producing systems of higher complexity with advanced functions”. The resulting hybrid nanoMOF@INPs will marry the unique properties of INPs (magnetism of iron oxide NPs and optics of Au NPs) to the functional porosity of MOFs.

The first part of InanoMOF encompasses the design, synthesis-assembly and characterisation of nanoMOF@INPs - advanced MOF-based sorbents that incorporate the functionality of the INPs used: magnetically controlled movement, in vivo detectability, enhanced biocompatibility and porosity, pollutant removal, or controlled sorption/delivery. The second part of InanoMOF entails studying the physicochemical properties of the synthesised nanoMOF@INPs and ascertaining their utility as drug-delivery/theranostic systems and as magnetic sorbents for pollutant removal. Specifically, we will study their stability in working media and determine their capacities for drug or pollutant sorption/delivery capacities. As proof-of-concept, we will study their toxicity in vitro and in vivo; enhancement of their in vitro therapeutic efficacy; and their capacity to remove pollutants (in real water and gasoline/diesel fuel samples) via magnetic assistance.

In InanoMOF we will endeavour to establish the synthetic bases for controlling the spatial ordering of nanoMOF crystals, whether alone or combined with other nanomaterials (e.g. INPs, graphene, etc.). We are confident that our work will ultimately enable researchers to create MOF-based composites having cooperative and synergistic properties and functions for myriad applications (e.g. heterogeneous catalysis, sensing and separation).","1942665","2014-04-01","2019-03-31"
"INCANA","Insect-inspired capillary nanostamping","Martin Georg Steinhart","UNIVERSITAET OSNABRUECK","Aim of the proposed project is a) development and establishment of insect-inspired capillary nanostamping (IICN) as next-generation contact nanolithography, b) replacing state-of-the-art lithographic and synthesis protocols requiring use of sacrificial templates or time-consuming self-assembly steps by IICN and c) significant IICN-driven acceleration and upscaling of the production of extended nanostructured systems. To meet these aims, IICN stamp design will be inspired by insect feet depositing small secretion droplets through arrays of hairy contact elements on counterpart surfaces. Monolithic IICN stamps extending cm2 will consist of spongy ink-filled substrates connected to extended arrays of spongy nanoscale dispensing elements with diameters in the 100 nm range (density up to ~130 dispensing elements per square micron). Ink supplied through the spongy pore systems forms capillary bridges between each dispensing element and counterpart surfaces, thus enabling massively parallel capillary bridge-guided nanorod synthesis. Capillary bridge rupture during stamp retraction leads to massively parallel lithographic deposition of ink nanodroplet arrays (target nanodroplet volume: a few 10 zeptolitres). IICN model applications include production of a) ultrathin nanoporous membranes for separation; b) ordered silicon nanostructures by IICN-supported metal-assisted etching; c) nearly-ergodic arrays of encapsulated liquid nanocontainers for massively parallel ensemble nanochemistry or ensemble tracing of single molecules; d) nearly-ergodic biochips for massively parallel analyte detection with single-molecule resolution. As example for substitution of time-consuming self-assembly in nanomaterial synthesis by IICN, IICN-accelerated production of ordered nanoporous alumina will be studied. To pave the way for upscaling and potential commercialization of IICN, high-throughput IICN devices for automated operation in batch and continuous roller modes will be constructed.","1918000","2015-09-01","2020-08-31"
"InCell","High speed AFM imaging of molecular processes inside living cells","Georg FANTNER","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Imaging the inside of living cells with single nanometre resolution has been a long-standing dream in bio-microscopy.   Direct observation of changes to molecular networks inside of living cells would revolutionize the way we study structural cell biology. Unfortunately, no such tool exists. Atomic force microscopy (AFM) is the closest we have, to nanoscale functional imaging of cells in their native, fluid environment. However, it is limited to imaging the outside of the cell.  
With InCell, I will remedy this by developing an AFM capable of imaging the inside of living cells. The approach is based on a microfabricated high speed AFM cantilever encased in a double barrel patch-clamp shell. The patch clamp shell seals onto the plasma membrane of the cell, so that the tip of the AFM cantilever can enter the cell without causing the cytosol to leak out. Parasitic interactions of the AFM tip with the cytosol will be subtracted from the cantilever deflection signal, using high speed photo-thermal off-resonance tapping (PT-ORT), a novel AFM mode we have recently developed in my lab. This allows the extraction of the true tip-sample interaction, even in viscous fluids. A dedicated InCell HS-AFM combined with confocal optical microscopy will be used to guide the InCell cantilever inside the cell to the area of interest. 
Using this minimally invasive technique we will study the formation of clathrin coated pits, a crucial part of endocytosis. By imaging for the first time the nanoscale dynamics of this process in living cells, we aim to answer fundamental questions about the clathrin coat assembly. We will characterize the kinetics, stability and force generation by the clathrin lattice. This will be the first example of how enabling nanoscale imaging inside living cells will be a game changer in cell biology. It will open up a myriad of possibilities for the study of vesicular transport, viral and bacterial infection, nuclear pore transport, cell signalling and many more.","1999925","2018-04-01","2023-03-31"
"INITIUM","an Innovative Negative Ion TIme projection chamber for Underground dark Matter searches","Elisabetta BARACCHINI","GRAN SASSO SCIENCE INSTITUTE","INITIUM: an Innovative Negative Ion TIme projection chamber for Underground dark Matter searches. INITIUM goal is to boost the advancement of gaseous Time Projection Chamber detectors in the Dark Matter (DM) searches field, one of the most compelling issues of todays fundamental physics. I believe this approach to be superior because of its active neutron/electron discrimination, directional and fiducialization capability down to low energies and versatility in terms of target material. Thanks to recent advances in Micro Pattern Gas Detectors amplification and improved readout techniques, TPCs are nowadays mature detectors to aim at developing a ton-scale experiment. INITIUM focuses on the development and operation of the first 1 m3 Negative Ion TPC with Gas Electron Multipliers amplification and optical readout with CMOS-based cameras and PMTs for directional DM searches at Laboratori Nazionali del Gran Sasso (LNGS). INITIUM will put new significant constraints in a DM WIMP-nucleon scattering parameter space still unexplored to these days, with a remarkable sensitivity down to 10-42-10-43 cm2 for Spin Independent coupling in the 1-10 GeV WIMP mass region. As a by-product, INITIUM will also precisely and simultaneously measure environmental fast and thermal neutron flux at LNGS, supplying crucial information for any present and future experiment in this location. Consequently, I will demonstrate the proof-of-principle and scalability of INITIUM approach towards the development of a ton-scale detector in the context of CYGNUS, an international collaboration (of which I am one of  the Spokespersons and PIs) recently gathered together with the aim to establish a Galactic Directional Recoil Observatory, that can test the DM hypothesis beyond the Neutrino Floor and measure the coherent scatter of galactic neutrinos, generating a significant long-term impact on detection techniques for rare events searches.","1995719","2019-03-01","2024-02-29"
"InnoSpace","Revolutionizing fibre-wireless communications through space-division multiplexed photonics","Ivana Gasulla Mestre","UNIVERSITAT POLITECNICA DE VALENCIA","Next generation global telecommunication paradigms will require entirely new technologies to address the current limitations to massive capacity and connectivity. A full integration between optical fibre and wireless networks will be the key for the upcoming multigigabit-per-second 5G wireless communications and the era of Internet of Things. Microwave Photonics (MWP) is the multidisciplinary technology to achieve such a convergence. There is one revolutionary approach that has however been left untapped in finding innovative ways to increase the end user capacity and provide adaptive radiofrequency-photonic interfaces: exploiting space - the last available degree of freedom for optical multiplexing. Space-Division multiplexing (SDM) has been recently touted as a solution for the capacity bottleneck in digital communications by establishing independent light paths in a single fibre. My pioneering idea is to develop a novel area of application for SDM by exploiting for the first time its inherent parallelism to implement a broadband tuneable true time delay line for radiofrequency signals, which is the basis of multiple MWP functionalities. Within this project I envision an unprecedented revolution in fibre-wireless communications through the powerful concept of SDM that will lead to unique processing capabilities as well as to a reduction of size, weight and power consumption. My unique research background developed around the two core of this project, SDM and MWP, puts me in the privileged position to unify them in this truly interdisciplinary program, merging novel ideas and methods from physics, radiofrequency and photonics. Based on my profile, my preliminary results and the available infrastructure at my host organization, I am best positioned to successfully carry out this innovative high-gain/high-risk approach, which will lead to revolutionary advancements of the state of the art and prospective evolution of MWP for future ubiquitous communication scenarios.","1998500","2017-03-01","2022-02-28"
"InOutBioLight","Advanced biohybrid lighting and photovoltaic devices","Rubén COSTA","FUNDACION IMDEA MATERIALES","InOutBioLight aims to design multifunctional rubbers with enhanced mechanical, thermal, color-converting, and light-guiding features towards advanced biohybrid lighting and photovoltaic technologies. The latter are placed at the forefront of the EU efforts for low-cost production and efficient consumption of electricity, a critical issue for a sustainable development.
In this context, the use of biomolecules as functional components in lighting and photovoltaic devices is still a challenge, as they quickly denature under storage and device operation conditions. This paradigm has changed using an innovative rubber-like material, in which the biofunctionality is long preserved. As a proof-of-concept, color down-converting rubbers based on fluorescent proteins were used to design the first biohybrid white light-emitting diode (bio-HWLED). To develop a new generation of biohybrid devices, InOutBioLight will address the following critical issues, namely i) the nature of the protein-matrix stabilization, ii) how to enhance the thermal/mechanical features, iii) how to design multifunctional rubbers, iv) how to mimic natural patterns for light-guiding, and v) how to expand the technological use of the rubber approach.
To achieve these goals, InOutBioLight involves comprehensive spectroscopic, microscopic, and mechanical studies to investigate the protein-matrix interaction using new polymer matrices, additives, and protein-based nanoparticles. In addition, the mechanical, thermal, and light-coupling features will be enhanced using structural biocompounds and reproducing biomorphic patterns. As such, InOutBioLight offers three major advances: i) a thorough scientific basis for the rubber approach, ii) a significant thrust of the emerging bio-HWLEDs, and iii) innovative breakthroughs beyond state-of-the-art biohybrid solar cells.","1999188","2019-09-01","2024-08-31"
"INSITE","Development and use of an integrated in silico-in vitro mesofluidics system for tissue engineering","Liesbet Laura J GERIS","UNIVERSITE DE LIEGE","Tissue Engineering (TE) refers to the branch of medicine that aims to replace or regenerate functional tissue or organs using man-made living implants. As the field is moving towards more complex TE constructs with sophisticated functionalities, there is a lack of dedicated in vitro devices that allow testing the response of the complex construct as a whole, prior to implantation.  Additionally, the knowledge accumulated from mechanistic and empirical in vitro and in vivo studies is often underused in the development of novel constructs due to a lack of integration of all the data in a single, in silico, platform.

The INSITE project aims to address both challenges by developing a new mesofluidics set-up for in vitro testing of TE constructs and by developing dedicated multiscale and multiphysics models that aggregate the available data and use these to design complex constructs and proper mesofluidics settings for in vitro testing. The combination of these in silico and in vitro approaches will lead to an integrated knowledge-rich mesofluidics system that provides an in vivo-like time-varying in vitro environment. The system will emulate the in vivo environment present at the (early) stages of bone regeneration including the vascularization process and the innate immune response. A proof of concept will be delivered for complex TE constructs for large bone defects and infected fractures. 

To realize this project, the applicant can draw on her well-published track record and extensive network in the fields of in silico medicine and skeletal TE. If successful, INSITE will generate a shift from in vivo to in vitro work and hence a transformation of the classical R&D pipeline. Using this system will allow for a maximum of relevant in vitro research prior to the in vivo phase, which is highly needed in academia and industry with the increasing ethical (3R), financial and regulatory constraints.","2161750","2018-09-01","2023-08-31"
"INTENSE","INTENSE: INTElligent use of climate models for adaptatioN to non-Stationary climate Extremes","Hayley Jane Fowler","UNIVERSITY OF NEWCASTLE UPON TYNE","""The research proposed here will use a novel and fully-integrated data-modelling approach to provide a step-change in our understanding of the nature and drivers of global precipitation extremes and change on societally relevant timescales. Extreme precipitation is increasing globally and theoretical considerations suggest this will continue with global warming, but opportunistic datasets indicate that sub-daily precipitation extremes will intensify more than is anticipated. Determining the precise response of precipitation extremes is hampered by coarse climate models which cannot adequately resolve cloud-scale processes and a lack of sub-daily observations. INTENSE will comprehensively analyse the response of precipitation extremes to global warming by constructing the first global sub-daily precipitation dataset, enabling substantial advances in observing current and past changes. Together with other new observational datasets and high-resolution climate modelling, this will quantify the nature and drivers of global precipitation extremes and their response to natural variability and forcing across multiple timescales. Specifically the project will examine the influence of local thermodynamics and large-scale circulation modes on observed precipitation extremes using new statistical methods which recognise the non-stationary nature of precipitation, and use these to identify climate model deficiencies in the representation of precipitation extremes. The recurrence of extreme hydrological events is notoriously hard to predict, yet successful climate adaptation will need reliable information which better quantifies projected changes. INTENSE will provide a new synergy between data, models and theory to tackle the problem using a process-based framework; isolating the precursors for extreme precipitation and intelligently using detailed modelling as a tool to understand how these extremes will respond to a warming world and the implications for adaptation strategy.""","1986801","2014-02-01","2020-01-31"
"INTERACT","Intelligent Non-woven Textiles and Elastomeric Responsive materials by Advancing liquid Crystal Technology","Jan Peter Felix Lagerwall","UNIVERSITE DU LUXEMBOURG","A grand challenge in today’s materials research is the realization of flexible materials that are also intelligent and functional. They will be the enablers of true breakthroughs in the hot trends of soft robotics and wearable technology. The standard approach to the latter is to decorate rubber sheets with electronic components, yielding two serious flaws: rubber is uncomfortable as it does not breath and solid state electronics will eventually fail as a garment is flexed and stretched when worn. While the softness of rubber is ideal it must be used in the form of textile fibers to provide breathability, and for long-term failure resistance we need intelligent components that are soft. A solution to this conundrum was recently presented by the PI with the concept of liquid crystal (LC) electrospinning. The extreme responsiveness of LCs is transferred to a non-woven textile by incorporating the LC in the fiber core, yielding a smart flexible mat with sensory function. Moreover, it consumes no power, providing a further advantage over electronics-based approaches. In a second research line he uses microfluidics to make LC rubber microshells, functioning as autonomous actuators which may serve as innovative components for soft robotics, and photonic crystal shells. This interdisciplinary project presents an ambitious agenda to advance these new concepts to the realization of soft, stretchable intelligent materials of revolutionary character. Five specific objectives are in focus: 1) develop understanding of the dynamic response of LCs in these unconventional configurations; 2) establish interaction dynamics during polymerisation of an LC precursor; 3) elucidate LC response to gas exposure; 4) establish correlation between actuation response and internal order of curved LCE rubbers; and 5) assess usefulness of LC-functionalized fibers and polymerized LC shells, tubes and Janus particles in wearable sensors, soft robotic actuators and high-security identification tags.","1929976","2015-04-01","2020-03-31"
"INTERACTION","Cloud-cloud interaction in convective precipitation","Jan Olaf Mirko Härter","KOBENHAVNS UNIVERSITET","State-of-the-art simulations and observations highlight the self-organization of convective clouds. Our recent work shows two aspects: these clouds are capable of unexpected increase in extreme precipitation when temperature rises; interactions between clouds produce the extremes. As clouds interact, they organize in space and carry a memory of past interaction and precipitation events. This evidence reveals a severe shortcoming of the conventional separation into ""forcing"" and ""feedback"" in climate model parameterizations, namely that the ""feedback"" develops a dynamics of its own, thus driving the extremes. The major scientific challenge tackled in INTERACTION is to make a ground-breaking departure from the established paradigm of ""quasi-equilibrium"" and instantaneous convective adjustment, traditionally used for parameterization of ""sub-grid-scale processes"" in general circulation models. To capture convective self-organization and extremes, the out-of-equilibrium cloud field must be described. In INTERACTION, I will produce a conceptual model for the out-of-equilibrium system of interacting clouds. Once triggered, clouds precipitate on a short timescale, but then relax in a ""recovery"" state where further precipitation is suppressed. Interaction with the surroundings occurs through cold pool outflow,facilitating the onset of new events in the wake. I will perform tailored numerical experiments using cutting-edge large-eddy simulations and very-high-resolution observational analysis to determine the effective interactions in the cloud system. Going beyond traditional forcing-and-feedback descriptions, I emphasize gradual self-organization with explicit temperature dependence. The list of key variables of atmospheric water vapor, temperature and precipitation must therefore be amended by variables describing organization. Capturing the self-organization of convection is essential for understanding of the risk of precipitation extremes today and in a future climate.","1314800","2018-07-01","2023-06-30"
"INTERCLOUDS","Using the Magellanic Clouds to Understand the Interaction of Galaxies","Maria-Rosa Cioni","","The Magellanic Clouds are the nearest gas-rich dwarf satellites of the Milky Way and illustrate a typical example of an early phase of a minor merger event, the collision of galaxies that differ in mass by at least a factor of ten. In spite of their important role in supplementing material to the Milky Way halo and the numerous investigations made in the last decade, there remain several uncertainties. Their origin is still a matter of debate, their satellite status is unclear, their mass is uncertain, their gravitational centres are undefined, their structure depends strongly on stellar populations and is severely shaped by interactions, their orbital history is only vaguely associated to star forming events, and their chemical history rests upon limited data. This proposal aims to remedy this lack of knowledge by providing a comprehensive analysis of the stellar content of the Magellanic Clouds and dissect the substructures that are related to their accretion history and the interaction with the Milky Way. Their internal kinematics and orbital history, establishing their bound/unbound status, will be resolved thanks to the analysis of state-of-the art proper motions from the VMC survey and the Gaia mission, and the development of sophisticated theoretical models. Multi-wavelength photometric observations from ongoing large-scale projects will be analysed together to characterise the stellar population of the Magellanic Clouds as has never been previously attempted, including the effects of separate structural components. New large-scale spectroscopic survey projects in preparation will resolve metallicity dependencies and complete the full six-phase space information (distance, position, and motion). This proposal will have a tremendous impact on our understanding of the consequences of minor mergers, and will offer a firm perspective of the Magellanic Clouds.","1985017","2016-10-01","2021-09-30"
"INTERFERE","Sparse Signal Coding for Interference-based Imaging Modalities","Peter Schelkens","VRIJE UNIVERSITEIT BRUSSEL","Since its invention in 1948 by Dennis Gabor holography has held the promise to empower full parallax 3D visualisation. Though the trajectory has been significantly longer than expected, recent developments in photonics, microelectronics and computer engineering have led to the prospective to realize within a decade dynamic full parallax holography with acceptable rendering quality and viewing angle. Unfortunately projections – based on the current state-of-the-art and expected evolution in the underlying “hardware” technologies – still predict exascale computing power and terabytes-per-second data rates.
Since dynamic digital holography requires huge amounts of pixels to be sensed, transmitted and represented, sparse signal representations hold a great promise reducing the computational complexity and bandwidth usage. INTERFERE will design a generic source coding methodology and architecture to facilitate the exploitation of sparse signal representations for dynamic, full parallax, large viewing angle digital holography and more generic, interference-based modalities, with the ambition to reduce the signal processing tailbacks while exploiting simultaneously human visual system characteristics.
Realizing these research objectives – with a strong focus on advanced signal representations, associated source coding methodologies and visual quality modelling – will provide a breakthrough with respect to the complexity reduction and thus realisation of full-parallax, wide viewing angle dynamic digital holography and benefit the earlier mentioned adjacent scientific fields. Intermediate results or components will have serendipic effects on other scientific disciplines and open new horizons for markets such as – but not limited to – medical imaging, biophotonics, life sciences, public safety, digital holographic microscopy, holographic biomedical sensors, data storage and metrology, illustrating the high-gain potential of INTERFERE.","1992615","2014-06-01","2019-05-31"
"InvGroGra","Asymptotic invariants of discrete groups, sparse graphs and locally symmetric spaces","Miklos Abert","MAGYAR TUDOMANYOS AKADEMIA RENYI ALFRED MATEMATIKAI KUTATOINTEZET","The PI proposes to study the asymptotic behavior of various invariants of discrete groups and their actions, of sparse graphs and of locally symmetric spaces. The game is to connect the asymptotic behavior of an invariant on a sequence of finite models to an analytic invariant on a suitable limit object of the sequence and then use the connection to get new results in both the finite and infinite worlds. The recently emerging notion of invariant random subgroups, initiated by the PI, serves as a unifying language for convergence.

  These invariants include the minimal number of generators, deficiency, Betti numbers over arbitrary fields, various spectral and representation theoretic invariants, graph polynomials and entropy. The limit objects arising are invariant processes on groups, profinite actions, graphings, invariant random subgroups and measured complexes. The analytic invariants include L2 Betti numbers, spectral and Plancherel measures, cost and its higher order versions, matching and chromatic measures and entropy per site.

  Energy typically flows both ways between the finite and infinite world and also between the different invariants. We list five recent applications from the PI that emerged from such connections. 1) Any large volume locally symmetric semisimple space has large injectivity radius at most of its points; 2) The rank gradient of a chain equals the cost-1 of the profinite action of the chain; 3) Countable-to-one cellular automata over a sofic group preserve the Lebesque measure; 4) Ramanujan graphs have essentially large girth; 5) The matching measure is continuous for graph convergence, giving new estimates on monomer-dimer free energies.

  Besides asymptotic group theory and graph theory, the tools of the proposed research come from probability theory, ergodic theory and statistical mechanics. The proposed research will lead to further applications in 3-manifold theory, geometry and ergodic theory.","1386250","2015-07-01","2020-06-30"
"IONOLOGY","Quantum Metrology with Trapped Ions","Roee Ozeri","WEIZMANN INSTITUTE OF SCIENCE LTD","We propose a quantum algorithmic approach to metrology and its implementation using trapped-ion qubits. Active decoherence suppression methods such as decoherence-free subspaces, Quantum error-correction codes and dynamic decoupling will be used to reduce the effect of noise while amplifying a measured signal, thus improving on the measurement signal-to-noise ratio. An ion trap architecture that best suits this approach will be designed and realized. Several metrology protocols will be demonstrated. Finally, we propose to apply these methods in actual precision measurements, including the detection of magnetic interaction between ions at large distances, optical frequency metrology, the measurement of parity violation in atomic transitions, and the detection of correlations in an ultra-cold gas of neutral atoms. The implications of scaling-up to large numbers of probe-qubits will be investigated as well.","1999882","2014-01-01","2018-12-31"
"IONOS","An iono-electronic neuromorphic interface for communication with living systems","Fabien Robert Jocelyn ALIBART","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","While our understanding of the brain have made huge progresses, we are still inefficient in interfacing biological systems with electronics, both in terms of energy and integration potential. Pushed by the need to use conventional computers for building complex systems dedicated to brain interface applications, we have mostly capitalized on technologies and architectures inherits from microelectronic that are intrinsically not adapted to interface living systems. The IONOS project will shift the brain interface paradigm by developing new technologies designed to interact intimately with biological cells and capitalizing heavily on bio-inspiration. To reach this goal, the IONOS project will explore how to sense, stimulate and compute biological signals from in-vitro neural cells’ assembly based on iono-electronic materials and devices. These emerging devices offer basics functionalities such as memory, ion-electron signal’s transduction, and amplification paving the way to a new field of device and circuit engineering that could efficiently reproduce key biological functions such as learning and spatio-temporal processing of information. This project will demonstrate how these concepts associated to the bio-inspired computing paradigm can unlock our fundamental limitations for communicating with living neural cells. Proof of concept will show how an artificial system can efficiently send, receive and compute information from a biological one, which constitutes the basic of communication.","1898520","2018-11-01","2023-10-31"
"IONPAIRSATCATALYSIS","Design Principles of Ion Pairs in Organocatalysis – Elucidation of Structures, Intermediates and Stereoselection Modes as well as Assessment of Individual Interaction Contributions","Ruth Maria Gschwind","UNIVERSITAET REGENSBURG","Ions are nearly omnipresent in chemistry and biochemistry. By providing the highest intermolecular interaction energies, ionic interactions have an extreme impact on molecular structures, which are the key to molecular functions. Experimentally determined structures of small contact ion pairs in solution are very rare and sometimes lacking in complete research fields. In addition, despite the amazing progress in theoretical and supramolecular chemistry, the subtle interplay of interactions in small organic ion pairs remains largely unknown. As a result design principles for small organic ion pairs in solution are not available. To solve this general problem there is an urgent and actual need of the synthetic community, because ion-pairing catalysis is the actual hot topic in asymmetric catalysis. There, new catalysts have to be screened with high effort in a black box mode and reviews state that structural and mechanistic studies will be an essential part of the further progress in the field. In previous projects spread over the fields of organometallic, bioorganic, supramolecular and medicinal chemistry as well as transition metal catalysis and organocatalysis, we gained special NMR expertise in the structure elucidation of ion pairs and reaction intermediates as well as the assessment of intermolecular interactions. Now in this project, nearly all of these various techniques and approaches will be combined in a new and so far unprecedented way and complemented by techniques used for protein ligand interactions and extreme low temperature measurements. With this unique combination, NMR approaches will be developed and applied to elucidate the structures of catalytically active ion pairs and their intermediates in solution and to dissect their intermolecular interactions. The resulting detailed design concept for small ion pairs in solution will revolutionize not only ion-pairing catalysis but all scientific fields working with organic ion pairs in solution.","1994685","2014-04-01","2019-03-31"
"IONPEN","Trapped-ion quantum information in 2-dimensional Penning trap arrays","Jonathan HOME","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","This project will develop a new platform for quantum computation and quantum simulation based on scalable two-dimensional arrays of ions in micro-fabricated Penning traps. It builds upon the rapid advances demonstrating high precision quantum control in micro-fabricated radio-frequency ion traps while eliminating the most problematic element - the radio-frequency potential - using a uniform magnetic field. This offers a significant advantage: since the magnetic field is uniform it provides confinement at any position for which a suitable static quadrupole can be generated. By contrast, r.f. potentials only provide good working conditions along a line. This changed perspective provides access to dense two-dimensional strongly interacting ion lattices, with the possibility to re-configure these lattices in real time. By combining closely-spaced static two-dimensional ion arrays with standard laser control methods, the project will demonstrate previously inaccessible many-body interacting spin Hamiltonians at ion numbers which are out of the reach of classical computers, providing a scalable quantum simulator with the potential to provide new insights into the links between microscopic physics and emergent behavior. Through dynamic control of electrode voltages, reconfigurable two-dimensional arrays will be used to realize a scalable quantum computing architecture, which will be benchmarked through landmark experiments on measurement-based quantum computation and high error-threshold surface codes which are natural to this configuration. Realizing multi-dimensional connectivity between qubits is a major problem facing a number of leading quantum computing architectures including trapped ions. By solving this problem, the proposed project will pave the way to large-scale universal quantum computing with impacts from fundamental physics through to chemistry, materials science and cryptography.","1999375","2019-04-01","2024-03-31"
"IPFLOW","Inverse Problems and Flows","Colin Alfred GUILLARMOU","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","In this project, we propose to study mixing and rigidity properties of a large class of flows in geometry and dynamical systems using novel microlocal and spectral methods. 
Such methods, recently developed for flows with hyperbolicity, are based on the construction of new functional spaces, adapted to the considered flow, on which the generating vector field is Fredholm with discrete spectrum, known as the resonance spectrum. We want to apply these tools to the following categories of long-standing problems:

1) Geometric inverse problems:  boundary and lens rigidity problems, analysis of the X-ray transforms for geodesic flows and its applications to Calderon and Gelfand inverse problems.
2) Rigidity for Anosov flows: determination of the minimal regularity of the stable/unstable foliations providing rigidity, rigidity questions for regular conjugacies of flows. 
3) Rate of mixing for flows of hyperbolic type: decay of correlations of Axiom A flows, Anosov flows, and their compact Lie groups extensions, frame flows of negatively curved manifolds.
4) Resonances for locally symmetric spaces: relation between resonances of the flow and the spectrum of Laplacians on bundles.

To address these problems, we will develop a thorough analysis for the regularity and the long time properties of solutions to transport equations. We are convinced that the proposed approach will provide solutions to these problems, which have been out of reach for a long time.","1133236","2017-01-01","2021-12-31"
"IPTheoryUnified","Inverse boundary problems: toward a unified theory","Mikko SALO","JYVASKYLAN YLIOPISTO","This proposal is concerned with the mathematical theory of inverse problems. This is a vibrant research field at the intersection of pure and applied mathematics, drawing techniques from PDE, geometry, and harmonic analysis as well as generating new research questions inspired by applications. Prominent questions include the Calderón problem related to electrical imaging, the Gel'fand problem related to seismic imaging, and geometric inverse problems such as inversion of the geodesic X-ray transform.

Recently, exciting new connections between these different topics have begun to emerge in the work of the PI and others, such as: 

- The explicit appearance of the geodesic X-ray transform in the Calderón problem.
- An unexpected connection between the Calderón and Gel’fand problems involving control theory.
- Pseudo-linearization as a potential unifying principle for reducing nonlinear problems to linear ones.
- The introduction of microlocal normal forms in inverse problems for PDE.

These examples strongly suggest that there is a larger picture behind various different inverse problems, which remains to be fully revealed.

This project will explore the possibility of a unified theory for several inverse boundary problems. Particular objectives include:

1. The use of normal forms and pseudo-linearization as a unified point of view, including reductions to questions in integral geometry and control theory.
2. The solution of integral geometry problems, including the analysis of convex foliations, invertibility of ray transforms, and a systematic Carleman estimate approach to uniqueness results.
3. A theory of inverse problems for nonlocal models based on control theory arguments.

Such a unified theory could have remarkable consequences even in other fields of mathematics, including controllability methods in transport theory, a solution of the boundary rigidity problem in geometry, or a general pseudo-linearization approach for solving nonlinear operator equations.","920880","2018-05-01","2023-04-30"
"IQFT","Integrable Structures in Quantum Field Theory","James Matthew Drummond","UNIVERSITY OF SOUTHAMPTON","Quantum field theory forms the foundation of our understanding of elementary particle physics. It provides the theoretical background for the interpretation of data from collider experiments. While quantum field theory is an old subject, over the last decade new features have begun to emerge which reveal new ways to understand it. In particular an astonishing simplicity has been found at the heart of the maximally supersymmetric gauge theory in four spacetime dimensions, a close cousin of Quantum Chromodynamics (QCD), which describes the strong interactions.

My research team will use the new methods I have been developing to construct explicit results for scattering amplitudes and correlation functions. We will develop these results into general statements about the analytic behaviour of scattering amplitudes. The approach will be based on my recent work on new dualities between amplitudes and Wilson loops and on new symmetries revealing an underlying integrable structure. This research will allow us to answer key foundational questions such as the origin of Regge behaviour of scattering amplitudes in the high energy limit, and the connection to string theory in the limit of strong coupling. We will also pursue the connection to quantum groups and formulate the problem of scattering amplitudes in this language. This provide a solid mathematical underpinning to the formulation of the scattering problem in quantum field theories and allow application of techniques from the field of integrable systems to gauge theories. 

An enormous effort goes into performing the calculations of scattering amplitudes needed to make precise predictions for collider experiments. New techniques to handle such calculations are much needed. We will develop new tools, such as the application of differential equation methods for loop integrals and analytic bootstrap methods for amplitudes. This research will allow us to greatly improve on existing efforts to calculate processes in QCD.","1992452","2015-10-01","2020-09-30"
"IRIS","Infrared imaging and sensing: the single-photon frontier","Robert Hugh Hadfield","UNIVERSITY OF GLASGOW","Infrared sensing technology has a central role to play in addressing 21st century global challenges in healthcare, security and environmental sensing.  Promising new applications hinge on the ability to detect individual quanta of light: single photons.  At infrared wavelengths this is a formidable task due to the low photon energy, and commercial-off-the-shelf technologies fall far short of the required performance.  IRIS will engineer revolutionary photon counting infrared imaging and sensing solutions, with unprecedented spectral range, efficiency, timing resolution and low noise.  Using state-of-the-art materials and nanofabrication techniques, novel superconducting detector technology will be scaled up from single pixels to large area photon counting arrays.  Efficient readout and optical coupling solutions will be developed and implemented.  IRIS will exploit space age cryogenic technology to create compact and mobile detector systems.   IRIS will deploy these systems for the first time in revolutionary infrared imaging and sensing applications: dosimetry for laser based cancer treatment, atmospheric remote sensing of greenhouse gases and real-time distributed fibre sensing for geothermal energy.","1792906","2015-06-01","2019-11-30"
"ISCQuM","Imaging, Spectroscopy and Control of Quantum states in advanced Materials","Fabrizio CARBONE","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Atomic confinement in 2D materials, topological protection in strong spin-orbit coupling systems or chiral magnets, all result in spin/charge textured states of matter. For example skyrmions, a whirling distribution of spins, behave as individual particles which controlled creation/annihilation/motion is of great importance in spintronics. To achieve control over skyrmions, or more generally over the constituents of disordered elastic media (vortices in superconductors, domain walls in magnets to name a few), the fundamental interplay between short-range and long-range interactions, influenced by topological protection, disorder and confinement, has to be understood and manipulated. This project aims at controlling with electromagnetic pulses a handful of charges and spins in nanostructured materials to be filmed with nm/fs resolution by  time-resolved Transmission Electron Microscopy. I propose to image and shape confined electromagnetic fields (plasmons) in nanostructured novel materials. With this ability, we will implement/demonstrate the ultrafast writing and erasing of individual skyrmions in topological magnets. These experiments will enable the fundamental investigation of defects in topological networks and possibly seed new ideas for application in ultradense and ultrafast data storage devices. Similarly, pinning of vortices in type II superconductors will be controlled by light and imaged, gaining new insights into out of equilibrium superconductivity. In my laboratory, shaping and filming plasmonic fields down to the nm-fs scales have been demonstrated, as well as laser-writing and imaging skyrmions in nanostructures. ISCQuM will allow implementing crucial advances: i) extending our photoexcitation to the far-infrared for creating few-cycles electromagnetic pulses and exciting structural or electronic collective modes; ii) upgrading our detection to higher sensitivity and spatial resolution, extending our ability to image spin and charge distributions.","1994385","2019-03-01","2024-02-29"
"ISLAS","Isotopic links to atmopheric water's sources","Harald SODEMANN","UNIVERSITETET I BERGEN","The hydrological cycle, with its feedbacks related to water vapour and clouds, is the largest source of uncertainty in weather prediction and climate models. Particularly processes that occur on scales smaller than the model grid lead to errors, which can compensate one another, making them difficult to detect and correct for. Undetectable compensating errors critically limit the understanding of hydrological extremes, the response of the water cycle to a changing climate, and the interpretation of paleoclimate records. Stable water isotopes have a unique potential to serve as the needed constraints, as they provide measures of moisture origin and of the phase change history. We have recently spearheaded a revised view of the atmospheric water cycle, which highlights the importance of connections on a regional scale. This implies that in some areas, all relevant processes can be studied on a regional scale. The Nordic Seas are an ideal case of such a natural laboratory, with distinct evaporation events, shallow transport processes, and swift precipitation formation. Together with recent technological advances in isotope measurements and in-situ sample collection, this will allow us to acquire a new kind of observational data set that will follow the history of water vapour from source to sink. The high-resolution, high-precision isotope data will provide a combined view of established and novel natural isotopic source tracers and set new benchmarks for climate models. A unique palette of sophisticated model tools will allow us to decipher, synthesize and exploit these observations, and to identify compensating errors between water cycle processes in models. In ISLAS, my team and I will thus make unprecedented use of stable isotopes to provide the sought-after constraints for an improved understanding of the hydrological cycle in nature and in climate models, leading towards improved predictions of future climate.","1999054","2018-08-01","2023-07-31"
"ISOCORE","New isotope tracers for core formation in terrestrial planets","Thorsten Kleine","WESTFAELISCHE WILHELMS-UNIVERSITAET MUENSTER","This proposal aims to develop new isotopic tools designed to constrain the core formation process in the Earth. We will use isotopic fractionations imparted by metal-silicate equilibration during core formation to obtain new and firm constraints on (i) the physical and chemical processes during formation of the Earth's core; and (ii) on the origin of volatile elements and the volatile accretion history of the Earth. The underlying concept of our  approach is to compare observed mantle-core isotopic fractionations (determined on natural samples) to the experimentally-determined isotope fractionation between liquid metal (core analogue) and liquid silicate (mantle analogue). Since the magnitude of isotope fractionation is strongly temperature-dependent, this comparison will enable us to evaluate core formation temperatures. I propose to use the stable isotope systematics of W, Mo and Cr to assess as to whether core formation temperatures for the Earth, Moon, Mars and asteroids are different, as would be expected if metal segregation in the Earth involved metal-silicate equilibration in a deep magma ocean. If instead all bodies have similar core formation temperatures, then formation of the Earth's core most probably involved some disequilibrium induced by direct core mergers during accretion from differentiated bodies. The second major theme of the proposed research uses Ge and Sb stable isotopes to trace the origins of Earth's volatiles. The combined investigation of Ge and Sb isotope fractionations in natural samples and metal-silicate equilibration experiments will enable us to determine as to whether Ge and Sb, and with them other volatile elements, show an isotope signature resulting from core formation. Identifying such a signature would provide the unequivocal evidence that volatile elements were delivered to the Earth during core formation and not subsequently, after the core had formed.","1940040","2014-02-01","2019-10-31"
"IsoMS","Mass Spectrometry of Isomeric Ions","Jana Roithova","STICHTING KATHOLIEKE UNIVERSITEIT","Mass spectrometry (MS) in combination with electrospray ionization (ESI) is one of the principal tools currently used to gain insight into newly developed catalytic reactions. It is used to identify key reaction intermediates and to study their structure and reactivity. This proposal is based on the combination of modern MS approaches with novel experiments in a unique cryo-trapping instrument. This combination allows the study of short-lived ionic species that cannot be studied by other known methods. Our distinguishing feature is the in situ helium-tagging of ions, which allows us to record their infrared spectra via a pre-dissociation technique. Here, we will go beyond this state-of-the-art approach in two directions:
(1) The unparalleled advantage of ESI-MS is its high sensitivity to low-abundant and reactive species. The pertinent question at the heart of all reaction mechanism investigations via MS is how the ions found in the gas-phase relate to the condensed-phase reaction. We will address this question using “Delayed Reactant Labelling”, which will directly link condensed phase kinetics to the abundance of isolated gaseous ions. 
(2) We will take advantage of long storage times in our cryogenic linear quadrupole trap and expand the portfolio of the methods available to address mixtures of ions with the same mass. Isobaric mixtures are resolved in MS by differences in ion mobilities, i.e. the ions are separated by their mass-to-charge ratios and by their shapes. We will perform ion mobility separation directly in the trap by excitation of the ion secular motion using a resonant dipolar electric field. Further, we will combine cryo-trapping experiments with the probing or modifying of the stored ions by reactive collisions with neutral molecules. The mobility experiments and the reactivity probing will be routinely combined with spectroscopic experiments.","1612500","2016-07-01","2021-06-30"
"ISOREE","New insight into the origin of the Earth, its bulk composition and its early evolution","Maud Boyet","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The main geochemical features of the mantles of terrestrial planets and asteroids can be attributed to differentiation events that occurred during or shortly after the formation of the Solar System. Numerous questions remain regarding the Earth’s bulk composition and the most likely scenario for its evolution prior to the last major differentiation event caused by a giant impact leading to the formation of the Moon. The aim of this five-year project is to evaluate the state-of-the-art models of the Earth’s early evolution with the following main objectives: (i) Defining precisely the age of the Moon’s formation, (ii) Refining the giant impact model and the Earth-Moon relationship, (iii) Dating the successive magmatic ocean stages on Earth, and (iv) Constraining the Earth mantle’s composition in terms of rare earth element concentrations. These different questions will be addressed using trace elements, radiogenic isotopic systematics (146Sm-142Nd, 147Sm-143Nd, 138La-138Ce) and stable isotopes. ISOREE is a multi-disciplinary project that combines isotope and trace element geochemistry, experimental geochemistry and spectroscopy. A large number of samples will be analysed, including terrestrial rocks with ages up to 3.8 Ga, chondrites, achondrites and lunar samples. 

This proposal will provide the tools to tackle a vast topic from various angles, using new methodologies and instrumentation and promoting innovation and creativity in European research. This research program is essential to further constrain the major events that occurred very early on in the Earth’s history, such as the Earth’s cooling, its crustal growth, the surface conditions and development of potential habitats for life.","2200000","2016-09-01","2021-08-31"
"ITUL","Information Theory with Uncertain Laws","Albert GUILLÉN I FÀBREGAS","UNIVERSIDAD POMPEU FABRA","Shannon's Information Theory paved the way for the information era by providing the mathematical foundations of digital information systems. A key underlying assumption of Shannon's key results is that the probability law that governing system is known, allowing to optimize the codebook and decoder accordingly. 

There are a number of important situations where perfectly estimating the system law is impossible; in these situations the codebook and decoder must be designed without complete (or no) knowledge of the system law.
The vast majority of the Information Theory literature makes strong simplifying assumptions on the model. Theoretical studies that provide a general treatment of information processing with uncertain laws are hence urgently needed. For general systems, standard asymptotic techniques cannot be invoked and new techniques must be sought. A fundamental understanding of the impact of uncertainty in general systems is crucial to harvesting the potential gains in practice. 

This project is aimed at contributing towards the ambitious goal of providing a unified framework for the study of Information Theory with uncertain laws. A general framework based on hypothesis testing will be developed and code designs and constructions that naturally follow from the hypothesis testing formulation will be derived.
This unconventional and challenging treatment of Information Theory will advance the area and will contribute to Information Sciences and Systems disciplines where Information Theory is relevant.

A comprehensive study of the fundamental limits and optimal code design with law uncertainty for general models will represent a major step forward in the field, with the potential to provide new tools and techniques to solve open problems in close disciplines. Therefore, the outcomes of this project will not only benefit communications, but also areas such as probability theory, statistics, physics, computer science and economics.","1888033","2017-08-01","2022-07-31"
"JetDynamics","High precision multi-jet dynamics at the LHC","Simon David BADGER","UNIVERSITY OF DURHAM","Precision tests at high energy colliders are an essential tool for gaining insight
into the nature of the Standard Model of particle physics and the fundamental interactions. The data currently being obtained by the LHC experiments will allow a large number of observables to be measured at a percent level accuracy. This data has the potential to probe deeper into the flaws of the Standard Model. However, the complexity of theoretical predictions using perturbative quantum field theory currently prevents many of these precision tests.

JetDynamics aims for a breakthrough in precision predictions for the measurements of Standard Model interactions through the study of the dynamics of multiple strongly interacting hadronic jets. Percent level predictions for 2 to 3 scattering processes involving the Higgs boson and electroweak vector bosons will allow a unique insight into fundamental properties of the Standard Model in the new high energy region probed by the LHC.

In order to achieve this goal a complete set of quantum corrections at next-to-next-to-leading order (NNLO) in perturbation theory are required. JetDynamics bridges the gap between mathematics physics and experimental collider physics and will develop a new generation of computational tools and methods} that will overcome current bottlenecks. The work program attacks this problem on two fronts:

A) Develop revolutionary new ideas from the study of on-shell scattering amplitudes to address the current bottlenecks in the computation of multi-leg two loop amplitudes in QCD.

B) Develop highly efficient tools for NNLO predictions with multi-jet final states and perform precision phenomenological studies of jet dynamics at the LHC.

C) Lay groundwork for jet production beyond NNLO and build towards 1% perturbative accuracy.

JetDynamics will lead to a new understanding of scattering at hadron colliders and take LHC physics into a new precision era.","1764478","2018-06-01","2023-05-31"
"JetNS","Relativistic Jets in Astrophysics -Compact binary mergers, Gamma-Ray Bursts, and Beyond","Ehud Nakar","TEL AVIV UNIVERSITY","What is the origin of the electromagnetic (EM) counterparts of gravitational waves observed from compact binary mergers? What makes short gamma ray bursts (GRBs)? What are the sources of IceCube’s high-energy neutrinos? Are all core-collapse supernovae exploding via the same mechanism? These are some of the puzzles that have emerged with the rapid progress of time domain astronomy. Relativistic jets in compact binary mergers and GRBs, and their interaction with the surrounding media hold the key to these, and other, seemingly unrelated broad-impact questions. Here I propose a new forefront study of how relativistic jets interact with their surrounding media and of its numerous implications, focusing on compact binary mergers and GRBs.
The goal of this project is to study, first, the jet-media interaction, and the microphysics of the radiation-mediated shocks that it drives. I will then use the results, together with available observations, to learn about compact binary mergers, GRBs and SNe, sheding light on the questions listed above, and probing the nature of relativistic jets in general. Important goals will include: (i) General models for the propagation of relativistic jets in various media types. (ii) Modeling of the EM signal generated by jet-media interaction following compact binary mergers. (iii) Estimates of the neutrino signal from jet-media interaction in GRBs and SNe. (iv) Constraint the role of jets in SN explosions. 
This project is timey as it comes at the beginning of a new multi-messenger era where the EM counterparts of GW sources are going to be detected on a regular basis and where the face of transient astrophysics is going to be changed by a range of large scale surveys such as LSST, the SKA, and more. This project will set the theoretical base for understanding numerous known and yet-to be discovered transients that will be detected in the next decade.","1981250","2019-01-01","2023-12-31"
"JointPrinting","3D Printing of Cell Laden Biomimetic Materials and Biomolecules for Joint Regeneration","Daniel John Kelly","THE PROVOST, FELLOWS, FOUNDATION SCHOLARS & THE OTHER MEMBERS OF BOARD OF THE COLLEGE OF THE HOLY & UNDIVIDED TRINITY OF QUEEN ELIZABETH NEAR DUBLIN","Osteoarthritis (OA) is a serious disease of the joints affecting nearly 10% of the population worldwide. Realising an efficacious therapeutic solution for treating OA remains one of the greatest challenges in the field of orthopaedic medicine. This proposal envisions a future where 3D bioprinting systems located in hospitals will provide ‘off-the-shelf’, patient-specific biological implants to treat diseases such as OA. To realise this vision, this project will use 3D bioprinting to generate anatomically accurate, biomimetic constructs that can be used to regenerate both the cartilage and bone in a diseased joint. The first aim of this proposal is to print a mesenchymal stem cell laden biomaterial that is both immediately load bearing and can facilitate the regeneration of articular cartilage in vivo, such that the bioprinted construct will not require in vitro maturation prior to implantation. Mechanical function will be realised by integrating an interpenetrating network hydrogel into a 3D printed polymeric scaffold, while chondro-inductivity will be enhanced by the spatially-defined incorporation of cartilage extracellular matrix components and chondrogenic growth factors into the bioprinted construct. The second aim of the proposal is to use 3D bioprinting to create a cell-free, composite construct to facilitate regeneration of the bony region of a large osteochondral defect, where vascularization will be accelerated by immobilizing spatial gradients of vascular endothelial growth factor into the implant. The third aim of the proposal is to scale-up the proposed 3D bioprinted construct to enable whole joint regeneration. Finite element modelling will be used determine the optimal structural characteristics of the scaled-up implant for it to fulfil its required mechanical function. If successful, such an implant would form the basis of a truly transformative therapy for treating degenerative joint disease.","1999700","2015-09-01","2020-08-31"
"justITSELF","Just-in-time Self-Verification of Autonomous Systems","Matthias ALTHOFF","TECHNISCHE UNIVERSITAET MUENCHEN","Engineers and computer scientists are currently developing autonomous systems whose entire set of behaviors in future, untested situations is unknown: How can a designer foresee all situations that an autonomous road vehicle, a robot in a human environment, an agricultural robot, or an unmanned aerial vehicle will face? Keeping in mind that all these examples are safety-critical, it is irresponsible to deploy such systems without testing all possible situations---this, however, seems impossible since even the most important possible situations are unmanageably many. I propose a paradigm shift that will make it possible to guarantee safety in unforeseeable situations: Instead of verifying the correctness of a system before deployment, I propose just-in-time verification, a new, to-be-developed verification paradigm where a system continuously checks the correctness of its next action by itself in its current environment (and only in it) in a just-in-time manner. Since future autonomous systems will have a tight interconnection of discrete computing and continuous physical elements, also known as cyber-physical systems, I will develop just-in-time verification for this system class. In order to prove correct behavior of cyber-physical systems, I will develop new formal verification techniques that efficiently compute possible future behaviors---subject to uncertain initial states, inputs, and parameters---within a small time horizon. Just-in-time verification will substantially cut development costs, increase the autonomy of systems (e.g., the range of deployment of automated driving systems), and reduce or even eliminate certain liability claims. The results will be implemented in an open-source software framework and will be primarily demonstrated for automated driving. Successful development of just-in-time verification techniques is yet more challenging than offline verification of autonomous systems, but expected to bring even greater rewards.","1999075","2019-07-01","2024-06-30"
"K3CRYSTAL","Moduli of Crystals and K3 Surfaces","Christian Liedtke","TECHNISCHE UNIVERSITAET MUENCHEN","Algebraic geometry deals with algebraic varieties, that is, systems of polynomial equations and their geometric interpretation. Its ultimate goal is the classification of all algebraic varieties. For a detailed understanding, one has to construct their moduli spaces, and eventually study them over the integers, that is, in the arithmetic situation. So far, the best results are available for curves and Abelian varieties.

To go beyond the aforementioned classes, I want to study arithmetic moduli spaces of the only other classes that are currently within reach, namely, K3 surfaces, Enriques surfaces, and Hyperkähler varieties. I expect this study to lead to finer invariants, to new stratifications of moduli spaces, and to open new research areas in arithmetic algebraic geometry. 

Next, I propose a systematic study of supersingular varieties, which are the most mysterious class of varieties in positive characteristic. Again, a good theory is available only for Abelian varieties, but recently, I established a general framework via deformations controlled by formal group laws. I expect to extend this also to constructions in complex geometry, such as twistor space, which would link so far completely unrelated fields of research.

I want to accompany these projects by developing a general theory of period maps and period domains for F-crystals, with an emphasis on the supersingular ones to start with. This will be the framework for Torelli theorems that translate the geometry and moduli of K3 surfaces, Enriques surfaces, and Hyperkähler varieties into explicit linear algebra problems, thereby establishing new tools in algebraic geometry.","1328710","2016-10-01","2021-09-30"
"KERNEL","Ultimate Angular Resolution Astrophysics with kernel-phase and full-aperture interferometry","Frantz Martinache","","Astronomy requires large telescopes to improve the sensitivity and the angular resolution of its observations. Of these qualities, angular resolution is the most difficult to maintain in the optical and near-infrared, since the atmosphere reduces it to that of a 10 cm aperture, regardless of the telescope size. On the one-hand, Adaptive Optics (AO) actively compensates for this effect but the improvement is often partial only. On the other hand, interferometric techniques (most notably sparse aperture masking interferometry) passively allow the extraction of self-calibrating observables, that boost the angular resolution, but severely affect the sensitivity of observations. A framework newly established by the PI of the proposal however now makes it possible to extract generalized self-calibrating observables called kernel-phases from conventional AO-corrected images. The work outlined in this proposal will make it possible to scientifically exploit the high angular resolution imaging capability of this technique, to improve its robustness and to expand its capabilities. The framework offers a very general purpose high angular resolution imaging tool for astronomers as well as wavefront control experts. This proposal is organized in five work-packages of increasing challenge that include: the reinterpretation of existing archival data
with a super-resolution capability, the expansion of its robustness to open up new more challenging use-cases, a special focus on the development of a very high-dynamic range mode, the adaptation of interferometric image reconstruction techniques, and the development of new advanced AO concepts. The consequences of this project will have a major impact on the design and scientific exploitation of future high angular resolution instrumentation on the existing generation of 8-10 meter class telescopes as well as on the upcoming generation of 30-40 meter giants, championned by Europe and its E-ELT.","1717811","2016-10-01","2021-09-30"
"KETJU","Post-Newtonian modelling of the dynamics of supermassive black holes in galactic-scale hydrodynamical simulations (KETJU)","Peter JOHANSSON","HELSINGIN YLIOPISTO","Supermassive black holes (SMBHs) with masses in the range ~10^6-10^10 M⊙ are found at the centres of all massive galaxies in the Local Universe. In the ΛCDM picture of structure formation galaxies grow bottom-up through mergers and gas accretion, leading to multiple SMBHs in the same stellar system. Current simulation codes are unable to resolve in a single simulation the full SMBH merging process, which involves dynamical friction, three-body interactions and finally gravitational wave (GW) emission. KETJU will provide a significant breakthrough in SMBH research by following for the first time accurately global galactic-scale dynamical and gaseous astrophysical processes, while simultaneously solving the dynamics of SMBHs, SMBH binaries and surrounding stellar systems at sub-parsec scales. Our code KETJU (the word for 'chain' in Finnish) is built on the GADGET-3 code and it includes regions around every SMBH in which the dynamics of SMBHs and stellar particles is modelled using a non-softened Post-Newtonian algorithmic chain regularisation technique. The remaining simulation particles far from the SMBHs are evolved using softened GADGET-3. Using KETJU we can study at unprecedented accuracy the dynamics of SMBHs to separations of ~10 Schwarzschild radii, the formation of cores in massive galaxies, the formation of nuclear stellar clusters and finally provide a realistic prediction for the amplitude and frequency distribution of the cosmological gravitational wave background. The UH theoretical extragalactic team is ideally suited for this project, as it has an unusually versatile background in modelling the dynamics, feedback and merging of SMBHs. KETJU is also particularly timely, as the spectacular direct detection of GWs in 2016 is paving the way for a new era in gravitational wave astronomy. Future space-borne GW observatories, such as the European Space Agency's LISA, require accurate global GW predictions in order to fully realise their science goals.","1953569","2019-07-01","2024-06-30"
"LACOPAROM","Lewis acid promoted copper catalysis to functionalise and dearomatise arenes","Syuzanna HARUTYUNYAN","RIJKSUNIVERSITEIT GRONINGEN","Aromatic compounds are cheap and readily available, making them ideal starting materials for the synthesis of chiral alicyclic compounds, important synthetic building blocks for both natural product synthesis and drug discovery. However, general strategies for efficient, catalytic dearomatisation of aromatics are lacking.
 
This proposal aims to fill this gap by developing general asymmetric methods for dearomatisation reactions of both electron-rich and electron-deficient aromatics. It relies on an innovative approach based on LA activation of the arenes, followed by copper catalyzed carbon-carbon bond forming reactions, with a special focus on environmentally benign and cost-effective processes.
 
To achieve the overall aim of the proposed project, the research program is composed of four distinct but complementary research lines aiming at catalytic asymmetric dearomatisation/carbon-carbon bond forming reactions using:
 
-         Electron-deficient carbonyl substituted arenes
-         Pyridines and other N-containing heteroarenes
-         Phenols and anilines and fused analogues
-         Benzylic aromatic systems
 
The remarkable and novel feature of this strategy is that it enables for the first time selective catalytic asymmetric dearomatisations of various classes of aromatic substrates following a general, unified concept. Furthermore, since sequential bond constructions take place in a single synthetic operation, a rapid increase of molecular complexity can be achieved at greatly reduced cost and increased atom-efficiency, thereby contributing to a more sustainable future. Consequently, there is huge potential for this strategy to become an invaluable instrument to access a wide variety of chiral carbocyclic compounds and I anticipate it will have a significant impact in the field of organic synthesis.","1999398","2018-09-01","2023-08-31"
"LactaDiff","Assessing cellular compartmentation of brain lactate using diffusion MR spectroscopy in vivo","Julien VALETTE","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","The idea has emerged that compartmentation of brain lactate, i.e. its distribution between different cell types and the extracellular space, plays a critical role in neurotransmission and brain plasticity. Dysregulations of lactate metabolism have also been reported in neurodegenerative diseases such as Alzheimer's disease. However, these notions remain challenged, and even fundamental mechanisms such as the astrocyte-to-neuron lactate shuttle, whereby astrocytes are supposed to export lactate to neurons to sustain neuronal energy needs, are still fiercely debated. This is largely due the lack of tools to evaluate cell-specific compartmentation of lactate in the living brain, in particular in Humans.
In this project, we will develop new nuclear magnetic resonance spectroscopy techniques to non-invasively measure lactate diffusion, including in cortical regions. We will then take advantage of the unique ability of these methods to differentiate between metabolites diffusing in different environments, based on diffusion properties imposed by the microstructure, to quantify lactate in the extracellular space and, most importantly, in neurons and astrocytes. After validation in rodent models, these methods will be transposed on a clinical MRI system at ultra-high magnetic field, to gain unprecedented access to lactate compartmentation in the Human brain and its modifications during brain activity, plasticity, and in Alzheimer's disease. This will open a new research field for magnetic resonance spectroscopy in vivo.","1999868","2019-05-01","2024-04-30"
"LaDIST","Large Discrete Structures","Daniel Kral","Masarykova univerzita","The proposed project seeks to introduce novel methods to analyze and approximate large graphs and other discrete structures and to apply the developed methods to solve specific open problems. A need for such methods comes from computer science where the sizes of input structures are often enormous. Specifically, the project will advance the recently emerged theory of combinatorial limits by developing new insights in the structure of limit objects and by proposing a robust theory bridging the sparse and dense cases. The analytic methods from the theory of combinatorial limits will be used to analyze possible asymptotic behavior of large graphs and they will be applied in conjunction with structural arguments to provide solutions to specific problems in extremal combinatorics. The obtained insights will also be combined with methods from discrete optimization and logic to provide new algorithmic frameworks.","1386859","2015-12-01","2020-11-30"
"LASSO","Layered semiconductors and hybrid systems for quantum optics and opto-valleytronics","Alexander HOEGELE","LUDWIG-MAXIMILIANS-UNIVERSITAET MUENCHEN","A new resource for quantum information processing has emerged recently in the form of the valley pseudospin in layered transition metal dichalcogenides. By virtue of strong spin-orbit and Berry curvature effects, these non-centrosymmetric crystals provide a quantum optical interface between spin- and valley-polarized electrons and circularly polarized photons. Such valley-contrasting optical selection rules in turn establish means to address the multivalley quantum resource all-optically. At this interface, where light meets valley quantum states of matter, the proposed research will aim at tailoring and mastering electron-hole-pair excitations and their coupling to photons in layered transition metal dichalcogenide semiconductors, heterostructures and hybrid systems. The project will combine semiconductor monolayers with ferroelectric and ferromagnetic supports to achieve synthetic opto-valleytronic functionality of substrate-modified excitons for the development of novel linear, non-linear and chiral quantum optical elements. Reciprocally, interfacial effect of the substrate on the valley dynamics of monolayer excitons will be utilized for the development of quantum-enhanced imaging of ferroic domain textures to facilitate fundamental studies of phase transitions in condensed matter systems. In parallel, we will develop on chip-circuitry to control long-lived dipolar excitons in hetero-bilayer semiconductors. Finally, light-matter quasiparticles in the form of exciton-polaritons with weak and strong mutual interactions in monolayer- and heterobilayer-cavity systems will be created, engineered and condensed at ultra-low temperatures into a macroscopic ground state. The realization of interacting polariton gases and condensates, paired with the opto-valleytronic phenomena inherent to layered transition metal dichalcogenides, will contribute topologically protected polaritons to the realm of systems with an integral role in all-optical quantum science and technology.","1996291","2019-01-01","2023-12-31"
"LATO","Large-Area Transparent Opto-Electronics using 2D Materials","Jamie Hans WARNER","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","Research in 2D materials has increased dramatically since the first isolation of graphene in 2004, with diverse interdisciplinary studies. In the last few years, 2D material research expanded beyond graphene by the development of other 2D materials, such as monolayered transition metal dichalcogenides, black phosphorous, and Boron Nitride. There are hundreds of possible 2D crystals that can be isolated, with properties ranging from metallic, semi-metallic, semiconducting to insulating, depending on the material composition. Semiconducting 2D materials have attracting interest in next-generation electronics/opto-electronics such as transistors, photo-gated transistors, photo-detectors, solar cells, and light emitting devices (LEDs), molecular sensors and optical imaging sensors. The unique structural form of 2D materials provides several benefits over other existing materials: ultrathin, flexible, highly transparent, large surface to volume ratio, and 2D quantum confinement. High transparency LEDs are required for applications in transparent displays on glass panels. Many 2D based opto-electronic devices have used mechanical exfoliation from bulk crystals, but this is limited to small areas. Recent work on chemical vapour deposition (CVD) to grow wafer-scale 2D materials has opened up exciting opportunities for commercial exploitation and has accelerated the intensity of research in this field towards real applications. The vision of this proposal is to realize a new class of ultra-thin, flexible, large-area, transparent, high-sensitivity opto-electronic device arrays based on all 2D materials, with a focus on imaging sensors and LEDs. This will involve wafer-scale CVD synthesis of 2D materials including novel blue and green 2D semiconductors, optical spectroscopy to probe the interlayer interactions, atomic level structure-property correlations using advanced electron microscopy, and the nanoscale fabrication and testing of high efficiency devices.","1999318","2017-04-01","2022-03-31"
"LBCAD","Lower bounds for combinatorial algorithms and dynamic problems","Michal Koucky","UNIVERZITA KARLOVA","This project aims to establish the time complexity of algorithms for two classes of problems. The first class consists of problems related to Boolean matrix multiplication and matrix multiplication over various semirings. This class contains problems such as computing transitive closure of a graph and determining the minimum distance between all-pairs of nodes in a graph. Known combinatorial algorithms for these problems run in slightly sub-cubic time. By combinatorial algorithms we mean algorithms that do not rely on the fast matrix multiplication over rings. Our goal is to show that the known combinatorial algorithms for these problems are essentially optimal. This requires designing a model of combinatorial algorithms and proving almost cubic lower bounds in it.

The other class of problems that we will focus on contains dynamic data structure problems such as dynamic graph reachability and related problems. Known algorithms for these problems exhibit trade-off between the query time and the update time, where at least one of them is always polynomial. Our goal is to show that indeed any algorithm for these problems must have update time or query time at least polynomial.

The two classes of problems are closely associated with so called 3SUM problem which serves as a benchmark for uncomputability in sub-quadratic time. Our goal is to deepen and extend the known connections between 3SUM, the other two classes and problems like formula satisfiability (SAT).","900200","2014-02-01","2019-01-31"
"LDMThExp","Going Beyond the WIMP: From Theory to Detection of Light Dark Matter","Tomer Volansky","TEL AVIV UNIVERSITY","The identity of dark matter (DM) is still unknown. For more than three decades, significant theoretical and experimental efforts have been directed towards the search for a Weakly Interacting Massive Particle (WIMP), often overlooking other possibilities. The lack of an unambiguous positive signal, at indirect- and direct-detection experiments and at the LHC, stresses the need to expand on other theoretical possibilities, and more importantly, to develop new experimental capabilities. Indeed it is conceivable that the WIMP paradigm has been misleading, and other theoretically motivated scenarios must be explored vigorously.
    This proposal focuses on light, sub-GeV dark matter. In addition to novel theoretical paradigms that point to DM in the low-mass regime, several new strategies to directly detect dark matter particles with MeV to GeV mass, far below standard direct detection capabilities, are studied. In particular, techniques to search for ionized electrons or chemical bond-breaking are considered. The latter possibility is revolutionary and requires new dedicated technologies and experiments. Sensitivity to one or few electrons, on the other hand, has been established and the PI has recently derived the first direct-detection limits on MeV to GeV dark matter using XENON10 data, demonstrating proof-of-principle. Significant efforts are required to lay the theoretical foundation of light DM and to study in depth and develop the various possibilities to directly detect it. The proposal is centered around these efforts.
    The innovative theoretical paradigms and novel avenues to experimentally detect sub-GeV DM, open up a new and groundbreaking field of research. The proposal at hand takes the necessary steps, and offers the opportunity to pave the way and enable the discovery of such a particle, if it exists.","1822083","2016-03-01","2022-02-28"
"Learn","Learning From Failing and Passing Executions At the Speed of Internet","Leonardo Mariani","UNIVERSITA' DEGLI STUDI DI MILANO-BICOCCA","Modern software systems must be extremely flexible and easily adaptable to different user needs and environments. However, this flexibility also introduces relevant quality issues. These problems are so common that is sufficient browsing the Web to find millions of reports about failures observed after updates and incompatibilities caused by the interaction of a newly installed component with the existing components. 

The impact of problems introduced by end-users can be dramatic because end-users can easily modify applications, like developers do, but end-users have neither the knowledge nor the skill of developers, and they cannot debug and fix the problems that they unintentionally introduce. It is thus necessary to timely develop novel solutions that can increase the reliability of the moderns systems, which can be extended and adapted by end-users, with the capability to automatically address problems that are unknown at development-time.

The Learn project aims to produce innovative solutions for the development of systems that can work around the problems introduced by end-users when modifying their applications. The three key elements introduced by Learn to automatically produce a (temporary) fix for the software are: (1) the definition of the InternetLearn infrastructure, which is a network infrastructure that enables communication between every individual instance of a same program running at different end-users’ sites, thus augmenting each application with the capability to access a huge amount of information collected in-the-field from other sites; (2) the definition of analysis techniques that can learn the characteristics of successful and failed runs by monitoring executions in the field from a number of instances running at many end-user sites; and (3) the definition of techniques for the automatic generation and actuation of temporary fixes on an Internet (World) scale.","1141875","2015-10-01","2019-09-30"
"LEGA-C","The Physics of Galaxies 7 Gyr Ago","Arjen Van der wel","UNIVERSITEIT GENT","Over the past decade, redshift
surveys and multi-wavelength imaging campaigns have drawn up an
empirical picture of how many stars had formed in which types of
galaxies over the history of the universe.  However, we have yet to
unravel the individual pathways along which galaxies evolve, and the
physical processes that drive them.  Continuing with the previous
approach -- larger and deeper photometric samples -- is not adequate
to achieve this goal.  A change of focus is required.

In this ERC project I will embark on a new way to address the question
of galaxy evolution.  I will do so as Principle Investigator of the
recently approved LEGA-C observing program that has been allocated 128
nights of observation time over the next 4 years with ESO's flagship
facility the Very Large Telescope.  This new survey will produce for
2500 distant (at z~1) galaxies with, for the first time,
sufficient resolution and S/N to measure ages and chemical
compositions of their stellar populations as well as internal velocity
dispersions and dynamical masses.  This will provide an entirely new
physical description of the galaxy population 7 Gyr ago, with which I
will finally be able solve long-standing questions in galaxy formation
that were out of reach before: what is the star-formation history of
individual galaxies, why and how is star-formation ``quenched'' in
many galaxies, and to what extent do galaxies grow subsequently
through merging afterward?

LEGA-C is worldwide the largest spectroscopic survey of distant
galaxies to date, and ERC funding will be absolutely critical in
harvesting this unparallelled database.  I am seeking to extend my
research group to realize the scientific potential of this substantial
investment (6.5M Eur) of observational resources by the European
astronomy community.  Timing of the execution of the VLT program is
perfectly matched with the timeline of this ERC program.","1884875","2016-04-01","2021-03-31"
"LEGO","Multimodal glycoconjugates: a molecular Lego approach for antitumoral immunotherapy","Olivier Pierre Renaudet","UNIVERSITE GRENOBLE ALPES","Despite significant progress in cancer therapy, current treatments are still controversial due to intolerable side effects. Targeted immunotherapy has recently emerged as an ideal alternative to improve treatment modalities for cancers patients. However, very limited approaches are available today and major issues remain to be addressed. The ERC grant offers a unique opportunity to propose a new paradigm for treating cancer. Through a ground-breaking interdisciplinary program, at the crossroad of supramolecular chemistry, synthetic chemistry, molecular engineering, biophysics, biochemistry, immunochemistry and glycoscience, it is my ambition to design, synthesize and study smart biomolecular structures with unprecedented combinations, complexity and immunological properties against cancers. To achieve this purpose, I will develop a “molecular LEGO” approach to construct synthetic molecules capable of redirecting endogenous antibodies present in the human bloodstream against tumors without preliminary immunization. Efficient tumoral killing by immune effectors will be provided by molecules combining innovative antibody and tumor binding modules that will be selected in vitro beforehand. To be successful, I will address fundamental questions that are still unresolved in chemical and biological sciences. The expected breakthroughs will represent a landmark achievement in these fields and will open promising horizons in cancer immunotherapy. Beyond this, it can be expected that our findings will pave the way to future development of synthetic molecules embedded with recognition, labeling, and/or therapeutic functions. They will thus find wider medicinal, diagnostic and even theranostic applications for which the development of more effective and selective biomolecular systems is of the utmost importance.","2000000","2015-09-01","2020-08-31"
"LEMAN","Deep LEarning on MANifolds and graphs","Michael Bronstein","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","The aim of the project is to develop a geometrically meaningful framework that allows generalizing deep learning paradigms to data on non-Euclidean domains. Such geometric data are becoming increasingly important in a variety of fields including computer graphics and vision, sensor networks, biomedicine, genomics, and computational social sciences. Existing methodologies for dealing with geometric data are limited, and a paradigm shift is needed to achieve quantitatively and qualitatively better results. 

Our project is motivated by the recent dramatic success of deep learning methods in a wide range of applications, which has literally shaken the academic and industrial world. Though these methods have been known for decades, the computational power of modern computers, availability of large datasets, and efficient optimization methods allowed creating and effectively training complex models that made a qualitative breakthrough. In particular, in computer vision, deep neural networks have achieved unprecedented performance on notoriously hard problems such as object recognition. However, so far research has mainly focused on developing deep learning methods for Euclidean data such as acoustic signals, images, and videos. In fields dealing with geometric data, the adoption of deep learning has been lagging behind, primarily since the non-Euclidean nature of objects dealt with makes the very definition of basic operations used in deep networks rather elusive. 

The ambition of the project is to develop geometric deep learning methods all the way from a mathematical model to an efficient and scalable software implementation, and apply them to some of today’s most important and challenging problems from the domains of computer graphics and vision, genomics, and social network analysis. We expect the proposed framework to lead to a leap in performance on several known tough problems, as well as to allow addressing new and previously unthinkable problems.","1997875","2017-10-01","2022-09-30"
"LENSNOVA","Cosmic Fireworks Première: Unravelling Enigmas of Type Ia Supernova Progenitor and Cosmology through Strong Lensing","Sherry Hsuan SUYU","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","The LENSNOVA project proposes a breakthrough both in cosmology and stellar physics, capitalising on 10 years of experience in the field of strong lensing time delays. Type Ia supernovae (SNe Ia) can now be watched on prime seats through strong lensing, where multiple images of the same SN appear at different times/locations around a foreground lens galaxy. After the first SN appears, the next SN occurrence (of the same SN event) can be predicted and observed in its entirety for the first time in history and with unprecedented temporal sampling. Observations of the beginning of SN explosions are key to revealing SN progenitors, that have been under debate for decades. Strongly lensed SNe Ia also allow an independent measurement of the Hubble constant (H0) that sets the cosmic expansion rate. The independent measurement is important to ascertain the possible need of new physics beyond the standard cosmological model, given the tensions in current H0 measurements. Capitalising on the PI’s expertise in strong lensing and success in predicting the reappearance of the first strongly lensed core-collapse SN, the objectives of LENSNOVA are to (1) place the best constraints on SNe Ia progenitors, and (2) pioneer the use of strongly lensed SNe Ia as a new cosmological probe. This will shed light on the natures of SNe Ia progenitors and dark energy, two of the greatest puzzles in the present era.
The advent of the Large Synoptic Survey Telescope and the Euclid mission makes LENSNOVA particularly timely for building the first sample of ~5 strongly lensed SNe Ia. Accurate predictions of the time delays in lensed SNe Ia will allow multiwavelength observations of the reappearances of SNe, especially in the earliest days of explosion for the first time, to place the best constraints on SN progenitors. These lensed SNe Ia will also potentially yield an H0 measurement with 2% uncertainty. LENSNOVA has thus the potential to revolutionise both fields of stellar physics and cosmology.","1992500","2018-06-01","2023-05-31"
"LEON","Compact THz lasers based on graphene quantum dots","Juliette MANGENEY","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The ambition of this project is to open new horizons in the field of graphene-based devices for THz technology. The major objective is to develop compact THz amplifiers and lasers operating at room temperature, analogous to the concept of semiconductor lasers in the visible and telecom wavelength range. 
THz radiation is extremely attractive for fundamental investigations of matter and emerging applications including, for example, security screening, medical imaging and spectroscopy. However, the THz spectral range remains one of the least exploited spectral regions, mainly due to the lack of compact powerful sources. The development of the typical semiconductor-laser scheme emitting at THz frequencies has been seriously hampered by the absence of an appropriate material with a sufficiently small bandgap. The LEON project addresses this technological and scientific blocking point with new semiconductor-laser schemes for THz emission centered on the integration of graphene-based materials. 
Indeed, graphene is potentially an excellent candidate for a THz semiconductor-laser model owing to its ‘zero’ bandgap. However, non-radiative recombination mechanisms, especially Auger recombination, reduce the lifetime of the optical gain to few hundreds of femtoseconds. This phenomenon drastically limits the feasibility of a THz laser. In order to suppress these detrimental non-radiative processes, a new concept is needed. The project proposes to exploit the full discretization of electronic states in graphene quantum dots. This high-risk high-gain project will provide important and far-reaching scientific advances, which cannot be achieved with the current state-of-the-art approaches.
This project has three major cornerstones: i) the demonstration of THz amplifiers based on graphene quantum dots, ii) the demonstration of THz lasers based on graphene quantum dots in a microcavity, iii) the exploitation of these THz amplifiers/lasers for security and communication applications.","1998596","2019-09-01","2024-08-31"
"LEXICAL","Lexical Acquisition Across Languages","Anna-Leena Korhonen","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Due to the growing volume of textual information available in multiple languages, there is a great demand for Natural Language Processing (NLP) techniques that can automatically process and manage multi-lingual texts, supporting information access and communication in core areas of society (e.g. healthcare, business, science). Many NLP tasks and applications rely on task-specific lexicons (e.g. dictionaries, word classifications) for optimal performance. Recently, automatic acquisition of lexicons from relevant texts has proved a promising, cost-effective alternative to manual lexicography. It has the potential to considerably enhance the viability and portability of NLP technology both within and across languages. However, this approach has been explored for a very small number of resource-rich languages only, leaving the vast majority of worlds’ languages without useful technology. The ambitious goal of this project is to take research in lexical acquisition to the level where it can support multi-lingual NLP, involving also languages for which no parallel language resources (e.g. corpora, knowledge resources) are available. Building on an emerging line of research which uses mainly naturally occurring supervision (connections between languages) to guide cross-lingual NLP, we will develop a radically novel approach to lexical acquisition. This approach will transfer lexical knowledge from one language to another as well as will learn it simultaneously for a diverse set of languages using new methodology based on guiding joint learning and inference with rich knowledge about cross-lingual connections. We not only aim to create next generation lexical acquisition technology but also aim to take cross-lingual NLP a big step toward to the direction where it is no longer dependent on parallel resources. We will use our approach to support fundamental tasks and applications aimed at broadening the global reach of NLP to areas where it is now critically needed.","1989203","2015-09-01","2020-08-31"
"LHCtoLISA","Precision Gravity: From the LHC to LISA","Rafael PORTO","STIFTUNG DEUTSCHES ELEKTRONEN-SYNCHROTRON DESY","The nascent field of gravitational wave (GW) science will be an interdisciplinary subject, enriching different branches of physics, yet the associated computational challenges are enormous. Faithful theoretical templates are a compulsory ingredient for successful data analysis and reliable physical interpretation of the signals. This is critical, for instance, to study the equation of state of neutron stars, the nature of black holes, and binary formation channels. However, while current templates for compact binary sources may be sufficient for detection and crude parameter estimation, they are too coarse for precision physics with GW data. We then find ourselves in a situation in which, for key processes within empirical reach, theoretical uncertainties may dominate. To move forward, profiting the most from GW observations, more accurate waveforms will be needed.
I have played a pioneering role in the development and implementation of a new formalism, known as the ‘effective field theory approach’, which has been instrumental for the construction of the state-of-the-art GW template bank. The goal of my proposal is thus to redefine the frontiers of analytic understanding in gravity through the effective field theory framework. Even more ambitiously, to go beyond the current computational paradigm with powerful tools which have been crucial for `new-physics' searches at the Large Hadron Collider. 
The impact of the high-accuracy calculations I propose to undertake will be immense: from probes of dynamical spacetime and strongly interacting matter, to the potential to discover exotic compact objects and ultra-light particles in nature. Furthermore, GW observations scan gravity in a regime which is otherwise unexplored. Consequently, the coming decade will tell whether Einstein's theory withstands precision scrutiny. In summary, my program will provide novel techniques and key results that will enable foundational investigations in physics through GW precision data.","1975000","2019-06-01","2024-05-31"
"LIFEGATE","Holographic super-resolution micro-endoscopy for in-vivo applications","Tomas Cizmar","LEIBNIZ-INSTITUT FUER PHOTONISCHE TECHNOLOGIEN E.V.","Complexity of living matter currently poses the most significant barrier to modern in-vivo microscopy. Fuelled by various branches of life sciences, the race is now to increase the penetration depth of super-resolution imaging inside living organisms. Additionally, no high-resolution in-vivo imaging technique has ever been introduced into medical, particularly surgical practice.  
This proposal sets out to develop new, ultra-thin endoscopic devices exceeding by orders of magnitude the performance of the current state of the art, thus paving the way for acquiring high-quality images from unprecedented depths of the most delicate tissues of living organisms. 
A team of transdisciplinary experts will push the fundamental and technological limits of the enabling principle - holographic control of light propagation in multimode fibres. Through advanced analytical and numerical modelling and major advancement of experimental methods, the project will develop a powerful platform for fast and efficient recovery of randomised imagery, retrieved from both rigid and flexible single-fibre endoscopes. 
This ‘gate-through-life’ will enable the team to deploy several prominent light-based imaging methods, including super-resolution approaches, inside freely moving animal models and ultimately humans. 
Supported by partners with broad expertise in in-vivo imaging, I will apply this methodology in the first instance to Neuroscience. This will provide a new, minimally invasive window into fundamental processes behind sub-cellular-scale functional connectivity of neurons and onset of common disabling neuronal disorders such as Alzheimer’s disease. 
Lastly, I will introduce the first technological basis for keyhole clinical diagnostics, enabling intra-operative live histology and microsurgery. This new imaging capacity will be able to reach currently inaccessible regions of the human body, while providing images with sub-cellular resolution in-situ.","1997973","2017-11-01","2022-10-31"
"LIFEINVERSE","Variational Methods for Dynamic Inverse Problems in the Life Sciences","Martin Burger","WESTFAELISCHE WILHELMS-UNIVERSITAET MUENSTER","This project will develop novel techniques for solving inverse problems in life sciences, in particular related to dynamic imaging. Major challenges in this area are efficient four- dimensional image reconstruction under low SNR conditions and further the quantification of image series as obtained from molecular imaging or life microscopy techniques. We will tackle both of them in a rather unified framework as inverse problems for time-dependent (systems of) partial differential equations.
In the solution of these inverse problems we will investigate novel approaches for the following aspects specific to the above-mentioned problems in the life sciences:

1. Solution of inverse problems for PDEs in complex time-varying geometries
2. Development of appropriate variational regularization models for dynamic images, including noise and motion models
3. Improved forward and inverse modelling of cellular and intracellular dynamics leading to novel inverse problems for nonlinear partial differential equations
4. Construction and implementation of efficient iterative solution methods for the arising 4D inverse problems and their variational formulation

All tasks will be driven by concrete applications in biology and medicine and their success will be evaluated in applications to real problems and data. This is based on interdisciplinary work related to electrocardiology and developmental biology. The overall development of methods will however be carried out in a flexible and modular way, so that they become accessible for larger problem classes.","966400","2014-03-01","2019-02-28"
"LifeLikeMat","Dissipative self-assembly in synthetic systems: Towards life-like materials","Rafal KLAJN","WEIZMANN INSTITUTE OF SCIENCE LTD","""Living organisms are sophisticated self-assembled structures that exist and operate far from thermodynamic equilibrium and, as such, represent the ultimate example of dissipative self-assembly. They remain stable at highly organized (low-entropy) states owing to the continuous consumption of energy stored in """"chemical fuels"""", which they convert into low-energy waste. Dissipative self-assembly is ubiquitous in nature, where it gives rise to complex structures and properties such as self-healing, homeostasis, and camouflage. In sharp contrast, nearly all man-made materials are static: they are designed to serve a given purpose rather than to exhibit different properties dependent on external conditions. Developing the means to rationally design dissipative self-assembly constructs will greatly impact a range of industries, including the pharmaceutical and energy sectors.

The goal of the proposed research program is to develop novel principles for designing dissipative self-assembly systems and to fabricate a range of dissipative materials based on these principles. To achieve this goal, we will employ novel, unconventional approaches based predominantly on integrating organic and colloidal-inorganic building blocks.

Specifically, we will (WP1) drive dissipative self-assembly using chemical reactions such as polymerization, oxidation of sugars, and CO2-to-methanol conversion, (WP2) develop new modes of intrinsically dissipative self-assembly, whereby the activated building blocks are inherently unstable, and (WP3&4) conceive systems whereby self-assembly is spontaneously followed by disassembly.

The proposed studies will lead to new classes of """"driven"""" materials with features such as tunable lifetimes, time-dependent electrical conductivity, and dynamic exchange of building blocks. Overall, this project will lay the foundations for developing new synthetic dissipative materials, bringing us closer to the rich and varied functionality of materials found in nature.""","1999572","2019-01-01","2023-12-31"
"LiftMatch","Lifting Methods for Global Matching Problems","Yaron LIPMAN","WEIZMANN INSTITUTE OF SCIENCE LTD","""This proposal presents a research program aimed at breaking new ground in theoretical, algorithmic and practical aspects of the notoriously difficult matching problems. The main goal is developing a unified algorithmic framework for matching problems that enjoys theoretical guarantees and high practical value for ``real-life'' applications.

The core methodological aspect is the modelling of matching problems as high-dimensional, lifted convex problems that can be efficiently approximated. We present several case-studies of this methodology, constructing efficient algorithms for approximating the solutions of important instances of the matching problem. The results already demonstrate state of the art performance and are backed-up with novel theoretical analysis proving tightness and correctness of the suggested convexifications for certain classes of non-trivial input.

This proposal has ``high risk - high impact'' profile: The ``high-risk"""" aspect of this proposal comes from the hardness of general matching problems which, when faithfully represented, are NP-hard. However, as we demonstrate, combining convex optimization tools in a careful way, that takes into account computational complexity, is likely to push forward the limits of current algorithmic solutions. The ``High-impact"""" will be immediate: As matching problems exist in almost every aspect of scientific research, practical generic algorithms for matching problems are likely to have a significant influence.

We believe that the inroads and preliminary results presented in this proposal already provide strong evidence for the potential success of the suggested research program.""","1675640","2018-03-01","2023-02-28"
"LightPipe","Antiresonant Hollow Optical Fibres for a Quantum Leap in Data and Optical Power Transmission","Francesco Poletti","UNIVERSITY OF SOUTHAMPTON","Fibre optics has revolutionised telecommunications, enabled the widespread diffusion of the internet and profoundly impacted industrial manufacturing, metrology, medical endoscopy and structural sensing, to name but a few. In many applications however, fibres are now being operated very close to fundamental physical limits of the glass that forms their core, and this is already providing hard limits, for example, to the maximum data capacity or optical intensity that can be transmitted through them. A transformative new technological step is required to help increasing the information capacity and power delivery capability of optical fibres to keep up with the 1.5dB/year growth in global data traffic and with the 2dB/year raise in laser output power. Air guiding hollow core fibres can provide a natural solution, but the state of the art technology suffers from conceptual physical limitations that bound their minimum loss, maximum information capacity, and transmitted optical power and energy. This proposal addresses these global challenges by developing the ‘ultimate’ hollow core optical fibre technology based on nested antiresonant nodeless fibres. Based on a recent discovery of the PI yet to find experimental demonstration, these fibres exploit antiresonances and multiple coherent reflections from the glass membranes to achieve, unlike any other known air-guiding optical waveguide, simultaneous minimisation of surface scattering and leakage loss. By targeting a 10 times increase in data capacity and power handling and a 5 times reduction in transmission loss as compared to state-of-the-art technology, all in an ultra-low nonlinearity fibre with excellent modal purity and spectral transparency, the outcomes of this project have the potential to revolutionise telecommunications 45 years after the development of ultra-low loss glass optical fibres and to produce a step-change in many industrial and scientific high power laser delivery applications.","2749639","2016-07-01","2021-06-30"
"LIGNINFIRST","The Lignin-First Approach for the Full Valorisation of Lignocellulosic Biomass","Roberto Rinaldi Sobrinho","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","Early-stage Catalytic Conversion of Lignin (ECCL), or the ‘Lignin-First’ approach, constitutes an emerging multidisciplinary research field targeting the valorisation of lignin. ECCL involves the concurrent extraction and catalytic conversion of the lignin fragments released from plant biomass in a one-pot process. In this manner, ECCL benefits from the intrinsically high reactivity of the lignin oligomers, leading to further depolymerisation (via hydrogenolysis of ether linkages) and, most importantly, to the passivation of the intermediates (via hydrodeoxygenation of aldehyde and ketone groups), thus protecting the lignin fragments from recondensation. In short, this novel approach renders a high yield of mono-aromatic products (>60%) and highly delignified pulps, allowing for the full utilisation of lignocellulose. LIGNINFIRST objectives will be achieved by high-risk/high-gain research into: (1) understanding (and control over) the solvolytic release of lignin fragments; (2) advancing the molecular understanding of H-transfer reactions catalysed by sponge Ni catalysts to accelerate the discovery of catalytic methods for lignin valorisation, and; (3) reaction engineering of the interdependent processing steps for fractionation of the initial biomass feedstock (catalytic upstream biorefining) to the intended value-added products (catalytic downstream processing). The full impact of LIGNINFIRST will be realised by undertaking pioneering research at the border of Wood Chemistry, Catalysis and Reaction Engineering. The most significant anticipated outcome is a profound understanding of the synergy between deconstruction of lignin, occurring in the plant tissue throughout the ‘cooking process’, and ECCL. The new scientific insights that will emerge from the implementation of this proposal have the great potential for revolutionising the utilisation of lignin in biorefineries.","1999756","2017-03-01","2022-02-28"
"LIMA","Controlling light-matter interactions by quantum designed 2D materials","Kristian Sommer THYGESEN","DANMARKS TEKNISKE UNIVERSITET","Progress within many contemporary or emergent technologies, including photovoltaics, single-photon light sources, and plasmonics, depends crucially on our ability to control the interactions between light and matter. The complexity of the light-matter interactions has made the development of photonic materials a slow, expensive, and empirical-based science. Of particular importance are the detrimental non-radiative processes mediated by defects and phonons that lead to efficiency losses in photovoltaics, reduce the quantum efficiency of single-photon emitters, and cause Ohmic losses in the metallic components of plasmonic devices. LIMA will develop ground breaking methods for calculating non-radiative relaxation rates in real materials from first principles. These will be used to evaluate key performance parameters such as photo-carrier lifetimes and plasmon propagation lengths and thus facilitate a realistic computational assessment of the application potential of photonic materials. In terms of materials, LIMA will focus on the emergent class of atomically thin two-dimensional (2D) materials. The possibility of combining different 2D materials into van der Waals heterostructures (vdWHs) provides a unique platform for controlling light-matter interactions with atomic scale precision. Multi-scale methods for predicting quasiparticle band structures of general, incommensurable vdWHs will be developed and used to design novel photonic materials with tailored light dispersion and multi-junction solar cells with high absorption and low thermalization losses. High-throughput computational screening will be used to identify novel color centers in 2D materials with potential to act as single-photon sources with high quantum yield and narrow linewidths, which are urgently needed by leading quantum technologies. The possibilities of controlling the color centers via strain engineering and light management will be explored in close collaboration with experimentalists.","1951354","2018-04-01","2023-03-31"
"LINCHPIN","A platform to LINk between CHemistry and PhysIcs of colloidal Nanomaterials","Dorota KOZIEJ","UNIVERSITAET HAMBURG","The recent successful applications of photon-in-photon-out spectroscopy in condense matter physics, bio-inorganic chemistry and catalysis build upon the high brilliance of modern X-ray sources and realization of dedicated emission spectrometers. However, probing with highly energetic X-ray beam puts many constraints on the sample environment and requires probing faster than the X-ray radiation damage occurs. This strongly limits the applicability of the method in studying the chemistry of colloidal nanomaterials. 
The objective of LINCHPIN is to investigate the emergence of electronic structure of nanomaterials in solution by hard X-ray photon-in-photon-out spectroscopy. To reach this very ambitious target, LINCHPIN consolidates an interdisciplinary engineering, spectroscopic and chemically driven effort. My group aim for developing micro-reactors, which will enable new fundamental insights related to the chemistry and electronic properties of the transition metal nitrides and sulfides. 
The main scientific goals are to study at the relevant time scales the kinetics and dynamics of: (a) short-lived molecular intermediate states and pre-nucleation clusters, (b) metal-sulfur and metal-nitrogen bond formation and their condensation in solution, (c) electronic structure changes during growth of nanostructures, and (d) concurrently interdependent electronic and chemical processes. The ultimate goal is to have a handle on designing and selecting, still in the reaction solution, the nanomaterials with the most promising electronic properties relevant for energy conversion and storage. Moreover, the proposed micro-reactors along with experimental spectroscopic protocols and the concurrent fundamental knowledge create a paradigm shift for in situ time-resolved experiments with an impact in many other fields ranging from catalysis, sustainable flow chemistry to biomedical applications.","1964375","2020-01-01","2024-12-31"
"LIPA","A unified theory of finite-state recognisability","Mikolaj Konstanty Bojanczyk","UNIWERSYTET WARSZAWSKI","Finite-state devices like finite automata and monoids on finite words, or extensions to trees and infinite objects, are fundamental tools of logic in computer science. There are tens of models in the literature, ranging from finite automata on finite words to weighted automata on infinite trees. Many existing finite-state models share important similarities, like existence of canonical (minimal) devices, or decidability of emptiness, or a logic-automata connection. The first and primary goal of this project is to systematically investigate these similarities, and create a unified theory of finite-state devices, which:

1. covers the whole spectrum of existing finite-state devices, including settings with diverse inputs (e.g. words and trees, or infinite inputs, or infinite alphabets) and diverse outputs (e.g. Boolean like in the classical automata, or numbers like in weighted automata); and

2. sheds light on the correct notion of finite-state device in settings where there is no universally accepted choice or where finite-state devices have not been considered at all.

The theory of finite-state devices is one of those fields of theory where even the more advanced results have natural potential for applications. It is surprising and sad how little of this potential is normally realised, with most existing software using only the most rudimentary theoretical techniques. The second goal of the project is to create two tools which use more advanced aspects of the theory of automata to solve simple problems of wide applicability (i.e. at least tens of thousands of users):

1. a system that automatically grades exercises in automata, which goes beyond simple testing, and forces the students to write proofs

2. a system that uses learning to synthesise text transformations (such a search-and-replace, but also more powerful ones) by using examples","1768125","2016-05-01","2021-04-30"
"Liquid2DM","Two-dimensional liquid cell dielectric microscopy","Laura FUMAGALLI","THE UNIVERSITY OF MANCHESTER","Understanding molecular organization and dynamics which are governed by electrostatic and electrodynamics interactions on the nanoscale requires the measurement of dielectric polarization at the molecular level. Yet, this has remained a formidable challenge because standard dielectric spectroscopy is limited to the micrometer scale that is achieved by using microfabricated electrodes at low frequencies and optical approaches at high frequencies. At the same time, despite the advances in atomistic calculations, theorists struggle to predict dielectric polarization when the system approaches molecular sizes. During the last years I pioneered the development of scanning dielectric microscopy, measuring the dielectric constants of nano-objects as small as tens of nanometers in size - a resolution unparalleled world-wide. In the next five years, I will push the boundaries of the technique and probe the polarizability of liquids and biological macromolecules under two-dimensional (2D) confinement by implementing novel experimental and theoretical approaches. By engineering 2D liquid cells with controlled properties by van der Waals assembly, I will probe polarization and thermodynamic properties of nanoconfined molecular liquids for the first time on the molecular scale with fundamental implications for physical and life sciences. It will provide the experimental data to validate first-principles predictions and mean-field computational methods on which the study of condensed/soft matter and molecular biology is based. The proposal will exploit my current lead to access a key physical property of matter that has remained unknown so far, enabling a wealth of new science in a vast range of research fields, from physical sciences to chemistry and biology, and facilitating the design of devices with novel functionalities.","1998829","2019-10-01","2024-09-30"
"LIQUIDMASS","High throughput mass spectrometry of single proteins in liquid environment","Montserrat Calleja Gomez","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Although mass spectrometry has brought about major advancements in proteomics in the last decade, protein mass spectrometers still have important limitations. One fundamental limitation is that they require sample ionization, desorption into the gas phase and fragmentation, clearly leading to protein denaturation. Since relevant protein complexes are unstable or transient, their characterization in its native state and physiological environment remains an unexplored route towards the full understanding of protein function and protein interactions. This problem has only been targeted to date through theoretical approaches or low throughput experimental techniques, such as atomic force spectroscopy, optical tweezers or FRET. A high throughput characterization technology capable of addressing single proteins in its native state would have a large impact in proteomics. The goal of LIQUIDMASS is to develop a high throughput spectrometric technique addressing single proteins from complex samples while in physiological conditions. LIQUIDMASS also proposes a new concept for protein spectrometry, by characterizing not only the mass, but also the hydrodynamic radius, geometry and stiffness of single proteins. This multiparameter approach will serve to open up new routes to understand protein structure-function relations by providing insight into the fast conformational changes that occur in liquids. In order to attain these goals, I propose to integrate nanomechanical resonators, nano-optics and nanofluidics. The disruptive approach proposed will bring about new knowledge about protein interactions and protein conformation that is elusive today. The enabling technologies aimed at the LIQUIDMASS will increase our understanding of protein misfolding related diseases, such as Alzheimer’s or diabetes, as well as bring closer a full understanding of the human interactome, contributing to the advancement of the proteomics field.","2470283","2016-11-01","2021-10-31"
"LiveSoft","Lightweight Verification of Software","Patrick Thomas Eugster","TECHNISCHE UNIVERSITAT DARMSTADT","As illustrated through the advent of cloud computing, cyberphysical systems, or the Internet of Things, more and more applications are inherently distributed. At the same time, programming distributed systems is notoriously hard. Programmers have to deal with asynchrony and have to cater for partial failures -- the possibility that certain communication(s), processes, or hosts fail while others remain operational. These failures can have drastic consequences such as the missing to react to critical events or inconsistent states respectively. Limitations on existing hardware infrastructure necessitate subtle assumptions on system and failure models though to achieve efficient yet complex algorithmic solutions, whose implementation is prone to delicate defects.


Existing techniques for engineering reliable distributed systems software require much effort (e.g., program annotations in the form of invariants) thus discouraging many developers from their use; other techniques require developers to explicitly run specific tools (e.g., model checkers) which are thus easily left out and still can not achieve complete validation.

LiveSoft investigates static techniques to verify a subset of relevant and failure-prone aspects of distributed software --- interaction between components --- in a way which is lightweight and can be integrated with compilation. Our techniques will be able to sieve out many important defects upfront by pushing software reliability into the software design process. To that end LiveSoft proposes protocol types which leverage experiences with session types yet focus on fault-tolerant distributed systems by emphasizing asynchrony, failure handling and recovery, protocol composition, security, and parameterization. A main challenge is to support different system and failure models including emerging hardware trends such as hardware transactional memory and non-volatile memory rather than hardwiring speicific notions of (a)synchrony and failures.","1999320","2014-07-01","2019-06-30"
"LIVIN","Light-Vapour Interactions at the Nanoscale","Uriel Levy","THE HEBREW UNIVERSITY OF JERUSALEM","The goal of this research is to develop a chip scale toolkit for exploring light-vapour interactions at the nanoscale. The integration of hot vapour cells with nanophotonics technology will be used for enhancing the interaction of light with vapours and for constructing miniaturized devices. Our main objectives are: I-developing an advanced and versatile platform which allows for the construction of miniaturized devices bringing together photonics/plasmonics and atomic vapours. II-exploring the science of light-vapour interactions at the nanoscale. III–exploiting the benefits and the uniqueness of our approach for mitigating challenging applications.
Two major platforms will be studied in great details. One is based on combining vapour cells with nanoscale dielectric waveguides and resonators, while the other consists of nanoscale plasmonic structures integrated with hot vapour cells. Using these platforms, plethora of physical effects will be studied and important applications will be demonstrated. Few examples include the study of atomic transitions near surfaces, weak and strong coupling between photonic and atomic resonant systems, slow and fast light effects, nonlinear optics, frequency standards and magnetometry. The proposed approach provides unique features, e.g. high optical densities, low power consumption, well-controlled coupling and small device footprint together with true chip scale integration. For example, owing to the enhanced light-vapour interaction and the small volume of the optical mode, it allows to explore few photons-few atoms interactions, with the ultimate goal of demonstrating effects in the single photon level regime.
Given the uniqueness of our approach, the successful implementation of the proposed research should provide an outstanding playground for conducting basic and applied research in the fields of nanophotonics, plasmonics and atomic physics, and will serve as a landmark for constructing novel miniaturized quantum devices.","1998863","2015-06-01","2020-05-31"
"Living Bionics","Living bioelectronics: Bridging the interface between devices and tissues","Rylie GREEN","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","When bionic devices such as cochlear implants, bionic eyes and brain-machine interfaces are implanted into the body they induce an inflammatory response that is difficult to control. Metals used historically for these types of devices are both stiff and inorganic, which makes them recognisable as foreign to the soft and organic human nervous system. Consequently, these implants are tolerated by the body rather than integrated and the device is walled off in a scar tissue capsule. As a result high powered and unsafe currents are required to activate tissues and produce a therapeutic response.  
I have brought together concepts from tissue engineering for regenerative medicine and bionic device technologies to pioneer living bioelectronics – creating a functional neural cell component as part of the device to avert scar formation. My laboratory has established a range of novel conductive polymeric biomaterials which can be used to coat existing devices or fabricate new devices from conductive polymers, hydrogels, proteins and cells.
Living Bionics is based on a world-wide unique combination of technologies and proposes to combine electronic devices with cell laden polymers to generate devices that can bridge the implant interface and improve tissue integration. Pioneering and ground breaking research within Living Bionics includes:
• An engineered hydrogel that can support differentiation of stem cells into neural cell networks on devices
• 3D patterning of living polymer electrode arrays that contain cells
• Understanding of the combined effects of environmental, biological and electrical cues to guide cell fate and create connections to nerve tissues
• In vivo proof of principle in the murine model
Living Bionics will be a ground breaking step towards safer neural cell stimulation, which is more compatible with tissue survival and regeneration. This research will create a paradigm shift in biomedical electrode design with tremendous impact on healthcare worldwide.","1996745","2018-05-01","2023-04-30"
"Loops and groups","Loops and groups: Geodesics, moduli spaces, and infinite discrete groups via string topology and homological stability","Nathalie Anne M. Wahl","KOBENHAVNS UNIVERSITET","This proposal lies at the intersection of algebra, topology, and geometry, with the scientific goal of answering central questions about homological stability, geodesics on manifolds, and the moduli space of Riemann surfaces. Homological stability is a subject that has seen spectacular progress in recent years, and recent work of the PI has opened up new perspectives on this field, through, among other things, associating a canonical family of spaces to any stability problem. The first two goals of the proposal are to give conditions under which this family of spaces is highly connected, and to use this to prove homological and representation stability theorems, with determination of the stable homology. Particular attention is given to Thompson-like groups, building on a recent breakthrough of the PI with Szymik. The last two goals concern geodesics and moduli spaces via string topology: The third goal seeks a geometric construction of compactified string topology, which we propose to use to address counting problems for geodesics on manifolds. Finally our fourth goal is to use compactified string topology to study the harmonic compactification itself, and give a new approach to finding families of unstable homology classes in the moduli space of Riemann surfaces. The feasibility of the last goals is demonstrated by the PIs earlier algebraic work in this direction; the proposal is to incorporate geometry in a much more fundamental way. 
The project combines breakthrough methods from homotopy theory with methods from algebraic, differential and geometric topology. Some of the goals are high risk, but we note that in those cases even partial results will be of significant interest. The PI has a proven track record at the international forefront of research, and as a research leader, e.g., through a previous ERC Starting Grant. The research team will consist of the PI together with 3 PhD students and 3 postdocs in total during the 5 years.","1864419","2018-09-01","2023-08-31"
"LOPRE","Lossy Preprocessing","Saket SAURABH","UNIVERSITETET I BERGEN","A critical component of  computational processing of data sets is the  `preprocessing' or `compression'  step which is the computation of a \emph{succinct, sufficiently accurate} representation 
of the given data. Preprocessing is ubiquitous and a rigorous mathematical understanding of preprocessing algorithms is crucial in order to reason about and understand the limits of preprocessing.

Unfortunately,  there is no mathematical framework to analyze and objectively compare two preprocessing routines while simultaneously taking into account `all three dimensions' --
 
-- the efficiency of computing the succinct representation, 
-- the space required to store this representation, and  
--  the accuracy with which the original data is captured in the succinct representation.   
 	
 
``The overarching goal of this proposal is the development of a mathematical framework for the rigorous analysis of preprocessing algorithms. ''

We will achieve the goal by designing new algorithmic techniques for  preprocessing, developing a framework of analysis to make qualitative comparisons between various preprocessing routines based on the criteria above and by developing lower bound tools required  
to understand the limitations of preprocessing for concrete problems. 

This project will lift our understanding of algorithmic preprocessing to new heights and lead to a groundbreaking shift in the set of basic research questions attached to the study of preprocessing for specific problems. It will significantly advance the analysis of preprocessing and yield substantial technology transfer between adjacent subfields of computer science such as dynamic algorithms, streaming algorithms, property testing and graph theory.","2000000","2019-05-01","2024-04-30"
"LOQO-MOTIONS","Local quantum operations achieved through the motion of spins","John Julian Larrarte MORTON","UNIVERSITY COLLEGE LONDON","Spins have long been appreciated as versatile tools for studying coherent quantum phenomena in a range of materials and have emerged as powerful components for the development of technologies such as quantum information processors and sensors. Results from the past 5 years have shown that spins can exhibit exceptionally long coherence lifetimes (seconds for the electron spin, hours for the nuclear spin), and can be measured with high fidelity in a single shot and at the single spin level. These achievements provide strong motivation to address what remains an open challenge: how to controllably couple such coherent spins in a scalable manner. This goal is being vigorously pursued by many groups following approaches such as those based on exchange interactions between spins, or coupling spins to optical or microwave photons and measurement-based entanglement. However, each of these approaches carries formidable challenges and a clearly realisable route to a scalable technology is still currently lacking.

The aim of LOQO-MOTIONS is to exploit the long coherence times observed in spins of atomic defects in materials and open up a new approach for coupling spins based on dipolar interactions combined with physical motion to achieve local quantum operations. This approach is inspired by a recent blueprint for the implementation of a surface code using donors in silicon, permitting fault-tolerant operation even with the limited positional accuracy of ion implantation. LOQO-MOTIONS assembles a comprehensive set of tools required to explore and exploit physically mobile spins, including: versatile single- donor spin measurement, coupling of donor spins and optically-addressable defect spins, and cryogenic scanning of probe spins over static spins to generate entanglement. In addition to developing a new platform for engineering spin-spin couplings, LOQO-MOTIONS has strong synergies with spin-based magnetometry and nano-scale quantum sensing applications will be explored.","2264167","2018-02-01","2023-01-31"
"LRC","Laser Resonance Chromatography of Superheavy Metals","Mustapha Laatiaoui","JOHANNES GUTENBERG-UNIVERSITAT MAINZ","This project aims at developing a novel method of optical spectroscopy to study the wholly unexplored atomic structure of the superheavy transition metals, starting with element 103, lawrencium (Lr). My team will experimentally identify optical spectral lines that will serve as fingerprints in the search for superheavy elements in the universe. The spectral lines are strongly influenced by relativistic and quantum electrodynamic effects and thus will constitute powerful benchmarks for atomic modeling incorporated within this project. Furthermore, since the nuclear charge distribution influences the atomic structure, our experimental data will advance our understanding of the effects of nuclear shells and deformations on the stability of radionuclides at the top of the Segré chart.
While I recently opened up the atomic structure of element 102, nobelium, the new challenges faced are the refractory nature of the elements, which lay ahead, coupled with shorter half-lives and decreasing production yields. I propose to overcome these by developing an ultra-sensitive and fast Laser Resonance Chromatography (LRC) to set the new standard in optical spectroscopy. The LRC method combines the element selectivity and spectral precision of laser spectroscopy with cutting-edge technology of ion-mobility mass spectrometry. Based on high-accuracy atomic calculations, my team will optically probe the 1S0-3P1 ground-state transition in singly-charged 255Lr ions and record the distinct arrival times of the ions after passing a drift tube to identify the laser resonance signal. We will perform the experiments at leading in-flight facilities such as the GSI velocity filter SHIP and the new GANIL separator S3. 
Crucially, the LRC method will be insensitive to physicochemical properties and tolerant of the decreasing yields with increasing atomic number. This paves the way for atomic structure studies of the superheavy elements, in particular, those of refractory nature beyond lawrencium.","1999750","2019-06-01","2024-05-31"
"MAFRAN","Mathematical Frontiers in the Analysis of Many-particle Systems","Clement MOUHOT","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","The recent growing mathematical activity around the partial differential equations of kinetic theory has lead to deeper and deeper conceptual breakthroughs. This has opened new paths, and has created new frontiers with other cutting-edge fields of research.
These frontiers correspond to three combined levels: the dialogue with another world-leading research community; the uncovering of deep new connexions and methods through this interplay; the possibilities of making significant progresses on a fundamental open problem:
I. with the elliptic regularity community (regularisation for nonlocal collision operators, De Giorgi- Nash theory): the main challenge is the well-posedness of the Landau-Coulomb equation;
II. with the dispersive and fluid mechanics equations communities (nonlinear stability driven by phase mixing): the main challenge is the damping stability of non spatially homogeneous structures;
III. with the dynamical system and probability communities (mean-field and Boltzmann-Grad limits): the main challenge is the rigorous derivation of the fundamental equations of statistical mechanics on macroscopic times;
IV. with the applications to biology, ecology and statistical physics (emerging collective phenomena for open many-particle systems): the main challenge is the understanding of steady or propagation front solutions and their stability outside the realm of the 2d principle of thermodynamics.
These frontiers can rapidly lead to key advances with potential impact in mathematical analysis and fundamental physics (plasma physics, statistical mechanics); the work program Horizon 2020 would strongly benefit from the construction of a world-class research centre devoted to them. This is my objective in this project: I have played a key role in the opening of these frontiers, I propose new approaches, I have experience in building a research group, and the University of Cambridge, where I am based, would provide a unique supportive environment.","1950637","2017-09-01","2022-08-31"
"MAGALOPS","The MAgnetic field in the GALaxy, using Optical Polarization of Stars","Marijke Haverkorn van Rijsewijk","STICHTING KATHOLIEKE UNIVERSITEIT","What makes our Galaxy’s ecosystem so fascinating is the complex interactions between its components: stars, gas, dust, magnetic fields, and cosmic rays. Of these components, the Galactic magnetic field (GMF) may well be the most enigmatic. Only partially observable through indirect means, its study relies heavily on modeling, almost exclusively using line-of-sight integrated radio-polarimetric data.  Although much has been learned, many questions are still unanswered especially about the turbulent, small-scale field component and out-of-plane field. 

The crucial innovations proposed here are large independent data sets with 3D (distance) information – which can only be provided by stars polarized due to differential absorption by interstellar dust, with known distances – and more advanced Bayesian statistics which allows including prior knowledge and enables quantitative model comparison. 

I propose to use 2 new polarization surveys in the V (visual) band, resulting in polarimetry of millions of stars across the southern sky. With distance information provided by the GAIA satellite, this improves the current data situation by 3 orders of magnitude. We will test GMF models against all available data, employing a Bayesian inference software package which we are developing. In the process, we will produce the first 3D all-sky (out to absorption limits) dust distribution consistent with both UV/optical/near IR absorption and optical polarization.

This research will result in a next-generation GMF model that includes all observational GMF tracers and can use informative priors. It will allow mapping out interstellar magnetized turbulence in the Galaxy, instead of providing averaged parameters only, and understanding the interplay between the local GMF, gas and dust. Its legacy is a 1000x increased stellar polarization catalog, an all-sky 3D dust model, a bayesian sampler for GMF models, and a superior GMF model for use in cosmic ray modeling or foreground subtraction.","2000000","2018-09-01","2023-08-31"
"MAGIC","Monsoons of Asia caused Greenhouse to Icehouse Cooling","Guillaume Dupont-nivet","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Unraveling the cause for Cenozoic global climate cooling is one of the most important unresolved questions challenging the Earth and Environmental sciences community today. Increased erosion and weathering of the uplifted Tibetan Plateau and Himalayas, is advocated as the primary cause for the enigmatic pCO2 drawdown, that led to global cooling 50 to 34 Myrs ago from the warm ice-free Greenhouse world to the bi-polar Icehouse conditions still prevailing today. Asian Monsoons are genetically linked to high orography associated with the India-Asia collision starting ca. 50 Myrs ago, however, the relation between Greenhouse to Icehouse cooling and Asian Monsoons remains to be explore as they were previously thought to intensify only much later ca. 25 Myrs ago. Our recent findings of monsoonal activity in Asia since at least 45 Myrs ago raises the fascinating possibility that Asian Monsoons may have triggered global cooling from Greenhouse to Icehouse conditions. Testing this novel hypothesis and exploring its implications on feedback mechanisms between regional environments, Asian Monsoons and global climate, will constitute the stimulating objectives of MAGIC. 3 PhDs will provide end-member monsoonal archives well-dated during greenhouse to icehouse cooling from 3 key locations (NE Tibet, SE Asia and Paratethys Sea). These will be analyzed by three postdocs expert in novel proxy methods tailored for MAGIC to infer temperatures, precipitation, salinity, seasonality, paleoaltimetry, wind-patterns, paleoecology and paleogeography at infra-annual, orbital and tectonic time scales. Ultimately, these records and boundary conditions will be integrated into climate models by a dedicated postdoc to unravel the role and behavior of Asian Monsoons with respect to long-term Greenhouse to Icehouse cooling, pCO2 levels as well as global hyperthermal and cooling event such as the PETM, MECO and EOT.","1999999","2015-09-01","2020-08-31"
"MAGMA","Melting And Geodynamic Models of Ascent","Boris Jozef Paul KAUS","JOHANNES GUTENBERG-UNIVERSITAT MAINZ","The production and migration of magma through the lithosphere results in spectacular geological processes such as volcanic eruptions, giant ore deposits, large magmatic intrusions, and is responsible for the formation of continents on Earth.
Since magmatic systems develop on timescales of millions of years and are not directly accessible, we have to reconstruct them indirectly, such as by studying exhumed magmatic intrusions, or by using geophysical methods. Interpreting these data is complicated, as geophysical techniques only give a present-day snapshot, whereas the geological record yields an incomplete picture of the underlying processes. As a result, most existing ideas on how magmatic systems work remain conceptual and are not necessarily consistent with the mechanics of the lithosphere, which hampers our understanding of such processes.
Here, we will develop and employ a new generation of 3D computer models to simulate the full magmatic system in arcs in a self-consistent manner, while taking both realistic rock rheologies and evolving melt chemistry into account. We will:
1. Derive mechanically-consistent interpretations of active magmatic plumbing systems by combining geophysical and petrological data with geodynamic inverse models.
2. Obtain insights into the physics of magma migration through arcs on geological timescales, by combining numerical simulations with geological constraints from exhumed arc roots, and by targeting several well-studied magmatic intrusions.
3. Unravel how arcs are built on geological timescales, what the role and the rates of magmatic differentiation processes are in this, and how this may have formed continental crust on Earth.
We can thus, for the first time, interpret the available data in a physically consistent manner. This will give deep insights in how magmatic systems develop over geological timescales and why only some evolve into large super-volcanoes.","1994250","2018-10-01","2023-09-30"
"MAGNESIA","The impact of highly magnetic neutron stars in the explosive and transient Universe","Nanda Rea","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","The gravitational wave window is now open. It is then imperative to build quantitative models of neutron stars that use all the available tracers to constrain fundamental physics at the highest densities and magnetic fields. The most magnetic neutron stars, the magnetars, have been recently suggested to be powering a large variety of explosive and transient events. The enormous rotational power at birth, and the magnetic energy they can release via large flares, put the magnetars in the (yet) hand-wavy interpretations of gamma-ray bursts, the early phases of double neutron star mergers, super-luminous supernovae, hypernovae, fast radio bursts, and ultra-luminous X-ray sources. However, despite knowing about 30 magnetars, we are lacking a census of how many we expect within the pulsar population, nor we have robust constraints on their flaring rates. The recent discovery of transient magnetars, of magnetar-like flares from sources with measured low dipolar magnetic fields and from typical radio pulsars, clearly showed that the magnetar census in our Galaxy is largely under-estimated. This hampers our understanding not only of the pulsar and magnetar populations, but also of them as possibly related to many of Universe’s explosive events. MAGNESIA will infer a sound Magnetar Census via an innovative approach that will build the first Pulsar Population Synthesis model able to cope with constraints/limits from multi-band observations, and taking into account 3D magnetic field evolution models and flaring rates for neutron stars. Combining expertise in multi-band observations, numerical modeling, nuclear physics, and computation, MAGNESIA will solve the physics, the observational systematic errors, and the computational challenges that inhibited previous works, to finally constrain the spin period and magnetic field distribution at birth of the neutron star population.","2263148","2019-06-01","2024-05-31"
"MaGRaTh","Matter and strong-field gravity: New frontiers in Einstein’s theory","VITOR MANUEL DOS SANTOS CARDOSO","INSTITUTO SUPERIOR TECNICO","Gravity is the weakest but the most intriguing fundamental interaction in the Universe. In the last decades a formidable intellectual effort has shown that the full-fledged geometric nature of gravity offers much more than a beautiful description and understanding of all stellar and galactic. In the quest for the ultimate theory of gravity, new and spectacular connections between high-energy physics, astrophysics, cosmology and theoretical physics have emerged. Triggered by breakthroughs at the observational, experimental and conceptual levels, strong gravity physics is experiencing a Golden Age, making it one of the most active fields of research of the 21st century. 

My group in Lisbon has been involved in groundbreaking research into the nature of strong-field effects in curved spacetime with applications in various fields, thus establishing international leadership in the field. This proposal aims at understanding, 
via perturbative techniques and full-blown nonlinear evolutions, the strong-field regime of gravity, and includes challenging nonlinear evolutions describing gravitational collapse, compact binary inspirals and collisions in the presence of fundamental fields. The proposed programme will significantly advance our knowledge of Einstein's field equations and their role in fundamental questions (e.g. cosmic censorship, hoop conjecture, spacetime stability, no hair theorems), but also its interplay with high energy, astro and particle physics (testing the precise nature of the interaction between compact objects and matter --such as dark matter candidates or accretion disks-- and its imprint on gravitational wave emission, understanding gravitational-led turbulence,etc).

This is a cross-cutting and multidisciplinary program with an impact on our understanding of gravity at all scales, on our perception of black hole-powered phenomena and on gravitational-wave and particle physics.","1588817","2015-12-01","2020-11-30"
"MagTendon","Magnetically Assisted Tissue Engineering Technologies for Tendon Regeneration","Maria Manuela ESTIMA GOMES","UNIVERSIDADE DO MINHO","The poor healing ability of tendons, which play a critical role in the musculoskeletal system, as well as the limitations of currently used therapies have motivated tissue engineering (TE) strategies to develop living tendon substitutes. However, the limited knowledge on tendon development and healing processes has hindered the design of TE procedures that more closely recapitulate tendon morphogenesis. Extending beyond the state-of-the-art, MagTendon will explore conventional and innovative tools such as multimaterial 3 dimensional (3D) bioprinting to design magnetic responsive systems mimicking specific aspects of tendon tissue architecture, composition and biomechanical properties, which, combined with adequate stem cells, will render appropriate behavioural instructions to stimulate the regeneration of tendon tissue. Stem cell bioengineering approaches based on superparamagnetic nanoparticles (SPMNs), namely cell sorting, mechanoreceptors targeting and cell programming, will be used to unveil the cellular signalling pathways that trigger the tenogenic differentiation of the widely and easily obtained human adipose derived stem cells. Simultaneously, the 3D cell-laden magnetic system shall enable sophisticated 3D tissue models to unravel mechanisms behind tendon homeostasis and repair that will support the base knowledge to establish rational design criteria for the biofabrication of living tendon substitutes with the adequate signaling and structural cues to recapitulate tendon tissue developmental patterns. Therefore, the ground-breaking nature of the research proposed relies on the development of disruptive technological concepts for obtaining unique cell-laden 3D magnetically responsive systems that recapitulate key features of the native tissue and that can be further remotely modulated both in vitro and in vivo by the application of external magnetic stimuli, offering the prospect of tendon regeneration as opposed to simple tissue repair.","1999854","2018-05-01","2023-04-30"
"MAIDEN","Masses, isomers and decay studies for elemental nucleosynthesis","Anu KANKAINEN","JYVASKYLAN YLIOPISTO","About half of the elements heavier than iron have been produced via the rapid neutron capture process, the r process. Its astrophysical site has been one of the biggest outstanding questions in physics. Neutrino-driven winds from proto-neutron stars created in core-collapse supernovae were long considered as the most favourable site for the r process. Recently, neutron-star mergers have become the most promising candidates, and new exciting observations from these compact objects, such as gravitational waves, are expected in the coming years. In order to constrain the astrophysical site for the r process, nuclear binding energies (i.e. masses) of exotic neutron-rich nuclei are needed because they determine the path for the process and therefore have a direct effect on the final isotopic abundances. In this project, high-precision mass measurements will be performed in three regions relevant for the r process, employing novel production and measurement techniques at the IGISOL facility in JYFL-ACCLAB. Long-living isomeric states, which also play a role in the r process, will be resolved from the ground states to obtain accurate mass values. Post-trap decay spectroscopy will be performed to confirm which state has been measured in order to avoid systematic uncertainties in the mass values. The new data will be compared with theoretical mass models and included in r-process calculations performed for various astrophysical sites. MAIDEN will advance our knowledge of nuclear structure far from stability and reduce nuclear data uncertainties in the r-process calculations, which can potentially constrain the astrophysical site for the r process and lead to a scientific breakthrough in our understanding of the origin of elements heavier than iron in the universe.","1999575","2018-06-01","2023-05-31"
"MarineIce","Ice Nucleating Particles in the Marine Atmosphere","Benjamin John Murray","UNIVERSITY OF LEEDS","The formation of ice in clouds is fundamentally important to life on our planet since clouds play a key role in climate and the hydrological cycle. Despite the significance of ice formation, our quantitative understanding of sources, properties, mode of action and transport of Ice-Nucleating Particles (INP) is poor. In order to improve our representation of clouds in models we need to understand the ice-nucleating ability of all major aerosol types, including those from the world’s oceans.

Despite oceans covering over 70% of the planet and sea spray being one of the dominant aerosol types in the atmosphere, its role in the formation of ice in clouds remains poorly understood. There are strong indications that biological organic components of sea spray can nucleate ice, but there is a lack of data to quantify it. In contrast, the ice-nucleating ability of major aerosol species from terrestrial sources, such as mineral dusts or bacteria, has received significant attention over the past few decades. A similar effort now needs to be made to understand marine INP. The key limitation to accurately representing INP in models over the world’s oceans is the lack of field data, a deficiency which I intend to address during this ERC fellowship.

I propose to develop and deploy a new semi-autonomous INP instrument based on novel microfluidics technology which will cover the full range of mixed phase cloud conditions, unlike existing instruments. It will be housed in a unique highly instrumented mobile laboratory, which will allow us to access the remote oceans from atmospheric observatories and research ships. The data from these campaigns will be used to constrain the oceanic INP source and define the spatial and temporal distribution of marine INP in a state-of-the-art global aerosol model. In combination, these activities will allow us to quantify this potentially important source of INP which is needed to underpin the next generation of weather and climate models.","2681881","2015-08-01","2020-07-31"
"MARS","Electronic Order, Magnetism, and Unconventional Superconductivity probed in Real-Space","Christian Peter Hess","LEIBNIZ-INSTITUT FUER FESTKOERPER- UND WERKSTOFFFORSCHUNG DRESDEN E.V.","The interplay of electronic order with antiferromagnetism and superconductivity has recently emerged as a vital question for rationalizing the physics of all classes of unconventional superconductors. The electronic order is rarely sufficiently long-range correlated to render it susceptible for diffraction techniques. Instead, a local probe is usually required to detect it experimentally. It is clear, however, that such a probe must provide sensitivity at the same time to electronic order, superconductivity, and static magnetism for clarifying the interplay between these ordering phenomena. The only experimental technique which is capable of fulfilling these requirements simultaneously is spin-polarized scanning tunneling microscopy (SP-STM). This technique utilizes spin-polarized tunneling currents in order to measure signatures of electronic order, superconducting gaps, and the magnetic structure at the atomic scale. To the best of our knowledge, SP-STM has never been applied to unconventional superconductors, despite the mandatory necessity.

Exactly this is the goal of the MARS project: We want to combine SP-STM, which we recently established in our microscopes, with our experience in scanning tunneling microscopy on unconventional superconductors. We will apply highest-resolution SP-STM systematically to prototype representatives of the most important classes of unconventional superconductors, viz. cuprate, iron-arsenide, and heavy-fermion superconductors. For this purpose, a unique milli-Kelvin scanning tunneling microscope will be built, in order to achieve unprecedented resolution in spin-polarization, energy, and real-space.","2747025","2015-09-01","2020-08-31"
"MarsFirstWater","The physicochemical nature of water on early Mars","Alberto Gonzalez Fairen","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Concepts of large bodies of glacial ice and liquid standing water, a robust hydrological cycle, and a rich Martian history of climate change are part of the current consensus model for early Mars. However, questions still poorly constrained include: a precise understanding of the inventory of water during the first billion years of Mars history and its early evolution on both global and local scales; whether liquid or solid H2O dominated, for what duration of time and where the water resided; what were the host-rock weathering rates and patterns and the physicochemical parameters defining such interactions; what specific landforms and mineralogies were generated during those periods; and what implications all these processes had on the possible inception of life on Mars. These fundamental questions represent large uncertainties and knowledge gaps. Therefore, a quantitative understanding of the basic characteristics of water on early Mars is very much needed and is the focus of this proposal.
This application outlines a plan for my research in the next five years, and explains how I propose to fully characterize the aqueous environments of early Mars through a quantitative and truly interdisciplinary investigation. Spacecraft mission-derived datasets will be consistently used to test hypotheses through paleogeomorphological reconstructions, geochemical modeling, mineralogical studies, and astrobiological investigations. The derived results will produce hard constraints on the physical evolution, chemical alteration and habitability of surface and near-surface aqueous environments on early Mars. The planned investigations will benefit from the combination of working with first-hand data from ongoing Mars missions and with the state-of-the-art laboratory tools at the host institution. The final expected result will be a complete understanding of the physicochemical nature of water on early Mars, also opening new paths for the astrobiological exploration of the planet.","1998368","2019-06-01","2024-05-31"
"MassiveCosmo","Massive Gravity and Cosmology","Claudia Anna DE RHAM","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","The ambition of this research program is to challenge the nature of gravity, provide an alternative to dark energy, and pave the way towards a potential resolution of one the most tantalizing problems of physics today: The Old Cosmological Constant Problem.

As General Relativity celebrates its centennial, its predictive successes and its status as our most elegant theory of gravity are incontrovertible. Nevertheless, while the recent discovery of the late-time acceleration of the Universe is in perfect agreement with observations, the 120 orders of magnitude discrepancy between expectations and observations is one of today's most challenging puzzles and may be the sign of new physics to uncover. This conundrum has driven the development of dark energy models as alternative sources for acceleration, but many of them suffer from a similar discrepancy and require an unnatural tuning of their parameters. Despite decades of attempts, the Old Cosmological Constant Problem remains yet unsolved.

This program proposes a distinct direction to address this problem and to explain the acceleration of the Universe where the graviton, the particle carrier of gravity, has a mass, or is effectively massive. Not only will this open a new panorama for cosmology, it will also answer the fundamental question of the nature of the graviton. Signatures and constraints will be derived through astrophysical and cosmological probes.

While striving to address these fundamental challenges, the program will also elucidate new aspects of massive gravity by establishing its theoretical viability and embedding as an effective field theory.  These developments will feed into new breakthroughs that have recently emerged from massive gravity.

As major missions and experiments are underway to probe dark energy and to detect gravitational waves, there is no better time to question gravity at the fundamental level, to provide alternatives to dark energy and to determine their unique signatures.","1975829","2017-05-01","2022-04-30"
"MASSLIP","Systems Medical Diagnostics by In-vivo Ambient Mass Spectrometric Profiling of Tissue Lipidome","Zoltan Takats","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","""The objective of the proposal is the development of ambient mass spectrometric methods for the characterisation of mucosal metabolome and lipidome. While recent advent of ambient MS provided new means for in-situ and imaging analyses and led to the development of real-time, in-vivo MS characterisation of tissues, there are no methods available for minimally invasive testing of mucosal surfaces including the associated microflora. Human mucosa-associated microbiome (with special emphasis on the gastrointestinal microbiota) has been recently demonstrated to play a key role in the pathogenesis of localised (cancer, chronic inflammatory disease) and systemic (hypertension, diabetes, obesity) conditions. While the microbiota interacts with the host mostly via production of a variety of metabolites, currently there is no method available for the in-situ metabolic profiling of mucosa. The envisioned methods will presumably fill this gap, by providing a technique for the diagnosis of a wide range of diseases ranging from acute infections through cancer to dysbiotic conditions of the microflora leading to chronic illnesses.
In the current proposal we put forward the development of different ambient ionisation setups utilising Jet Desorption Ionisation, Sonic Spray Ionisation and Rapid Evaporation Ionisation MS covering a broad range of invasiveness. We plan to combine the methods with standard endoscopic tools and develop the concept of ´chemically aware´ or intelligent endoscopic device capable of the unambiguous identification of pathological conditions of the mucosa. Since the metabolic profile-based identification approach requires large authentic datasets, we plan to create both histopathological and bacterial spectral databases with histological and 16SrRNA-based validation. The proposal also comprises the development of novel multivariate statistical analysis workflows and data fusion algorithms allowing rapid and accurate identification using multimodal MS datasets.""","1997663","2014-06-01","2019-05-31"
"MatEnSAP","Semi-Artificial Photosynthesis with Wired Enzymes","Erwin Reisner","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Nature has been harnessing solar energy to drive endergonic life-sustaining reactions such as photosynthesis for billions of years. However, the overall biological processes are inefficient despite the evolution of efficient enzymes for carrying out specific reactions. Currently, there is an urgent need to develop superior strategies for the large scale conversion of solar energy into a renewable chemical fuel through artificial photosynthesis, which uses the same fundamental science as natural photosynthesis. Here we integrate the strengths of both natural and artificial photosynthesis to explore novel pathways for efficient solar-to-chemical conversion, which are otherwise inaccessible to either field alone.

In aim 1, we develop advanced materials and strategies for the rational integration of photosynthetic enzymes into photoelectrochemical cells. A platform will be established in which enzymes can be artificially coupled to light absorbers, and also be wired together to perform novel chemical reactions.

In aim 2, we adapt advanced analytical techniques, including scanning electrochemical microscopy and time-resolved spectroscopy, to gain mechanistic insights into the nature, extent, and mechanism of the enzyme-material interaction. This will aid rational cell design and shed light into reaction bottlenecks.

In aim 3, we wire the enzyme-electrodes together in rational combinations to arrive at novel and efficient pathways for performing solar-to-fuel conversions. We will demonstrate the efficient coupling of solar energy harvesting with water oxidation and proton/carbon dioxide reduction.

This integrated approach will lead the emergent field of semi-artificial photosynthesis beyond conventional solar fuels research. It will probe into the strengths and weaknesses of biological processes, and be used to explore how other processes (e.g. nitrogen fixation, C–H bond activation) can be more efficiently re-wired or be coupled to photochemistry.","1960289","2016-10-01","2021-09-30"
"Mathador","Type and Proof Structures for Concurrent Software Verification","Aleksandar Nanevski","FUNDACION IMDEA SOFTWARE","Verification of concurrent software is a notoriously difficult subject, whose complexities stem from the inability of the existing verification methods to modularize, and thus divide-and-conquer, the verification problem.

Dependent types are a formal method well-known for its ability to modularize and scale complex mathematical proofs. But, when it comes to programming, dependent types are considered limited to the purely functional and terminating programming model.

The grand challenge of this project is to remove the limitation and scale dependent types to support implementation of stateful concurrent programs, and their correctness proofs, simultaneously. By applying the modularizing power of dependent types to both programs and proofs, the project will obtain novel and scalable foundations for the field of concurrent software verification.

Writing mechanized proofs of software, concurrent or otherwise, is generally considered infeasible. But if one chooses the right linguistic abstractions to express the proofs, we argue that it does not have to be so. This observation is supported by our encouraging preliminary results. The project will discover further novel linguistic abstraction that facilitate engineering of practically feasible formal proofs, and experimentally evaluate them by mechanically verifying extensive concurrent programs drawn from realistic applications, such as concurrent garbage collectors, OS kernels, and popular open-source concurrent libraries.

The project is high risk because it proposes novel foundations for concurrent software verification, whose development requires deep intertwining of logic and program semantics theory, with significant hands-on implementation and experimentation with formal proofs. But it is also high gain, as scaling concurrent software verification is the most significant open problem of present-day programming languages and semantics research.","1999895","2017-04-01","2022-03-31"
"MaTissE","Magnetic approaches for Tissue Mechanics and Engineering","Claire Wilhelm","UNIVERSITE PARIS DIDEROT - PARIS 7","""While magnetic nanomaterials are increasingly used as clinical agents for imaging and therapy, their use as a tool for tissue engineering opens up challenging perspectives that have rarely been explored. Lying at the interface between biophysics and nanomedicine, and based on magnetic techniques, the proposed project aims to magnetically design functional tissues and to explore the tissular fate of nanomaterials. Magnetic nanoparticles will be safely introduced into therapeutic cells, thus allowing them to be remotely manipulated by external magnets. 3D manipulations of the magnetized cells (patented in 2012) will be used to form tissues with a controlled size and shape through the development of a unique magnetic bioreactor.  In a self-integrating all-in-one process, 3D tissue will be shaped from cellular ""bricks"" without the need for a scaffold. The magnetic tissue will be amenable to mechanical stimulation and in situ imaging at each step of its maturation. The project is inherently multidisciplinary:
1) From a biophysics standpoint, controlled tissue stimulation, forced cell alignment, and mapping of cell-cell forces, will be used to answer pressing questions on the role of physical stresses in cell and tissue functions, such as differentiation.
2) From a regenerative medicine standpoint, this magnetic technology will be applied to cartilage and cardiac tissue repair. The functionality of the constructs and their centimetric size range, combined with a surgeon-friendly tissue handling with a dedicated magnetic tool, and the inherent magnetic resonance imaging properties of the constructs will be major advantages for clinical translation.
3) From a nanomaterials standpoint, nanomaterial fate will be explored in situ using nanomagnetic methods, both at the tissue scale (macroscopic) and at the nanoscale. This is a necessary corollary for the use of nanomaterials in regenerative medicine, and one that is largely unexplored.""","1589000","2015-07-01","2020-12-31"
"MDFT","Mathematics of Density Functional Theory","Mathieu LEWIN","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Density Functional Theory (DFT) is one of the most famous methods used in quantum physics and chemistry to describe matter at the microscopic scale. The purpose of the proposal is to investigate the mathematical foundations of this theory. The questions which have to be solved involve advanced tools from nonlinear analysis, partial differential equations, spectral theory, optimal transport, and numerical analysis. Several have stayed unsolved for many years. The project is prone to have an impact in many areas of mathematics, as well as in physics and chemistry.

The proposal is divided into three main tasks. The first is focused on some important questions on the foundations of DFT, including excited states, its time-dependent formulation, and the local density approximation based on the uniform electron gas model. DFT can be formulated as an inverse problem, the main question being to find the external potential knowing only the density of particles in the system. We will investigate the invertibility of the potential-to-density map, both in the stationary and time-dependent cases.

The second task deals with the derivation of simple DFT models from the true Schrödinger equation, a problem which has been largely discussed in the literature. We will work on the most challenging open questions, including for instance the relativistic Scott correction, or the proof of Bose-Einstein condensation for an infinite Bose gas in the mean-field limit.

Finally, in the last task we study some particular DFT models, which are particularly challenging from the mathematical point of view. This includes for example a highly nonlinear model for neutrons and protons, infinite crystals with deterministic and random perturbations, and a time-dependent electromagnetic field solving Maxwell's equations coupled to the quantized Dirac quantum vacuum.","1534159","2017-09-01","2022-08-31"
"MechaDynA","Multi-scale mechanics of dynamic leukocyte adhesion","Felix Emilio RICO CAMPS","UNIVERSITE D'AIX MARSEILLE","Leukocytes, white blood cells, patrol the vascular wall of our vessels in search of sites of inflammation. In the so-called leukocyte adhesion cascade, leukocytes flowing at high velocities (up to mm/s) impact the vessel wall, roll at µm/s, and finally migrate at nm/s to the site of inflammation. They are thus subjected to mechanical forces from sub-msec to several minutes. Complete understanding of the physical processes behind leukocyte adhesion requires an approach over multiple length and time scales, from single protein molecules to the whole cell. This is far from being established due, in part, to the lack of techniques covering the wide range of length and time scales involved. We have recently implemented high-speed atomic force microscopy (HS-AFM) to perform force spectroscopy measurements on biological samples with microsec time resolution. The novel acoustic force spectroscopy (AFS) traps hundreds of particles in parallel allowing hours-long measurements on single molecules.
MechaDynA proposes to develop and apply these two novel nanotools to allow force measurements on living cells with the goal of obtaining a complete, multi-scale picture of the physics behind the leukocyte adhesion cascade over the widest dynamic range (µs-min). This will require development of HS-AFM technology and coupling with advanced optical microscopy. We will probe the binding strength of single adhesion complexes, and membrane and cytoskeleton mechanics at physiologically relevant time scales not explored so far. Technologically, it will establish HS-AFM and AFS as force measurement tools for living cells covering the widest temporal range. This will open the door to unexplored physical phenomena in cell biology, biological physics and soft condensed matter. Biomedically, the expected outcomes will provide a mechanistic description of the physical phenomena in leukocyte immune response that may lead to better diagnosis and therapeutics.","2068959","2018-09-01","2023-08-31"
"Mechan-of-Chromo","Unfolding the Mechanism of Chromosome Cohesion and Condensation using Single-Molecule Biophysical Approaches","Fernando Moreno-Herrero","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","The global folding of the chromosome is mediated by Structural Maintenance of Chromosome (SMC) proteins, which stabilize the higher-order chromatin architecture by bringing distant DNA sequences together. Despite over a decade of work on these systems, their mechanism remains unknown, largely because of difficulty in re-capitulating physiological DNA binding and condensation in vitro. Moreover, traditional biochemical approaches are poorly suited for the study of processes that are fundamentally mechanical in nature. However, key breakthroughs, including the discovery that SMC is loaded by Spo0J protein at parS sites in vivo, and that parS sites act as global condensation centres for the chromosome have opened new possibilities to study chromosome organisation using single-molecule (SM) approaches. Importantly, our recent experiments with Magnetic Tweezers (MT) have already revealed a novel function of Spo0J in condensing DNA via a parS-independent binding mechanism.

Inspired by these recent discoveries, I have devised a series of novel SM biophysical approaches with the ambitious goal of determining the mechanism of action of SMC complexes, including understanding the role of SMC loaders and SMC accessory subunits, and how these proteins are regulated by ATP binding and hydrolysis for chromosome organisation. The rationale behind this approach is that SM methods are particularly well-suited for monitoring DNA cohesion and condensation where manipulation of individual DNA molecules, measurement of forces, and addition of proteins and buffer solutions can be carefully controlled. High throughput MT will be combined with fast video imaging, optical trapping, and fluorescence; and will be used to interrogate hypothetical models for SMC-DNA interactions. Finally, the novel assays developed here may be applicable to other protein-DNA interactions including variant SMC-like proteins specialized for other biological functions such as DNA repair.","1894999","2016-06-01","2021-05-31"
"MechaniChiral","Mechanical Chirality: Synthesis, Properties and Applications at a New Horizon in Supramolecular Stereochemistry","STEPHEN MICHAEL GOLDUP","UNIVERSITY OF SOUTHAMPTON","Molecular chirality is a central theme in chemistry; in 2015 approximately 13% of publications in J. Am. Chem. Soc. and 12% in Angew. Chem. concerned chirality. All previously studied forms of molecular asymmetry (central, axial, planar and helical chirality) have found applications throughout the sub-disciplines of chemistry including as catalysts, materials and sensors.

Mechanically chiral rotaxanes are molecules in which the mechanical bond between a macrocycle and dumbbell-shaped component is the source of asymmetry rather than the covalent structure of the components themselves. These unusual molecules represent a novel and unexplored chiral supramolecular environment as the lack of a scalable synthetic approach for their isolation in enantiopure form has prevented all but the most cursory investigation of their properties. Thus, mechanical chirality remains an unexplored frontier of molecular asymmetry with the potential to deliver novel functions and impact across a range of chemical disciplines from materials chemistry to the synthesis of pharmaceutically active compounds.

The Goldup Group has recently demonstrated the first practical method for the synthesis of enantiopure mechanically chiral rotaxanes using a flexible active template methodology and thus the stage is finally set for the study and exploitation of this novel form of supramolecular asymmetry. Within the period of this ERC Consolidator Grant the PI will lead a team to investigate the synthesis, properties and applications of these intriguing mechanically chiral molecules.","1998928","2017-04-01","2022-03-31"
"MECHANICS","Mechanics of cells: the role of intermediate filaments","Sarah Friederike KOESTER","GEORG-AUGUST-UNIVERSITAT GOTTINGENSTIFTUNG OFFENTLICHEN RECHTS","The mechanical properties of each of the over 200 cell types in the human body are perfectly well adapted to their function. The large variety of viscoelastic profiles, ranging from soft brain cells to stiff cartilage, and the temporal variability in the mechanical stress response when stationary cells begin to migrate, e.g. in embryogenesis, wound healing or cancer metastasis, is reflected in a surprisingly small number of molecular building blocks. Three distinct filament systems, actin filaments, microtubules and intermediate filaments (IFs), self-organize into a wealth of structural units, collectively termed the cytoskeleton. The main molecular players of this remarkable composite material are largely known. However, from a physics point of view, in particular IFs are poorly understood, despite their importance in health and disease and astonishing mechanical properties, like extreme extensibility and high flexibility. It is not known, how these properties are encoded in the molecular interactions of the protein filament and how they feed into the mechanical behavior of a whole cell. The aim of the proposed research is thus to establish a structure-mechanics-function relationship for this important component of the cytoskeleton. The genetic complexity of the IF protein family with 70 members that are expressed in a tissue specific manner requires a strategic approach involving well-defined model systems and the combination of in vitro and cell work. Direct mechanical testing by applying stress and in situ high-resolution imaging will link mechanical properties to molecular interactions in the hierarchical IF architecture. The results of these in vitro studies will be related to cell experiments to decipher the link between IF type and cell mechanics. The work program will lead to models that predict, how modifications, e.g., in the type of IF protein or specific charge interactions, are associated with changes in cell mechanics and eventually in cell function.","2413250","2017-05-01","2022-04-30"
"MechanoTubes","Supramolecular machineries with life-like mechanical functions","Tibor Kudernac","UNIVERSITEIT TWENTE","Artificial molecular motors and switches have the potential to become a core part of nanotechnology. However, a wide gap in length scales still remains unaccounted for, between the operation of these molecules in solution, where their individual mechanical action is randomly dispersed in the Brownian storm, and on the other hand their action at the macroscopic level, e.g. in polymer networks and crystals. 

This proposal is about bridging this gap, by developing chemo-mechanical transduction strategies that will allow dynamic molecules to perform a range of unprecedented tasks, e.g. by generating strong directional forces at the nanoscale, and through shape-shifting microscopic formations.

This project aims to harness the mechanically-purposeful motion of dynamic molecules as to generate measurable forces from the nanoscale, and ultimately establish operational principles for chemo-mechanical transduction in supramolecular systems. 

In my wholly synthetic approach, I draw inspiration from the operational principles of microtubules. I will incorporate molecular photo-switches into supramolecular tubes, and enable the controlled growth and disassembly of the tubes by using light as the energy input. Thus, I will: (i) Synthesize stiff supramolecular tubes that grow actively under continuous illumination, and disassemble with a power stroke as soon as illumination stops; (ii) Measure, and harvest the forces generated by the tubes to manipulate individual nanoparticles with a sense of directionality; and (iii) Encapsulate the tubes into water droplets and vesicles, to yield shape-shifting, and eventually rudimentary splitting models for cells. 

This project reaches beyond the state of the art in adaptive molecular nano-systems, by pioneering strategies to engineer and harness strain in supramolecular assemblies. It thus lays the foundations for machineries that are capable of manipulating matter at length scales that are also those at which the cytoskeleton operates.","2000000","2019-03-01","2024-02-29"
"MERIR","Methane related iron reduction processes in sediments: Hidden couplings and their significance for carbon and iron cycles","Orit Sivan","BEN-GURION UNIVERSITY OF THE NEGEV","About one-third of annual methane (CH4) emissions to the atmosphere originate from natural, nonanthropogenic
sources. However, if all the naturally produced methane actually did reach the atmosphere, its
levels would increase by an order of magnitude, dwarfing anthropogenic CO2 emissions. Fortunately, natural
scavengers of this methane near its production zone limit its release. One of these scavengers, iron (Fe) oxide,
can become a major sink for methane when sulfate concentrations are low. Methane-iron couplings in
established sediments, however, are poorly understood. Specifically, significant iron oxide reduction has been
observed in many aquatic sediments at depths well below its expected redox zone, where methane is produced
by methanogenesis, often accompanied by decreases in methane concentrations. These observations challenge
our understandings of iron-methane couplings and microbial players in the deep methanogenic zone and their
impacts on the carbon, iron and other cycles. I aim in the proposed research to elucidate the unexplored
mechanisms of methane-related iron reduction (MERIR) in the methanogenic zone of established
sedimentary profiles under various environmental conditions and their impact on global biogeochemical
cycles. I will resolve two striking yet unexplained phenomena: (1) the active involvement of aerobic
methanotrophs in iron-coupled anaerobic oxidation of methane (AOM), and (2) the unusual reactivity
of iron minerals toward reduction that is accompanied by intensive authigenic magnetite precipitation, and
the effects of this mineralogy change on sedimentary magnetism. My expertise will enable me to achieve the
objectives of this interdisciplinary proposed work using novel approaches from different fields. The project
will likely lead to breakthroughs in our understanding of microbial survival strategies, reveal novel pathways
for aerobic methanotrophs, and change our perspectives on iron mineral reactivities and sedimentary
magnetism.","2000000","2019-04-01","2024-03-31"
"MeSoMat","Metabolic soft matter with life-like properties","André ESTEVEZ-TORRES","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","A fundamental difference between man-made and living matter is metabolism: the ability to dissipate chemical energy to drive many different chemical processes out of equilibrium. Metabolism endows chemical systems within living organisms with properties that are standard in biology but odd in chemistry: the capability to process information, to move and to react to the external world.

My goal is to endow soft materials with dynamic life-like properties. I have chosen four: molecular computation, movement, self-construction and the capacity to entertain complex chemical conversations with living cells. To do so I will embed stimuli-responsive materials with a biocompatible synthetic metabolism capable of sustaining autonomous chemical feedback loops that process information and perform autonomous macroscopic actions. My approach combines concepts from systems chemistry, synthetic biology and DNA molecular programming with soft materials and uses a biochemical system that I have contributed to pioneer: DNA/enzyme active solutions that remain out of equilibrium by consuming a chemical fuel with non-trivial reaction kinetics. This system has three unique properties: programmability, biocompatibility and a long-term metabolic autonomy.

Metabolic matter will be assembled in two stages: i) enabling metabolic materials with dynamic chemical, biological and mechanical responses, and ii) creating metabolic materials with unprecedented properties, in particular, the capacity of self-construction, which I will seek by emulating embryogenesis, and the ability to autonomously pattern a community of living cells. By doing this I will create for the first time chemical matter that is both dynamically and structurally complex, thus bringing into the realm of synthetic chemistry behaviors that so far only existed in biological systems. In the long term, metabolic matter could provide revolutionary solutions for soft robotics and tissue engineering.","1899333","2018-06-01","2023-05-31"
"MesoPhone","Vibrating carbon nanotubes for probing quantum systems at the mesoscale","Edward LAIRD","LANCASTER UNIVERSITY","Many fascinating quantum behaviours occur on a scale that is intermediate between individual particles and large ensembles. It is on this mesoscopic scale that collective properties, including quantum decoherence, start to emerge.
This project will use vibrating carbon nanotubes – like guitar strings just a micrometre long – as mechanical probes in this intermediate regime. Nanotubes are ideal to explore this region experimentally, because they can be isolated from thermal noise; they are deflected by tiny forces; and they are small enough that quantum jitter significantly affects their behaviour. To take advantage of these properties, I will integrate nanotube resonators into electromechanical circuits that allow sensitive measurements at very low temperature. 
First, I will study the motional decoherence of the nanotube itself, by using it as the test particle in a new kind of quantum interferometer. This experiment works by integrating the nanotube into a superconducting qubit, and will represent a test of quantum superposition on a larger mass scale than ever before. It will answer a longstanding question of physics: can a moving object, containing millions of particles, exist in a superposition of states?
Second, I will use the nanotube device as a tool to study superfluid helium 3 – the mysterious state of matter that may emulate the interacting quantum fields of the early universe. By measuring an immersed nanotube viscometer, I will be able to measure the behaviour of superfluid excitations on a scale where bulk superfluidity begins to break down.
Third, I will add to the device a nanomagnet on nanotube springs, creating an ultra-sensitive magnetic force sensor. This offers a way to perform nuclear magnetic resonance on a chip, ultimately creating a microscopy tool that could image for example single viruses.","2748271","2019-03-01","2024-02-29"
"METAFOAM","Novel assembly strategies in liquid dispersion via interface control – towards cellular metamaterials","Wiebke DRENCKHAN-ANDREATTA","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The astounding properties of metamaterials result from a characteristic spatial organisation of purpose-designed structural units. Research on metamaterials has greatly advanced thanks to their reliable top-down fabrication (lithography, 3D-printing,...). For large-scale production, however, smart bottom-up design strategies are required, for example through self-assembly of the structural units. While this has been developed for thermally-driven systems with sub-micrometric units, no systematic design strategies are established for mechanically-driven systems with larger units.  
The METAFOAM project will fill this gap by addressing the scientific challenges towards controlled bottom-up structuring of bubble/drop packings in liquid foam/emulsion templates. While “ordinary” foams/emulsions have been investigated in depth, the control over their structure is very limited. The METAFOAM project will provide access to very different structures by explicitly tuning the bubble/drop interactions through the presence of a polymeric skin with controlled repulsive, adhesive and frictional properties. 
We will develop methods to reliably create/characterise these skins and establish a state diagram which systematically relates the resulting bubble/drop interactions and the foam/emulsion structure. Solidification of the most promising structures will provide new types of cellular polymers with currently inaccessible mechanical or acoustic meta-properties: high stiffness-to-weight-ratios, negative Poisson ratios, and acoustic band-gap properties.
The impact of this interdisciplinary project at the interface between physics and chemistry is therefore two-fold. In the liquid state it will advance our understanding of the a-thermal packing of very soft objects with tuneable interactions, linking the physics of granular media and biological tissues. In the solid state it will provide new cellular systems for the fabrication and investigation of mechanical and acoustic metamaterials.","1999677","2019-05-01","2024-04-30"
"METAmorphoses","Shapeshifting Metasurfaces for Chemically Selective Augmented Reality","Antonio AMBROSIO","LABORATORIO IBERICO INTERNACIONAL DE NANOTECNOLOGIA","I propose to realize the first shapeshifting optical metasurface that changes its functionality on-demand and adapts to changing external conditions. The metasurface may work as a chemically selective lens that allows transmission only of the spectral fingerprint of a specific molecule in the mid-IR wavelength range. The same metasurface can later be turned into an adaptive lens for focusing and detection under the skin. For such ambitious goal, a radically new approach is needed.
I will realize shapeshifting metasurfaces made of a polymer containing photo-switchable molecules. The surface of such polymers undergoes a morphology re-organization (surface structuring) when illuminated by an external visible light pattern. The polymer will be structured with visible light and the resulting metasurfaces will work in the mid-IR. I will use state-of-the-art optical nano-imaging techniques to investigate the surface structuring phenomenon at the nanoscale in order to achieve full control of the mechanism.
Since the polymer surface can continuously be adjusted with the illuminating visible light, it will be possible to shift from one encoded optical functionality to a completely different one. Once optimized, this completely out-of-the-box approach will be completed by developing a feedback mechanism that allows for self- adjustment of the polymeric metasurface to changing external conditions. This will open endless possibilities in many fields, from medical imaging to security and quality control.
The proposed approach is unprecedented but it is perfectly in line with my research activities, resulting in fact from merging different techniques that I master into a new research field.
My approach is also inexpensive relative to the usual nano-fabrication techniques and immediately compatible with high-volume production, providing a viable technology platform for lightweight, eyewear technology, that reflects the views of key industrial players in the field.","2745000","2019-09-01","2024-08-31"
"METLAKE","Predicting future methane fluxes from Northern lakes","DAVID TORBJORN EMANUEL BASTVIKEN","LINKOPINGS UNIVERSITET","The new global temperature goal calls for reliable quantification of present and future greenhouse gas (GHG) emissions, including climate feedbacks. Non-CO2 GHGs, with methane (CH4) being the most important, represent a large but highly uncertain component in global GHG budget. Lakes are among the largest natural sources of CH4 but our understanding of lake CH4 fluxes is rudimentary. Lake emissions are not yet routinely monitored, and coherent, spatially representative, long-term datasets are rare which hamper accurate flux estimates and predictions.

METLAKE aims to improve our ability to quantify and predict lake CH4 emissions. Major goals include: (1) the development of robust validated predictive models suitable for use at the lake rich northern latitudes where large climate changes are anticipated in the near future, (2) the testing of the idea that appropriate consideration of spatiotemporal scaling can greatly facilitate generation of accurate yet simple predictive models, (3) to reveal and quantify detailed flux regulation patterns including spatiotemporal interactions and response times to environmental change, and (4) to pioneer novel use of sensor networks and near ground remote sensing with a new hyperspectral CH4 camera suitable for large-scale high resolution CH4 measurements.

Extensive field work based on optimized state-of-the-art approaches will generate multi-scale and multi-system data, supplemented by experiments, and evaluated by data analyses and modelling approaches targeting effects of scaling on model performance. 

Altogether, METLAKE will advance our understanding of one of the largest natural CH4 sources, and provide us with systematic tools to predict future lake emissions. Such quantification of feedbacks on natural GHG emissions is required to move beyond state-of-the-art regarding global GHG budgets and to estimate the mitigation efforts needed to reach global climate goals.","2000000","2017-04-01","2022-03-31"
"MFreeB","Membrane-Free Redox Flow Batteries","Rebeca MARCILLA GARCIA","Fundacion IMDEA Energia","The environmental concerns over the use of fossil fuels have promoted great interest in generating electric energy from renewable sources such as solar and wind. However, the intermittent nature of those resources demands high performing and cost-effective energy storage systems. Redox Flow Batteries (RFBs) present several advantages, namely, total decoupling of power and energy densities and the possibility of rapid mechanical charging by substituting spent electrolytes with fresh ones. The major issues of the current Vanadium RFBs are the high price and toxicity of vanadium components and the high cost and low performance of the ion-selective membranes they require. 
MFreeB project proposes to completely remove the problematic membrane of RFBs by developing a disruptive, versatile and scalable concept of Membrane-Free RFB implementing efficient catholytes and anolytes in which the metallic redox pairs are replaced by cheap, abundant and environmental-friendly molecules. In order to achieve this objective, I propose a multi- and interdisciplinary research methodology across a wide range of expertise including fundamental electrochemistry, thermodynamics, physical chemistry, modelling, and mechanical engineering. I will make use of advantages of different electrolytes to develop a versatile concept of Membrane-Free RFB with a wide range of applications.
This Consolidator Grant (ERC) would provide adequate support to consolidate my own independent research team and programme. During my scientific career, I have demonstrated creative thinking and excellent capacity to carry out research going beyond the state of the art. My meritorious record of scientific publications (55 ISI articles, h index = 25), project leadership, international collaborations and capacity for supervising and coordinating a research team are presented in the proposal. I am now in an excellent position and research environment to commit and be devoted to this encouraging and challenging project","1998407","2017-06-01","2022-05-31"
"MHDiscs","From non-ideal magnetohydrodynamics to the structure and evolution of protoplanetary discs","Geoffroy LESUR","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Circumstellar discs are the birthplaces of planets. They form around young protostars and dissipate in a few million years. Modern submillimeter and optical telescopes such as ALMA and VLT/SPHERE are now able
to resolve thin structures in the bulk of these objects, such as rings, crescents, spirals and winds, probing the very origin of planetary systems similar to our own. Our current understanding of these discs relies on a very crude modelling of a hypothetic magneto-hydrodynamic (MHD) turbulence thought to play an essential role in the evolution and structure of these systems. However, there is now compelling theoretical and observational evidence that these discs are weakly turbulent, if not laminar, because of their low ionisation fraction and thus poor coupling to the magnetic field. This suggests that subtle MHD processes are driving the dynamics of these objects. 

Moreover, my recent theoretical breakthroughs demonstrate that these gaseous discs are subject to self-organisation and magneto-thermal winds. These processes play a key role for the disc as they can control its radial structure and evolution. I propose that computing global non-ideal MHD models from massively parallel numerical simulations will shed a new light on these processes, connecting the long-term evolution of these discs to the formation of large scale structures seen by ALMA and SPHERE. We expect MHDiscs to provide reliable global evolution models by coupling gas dynamics to dust and irradiation. These models will be used to predict discriminant observables of the processes I propose, setting the stage for a deeper understanding of the formation of planetary systems.","1784300","2019-09-01","2024-08-31"
"MHETSCALE","Mixing in Heterogeneous Media Across Spatial and Temporal Scales: From Local Non-Equilibrium to Anomalous Chemical Transport and Dynamic Uncertainty","Marco Dentz","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Transport, mixing and reaction of solutes and particles in natural media are of central importance in many fields of science and engineering, ranging from contaminant dispersion in geophysical flows to diffusion in living cells. Transport in these intrinsically heterogeneous media is characterized by early and late solute and particle arrivals, tailed spatial distributions, and scale effects in measured parameters. These behaviors cannot be explained by available models based on Fick’s law and are called anomalous despite their ubiquity. The origin of such phenomena lies in heterogeneity-induced mixing processes that lead to fluctuations in chemical concentration, or, in other words, to physical non-equilibrium. Current transport formulations based on the advection-dispersion-reaction equation or phenomenological non-equilibrium models lack the relation to the heterogeneity controls, fail to describe mixing and concentration variability and thus are not suited for the quantification of chemical reactions. The main objective of this proposal is to establish a global predictive framework that quantifies mixing across scales, anomalous transport and reaction, and dynamic uncertainty for heterogeneous media. We propose an integrated approach that links the interrelated phenomena of mixing, anomalous transport and chemical reaction. In short, the idea consists in quantifying microscale heterogeneity-induced mixing in terms of the flow kinematics and heterogeneity structure and linking it to transport through its relation to Lagrangian particle dynamics. These dynamics will be quantified stochastically by a novel generalized continuous time random walk approach and used to model chemical reactions under physical non-equilibrium in order to obtain a new solid approach for simulating reactive and conservative transport through natural media.","1904186","2014-04-01","2020-03-31"
"MICHELANGELO","MultiphasIc NanoreaCtors for HEterogeneous CataLysis via SmArt ENGinEering of TaiLored DispersiOns","Marc PERA TITUS","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Gas-liquid-solid (G/L/S) multiphasic reactors are extensively used in the chemical industry for catalytic processes. However, conventional reactors, such as packed beds and slurry reactors, typically suffer from resilient mass/heat transfer limitations due to their low specific interface areas, long mixing times, and a reduced accessibility of the gas reactants to the catalyst surface. To overcome these limitations, continuous flow microreactors and catalytic membrane reactors have been considered for increasing the G/L interface area, but these systems require complex equipment and still do not guarantee an efficient L/S contact at the catalyst surface. For a major improvement on current systems in terms of cost efficiency and energy savings, G/L/S reactors operating at the nanoscale are required.
The aim of this ERC project is to design robust particle-stabilized G/L dispersions (i.e. micro/nano-bubbles and liquid marbles) as highly efficient G/L/S nanoreactors for conducting catalytic reactions at mild conditions.

We will (i) prepare NPs with defined sizes, shapes, hydrophilic-lipophilic balance (HLB), including catalytic functions; (ii) generate particle-stabilized bubbles and liquid marbles affording highly active and selective reactions at the G/L/S interface with NP recycling after each catalytic cycle using external stimuli; examine the interplay between the NP assembly at the G/L interface and the catalytic properties along the reaction by combining well-designed experiments with simulations; and (iv) reengineer G/L/S multiphasic reactors using our particle-stabilized nanoreactors to achieve a high catalytic performance at milder operation conditions compared to conventional reactors while keeping a high degree of stability and flexibility at reduced layouts.

Through innovation on both amphiphilic catalysts and process intensification, MICHELANGELO will deliver a radical step change towards a higher efficiency and competitiveness in the process industry.","1956720","2018-10-01","2023-09-30"
"MICROCRYO","Microsystems for Cryomicroscopy","Thomas BURG","TECHNISCHE UNIVERSITAT DARMSTADT","This proposal aims to revolutionize time-resolved light and electron cryo-microscopy of fast cellular dynamics using a new class of cryogenic microsystems for the reversible cryofixation of cells and small model organisms by ultra-rapid cooling. This will contribute to our understanding of biological structure and function by revealing the dynamics of specific proteins in the ultrastructural context of a cell at nanometer spatial and millisecond temporal resolution.

Despite rapid progress in the field, much of the potential of microscopy at cryogenic temperature today is still untapped due to limitations in methods and instrumentation for sample preparation. First, vitrification technologies for cryo-microscopy have evolved only incrementally since the 1960s and cannot be combined with many of the sophisticated live imaging methods that have emerged over the past decade. Second, while the synergy of light and electron cryo-microscopy is extremely powerful, cryo-microscopy with light is still in its infancy. Finally, new technologies for ultra-rapid heating and cooling of single cells are needed to systematically advance our understanding of reversibility in the cryopreservation of e.g. stem cells, oocytes, or sperm cells. Here I propose to create a microfluidic technology for the direct vitrification of cells in the light microscope by ultra-rapid cooling with millisecond time resolution. The cells will then be imaged at high resolution using electron microscopy and advanced modes of light microscopy combined with new optics adapted to cryogenic conditions. Ultimately, we will elucidate if and under which conditions cryofixation can be reversed by ultra-rapid warming such that dynamic cellular processes resume unperturbed.

We expect that the research proposed here will enable breakthroughs in understanding the structural and molecular basis of fast cellular events including transport, membrane trafficking, cell division, and synaptic transmission.","1994562","2019-02-01","2024-01-31"
"MicroDegrade","Identifying and Overcoming Bottlenecks of Micropollutant Degradation at Low Concentrations","Martin Elsner","HELMHOLTZ ZENTRUM MUENCHEN DEUTSCHES FORSCHUNGSZENTRUM FUER GESUNDHEIT UND UMWELT GMBH","""MicroDegrade aims to reveal bottlenecks of degradation, and to identify superior bioremediation strategies for a most notorious environmental pollution of our time: chemical micropollutants at low (sub-ug/L) concentrations. Finding out why micropollutants occur in ground and surface water despite the presence of bacterial degraders has become an elusive goal for microbiologists, environmental scientists and geochemists. Competing paradigms claim that either (i) mass transfer limitations (bioavailability, cell uptake) or (ii) physiological limitations (enzyme down-regulation) prevent complete biodegradation at contaminant threshold concentrations. To design strategies for remediation, insight is warranted which bottlenecks of degradation prevail. """"Do molecules - once inside an organism - get out into solution again? Or is mass transfer so limiting that organisms are desperate for supply?"""" Pillaring on our recent advances with compound-specific isotope analysis at sub-ug/L concentrations, MicroDegrade will be able to provide a revolutionary angle on this dilemma.  Isotope fractionation will give the first direct answers to these questions for degradation of two prominent pollutants at low bacterial growth and low concentrations - 2,6-dichlorobenzamide (BAM), a highly recalcitrant, ubiquitous pesticide metabolite with Aminbacter MSH1; and toluene, an abundant groundwater pollutant with Geobacter metallireducens. The approach pillars on three consecutive aims: (1) investigate if, and at what concentrations mass transfer becomes limiting in chemostat cultures; (2) understand analogous limitations in concentrations gradients of an aquifer model; (3) derive superior bioremediation strategies. The objectives of MicroDegrade have the potential to change our view on drivers behind thresholds values and bottlenecks of degradation, to offer a new angle on competitive strategies of microorganisms at low concentrations, and to identify superior future bioremediation strategies.""","1962630","2014-05-01","2019-04-30"
"microKIc","Microscopic Origins of Fracture Toughness","Erik BITZEK","FRIEDRICH-ALEXANDER-UNIVERSITAET ERLANGEN NUERNBERG","The resistance to crack propagation is undoubtedly one of the most important properties of structural materials. However, our current mechanistic understanding of the fracture processes in typical semi-brittle materials like steels, refractory metals or semiconductors is not sufficiently advanced to predict the fracture toughness KIc and its dependence on the microstructure, temperature and strain rate. Therefore, KIc is commonly regarded as a phenomenological material parameter for fracture mechanics models that require experimental calibration. 

The aim of microKIc is to study fracture in model materials in order to gain a detailed understanding of the microscopic crack-tip processes during fracture initiation, propagation and arrest, and to systematically study the interactions of cracks with constituents of the microstructure like dislocations, voids, precipitates and grain boundaries. To this end, we will perform fully 3D, large-scale atomistic simulations on cracks in bcc-based materials (W, NiAl) with varying crack orientation, crack front quality, and in the presence of dislocations and microstructural obstacles. The obtained criteria for crack advance and dislocation nucleation at crack tips will be implemented in a coupled finite element - discrete dislocation dynamics code, which will allow for the first time a fully 3D study of fracture and crack-tip plasticity at the mesoscale. The simulations will be compared to in-situ micro-mechanical tests on well-characterized fracture specimens produced by focused ion beam milling.

The ultimate goal of microKIc is to use this experimentally validated multiscale modelling framework to develop a microstructure-sensitive, physics-based micromechanical model of the fracture toughness, which will be tested against macroscopic fracture experiments. Such predictive models are crucial for the development of new failure-resistant materials and for improved design guidelines for safety-relevant structures and components.","1996570","2017-05-01","2022-04-30"
"MILESTONE","From mineral inclusions in zircon to continents: An in situ isotopic perspective on the evolution of the continental crust, the onset of plate tectonics and the development of a habitable Earth","Bruno DHUIME","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The continental crust is the principal record of conditions on Earth during the past 4.4 billion years, yet how it formed and evolved through time remains unresolved. Zircon lies at the core of crustal evolution studies, and yet our knowledge has remained restricted to the geochemical information that can be extracted from this mineral with current techniques. This CoG moves the debate to a different scale analytically, to the scale of mineral inclusions encapsulated within zircons. A key motivation is the recent analytical breakthrough in the microanalysis of minute samples, which was achieved by the PI and the team he led at the University of Bristol, using state-of-the-art instruments similar to those now available at the PI’s host laboratory. 

The integrated analysis of Sr and Pb isotopes of mineral inclusions, along with the trace elements, U-Pb, Hf and O isotopes analysis of their host zircons, for over 5000 zircons of different ages and provenance, will provide new and different information to that available from the 'zircon only' record – ultimately to i) probe the inferred transition from intraplate- to subduction-related magmatism associated with the onset of plate tectonics; ii) date this transition and its duration precisely in different places; iii) develop a global model of continental crust evolution from the Hadean (i.e. >4 Ga) to the Present, in which the Earth has progressively, or more suddenly, become a habitable planet. These goals will be achieved through:

1. Building a worldwide collection of inclusion-bearing zircons with a range of ages and provenance (WP1).

2. Evaluating changes in the degree of differentiation of the newly generated continental crust through time, using the Sr isotope record of apatite inclusions (WP2).

3. Addressing changes in the tectonic settings of new crust formation, using the Pb isotope record of feldspar inclusions (WP3). 

4. Modelling the variation in the new crust thickness through space and time (WP4).","1999500","2019-09-01","2024-08-31"
"MIMIC","Modeling microgels: from microscopic design to macroscopic description","Emanuela Zaccarelli","CONSIGLIO NAZIONALE DELLE RICERCHE","Soft matter provides the ideal playground for exploring physical phenomena that have no counterpart in atomic and molecular systems. A continuous progress in particle synthesis has provided a rich variety of soft, polymeric colloids, which are highly interpenetrable and can reach ultra-dense, jammed states. Such colloids offer exquisite control of material properties through a change in their internal architecture. Among this new generation of soft particles, microgels – colloidal-scale particles individually made by crosslinked polymer networks – have become a favourite model system for their responsive swelling properties and their multitude of applications. Notwithstanding their potentialities, knowledge of their behaviour from a fundamental point of view is still very limited. The present theoretical description is mostly based on simple models, which do not account for the internal, polymeric nature of the particles. Using state-of-the-art computational techniques across all scales (from atomistic to multi-blob coarse-graining), this 5-years work-program will provide an accurate model of both the microgels and of the effective interactions among them. The model will account for polymer/solvent interactions and for variation of the external control parameters at all densities, up to jamming conditions. In this way, I will develop a unified framework from the design at the molecular level of the individual particle up to the description of the macroscopic properties of the material. At all steps, I will verify my theoretical progress with experimental measurements performed by world-leading collaborators. This proposal will thus bring the current understanding of microgels to a new level: besides rationalizing existing results, it will open the way for new uses and applications of these fascinating systems.","1314375","2016-06-01","2021-05-31"
"MINERVA","Communication Theoretical Foundations of Nervous System Towards BIO-inspired Nanonetworks and ICT-inspired Neuro-treatment","Ozgur B. Akan","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","“There’s Plenty of Room at the Bottom”, stated by Nobel laureate Richard Feynman, describes the possibility of manipulating individual atoms and molecules to realise nanomachines. Emerging nanoscale applications mandate enabling nanomachines to communicate and form nanonetworks to overcome the limitations of a single one. Thus, our aim is to find the answer to the profound question, i.e., “is the room down there sufficient for a communication network?” Thanks to natural evolution, the affirmative answer is right inside us. Human body is a large- scale communication network of molecular nanonetworks composed of billions of nanomachines, i.e., cells, which use molecules to encode, transmit and receive information. Any communication failure that is beyond the recovery capabilities of this network leads to diseases. In this project, first, (1) we will investigate the communication theoretical foundations of nanoscale neuro-spike communication channels between neurons. Second, (2) we will study multi-terminal, i.e., multiple-access, relay, broadcast, neuro-spike channels and nervous nanonetwork in terms of communication theoretical metrics. Third, (3) we will validate our channel and nanonetwork models with physiological data, and develop a nervous nanonetwork simulator (N4Sim). Finally, (4) we will develop the first nanoscale bio-inspired communication system for ICT-inspired neuro-treatment for spinal cord injury, i.e., nanoscale artificial synapse, which will mimic neuron behaviour by realising both electrical and nanoscale molecular communications.The MINERVA project will pave the way for the realisation of emerging nanonetwork applications with significant societal impact, e.g., intra-body networks for health monitoring, drug delivery, chemical and biological attack prevention systems. The project will help develop the future ICT-inspired treatment techniques for communication related neural disorders.","1757039","2014-03-01","2019-02-28"
"MINERVA","MIcrobiota-Gut-BraiN EngineeRed platform to eVAluate intestinal microflora impact on brain functionality","CARMEN GIORDANO","POLITECNICO DI MILANO","What is the relation between the intestinal microflora and the brain in the development of neurodegenerative disorders like Alzheimer's and Parkinson's disease? 
A functional relation between the intestinal microflora (microbiota) and the brain, referred to as the “microbiota-gut-brain axis”, was hypothesized more than 100 years ago but only recently has been re-evaluated becoming a new, exciting hypothesis in neuroscience. We have the proof that aging, bad alimentary habits, poor food quality and stress can affect our intestinal microbiota: the impact of this modification on brain functionality has been observed but the absence of suitable research tools does not allow verifying this research hypothesis. My aim is to overcome this limitation through a bioengineering approach: I will develop the first microbiota-gut-brain platform relying on three miniaturized microfluidic compartments, representing in vitro the most important features of microbiota-brain interaction. Once validated, my platform will be challenged in healthy and neurodegenerative scenarios by using human complete microbiota. MINERVA has a ground breaking potential: the proof of a causal link between intestinal microbiota and brain functionality would completely change the actual scenario, shifting the investigation of neurodegenerative disorders causes from the brain to the body periphery. MINERVA is a high gain project: if its vision succeeds, neurodegenerative disorders will benefit from new, cost effective, low invasive preventative and therapeutic strategies based on microbiota management by food ingredient and probiotics with an enormous beneficial impact worldwide. MINERVA will provide a versatile platform that will overcome the strong limitations arising from the current in vivo models and standard in vitro tools: by changing cell type or culturing conditions, it could address microbiota impact not only on neurodegenerative disorders, but also on other severe other-than-nervous pathologies.","1999194","2017-05-01","2022-04-30"
"MINORG","The role of minerals in the oceanic carbon cycle","Caroline Louise Peacock","UNIVERSITY OF LEEDS","The oceanic carbon cycle is key for regulating the Earth system because, in sediments and seawater, the balance between the degradation and preservation of organic carbon (OC) exerts a first order control on atmospheric CO2 and O2. In sediments, OC is preserved over millions of years, while in seawater, a dissolved form of recalcitrant OC has been recently recognised as critical to OC storage over anthropogenic timescales. Both sedimentary and seawater OC are derived from living organisms, and should therefore be easily degraded. Their persistence is therefore profoundly puzzling. Quite simply we do not know how or why OC is preserved. A long-standing hypothesis suggests that protection of OC inside minerals might account for the vast OC stores preserved in sediments. In a NEW hypothesis, based on recent work by the PI and proposed here for the first time, the interaction of OC with minerals might ALSO account for the even larger stores of dissolved OC preserved in seawater. Together these concepts could revolutionise our understanding of OC degradation and preservation, but the extent to which minerals preserve OC in sediments and seawater is (still) unknown, largely because the mechanisms that control how OC interacts with minerals are almost entirely unconstrained. MINORG will quantify the role of minerals in the preservation of OC for the first time, by combining cutting-edge molecular-level techniques with the first ever comprehensive and fully integrated experimental and modelling campaign, to determine in unprecedented detail the exact mechanisms responsible for the interaction of OC with minerals, and its subsequent degradation and preservation behaviour. MINORG hypothesises that minerals play a MAJOR role in the preservation of OC, in both its sedimentary and seawater forms, and is uniquely poised to test this. This project will majorly contribute to our quantitative understanding of the oceanic carbon cycle, and so to predicting current climate change.","1985996","2017-06-01","2022-05-31"
"MINT","Emerging electronic states and devices based on Mott insulator interfaces","Manuel Alain Bibes","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Transition metal oxides possess a broad range of functionalities (superconductivity, magnetism, ferroelectricity, multiferroicity) stemming from the interplay between structural effects and electronic correlations. Recent work has revealed exciting physics at their interfaces, including two-dimensional (2D) conductivity and superconductivity in the electron gas that forms at the interface between two band insulators, LaAlO3 and SrTiO3. However, to date, no interfacial system has truly shown electronic properties that are absent from the phase diagram of both bulk constituents. I argue that to fully embrace the immense potential of oxide interfaces and unveil unprecedented electronic phases, combining insulators with stronger electronic correlations is mandatory.

At the crossroad between strongly-correlated electron physics, microelectronics and spintronics, the MINT project will pioneer routes toward a new realm of solid-state physics. MINT will harness electronic and magnetic instabilities in correlated oxides to craft new electronic phases controllable by external stimuli. These phases will be generated by the synergic action of strain engineering, interfacial charge/orbital/spin reconstruction and octahedra connectivity control, using rare-earth titanate RTiO3 Mott-Hubbard insulators as templates.

Emerging states that are foreseen include 2D electron gases with ferroic order, superconductivity at relatively high temperature, topological states and new forms of multiferroicity and magnetoelectric coupling. The discovery of any of these new states would represent a major breakthrough in oxide electronics. They will open possibilities for innovative devices yielding giant electroresistance without ferroelectrics, and new schemes to control spin currents by electric fields.

At full term, MINT will establish whether oxide interfaces will live up to their expectations and start in the coming decades a technological revolution comparable to that of silicon.","1998026","2014-10-01","2019-09-30"
"MISOTOP","Mechanochemistry: a unique opportunity for oxygen isotopic labelling and NMR spectroscopy","Danielle, Anna LAURENCIN","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Oxygen is an element of major importance, due to its presence in the vast majority of molecules and materials. Over the years, much effort has been put into the development of analytical techniques allowing the study of oxygen environments, in view of elucidating key questions about the structure and reactivity of a variety of systems. In this context, Nuclear Magnetic Resonance (NMR) spectroscopy has been the focus of much attention, because it has progressively emerged as a technique capable of providing deep insight into the local structure around this atom. However, NMR spectroscopy is highly challenging for oxygen, mainly because the NMR-active isotope, oxygen-17, has a very low natural abundance (0.04%), and hence a very poor sensitivity. Because of this, the majority of 17O NMR studies require enriching the molecules and materials of interest in 17O. Unfortunately, 17O-labelling is simply unaffordable at the moment for most research groups, meaning that 17O NMR spectroscopy is inaccessible to the broad community, and still considered as an “exotic” tool of analysis. 
In this ERC project, the goal is to develop new rapid, user-friendly, and low-cost protocols for enriching a wide variety of organic and inorganic compounds in 17O by using mechanosynthesis. This original approach will then be taken as a unique opportunity (i) to push the current boundaries of 17O solid state NMR spectroscopy (by developing new tools for studying the structure of complex molecular and materials systems), and (ii) to elucidate major questions which could not be addressed so far, especially concerning reaction mechanisms between solids and the structure of interfaces of biological relevance. 
In doing so, the overall idea is to make 17O NMR spectroscopy become a more standard analytical tool used by a vast research community, including chemists, biologists and physicists.","1999836","2018-10-01","2023-09-30"
"MIX2FIX","Hybrid, organic-inorganic chalcogenide optoelectronics","Thomas STERGIOPOULOS","ARISTOTELIO PANEPISTIMIO THESSALONIKIS","The new generation of optoelectronics seeks for emerging semiconductors which combine high performance with low cost. Lead halide organic-inorganic perovskites manifest as excellent optoelectronic materials for this purpose, but at the expense of robustness and environmental compatibility. This presents a major challenge which this research addresses directly. Viable alternatives have to be identified. To tackle this challenge, MIX2FIX proposes to develop a new class of solution-processable optoelectronic devices based on air-stable, non-toxic metal chalcogenides endowed with an organic part, which will facilitate solution-processing and potentially enrich the compounds with the spectacular properties of halide perovskites. To achieve this, the CoG project has set the following objectives: (i) designing and developing optoelectronically-active, organic-inorganic chalcogenide thin films that have never been explored before, by mimicking strategies from established perovskite technology, (ii) devising means to improve their optoelectronic quality so as to be comparable with the best single-crystal semiconductors and (iii) implementing optimized materials into boundary-pushing PV and LED devices. Addressing these objectives will enable the development of novel functional hybrids at the boundaries of perovskite and chalcogenide thin films. With this, optoelectronics with efficiency and stability, comparable or higher than those of lead halide perovskite or chalcopyrite devices, will be demonstrated. This project will therefore permit the transition for emerging optoelectronic materials from toxic lead halide perovskites to green hybrid chalcogenides. Consolidating this unproven but disruptive technology will secure sustainable future for other areas of interest beyond photovoltaics, displays and lighting such as in X-Rays detectors and phototransistors or even beyond optoelectronics, in systems such as batteries and supercapacitors.","2731250","2019-09-01","2024-08-31"
"MMGNRs","Molecular Magnetic Graphene Nanoribbons","Lapo BOGANI","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","Intense research efforts are currently aimed at establishing a fundamental link between spintronics, molecular electronics and quantum computation. Novel materials could usher a true revolution in this area, and magnetic graphene nanoribbons, in particular, have attracted impressive theoretical attention. However, creating them with the necessary level of precision has, until now, proved elusive, so that the extensive theoretical work remains fundamentally untested, and the applicative potential untapped.

MMGNRs will investigate these uncharted waters, by developing a radically new approach: instead of the usual methods of cutting out graphene nanoribbons from large sheets, or randomly placing magnetic molecules on graphene surfaces, we will create graphene nanoribbons from a molecular bottom-up synthetic procedure, and attach molecular magnetic centres to their sides, at well-defined periodic intervals. In this way, a spin density is injected into the graphene backbone, and the homogeneity of the sample allows studying edge spin with unprecedented accuracy.

MMGNRs will test the chemical possibilities offered by this approach, and will then use low-temperature transport and pulsed electron-paramagnetic-resonance spectroscopy to reveal the classical and quantum magnetic properties of graphene spin states. 

The success of MMGNRs will answer three fundamental questions: are our extensive theories of graphene magnetic states, for which there is no clean experimental counterpart, right? Can we use graphene magnetic states to perform quantum logic operations? Is it possible to push the quantum effects to high temperatures, and include them into electronic nanodevices? While answering these questions, MMGNRs will open a totally new area of chemical synthesis, redefine our experimental and theoretical knowledge of spins in graphene, and assess the limits and applicative potential of graphene and molecular spintronic devices.","1729668","2019-01-01","2023-12-31"
"MODEST","Mathematical Optimization for clinical DEcision Support and Training","Sebastian Sager","OTTO-VON-GUERICKE-UNIVERSITAET MAGDEBURG","Physicians need to make many important decisions per day. One clinical example is the scheduling and dosage of chemotherapy treatments. A second example is the discrimination of atrial fibrillation from atypical atrial flutter, based on ECG data. Such important and complex decisions are usually based on expert knowledge, accumulated throughout the life of a physician and shaped by subjective (and sometimes unconscious) experience. It is not readily transferable and may be unavailable in rural areas. At the same time, the available imaging, laboratory, and basic clinical data is abundant and waits to be used. This data is not yet systematically integrated and often single data-points are used to make therapy decisions. 

More and more clinical decision making tasks will be modeled in terms of mathematical relations. 
I propose a systematic approach that supports and trains individual decision making. The developed ideas, mathematical models, and optimization algorithms will be generic and widely applicable in medicine and beyond, but also exploit specific structures, resulting in a patient- and circumstance-specific personalized medicine.

This allows, e.g., a physician to first simulate the impact of his decisions on a computer and to consider optimized solutions.
In the future, it will be the rare and unwanted exception that an important decision can not be backed up by consultation of a model-driven decision support system or based upon a systematic model-driven training.

MODEST has a mathematical core. It builds on a comprehensive, interdisciplinary work program, based on disciplinary expertise in mixed-integer optimal control and existing collaborations with medical and educational experts. It is both timely, given the increasing availability of data and the maturity of mathematical methods, models, and software; as well as high-impact, due to the large number of clinical areas that may benefit from optimization-based decision support and training tools.","1998500","2015-07-01","2020-06-30"
"MODMAT","Nonequilibrium dynamical mean-field theory: From models to materials","Philipp WERNER","UNIVERSITE DE FRIBOURG","Pump-probe techniques are a powerful experimental tool for the study of strongly correlated electron systems. The strategy is to drive a material out of its equilibrium state by a laser pulse, and to measure the subsequent dynamics on the intrinsic timescale of the electron, spin and lattice degrees of freedom. This allows to disentangle competing low-energy processes along the time axis and to gain new insights into correlation phenomena. Pump-probe experiments have also shown that external stimulation can induce novel transient states, which raises the exciting prospect of nonequilibrium control of material properties. 
   
The ab-initio simulation of correlated materials is challenging, and the prediction of a material's behavior under nonequilibrium conditions is an even more ambitious task. In the equilibrium context, a significant recent advance is the implementation of dynamical mean field theory (DMFT) schemes capable of treating dynamically screened interactions. These techniques have enabled the combination of the GW ab-initio method and DMFT in realistic contexts. Another recent development is the nonequilibrium extension of DMFT, which has been established as a flexible tool for the simulation of time-dependent phenomena in correlated lattice systems.     

The goal of this research project is to combine these two recently developed computational techniques into a GW and nonequilibrium DMFT based ab-initio framework capable of delivering quantitative and material-specific predictions of the nonequilibrium properties of correlated compounds. The new formalism will be used to study photoinduced phasetransitions, unconventional superconductors with driven phonons, and strongly correlated devices such as Mott insulating solar cells.","1854321","2017-05-01","2022-04-30"
"MOF-reactors","Metal-Organic Frameworks as Chemical Reactors for the Synthesis of Well-Defined Sub-Nanometer Metal Clusters","Emilio PARDO","UNIVERSITAT DE VALENCIA","Humankind advancement is connected to the use and development of metal forms. Recent works have unveiled exceptional properties –such as luminescence, biocompatibility, antitumoral activity or a superlative catalytic activity– for small aggregations of metal atoms, so–called sub–nanometer metal clusters (SNMCs). Despite this importance, the gram-scale synthesis of structurally and electronically well–defined SNMCs is still far from being a reality.
The present proposal situates at the centre of such weakness and aims at making a breakthrough step-change on the use of metal-organic frameworks (MOFs) as chemical reactors for the in–situ synthesis of stable ligand-free SNMCs with such unique properties. This challenging synthetic strategy, which is assisted by striking published and inedited preliminary results, has solid foundations. Firstly, the design and large-scale preparation of cheap and novel families of highly robust and crystalline MOFs with tailor-made functional channels to be used as chemical reactors. Secondly, the application of solid-state post-synthetic methods to drive the multigram-scale preparation of unique ligand-free homo- and heterometallic SNMCs, which are, in the best-case scenario, very difficult to be obtained and stabilised outside the channels. Last but not least, single-crystal X-Ray diffraction will be used as the definitive tool for the characterisation, at the atomic level, of such ultrasmall species offering unprecedented snapshots about their real structures and formation mechanisms.
The ultimate goal will be upscaling this synthetic strategy aiming at the large-scale fabrication of SNMCs and their industrial application will be then evaluated. A successful achievement of all the aforementioned objectives of this ground-breaking project would open new routes for the use of MOFs as chemical reactors to manufacture, at competitive prices, MOF-driven, structurally and electronically well–defined, ligand–free SNMCs in a multigram-scale.","1886000","2019-03-01","2024-02-29"
"MOFcat","Fundamental and Applied Science on Molecular Redox-Catalysts of Energy Relevance in Metal-Organic Frameworks","Sascha Ott","UPPSALA UNIVERSITET","Organometallic redox-catalysts of energy relevance, i.e. water and hydrogen oxidation, and proton and carbon dioxide reduction catalysts, will be incorporated into metal-organic frameworks (MOFs). Immobilization and spatial organization of the molecular catalysts will stabilize their molecular integrity and ensure longevity and recyclability of the resulting MOFcats. The organized environment provided by the MOF will enable the control of conformational flexibility, diffusion, charge transport, and higher coordination sphere effects that play crucial roles in enzymes, but cannot be addressed in homogenous solution and are thus largely unexplored. The effect that the MOF environment has on catalysis will be directly probed electrochemically in MOFcats that are immobilized or grown on electrode surfaces. In combination with spectroscopic techniques in spectroelectrochemical cells, intermediates in the catalytic cycles will be detected and characterized. Kinetic information of the individual steps in the catalytic cycles will be obtained in MOFs that contain both a molecular photosensitizer (PS) and a molecular catalyst (PS-MOFcats). The envisaged systems will allow light-induced electron transfer processes to generate reduced or oxidized catalyst states the reactivity of which will be studied with high time resolution by transient UV/Vis and IR spectroscopy. The acquired fundamental mechanistic knowledge is far beyond the current state-of-the-art in MOF chemistry and catalysis, and will be used to prepare MOFcat-based electrodes that function at highest possible rates and lowest overpotentials. PS-MOFcats will be grown on flat semiconductor surfaces, and explored as a novel concept to photoanode and -cathode designs for dye-sensitized solar fuel devices (DSSFDs). The design is particularly appealing as it accommodates high PS concentrations for efficient light-harvesting, while providing potent catalysts close to the solvent interface.","1968750","2017-01-01","2021-12-31"
"MOLEMAT","Molecularly Engineered Materials and process for Perovskite solar cell technology","Shahzada AHMAD","FUNDACION BCMATERIALS -  BASQUE CENTRE FOR MATERIALS, APPLICATIONS AND NANOSTRUCTURES","Societal pressure to develop inexpensive yet efficient solar energy conversion requires a new approach. Recently emerged organic-inorganic perovskites, offer to harvest light at cost effective price. Perovskites hold merits to the existing materials, however, a fundamental challenge for high performance devices is to optimize the crystals for maximize charge carrier generation and minimize recombination losses. Their widespread use is, however, limited by insufficient stability, scalability and reproducibility. We have recently developed new concepts to fabricate efficient and stable perovskite solar cells at lab scale that are potentially up-scalable to industrial production. MOLEMAT will accomplish this by, pioneering innovative methods and will demonstrate that molecularly engineered materials enable the tuning of the charge transport and interface. Our interdisciplinary approach, combining materials science, chemistry, device physics and engineering, will not only lead to improvements in the performance and stability of perovskite solar cell beyond 24% at lab scale, but will also provide deep insights in the functioning of solar cells. The success of MOLEMAT will rapidly advance the field by enabling reproducible and stable performance adding a significant value with respect to current state of the art. However, for making it marketable product, several developments are required and the MOLEMAT targets will provide relevant answers to three key limitations: encapsulation, stability and cost competitive materials. MOLEMAT envisages the development of 30×30 cm2 modules, with a power conversion efficiency of c.a 18% and a lifetime of 10+ years. MOLEMAT is divided into two parallel research directions, a fundamental research line, dealing with rational design of materials and to gain its understanding. Simultaneously an applied research line targets the development of module by the identification of scale up process to pave the way for its industrialization.","1878085","2017-11-01","2022-10-31"
"MOLEQULE","Unraveling molecular quantum dynamics with accelerated ab initio algorithms","Jiri Vanicek","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Many physical and chemical processes in nature as well as an increasing number of man-made devices exploit the quantum properties of electrons, nuclei, and the quantum signatures of the coupling between nuclear and electronic motions. To optimize the design of novel devices and to correctly interpret physical processes studied, e.g., by experiments probing the molecular dynamics induced by interactions with ultrafast laser pulses, quantitative simulations are required. Although ninety years have passed since the discovery of Schrödinger’s equation, these simulations remain extremely difficult for systems with more than a few degrees of freedom.  While some physicists are satisfied with a theoretical model that describes the system qualitatively, in chemistry the promising term ``ab initio quantum molecular dynamics'' is frequently misused for methods treating nuclear motion classically and using quantum mechanics only for electrons. The first goal of this project is, therefore, to bridge these two philosophies and combine accurate ab initio electronic structure calculations with accurate quantum or semiclassical treatment of the nuclear dynamics.  Since the exact solution of time-dependent Schrödinger’s equation scales exponentially with the number of atoms, accelerating computers even by orders of magnitude will not break the exponential barrier to simulating molecular quantum dynamics. The second goal of this project is, therefore, developing and implementing both exact and approximate computationally efficient quantum dynamics methods applicable to polyatomic molecules. The last goal of the project is developing systematic methods for interpreting spectra of complex systems in terms of the underlying nuclear and electronic dynamics. To summarize in simple terms, the ultimate objective is developing theoretical methods that will allow replacing the popular classical molecular dynamics movies by their quantum analogs.","1998638","2016-09-01","2021-08-31"
"MolStrucDyn","Ultrafast Molecular Structural Dynamics","Sebastian Westenhoff","GOETEBORGS UNIVERSITET","Chemical reactions in solution are strongly influenced by femtosecond solvent-solute dynamics. Likewise, proteins provide specific environments to control the outcome of substrate reactions. The molecular understanding of these effect are currently poorly developed. 

I propose to fill this knowledge gap by ‘filming’ elementary chemical reactions in solution and in proteins. I will pioneer new time-resolved scattering and diffraction experiments using X-ray Free Electron Lasers (XFELs).

Using femtosecond time-resolved X-ray scattering, I plan to decipher the structural dynamics of bond breaking and bond formation in iodine containing compounds in solution. I will pioneer time-resolved fluctuation correlation X-ray scattering to recover full electron density maps of the reaction trajectories at an atomic resolution. I will visualize the as yet unknown structures of reaction intermediates and the solvent response. 

Furthermore, I propose to investigate the molecular photoresponse of phytochrome photoconversion with femtosecond time-resolved serial microcrystallography. Phytochromes are ubiquitous photosensory proteins in plants and are essential to all vegetation on earth. I will resolve how the chromophore and the protein react collectively to photoexcitation and how this leads to conformational changes.

Combined, this interdisciplinary project will yield microscopic understanding on how the surrounding of reactants guides the outcome of elementary (bio)chemical reactions. 

This program builds on my strengths in structural biology of phytochromes (Takala et al., Nature, 2014), time-resolved X-ray scattering (Westenhoff et al., Nature Methods 2010), and femtosecond spectroscopy (21 papers in PRL, JACS, Nature Methods 2006-2012 & 2016).

The new XFEL-based methods will have wide-ranging applications in chemistry and biology. My work will open new horizons in physical chemistry and structural biology.","2000000","2017-06-01","2022-05-31"
"MOOiRE","Mix-in Organic-InOrganic Redox Events for High Energy Batteries","Alexandru VLAD","UNIVERSITE CATHOLIQUE DE LOUVAIN","The ever-increasing demand for improved electrochemical energy storage technologies has fostered intense, worldwide and interdisciplinary research over the past decade. The field of positive electrode materials remains largely dominated by transition metal compounds in which only the redox of metal cations contributes to the energy storage. The development of new materials and technologies, wherein both anions and cations display reversible, multi-electron redox, is bound to strongly impact this field. 
MOOiRÉ will challenge this goal through innovative approaches on Metal Organic Compounds and Frameworks (MOC/Fs) with mix-in many-electron reversible redox of both, transition metal cations and organic ligand anions. Building on our preliminary results MOOiRÉ will adopt an integrated approach. We will combine performance oriented MOC/F molecular design supported by in-operando analytical inspection tools with novel electrode engineering approaches to overcome the limitations and enable efficient electrochemical charge storage. Through this highly interdisciplinary research, MOOiRÉ intends to advance the science and technology of mix-in redox MOC/Fs for next generation batteries, supercapacitors and their hybrids. 
MOOiRÉ will also be a major systematic study of the fundamentals of MOC/F-based energy storage systems in view of a practical implementation. The overall impact will extend beyond the energy science community: the developed knowledge, tools and procedures will influence research and development related to porous composite materials, sorption, ion exchange and electrocatalysis. In the context of energy storage, this will be a disruptive development, enabling the use of MOC/Fs electrodes, with superior levels of performance as compared to current technology, at affordable costs and based on novel protocols.","1997541","2018-09-01","2023-08-31"
"MOPSA","Modular Open Platform for Static Analysis","Antoine Miné","UNIVERSITE PIERRE ET MARIE CURIE - PARIS 6","The Mopsa project aims at creating methods and tools to make computer software more reliable.
Programming errors are pervasive with results ranging from user frustration to huge economical or human losses. Traditional test-based methods are insufficient to eliminate all errors. The project will develop static analyses able to detect at compile-time whole classes of program defects, leveraging the theory of abstract interpretation to design analyses that are approximate (to scale up to large programs) and sound (no defect is missed). Static analysis has enjoyed recent successes: Astrée, an industrial analyzer I have coauthored, was able to prove the absence of run-time error in Airbus software. But such results are limited to the specific, well-controlled context of critical embedded systems. I wish to bring static analysis to the next level: target larger, more complex and heterogeneous software, and make it usable by engineers to improve general-purpose software.
We focus on analyzing open-source software which are readily available, complex, widespread, and important from an economical standpoint (they are used in many infrastructures and companies) but also societal and educational ones (promoting the development of verified software for and by citizens). A major target we consider is the set of technologies at the core on Internet on which static analysis could be applied to ensure a safer Internet. The scientific challenges we must overcome include designing scalable analyses producing relevant information, supporting novel popular languages (such as Python), analyzing properties more adapted to the continuous development of software common in open-source. At the core of the project is the construction of an open-source static analysis platform. It will serve not only to implement and evaluate the results of the project, but also create a momentum encouraging the research in static analysis and hasten its adoption in open-source development communities.","1773750","2016-06-01","2021-05-31"
"Morpheus","Morphogenesis of photo-mechanized molecular materials","Nathalie Hélène Katsonis","UNIVERSITEIT TWENTE","The sophistication reached by organic chemistry has enabled the design and synthesis of a wide range of dynamic molecules that display controlled shape changes with an ever-increasing refinement. However, amplifying these molecular-scale dynamics to support shape-transformation in a broad range of macroscopic functions remains a key challenge.

To address this challenge, I draw inspiration from living materials where molecular machines maintain out of equilibrium states by ingenious coupling with their anisotropic supramolecular environment, and ultimately promote the appearance of emergent properties on higher levels of organization.

The aim of Morpheus is to develop shape-shifting materials and shape-generating photochemical systems by amplifying the motion of molecular machines over increasing length scales, towards the emergence of cohesive shape transformation in artificial tissue-like materials. 

We will (i) develop motorized materials by coupling light-driven molecular motors to liquid crystals and pre-program photoreaction-diffusion processes to achieve continuous motion; (ii) combine microfluidics with the anisotropic response of liquid crystal elastomers to create a library of shape-shifting bubbles and shells that undergo pre-programmed shape modification under irradiation with light; (iii) promote adhesion between units of mechanized matter, while preserving their original shape-shifting and shape-generating properties; and (iv) assemble tissue-like morphing materials from large cohesive networks of shape-shifting micro-spheres.

This project will lay the scientific foundation for a new and multidisciplinary approach towards shape-generating molecular materials. It will yield unprecedented examples of emergent dynamics, provide simple models to untangle the underpinnings of mechanical transduction in nature, and contribute to  developing new paradigms for the design of active matter.","2000000","2018-09-01","2023-08-31"
"MOSAIC","Multi object spectrometer with an array of superconducting integrated circuits","Jochem Jan Anton Baselmans","STICHTING NEDERLANDSE WETENSCHAPPELIJK ONDERZOEK INSTITUTEN","Recent sub-millimeter instruments on the Herschel Space Observatory, operational from 2009-2013, have discovered thousands of sub-millimeter galaxies, whose combined emission forms the cosmic infrared background. A major challenge is to measure their distance, or age, by determining their redshifts, which also has to be based on the sub-millimeter signals (because they do not have an optical counterpart).  

I propose to develop a new redshift survey instrument, using recent progress in superconducting nanotechnology, which can spectrally resolve a large fraction of the cosmic infrared background from the ground. The instrument is a Multi-Object Spectrometer with an Array of superconducting Integrated Circuits. It consists of a 3D integrated field spectrograph with a 2D array of 25 pixels sparsely filling the re-imaged focal plane of the observatory. For each pixel the instrument measures the radiation spectrum in a 325-905 GHz window with a resolution R=F/δF=500. Additionally the beam of each pixel can be steered electrically to lock onto an individual astronomical object. This allows fast, high accuracy redshift determination of 25 objects simultaneously by measuring the frequency shift of the CII and CO lines. I will develop the instrument, build it, install it on the 10 m Japanese ASTE observatory in Chile and facilitate its use.

MOSAIC will be fully based on novel superconducting circuits: a broad-band antenna with electrical beam steering and an on-chip spectrometer, combined on a single chip. The design of the instrument is based on recent developments in superconducting nanotechnology, for signals in the GHz to THz range, in which I am currently playing a leading role. The instrument will be developed with a team of experts in the fields of antennas, spectrometer and readout electronics.","2400894","2016-01-01","2020-12-31"
"MOTMELSUM","Motivic Mellin transforms and exponential sums through non-archimedean geometry","Raf Cluckers","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","""We aim to create a new and powerful theory of motivic integration which incorporates Mellin transforms. The absence of motivic Mellin transforms is a major drawback of the existing theories. Classical Mellin transforms are in essence Fourier transforms on the multiplicative group of local fields. We aim to apply this theory to study new motivic Poisson summation formulas, new transfer principles, and applications of these. All of this has so far only been studied in the presence of additive characters, and remains completely open for multiplicative characters. Understanding all this at a motivic level yields a uniform understanding when the local field varies and will require an approach using non-archimedean geometry. We will open up possibilities for applications via new transfer principles and will give access to motivic Poisson formulas of other groups than the additive group. For these applications it is important that Fubini Theorems are present at the level of the motivic integrals, which we aim to develop. We will overcome the major obstacle of the totally different nature of the dual group of the multiplicative group by a proposed sequence of germs of ideas by the author. The importance of our work on motivic Fourier transforms on the additive group is already widely recognized, and this proposal will complement it by exploring the new territory of motivic multiplicative characters. A final topic is the study of the highly non-understood exponential sums modulo powers of primes, in relation with Igusa's foundational work. We will try to discover a deeper understanding of the uniform behavior of these sums when the prime number varies. These sums are linked to geometrical concepts like the log-canonical threshold, and also to Poisson summation, after the work by Igusa. We will aim to prove a highly generalized form of Igusa's conjecture on exponential sums.""","912000","2014-03-01","2019-02-28"
"MOUSSE","Multilingual, Open-text Unified Syntax-independent SEmantics","Roberto NAVIGLI","UNIVERSITA DEGLI STUDI DI ROMA LA SAPIENZA","The exponential growth of the Web is resulting in vast amounts of online content. However, the information expressed therein is not at easy reach: what we typically browse is only an infinitesimal part of the Web. And even if we had time to read all the Web we could not understand it, as most of it is written in languages we do not speak. Computers, instead, have the power to process the entire Web. But, in order to ”read” it, that is perform machine reading, they still have to face the hard problem of Natural Language Understanding, i.e., automatically making sense of human language. To tackle this long-lasting challenge in Natural Language Processing (NLP), the task of semantic parsing has recently gained popularity. This aims at creating structured representations of meaning for an input text. However, current semantic parsers require supervision, binding them to the language of interest and hindering their extension to multiple languages.
Here we propose a research program to investigate radically new directions for enabling multilingual semantic parsing, without the heavy requirement of annotating training data for each new language. The key intuitions of our proposal are treating multilinguality as a resource rather than an obstacle and embracing the knowledge-based paradigm which allows supervision in the machine learning sense to be replaced with efficacious use of lexical knowledge resources. In stage 1 of the project we will acquire a huge network of language-independent, structured semantic representations of sentences. In stage 2, we will leverage this resource to develop innovative algorithms that perform semantic parsing in any language. These two stages are mutually beneficial, progressively enriching less-resourced languages and contributing towards leveling the playing field for all languages. Enabling Natural Language Understanding across languages should have an impact on NLP and other areas of AI, plus a societal impact on language learners.","1497250","2017-06-01","2022-05-31"
"MPM","Modern Pattern Matching","Ely Porat","BAR ILAN UNIVERSITY","The advances in technology over the last decade and the massive amount of data passing through the internet has intrigued and challenged computer scientists, as the old models of computation used before this era are now less relevant or too slow. New computational models have been suggested to tackle these technological advances. In the most basic sense, these modern models allow one to scan the input only once, possible with small auxiliary memory. Nevertheless, modern techniques have also been introduced such as sparse recovery which has proven to be a very useful tool for dealing with modern challenges, and the very popular notion of conditional lower bounds which has provided evidence of hardness for various algorithmic tasks based on very popular conjectures.

Pattern matching plays a crucial role in many computing applications that can be seen in day to day life. However, its research community has only recently started gaining insight on what can be done in modern models, and is lagging behind in this respect. In particular, there are no algorithms for pattern matching problems that have utilized ideas from sparse recovery, and only recently has there been progress in proving conditional lower bounds for string problems. Furthermore, conditional lower bounds suffer from the lack of hardness conjectures which address time/space tradeoffs.

This proposal will close this gap for many important pattern matching problems within the new models of computation, and will be the first to utilize modern algorithmic techniques, such as sparse recovery, and adapting them into the pattern matching world. Furthermore, this proposal will focus on developing a theory for proving conditional time/space lower bounds, based on new hardness conjectures. This will greatly influence not only the pattern matching sub-field, but the entire algorithmic field at large.","1994609","2017-07-01","2022-06-30"
"mPP","machine learning for Particle Physics","Maurizio PIERINI","EUROPEAN ORGANIZATION FOR NUCLEAR RESEARCH","This project proposes to use modern Machine Learning (ML),  particularly Deep Learning (DL), as a breakthrough solution to address the scientific, technological, and financial challenges that High Energy Physics (HEP) will face in the decade ahead. The quest for new physics is increasing the complexity of the experiments and, consequently, the human and financial costs to operate these detectors, with experiments facing at best flat budgets. ML offers a way out of this impasse. With the development of DL, ML has successfully addressed tasks such as image recognition and text understanding, which eventually opened the way to automatizing complex tasks. These progresses have the potential to revolutionize HEP experimental techniques. We propose to apply cutting-edge ML technologies to HEP problems, paving the way to self-operating detectors, capable of visually inspecting events and identifying the physics process generating them, while monitoring the goodness of the data, the correct functioning of the detector components and, if any, the occurrence of anomalous events caused by unspecified new physics processes. We structure the work in a set of working packages, representing intermediate steps towards this final goal. We propose to apply ML to data taking, event identification, data-taking monitoring, and event reconstruction as intermediate steps toward using these techniques for unsupervised physics searches. The project resources will by used to create a team of computer scientists, who will carry on a systematic R&D program to apply  cutting-edge ML technology to HEP: reinforced learning, generative models, event indexing, data mining, anomaly and outliers detection, etc. Being hosted at CERN, the project will benefit from existing computing infrastructures, large datasets availability, the presence of local experts of each aspect of HEP, and established collaborations with private companies on hardware and software R&D.","1703750","2018-04-01","2023-03-31"
"MSMA","Moduli Spaces, Manifolds and Arithmetic","Søren Galatius","KOBENHAVNS UNIVERSITET","This proposal concerns the application of homotopy theoretic methods to multiple questions of geometric nature, and in particular the study of moduli spaces. Firmly based in topology, the research proposed here is strongly motivated by applications and potential applications to differential geometry, algebraic geometry and especially number theory.
Any “moduli space” parametrizes how certain objects may vary in families. The moduli spaces of manifolds parametrize how smooth manifolds may vary in families (smooth fiber bundles), and the representation varieties studied in the second major component parametrize how linear representations of a group may vary in algebraic families.

The homotopy theoretic study of moduli spaces of manifolds has seen spectacular successes in the last 15 years, kickstarted by a theorem of Madsen and Weiss concerning the topology of moduli spaces of 2-dimensional manifolds. Very recently, anongoing collaboration between O. Randal-Williams and myself promises to establish analoguous results for manifolds of higher dimension. If funded, the research proposed here will bring this research program to a point where all major results about surface moduli spaces have proven analogues for manifolds of higher dimension. 
The second major component of this proposal has strong number-theoretic origins, but is essentially homotopy theoretic. It concerns the study of universal deformations of representations of (Galois) groups. If funded, the research in this component of the proposal, joint with Akshay Venkatesh, will develop derived (simplicial) deformation rings. Classical deformation rings have had spectacular applications in number theory (starting with Wiles’ work) and we also propose to begin the study of applications ofderived deformation rings.

Finally, the proposal contains smaller or more speculative projects, and points out many questions which might be suitable for the Ph.D.-students and postdocs also applied for in this proposal.","1991061","2016-06-01","2021-11-30"
"MSMATH","Molecular Simulation: modeling, algorithms and mathematical analysis","Tony Gilbert Lelievre","ECOLE NATIONALE DES PONTS ET CHAUSSEES","Many models for materials rely on a microscopic description. In a classical regime and for a fixed temperature, atoms are described by particles that interact through a force field and evolve according to Newton’s equations of motion, with additional stochastic terms to model thermostating. This simulation technique is called molecular dynamics. Applications are ubiquitous, ranging from biology to materials science.

The direct numerical simulation of these models is extremely computationally expensive, since the typical timescale at the microscopic level is orders of magnitude smaller than the macroscopic timescales of interest. Many algorithms used by practitioners have not yet been investigated by applied mathematicians. The aim of this proposal is to further develop the mathematical analysis of these methods and to build new and more efficient algorithms, validated by precise error estimates.

The underlying theoretical questions are related to the mathematical definition and quantification of metastability for stochastic processes. Metastability refers to the fact that the stochastic process remains trapped in some regions of the configuration space for very long times. Using naive simulations, transitions between these states are very rarely observed, whereas these transition events are actually those which matter at the macroscopic level. Metastability is one of the major bottlenecks in making molecular simulations predictive for real life test cases.

The main challenges motivating this proposal are: the design of efficient techniques to sample high-dimensional multimodal measures, the development and analysis of algorithms to sample metastable dynamics and the construction of coarse-graining techniques for high-dimensional problems.

This project relies on strong collaborations with practitioners (biologists and physicists) in order to propose common benchmarks, to identify the methodological bottlenecks and to apply new algorithms to real life test cases.","1773600","2014-06-01","2019-05-31"
"Mu-MASS","Muonium Laser Spectroscopy","Paolo CRIVELLI","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","Striking anomalies in the muon sector have accumulated in recent years: notably the famous anomalous muon magnetic moment (g-2) and the muonic hydrogen Lamb shift measurement which prompted the so-called proton charge radius puzzle. These tantalizing results triggered vibrant activity on both experimental and theoretical sides. Different explanations have been put forward including exciting solutions invoking New Physics beyond the Standard Model. To contribute to clarifying the origin of these anomalies, I propose Mu-MASS, an experiment aiming for a 1000-fold improvement in the determination of the 1S-2S transition frequency of Muonium (M), the positive-muon/electron bound state. This substantial improvement beyond the current state-of-the-art relies on the novel cryogenic M converters and confinement techniques developed by the PI, and on the new laser and detection schemes which the PI implemented for positronium spectroscopy. This experiment will be performed at the Paul Scherrer Institute (PSI). 
With the Mu-MASS result our knowledge of the muon mass can be improved by almost two orders of magnitude.  By using the expected results of the ongoing hyperfine splitting measurement of M in Japan, it will provide one of the most sensitive tests of bound-state Quantum Electrodynamics. It can also be used to extract the muon g-2 from the ongoing experiment at Fermilab. Since M is a unique system composed of two different leptons (point-like particles), the Mu-MASS results will provide the most stringent test of charge equality between the lepton generations. Moreover, it can be used to determine the Rydberg constant free from nuclear and finite-size effects and contribute to solving the proton charge radius puzzle. Mu-MASS is thus very timely and essential to the worldwide effort to understand the interesting observed discrepancies, which could be a hint of New Physics and therefore have profound implications on our understanding of the Universe.","1999150","2019-02-01","2024-01-31"
"Multi-Pop","Fulfilling the Potential of Globular Clusters as Tracers of Cosmological Mass Assembly","Nathan Bastian","LIVERPOOL JOHN MOORES UNIVERSITY","Globular clusters (GCs) are among the oldest luminous sources in the universe, bearing witness to the earliest stages of galaxy formation as well as their evolution to the present day. While GCs have played a pivotal role in our understanding of the assembly of galaxies, their full potential remains unfulfilled due to our lack of understanding of how they form. One of the largest stumbling blocks has been the anomalous chemistry (both metallicity distributions and abundance patterns) of GCs relative to field stars within galaxy.
Here, we will turn the problem around and exploit these differences to understand the co-evolution of GCs and their host galaxies.

Our understanding of GCs and their formation has undergone a radical change in the past two decades. First, it is now clear that while traditionally thought of as the quintessential simple stellar populations (i.e., all stars within a cluster have the same chemical abundances and age), globular clusters host multiple stellar populations with spreads in He, many light elements (e.g., Na, O, Al) and even Fe in a few cases. Secondly, GCs, once thought to only be able to form in the special conditions present in the early Universe, are now known to be still forming today (known as Young Massive Clusters - YMCS). These two facts have opened up a new window into the interconnectedness of GC and galaxy formation and co-evolution.

In this project we will quantitatively test current GC formation models with observations of YMCs, as well as organise what is known of the stellar populations within GCs (e.g., abundance spreads, CMD morphologies), providing, for the first time, a global view (i.e., which characteristics are specific to individual GCs and which are common to all GCs). These results, when combined with what is known about massive cluster formation in the local universe, will provide an unprecedented opportunity to use GCs to constrain the hierarchical assembly of galaxies.","1429439","2015-09-01","2020-08-31"
"MULTIFLEXO","Hierarchical multiscale modeling of flexoelectricity and related materials properties from first principles","Massimiliano STENGEL","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Flexoelectricity, the coupling between an inhomogeneous deformation and the electrical polarization, has emerged a “hot” topic in modern materials science due to its cross-cutting relevance to many phenomena of fundamental and technological interest. Understanding the intriguing physics that governs its behaviour at the nanoscale is crucial to harnessing the potential of strain gradients in practical applications, and such a progress requires a substantial support from theory. In spite of impressive recent advances, first-principles calculations of flexoelectricity remain technically challenging at several levels: first, the breakdown of translational lattice periodicity that a strain gradient entails is problematic to treat in the context of traditional electronic-structure methods; second, the stringent length- and time-scale constraints of direct quantum-mechanical approaches limit the applicability of these methods to real problems, which often involve complex sample shapes and morphologies. This project is aimed at overcoming these obstacles from their very root, via the development of ground-breaking innovations in electronic-structure and multiscale methodologies, and at using these advances to address a number of pressing physical questions in the context of energy and information technologies. In particular, the objectives of this project are: (i) identifying the microscopic mechanisms that are most effective at delivering a strong flexoelectric response in a variety of materials; (ii) understanding how these bulk effects are modified by size, shape and boundary conditions, and how they interact with other material properties; (iii) supporting the experimental interpretation by critically assessing alternative physical interpretations of the observed effects (e.g. compositional gradients); (iv) exploring the functionalities enabled by strain gradients in complex materials systems, including 2D crystals, semiconductor nanowires and multiferroics.","1470000","2017-04-01","2022-03-31"
"MultiphysMicroCaps","Multiphysics study of the dynamics, resistance and targeted therapy potential of deformable Micro-Capsules","Anne-Virginie SALSAC","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Encapsulation consists in enclosing an internal medium in a solid semi-permeable membrane to protect it and control the exchanges with the environment. Being at the source of innovative applications in the fields of biotechnologies, pharmacology, energy storage and food industry, capsules offer tremendous potential in the process engineering world. But scientific challenges remain to be met, such as finding the optimal compromise between payload and membrane thickness, characterizing the membrane resistance and controlling the moment of rupture. 
The project explores the use of deformable liquid-core capsules of micrometric size to efficiently transport active material, with a primary focus on health-related applications. We will design innovative sophisticated numerical models and high-tech experiments, needed to determine the potential of such vectors for the protection of active substances, predict membrane breakup to control the delivery, and optimize their properties for specific industrial and biomedical applications. The project will, for the first time, study the effect of a finite wall thickness on the dynamics of elastic microcapsules, propose advanced modelling approaches and microfluidic experiments of their deformability and breakup under hydrodynamic stresses, account for the inherent size variability of given capsule populations, and introduce reduced-order models to facilitate real-time simulations. As a specific application, we will study the potential of liquid-core microcapsules to encapsulate antioxidants for food enrichment. 
The project outcomes will be (i) new advanced three-dimensional numerical models of the fluid-structure interactions and rupture of a microcapsule, taking into account a finite wall thickness, (ii) microcapsule optimization tools based on reduced-order models, (iii) microscopic techniques to measure the capsule mechanical properties, and (iv) an applied study of optimization of antioxidant encapsulation in microcapsules.","1999470","2018-06-01","2023-05-31"
"MULTIPLES","The MULTIPLicity of supErnova progenitorS","Hugues Albert SANA","KATHOLIEKE UNIVERSITEIT LEUVEN","With stellar masses in the range of eight to several hundreds of solar masses, massive stars are among the most important cosmic engines, each individual object strongly impacting its local environment and populations of massive stars driving the evolution of galaxies throughout the history of the universe. Recently, I have shown that stars more massive than 15 Msun rarely, if at all, form and live in isolation but rather as part of a binary or higher-order multiple system. Understanding the life cycle of massive multiple systems, from their birth to their death as supernovae and long-duration gamma ray bursts, is one of the most pressing scientific questions in modern astrophysics. 

To obtain the key observational breakthroughs needed to revolutionize our understanding of high-mass stars, my research program is developed along three themes: 
(i)    investigate the physical processes that set the multiplicity properties of massive stars, 
(ii)  establish the multiplicity properties of unevolved massive stars across the entire mass range,
(iii) identify and uniquely characterize post-interaction products. 

The implementation of the MULTIPLES program involves ambitious time-resolved observational campaigns targeting large populations of massive stars at key stages of their pre-supernova evolution and in different metallicity environments. These campaigns will combine state-of-the-art spectroscopy and high-angular resolution techniques with novel multiplicity and atmosphere analysis methods appropriate for multiple systems.  Upon completion, the observational constraints that will be obtained in this project will have implications that extend well beyond the sole domain of stellar astrophysics.","1991243","2018-10-01","2023-09-30"
"MultiplexGenomics","Exploring the Epigenome by Multiplexed Physical Mapping of Individual Chromosomes","Yuval EBENSTEIN","TEL AVIV UNIVERSITY","The genome is composed of the genetic code and a rich repertoire of epigenetic chemical DNA modifications, the Epigenome, with distinct signatures in health and disease. Unmasking the interplay between different genomic features is critical for understanding the operating system of life. Specifically, revealing long-range epigenetic regulation may uncover predisposition to cancer. Nevertheless, due to the short read-length of single-cell next-generation sequencing, there is no method today that can integrate multiple genomic observables, on the same genome and at the same time. The missing picture constitutes a major genomic “blind spot”, obscuring epigenetic regulation of gene expression. This project aims to provide a multiplexed view of the genome never before accessible. I will utilize single-molecule physical and chemical mapping of individual chromosomes to discover long-range epigenetic correlations, focusing on markers for predisposition to breast cancer. I will approach multiplexing by applying optical and electrical sensing concepts to detect chemical tags attached to long genomic DNA molecules. Equipped with a toolbox of biochemical DNA labeling reactions, I will develop a unique spectral imager for simultaneous acquisition of high-content genomic information from DNA stretched in nanochannel arrays. DNA tagging will also be used to enhance electrical contrast for nanopore epigenetic sequencing. Finally, by combining electric sensing inside nanochannels I will develop new integrated devices for electro-optical genomic analysis. Together, these developments cover the full range of genomic length scales and resolution. MultiplexGenomics will  establish a groundbreaking experimental framework for genetic/epigenetic profiling of native chromosomal DNA. A successful completion of this project will make possible the discovery of novel control networks and hidden long-range regulation, opening new horizons for basic genomic research and personalized medicine.","2750000","2019-10-01","2024-09-30"
"MULTIPROSMM","MULtiple PROperties Single Molecule Magnets","Fabrice Philippe POINTILLART","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The goal of the MULTIPROSMM project is to design systems able to present magnetic bistabilities under different stimuli (temperature, magnetic field or light) on an unprecedented large temperature range, i.e. very low temperature with Single Molecule Magnet (SMM) behaviour, intermediate temperature with Light Induced Excited State Trapping (LIESST) and high temperature with SpinCrossOver (SCO). On one hand, as a photography of the energy-splitting of the spectroscopic states, the lanthanide luminescence will be used as a key tool for the understanding of the magnetic properties of lanthanide ions. On the other hand, Circularly Polarized Luminescence (CPL) combines the sensitivity of the luminescence with crucial information on the chiral environment. A step by step synthetic strategy will be used to elaborate molecular systems in which the coexistence of i) SMM and SCO; ii) SMM and CPL and iii) SMM, SCO and CPL are operating. The enhancement of the magnetic properties is needed to step forward towards applications. To reach such optimizations, the quantum regime of the SMM and the internal magnetic field must be vanished playing with the hyperfine coupling and magnetic dilutions. Both isotopic enrichment and shaping (i.e. decoration of both mesoporous silica and nanoparticle surfaces) of the designed systems could allow high magnetic performance in multiple properties SMM. The final result could be a system suitable for very high density data storage on a wide temperature range (from cryogenic to room temperature).","1505000","2017-08-01","2022-07-31"
"MULTISCOPE","Multidimensional Ultrafast Time-Interferometric Spectroscopy of Coherent Phenomena in all Environments","Tobias Manuel Brixner","JULIUS-MAXIMILIANS-UNIVERSITAT WURZBURG","""We propose to develop and apply novel methods of nonlinear spectroscopy to investigate the significance and consequences of coherent effects for a variety of photophysical and photochemical molecular processes. We will use coherent two-dimensional (2D) spectroscopy as an ideal tool to study electronic coherences.

Quantum mechanics as described by the Schrödinger equation is fully coherent: The phase of a wavefunction evolves deterministically in the time-dependent case. However, observations are restricted to reduced “systems” coupled to an “environment.” The resulting transition from coherent to incoherent behavior on an ultrafast timescale has many yet unexplored consequences, e.g. for transport in photosynthesis, photovoltaics or other molecular “nanomaterials.”

In contrast to conventional 2D spectroscopy, we will not measure the coherently emitted field within a four-wave mixing process but rather implement a range of incoherent observables (ion mass spectra, fluorescence, and photoelectrons). Yet we can still extract all the desired information using “phase cycling” with collinear pulse sequences from a femtosecond pulse shaper. This opens up a new range of interdisciplinary experiments and will allow for the first time a direct nonlinear-spectroscopic comparison of molecular systems in all states of matter. Specifically, we will realize 2D spectroscopy in molecular beams, liquids, low-temperature solids, and on surfaces including heterogeneous and nanostructured samples. Tuning the external couplings will help elucidating the role of the environment in electronic (de)coherence phenomena.

Furthermore, we will combine 2D spectroscopy with subdiffraction spatial resolution using photoemission electron microscopy (PEEM). This enables us to map transport in molecular aggregates and other heterogeneous nanosystems in time and space on a nanometer length scale. Thus we access the intersection between the domains of electronics and nanophotonics.""","2669124","2014-04-01","2019-03-31"
"MY-CUBE","3D integration of a logic/memory CUBE for In-Memory-Computing","Francois ANDRIEU","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","For integrated circuits to be able to leverage the future “data deluge” coming from the cloud and cyber-physical systems, the historical scaling of Complementary-Metal-Oxide-Semiconductor (CMOS) devices is no longer the corner stone. At system-level, computing performance is now strongly power-limited and the main part of this power budget is consumed by data transfers between logic and memory circuit blocks in widespread Von-Neumann design architectures. An emerging computing paradigm solution overcoming this “memory wall” consists in processing the information in-situ, owing to In-Memory-Computing (IMC).
However, today’s existing memory technologies are ineffective to In-Memory compute billions of data items, as it is the case in the brain. Things may change with the emergence of three key enabling technologies: non-volatile resistive memory, new energy-efficient nanowire transistors and 3D-monolithic. My-CUBE will leverage them towards a functionality-enhanced system with a tight entangling of logic and memory. Only such a technology can support the scalability of the IMC concept.
Following a holistic approach from the system to the material, My-CUBE unique solution relies on a new class of nano-technology, mixing at the fine-grain level a high capacity of non-volatile resistive memory coupled with new junctionless nanowire transistors 3D-interconnected at low-temperature, to perform data-centric computations. A 3D IMC accelerator circuit will be designed, manufactured and measured, targeting a 20x reduction in (Energy x Delay) Product vs. Von-Neumann systems. This technology that adds smartness to memory/storage will not only be a game changer for artificial intelligence, machine learning, data analytics or any data-abundant computing systems but it will also be, more broadly, a key computational kernel for next low-power, energy-efficient European integrated circuits.","2734139","2019-04-01","2024-03-31"
"MyNano","Towards the design of Personalised Polymer-based Combination Nanomedicines for Advanced Stage Breast Cancer Patients","Maria Jesus Vicent Docon","FUNDACION DE LA COMUNIDAD VALENCIANA CENTRO DE INVESTIGACION PRINCIPEFELIPE","Research on anticancer therapies has provided little progress towards improved survival rates for patients with metastatic disease. The intrinsic advantages of polymer conjugates can be optimised to rationally design targeted combination therapies, concept I pioneered that allows enhanced therapeutic efficiency. Early clinical trials involving conjugates showed activity in chemotherapy refractory patients and reduced drug-related toxicity. However, there is a growing concern on patient variability regarding tumor patho-physiology that underlie successful therapeutic outcome. Specific biomarkers are required to select those patients most likely to show good clinical response to these therapies. 
The objective of MyNano is to engineer polymer-based combination therapies designed to treat metastatic breast cancer in a patient personalised manner. Therefore, novel multicomponent polymer conjugates with precise control over size, shape, solution conformation, multifunctionality and bioresponsiveness will be obtained while in parallel their structure activity relationships to underlying proposed mechanisms of action in clinically relevant models will be studied. Polyglutamates obtained by controlled polymerisation and self-assembly strategies will be the carriers. Primary breast cancer patient tissue will be used to generate cell and in vivo models representing different clinical molecular subtypes. MyNano will also investigate new combination strategies using current treatments together with inhibitors of tumor-derived exosome release pathways, phenomenon related to metastasis and resistance mechanisms. 
The aim is to provide a novel methodological approach that would allow by reiterative design to optimise the design of the next generation nanoconjugates for the treatment of specific metastatic cancer clinical subtypes. MyNano will be a breakthrough as it introduces a paradigm shift in the strategy to design nanomedicines in areas of unmet clinical need.","1724169","2015-07-01","2020-06-30"
"N2FEED","N2 as Chemical Feedstock – Synthetic Nitrogen Fixation beyond Haber-Bosch","Sven Schneider","GEORG-AUGUST-UNIVERSITAT GOTTINGENSTIFTUNG OFFENTLICHEN RECHTS","The chemical transformation of dinitrogen is one of the most important industrial processes. Thereby produced ammonia serves as nitrogen source for almost any synthetic nitrogen containing compound, such as fertilizers or many polymers and pharmaceuticals. However, despite forcing conditions associated with high energy consumption, the Haber-Bosch process gives low yields in NH3. Hence, homogeneous, bioinspired nitrogen fixation is a longstanding goal, yet with very limited success. In this proposal, we strive to circumvent the Haber-Bosch process for the synthesis of N-containing chemicals by direct N2 functionalization upon initial splitting into molecular nitrides at ambient conditions and subsequent C–N bond formation. Catalytic platforms will be developed based on late, electron rich transition metal complexes with functional pincer ligands, which represents a fundamentally new approach for this purpose. The overall N2 functionalization effort will be broken down into three elementary steps, i.e. N2 splitting, de-/hydrogenation of metal bound N-species, and C–N bond formation. These subprojects are examined individually with a combination of modern synthetic, physical inorganic, and computational methods. These results will finally enable the rational design of homogeneous catalysts. Hence, besides the primary goal to directly use N2 as chemical feedstock this project will also serve the secondary objectives of making important contributions to related timely and challenging topics, such as C–N coupling by nitrenoid transfer or the use of nitrogen compounds, especially ammonia, as chemical fuels in energy storage applications. The previous record of my group in the chemistry of electron-rich transition metal complexes with functional pincer ligands, N2 splitting/coupling, and the activation of other N-containing small-molecules provide a strong basis for the feasibility of these challenging goals.","1998500","2015-06-01","2020-05-31"
"N2RED","Spectroscopic Studies of N2 Reduction: From Biological to Heterogeneous Catalysis","Serena Debeer","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","""The conversion of dinitrogen (N2) to ammonia (NH3) is of fundamental biological and economic importance. The catalytic conversion is achieved either industrially, using heterogeneous catalysts or biologically, by the nitrogenase enzyme. However, in both cases, the mechanistic details of the process are not fully understood. In order to design advance catalysts that will be essential for a sustainable energy economy, an in-depth understanding of both the biological and chemical mechanisms is required. The goal of this proposal is to develop advanced spectroscopic tools, which will allow for a detailed description of the atomic level processes in the both the biological and the heterogeneous systems. This will include the development of valence to core resonant X-ray emission spectroscopy as a unique probe of transition metal ligation in complex media. High-resolution X-ray absorption, X-ray emission, X-ray magnetic circular dichroism, and nuclear resonant vibrational spectroscopy will be utilized and their chemical information content fully developed. These experiments will be correlated to advanced quantum chemical calculations to obtain a detailed picture of the electronic structure of the catalytic systems. The results should provide a clear understanding of the electronic factors that govern N-N bond cleavage. The proposed research will bring together the fields of biochemistry and heterogeneous catalysis, by utilizing inorganic, physical and theoretical chemistry to advance our fundamental understanding of N2 cleavage. The proposed developments will provide a powerful set of novel tools for the elucidation of transition metal catalyzed homogenous and heterogeneous reaction mechanisms. The long-term goal is to pave the way for rationally designed catalytic systems, based on fundamental mechanistic knowledge.""","1989600","2014-04-01","2019-03-31"
"NANO-INSITU","Nanoscale Chemical Reactions Studied with In-Situ Transmission Electron Microscopy","Marijn Arnout Van Huis","UNIVERSITEIT UTRECHT","Great successes have been achieved in nanoscience where the development of functional properties and the assembly of nanostructures into nanomaterials have become increasingly important. In general, both the tuning of the chemical and physical properties and the self-assembly of nanocrystals into 2D or 3D superstructures take place in a liquid environment. When analysing the structural properties of nanocrystals using Transmission Electron Microscopy (TEM), this liquid environment is contained between membranes to keep it in the high vacuum. At present, the thickness of the liquid is not controlled, which renders standard imaging at atomic resolution impossible. Here I propose to integrate micro-electromechanical actuator functionalities in the Liquid Cell chips to overcome this problem so that real-time atomic resolution imaging and chemical analysis on nanoparticles in solution becomes a reality. 
This new in-situ technology will elucidate what really happens during chemical reactions, and will thereby enable the development of new nanomaterials for optoelectronics, lighting, and catalysis. Oriented attachment processes and self-assembly of nanoparticles, which are key to the large-scale production of 2D and 3D nanomaterials, can also be followed in the Liquid Cell. Furthermore, the hydration of nanoscale model systems of earth materials such as magnesia, alumina, and calcium oxide is of major importance in the geosciences.  In the field of enhanced oil recovery, for example, the huge volumetric expansion that comes with the hydration of these minerals could facilitate access to reservoirs. 
My research group has extensive experience in in-situ TEM and recently has achieved significant successes in Liquid Cell studies. We are in an ideal position to develop this new technology and open up these new research areas, which will have a major impact on science, industry, and society.","1996250","2016-09-01","2021-08-31"
"NANODYNAMITE","Quantifying Aerosol Nanoparticle Dynamics by High Time Resolution Experiments","Paul Martin Winkler","UNIVERSITAT WIEN","""The formation of aerosol nanoparticles by vapour nucleation and condensational growth is currently considered the dominant source of cloud condensation nuclei on global scale, hence impacting radiative properties of the atmosphere and precipitation patterns of clouds. Despite considerable experimental and theoretical efforts, the mechanisms of the gas-to-particle conversion are still poorly understood, and so are the parameterizations of this process in climate models. Improving the situation critically depends on the continuous development of experimental techniques. For the quantitative characterization of nanoparticle dynamics especially time resolution deserves more attention. I am thus proposing to design instruments that will improve time resolution by up to five orders of magnitude. Specifically, I am planning the design of a fast-scanning electrical mobility based nanoparticle spectrometer delivering size distributions from 1 nm upwards at 1 Hz, for number concentrations as low as 100 cm-3. Secondly, in a new approach to the study of secondary organic aerosol formation I am planning to apply small angle x-ray scattering providing direct information on particle size and number at sub-millisecond time-resolution. Thirdly, the study of fundamental growth kinetics by Mie scattering at short wavelengths will constitute an important part of my research. And finally, an application oriented research task will deal with the design and construction of a nucleation based trace-gas removal system capable of generating liquid water from plain ambient air.
The research on phase transition processes constitutes a vital link between molecular scale interactions and macroscopically relevant outcome. The current proposal aims at identifying and quantifying nanoparticle formation mechanisms by new experimental approaches. Thereby it will be possible to reliably predict and utilize macroscopic effects caused by aerosol mechanisms on the nano-scale.""","1810698","2014-03-01","2019-02-28"
"NANOHEDONISM","A Photo-triggered On-demand Drug Delivery System for Chronic Pain","Manuel Arruebo Gordo","UNIVERSIDAD DE ZARAGOZA","""Nerve pain affects millions of people, and can be personally devastating for people who experience it. Current methods for pain management (e.g. local injection of pain killers) are inadequate because of the short duration of action. Even sustained release treatments, such as drug-loaded liposomes, provide only one week of analgesia producing a continuous extended nerve blockade without allowing for changes in daily physical activity or level of pain relief. More importantly, such systems cannot be turned off until they run their course.

In this proposal, a locally-injected or implanted near infrared (NIR)-sensitive drug reservoir that can be triggered by a simple handheld laser device applied externally is described. The device enables drug release with consistent response over multiple on/off cycles. Such a device, implanted (or eventually injected) on a nerve or near the neuraxis, could have substantial clinical impact in the treatment of chronic (or prolonged perioperative) pain.

This system will consist of an impermeable ethylcellulose membrane embedded with temperature-sensitive polymer nanoparticles and NIR-active gold nanoparticles. The membrane will be engineered such that the nanoparticles form a disordered but interconnected network throughout. The gold nanoparticle concentration will be adjusted so that light-induced heating of the nanoparticles produces sufficient heat to collapse the polymer, thus opening the porous network. Those nanostructured materials which compose the device will be produced in a continuous manner by using microfluidic reactors to avoid the characteristic disadvantages when using conventional discontinuous (batch) reactors. Nanoparticle-synthesis protocols will be supported by computational fluid dynamics.

The specific aims will be geared toward engineering a NIR-triggered drug release device and optimizing for a variety of drug types, then demonstrating its biocompatibility and therapeutic effectiveness in vivo.""","1570091","2014-03-01","2019-02-28"
"NanoMOFdeli","Design of NanoMOFs Capsules for Drug Delivery and Bioimaging.","David FAIREN-JIMENEZ","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Cancer is a major health problem worldwide, being the most common cause of death after cardiovascular diseases. The major goal of new anticancer therapies is to specifically kill tumour cells while leaving healthy cells unharmed. A main challenge to achieve this aim is the development of better drugs, including novel treatments based on the use of siRNAs. These macromolecules are potentially the most powerful anti-cancer drugs that exist, but still there is no efficient way of getting them delivered specifically to the tumour. Indeed, lifetime of such molecules is generally too short and therefore need to be protected in a carrier until they are delivered into tumour target cells.

This project focuses in the development of nanocarriers based on metal-organic frameworks (MOFs), one of the most exciting developments in recent porous materials science. The study of the mechanisms that control drug delivery is of critical importance to nanomedicine applications, where nanotechnology has the potential to revolutionise cancer therapy. Given the challenging nature of the drug delivery problem for cancer therapy, this project builds on 4 interrelated main concepts: i) the design of bio-compatible MOFs for drug delivery applications; ii) the post-synthesis engineering of MOFs to enhance stability, controlled drug release, and targeting; iii) the identification of optimal textural properties (i.e. pore size distribution, surface area, pore volume) and surface chemistry of MOFs for siRNA delivery using experiments and molecular simulation techniques; iv) the assessment of their performance in vitro and in vivo, giving a translational dimension to the proposed research. The novelty of this work lies therefore in the synergistic combination of tools from different areas and disciplines (chemistry, biochemical engineering and medicine) to produce advances that are of both fundamental scientific interest and of bioengineering relevance in nanomedicine applications.","1903685","2017-09-01","2022-08-31"
"NanoPD","Single Molecule Nanoscale Sensors for Improved Therapies and Diagnostics","Joshua Benno EDEL","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","One of the most significant challenges facing the healthcare community is the accurate and selective detection and quantification of trace levels of analyte. This can have enormous impact with numerous application, especially in the context of biosensing, where applications can range from early stage detection of disease to the identification of new markers amongst others. These challenges are compounded when the analysis of real samples or even complex mixtures are required. To address this need, single molecule or near single molecule methods are currently being heavily pursued which allows for the discrimination of events with low copy numbers by removing the “clouding” associated with ensemble averaging.  Although strategies for detecting single molecules have existed for a number of years, efficient and cost-effective label-free methods without the need for chemical modification are lacking especially when considering smaller molecules directly in unprocessed clinical samples. As part of this proposal, I intend to address this limitation by developing new strategies in single molecule nanoscale sensing which will be both highly sensitive and selective for improved therapeutics and diagnostics applications.","1997680","2017-10-01","2022-09-30"
"NanoPokers","Deciphering cell heterogeneity in tumors using arrays of nanowires to controllably poke single cells in longitudinal studies","Christelle Nathalie Prinz","LUNDS UNIVERSITET","Cancer is responsible for 20% of all deaths in Europe. Current cancer research is based on cell ensemble measurements or on snapshot studies of individual cells. However, cancer is a systemic disease, involving many cells that interact and evolve over time in a complex manner, which cell ensemble studies and snapshot studies cannot grasp. It is therefore crucial to investigate cancer at the single cell level and in longitudinal studies (over time). Despite the recent developments in micro- and nanotechnologies, combined with live cell imaging, today, there is no method available that meets the crucial need for global monitoring of individual cell responses to stimuli/perturbation in real-time.  
This project addresses this crucial need by combining super resolution live-cell imaging and the development of sensors, as well as injection devices based on vertical nanowire arrays. The devices will penetrate multiple single cells in a fully controlled manner, with minimal invasiveness.

The objectives of the project are:
1) To develop nanowire based-tools in order to gain controlled and reliable access to the cell interior with minimal invasiveness.
2) Developing mRNA sensing and biomolecule injection capabilities based on nanowires.
3) Performing longitudinal single cell studies in tumours, including monitoring gene expression in real time, under controlled cell perturbation.

By enabling global, long term monitoring of individual tumour cells submitted to controlled stimuli, the project will open up new horizons in Biology and in Medical Research. It will enable ground-breaking discoveries in understanding the complexity of molecular events underlying the disease. This cross-disciplinary project will lead to paradigm-shifting research, which will enable the development of optimal treatment strategies. This will be applicable, not only for cancer, but also for a broad range of diseases, such as diabetes and neurodegenerative diseases.","2621251","2016-09-01","2021-08-31"
"NANOPRS","Nano-Particle-Resolved Studies","Royall","UNIVERSITY OF BRISTOL","""Amorphous materials may be classified into three types – thermodynamically stable liquids, metastable (supercooled) liquids and solid glasses. The second type represents the meeting point of many of the great challenges of statistical physics and materials science. What is the mechanism of dynamical arrest, by which structural relaxation become progressively inhibited upon cooling from a liquid to a glass? Can we develop physical pictures of the sequence of fluctuations associated with irreversible relaxation in metastable liquids? How do crystals emerge from these fluctuations?

Here we take a structural approach coupled with novel experiments and computer simulations to tackle two specific questions. Firstly, it has long been believed that there should be some structural mechanism underpinning the glass transition, where deeply supercooled liquids continuously transform into solid glasses. Secondly, the fate of the supercooled liquid – whether it crystallises on accessible timescales – should also be related to the local atomic arrangements in the liquid. Tackling the first will lead to insight into the nature of the glass transition - it is not known whether or not there is a true thermodynamic transition to a glass. As for crystallisation, predicted nucleation rates vary wildly with those obtained experimentally in the only system in which both have been compared, little is known beyond trial and error of means by which crystallisation in mixtures can be controlled. In short, our understanding of the fate of supercooled liquids is lacking in a variety of ways. Understanding the glass transition and nucleation is of fundamental importance, and both have important applications for example in metallic glasses and phase change materials. The former are prized for their superior mechanical properties such as extreme toughness while latter underpin emergent technologies such as optical data storage and phase change memory.""","2336887","2014-05-01","2019-04-30"
"NANOQUANT","Nanofiber Quantum Networks","Arno Rauschenbeutel","TECHNISCHE UNIVERSITAET WIEN","We propose to establish nanofiber-based atom-light interfaces as quantum-enabled fiber-optical components for quantum information processing and communication (QIPC). The key ingredient of this interface is a nanofiber-based optical dipole trap which stores laser-cooled atoms in the evanescent field surrounding the nanofiber. In this evanescently coupled atom-waveguide-system, even a few hundred atoms are already optically dense for near-resonant photons propagating through the nanofiber. In combination with the proven good coherence properties of nanofiber-trapped atoms, these highly efficient light-matter interfaces are thus perfectly suited for the implementation of practical QIPC devices. More specifically, the first goal of this project is to realize quantum memories which allow one to directly store and retrieve the quantum state of fiber-guided photons. The efficiency of the retrieval process will highly benefit from the fact that conservation of energy and momentum stabilizes the emission of the stored light into the nanofiber-guided mode. Furthermore, nanofiber-coupled atomic ensembles can provide a strong optical non-linearity which, due to the waveguide-geometry, scales with the square root of the length of the sample and can be much larger than for freely propagating light beams. The second goal of this project is to explore and to maximize this non-linearity until it prevails down to the single photon level. This single-photon non-linearity would enable optical quantum switches and photon-photon quantum gates which are essential for implementing deterministic optical quantum computation. The final goal is then to interconnect these components in order to demonstrate three different fiber-optical quantum network applications: highly efficient photon counting using fiber-coupled quantum memories, highly efficient heralded entanglement of two fiber-coupled quantum memories, and a non-linear interaction between two single-photon pulses.","1993526","2014-06-01","2019-05-31"
"NANOREACTOR","Multiscale modelling of stimuli-responsive nanoreactors","Joachim Dzubiella","ALBERT-LUDWIGS-UNIVERSITAET FREIBURG","The catalysis by metal nanoparticles is one of the fastest growing areas in nanoscience due to our society's exploding need for fuels, drugs, and environmental remediation. However, the optimal control of catalytic activity and selectivity remains one of the grand challenges in the 21st century.

Here, I propose to theoretically derive design rules for the optimization of nanoparticle catalysis by means of thermosensitive yolk-shell carrier systems. In the latter, the nanoparticle is stabilized in solution by an encapsulating, thermosensitive hydrogel shell. The physicochemical properties of this polymeric 'nanogate' react to stimuli in the environment and thus permit the reactant transport and the diffusion-controlled part of the catalytic reaction to be switched and tuned, e.g., by the temperature or the pH. The novel hybrid character of these emerging 'nanoreactors' opens up unprecedented ways for the control of nanocatalysis due to new designable degrees of freedom.

The complex mechanisms behind stimuli-responsive nanocatalysis call for a concerted, interdisciplinary modelling approach that has converged in my group in the recent years. In particular, it can only be achieved by combining my expertise in multiscale computer simulations of solvated polymers with the statistical and continuum mechanics of soft matter structures and dynamics. The key challenge is to integrate the molecular solvation effects and our growing knowledge of hydrogel mechanics and thermodynamics into advanced reaction-diffusion equations for a quantitative rate prediction. In addition, I envision exciting novel phenomena such as a chemo-mechanical 'self-regulated catalysis' or an amplifying 'resonant catalysis', if hydrogel response and fluctuations couple to the chemical output signal.

The expected results and design principles will help our collaborators to synthesize tailor-made, superior nanocatalysts and will advance our understanding of their structure-reactivity relationship.","1987500","2015-08-01","2020-07-31"
"NanoSpin","Nanoscale spin interactions and dynamics on superconducting surfaces","Katharina Jennifer Franke","FREIE UNIVERSITAET BERLIN","The latest concepts for quantum computing and data storage envision the use of single spins, which can be addressed and manipulated reliably. One of the main limitations towards this challenging goal is the ultra-short lifetime of excited spin states due to the interaction with the contacting leads. Another limitation is that coherence between individual spins is quickly lost. Already the measurement process for resolving coherent electron-spin interactions at the single atom level is highly challenging and has not been achieved so far.
Within our proposal, we will construct a low-temperature scanning tunneling microscope with a radio-frequency current detection system and a microwave source close to the tip. With this unique machine, we will be able to carry out state-of-the-art STM experiments combined with atomic-scale precision of measuring electron-spin resonance signals. With the approach of measuring in the frequency domain, we increase our energy resolution beyond the thermal energy level broadening into the µeV range and can thus investigate magnetic coupling, hyperfine interactions and spin coherence properties, which are not accessible in conventional STM experiments. We will also be able to probe the timescales of spin-lattice and spin-spin relaxations by pump-probe excitation schemes.
We will use this machine for resolving magnetic properties of single atoms and atomic-size nanostructures on superconducting substrates. These substrates exhibit two peculiarities, which are of crucial importance for quantum information processing. The spin lifetimes are orders of magnitudes larger than on normal metal surfaces. Furthermore, the long coherence length of Cooper pairs mediates coherent coupling of the spin states of paramagnetic atoms. We will manipulate the spin states by the intrinsic Josephson current as well as with external microwave radiation. Our model systems on superconductors will provide crucial steps towards quantum spin processing.","1999469","2014-05-01","2019-04-30"
"NanoSurfs","Nanostructured Surfaces: Molecular Functionality on advanced sp2-bonded substrates","Wilhelm Auwärter","TECHNISCHE UNIVERSITAET MUENCHEN","Inspired by the diverse functionalities of complex molecular building blocks evidenced in manifold life processes as transport of respiratory gases, metabolism or light harvesting, we aim for a comprehensive characterization and control of molecular properties in surface-based model systems. To fully exploit and tune molecular functionality on substrates, a paradigm shift away from conventional metal supports, which might drastically affect adsorbates, is mandatory. We propose to apply nanostructured boron nitride (BN) monolayers and sp2-heterostructures as templates for molecular units and architectures. As indicated by the fascinating nanomesh interface and the electronically corrugated atomically thin BN sheet on Cu we recently reported, inert, temperature stable and insulating BN has a huge potential as advanced substrate supporting molecular functionality, self-ordering and intercalation.
By combining the inherent functionality of organic or bio-molecular building blocks with the unusual electronic and structural characteristics of  advanced sp2-bonded substrates grown by chemical vapour deposition, we aim to achieve desired properties, including electronic, magnetic and conformational switching, tunable reactivity, or tailored electronic band gaps. Special emphasis will be put on economic substrates as thin films or foils, which open perspectives for scalable processing.
With this proposal, we wish to establish research at the interface of surface science, supramolecular chemistry and materials engineering, yielding new insight into physicochemical processes at the single-molecule level, but also offering pathways to molecular sensors, switches, catalysts and devices, thus making a viable contribution to the on-going quest for innovation in nanotechnology. State-of-the-art scanning probe microscopy, a proposed new apparatus for the growth and handling of sp2-sheets and complementary X-ray based techniques will be used to tackle this ambitious project.","1983841","2014-04-01","2019-03-31"
"NanoThermo","Energy Conversion and Information Processing at Small Scales","Massimiliano Gennaro Esposito","UNIVERSITE DU LUXEMBOURG","Thermodynamics provided mankind with the intellectual tools to master energy transfers and energy conversion in macroscopic systems operating close to equilibrium. It is now one of the most fundamental theories in physics. My goal is to establish a thermodynamic theory describing energy conversion and information processing in small synthetic or biological systems operating far from equilibrium. Significant progress has been achieved in this direction over the last decade. The new theory is called stochastic thermodynamics (ST). It allows us to describe and understand energy conversion in systems as diverse as quantum junctions and molecular motors, and also to predict the energetic cost of information processing operations such as erasing bits of information or feedback controlling a small device. It was validated in single molecule pulling experiments, electronic circuits, NMR and colloidal particles in optical tweezers. Nevertheless, ST still suffers from serious limitations which prevent its application in more complex systems. Therefore, I propose to expand the theoretical foundations of ST far beyond its current realm of validity and to broaden the scope of its applications in various new directions. I want to answer questions such as: Can one design devices made of many small energy converters (e.g. thermoelectric junctions) arranged in such a way as to generate collective behaviors (e.g. synchronization) prompting higher powers and efficiencies? Can one do the same by engineer quantum effects? How can one reduce the dissipation occurring when computing very quickly with small devices? Why are metabolic networks so efficient in converting energy, transmitting information, and preventing errors (e.g. toxic byproducts)? I will do so in close contact with leading experimental groups in the field. My conviction is that ST will become as important for nanotechnologies and molecular biology as thermodynamics has been for the industrial revolution.","1669029","2016-07-01","2021-06-30"
"NatDyReL","Utilizing Natural Dynamics for Reliable Legged Locomotion","Christian OTT","DEUTSCHES ZENTRUM FUER LUFT - UND RAUMFAHRT EV","Despite the significant progress made in the field of humanoid robotics over the last 10-15 years, bipedal locomotion in robotics is still far from human performance in terms of speed, versatility, and robustness. The design of most humanoid robots nowadays is dominated by the aim at high rigidity and position accuracy in the motor units. 
In contrast, the NatDyReL project aims at a fundamental shift of paradigm in the design and control of humanoid robots, towards a new generation of intrinsically compliant robots that can adjust their open loop actuator impedance in real-time to the task. We believe that the maturing technology of variable impedance actuators in combination with novel control approaches for the intrinsically elastic dynamics has the potential of bringing humanoid locomotion and multi-contact motions to a new level in terms of energy-efficiency and execution speeds more similar to the human archetype. However, to fully utilize the ultimate benefits promised by variable impedance actuators, i.e. to store and release energy as well as to provide physical protection against shocks caused by impacts, it is necessary to exploit the natural compliant whole body dynamics on all levels of the system design, planning and control hierarchies.
This project follows two scientific tracks for achieving (a) energetically efficient and high performant legged locomotion and (b) robust and dynamic contact transitions and in-contact motions for whole body locomotion in uncertain and confined spaces. As a strong basis to the mentioned application oriented objectives, we also aim at fundamental contributions on the control challenges related to novel variable impedance actuator technologies. 
The project is expected to make a strong impact on bipedal humanoid locomotion. Moreover, the developed methods will be sufficiently general such that they can also be transferred to other morphologies such as e.g. multi-limbed walking or climbing robots.","1981500","2019-04-01","2024-03-31"
"Naturale CG","Engineering Bio-inspired Materials for Biosensing and Regenerative Medicine","Molly Stevens","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","In Naturale CG I propose transformative bioengineering approaches that will overcome severe limitations in current materials in two main areas, namely 1) Biosensing and 2) Regenerative Medicine. A key focus is on understanding and engineering the biomaterial interface using innovative designs and state of the art materials characterisation methods. Firstly I aim to transform the way that we can currently detect disease through innovations in the design and development of nanomaterials-based biosensors that could be used to detect a number of diseases with global implications, such as cancer, malaria, heart failure and tuberculosis. These innovations in biosensor design will involve both building on our existing highly successful work on plasmonic biosensors and also involve the design and development of completely new polymersome and fluorescent based biosensors. Another key aim of Naturale CG is to design first in kind biosensors for the facile detection of microRNAs. Secondly, the goal of regenerating failing organs before the body as a whole is ready to surrender, is now timelier than ever and one in which the design of new bio-inspired materials can play an important role. In Naturale CG I will build on my previous research in the design of 3-dimensional tissue engineering scaffolds and address an important new direction in the engineering of new bio-inspired conducting polymers as tissue engineering materials to promote cardiac tissue regeneration. First-in-field biomaterials-based innovations generated from this programme could enable far more effective regeneration of functional myocardial tissue which has been notoriously difficult to achieve thus far. Whilst I will lead this grant and the research within it, the proposed innovations are truly multidisciplinary in nature and will be accelerated towards clinical translation through the numerous clinical, scientific and industrial collaborations that I have established.","1999460","2014-07-01","2019-06-30"
"NAUTILUS","Neutron cAptUres consTraIning steLlar nUcleosynthesiS","Rene Reifarth","JOHANN WOLFGANG GOETHE-UNIVERSITATFRANKFURT AM MAIN","""NAUTILUS will investigate the nucleosynthesis of the chemical elements during the evolution of stars, which is the basis for understanding the chemical history of the Universe. The vast majority of the elements heavier than iron are produced by neutron capture reactions. The precise knowledge of the involved neutron capture cross sections for certain isotopes sets tight limits for stellar parameters and puts strong constraints on the age of the Universe.

Accurate measurements of the key nuclear reactions in the mass region around the radioactive 85Kr will lead to the improvements needed to characterize the production processes of the elements in stars. The respective high-accuracy abundance patterns in single stars can then be interpreted as diagnostic tools for the deep stellar interior and the isobaric 87Sr/87Rb chronometer constraints the history of the Universe.

The neutron capture cross section of radioactive isotopes for neutron energies in the keV region will be measured by a time-of-flight (TOF) experiment. NAUTILUS will provide a unique facility realizing the TOF technique with an ultra-short flight path at the FRANZ setup at Goethe University Frankfurt am Main, Germany. A highly optimized spherical photon calorimeter will be built and installed at an ultra-short flight path.

NAUTILUS opens new horizons in the area of neutron-induced reaction research, as smallest samples like of 85Kr - which will be produced as an isotopically pure radioactive sample - will become measureable in reasonable times.

Future applications include the study of neutron capture cross sections important for next generation nuclear reactors: For the first time the high neutron fluxes needed to study the mass region of interest in the keV energy range will be available.""","1871596","2014-04-01","2019-03-31"
"NBEB-SSP","Nonparametric Bayes and empirical Bayes for species sampling problems: classical questions, new directions and related issues","Stefano FAVARO","UNIVERSITA DEGLI STUDI DI TORINO","Consider a population of individuals belonging to different species with unknown proportions. Given an
initial (observable) random sample from the population, how do we estimate the number of species in the
population, or the probability of discovering a new species in one additional sample, or the number of
hitherto unseen species that would be observed in additional unobservable samples? These are archetypal
examples of a broad class of statistical problems referred to as species sampling problems (SSP), namely:
statistical problems in which the objects of inference are functionals involving the unknown species
proportions and/or the species frequency counts induced by observable and unobservable samples from the
population. SSPs first appeared in ecology, and their importance has grown considerably in the recent years
driven by challenging applications in a wide range of leading scientific disciplines, e.g., biosciences and
physical sciences, engineering sciences, machine learning, theoretical computer science and information
theory, etc.
The objective of this project is the introduction and a thorough investigation of new nonparametric Bayes
and empirical Bayes methods for SSPs. The proposed advances will include: i) addressing challenging
methodological open problems in classical SSPs under the nonparametric empirical Bayes framework, which
is arguably the most developed (currently most implemented by practitioners) framework do deal with
classical SSPs; fully exploiting and developing the potential of tools from mathematical analysis,
combinatorial probability and Bayesian nonparametric statistics to set forth a coherent modern approach to
classical SSPs, and then investigating the interplay between this approach and its empirical counterpart;
extending the scope of the above studies to more challenging SSPs, and classes of generalized SSPs, that
have emerged recently in the fields of biosciences and physical sciences, machine learning and information
theory.","982930","2019-03-01","2024-02-29"
"NEARFIELDATTO","Attosecond physics at nanoscale metal tips - strong field physics in the near-field optics regime","Jens Peter Hommelhoff","FRIEDRICH-ALEXANDER-UNIVERSITAET ERLANGEN NUERNBERG","Electron dynamics in metals and nanostructures take place on attosecond timescales. Until today, these extremely fast processes are little understood let alone utilized. With NearFieldAtto, strong-field driven phenomena at nanoscale metal structures will be explored to elucidate collective electron dynamics and to induce optical-field-driven currents -- on attosecond timescales. We will investigate the near-field of a nanotip, resulting from the collective dynamics, both in amplitude and phase. Conversely, we will use the tip as a nanometric sensor to map out the electric field inside the focus of a pulsed laser beam and will directly measure the local phase. In two-tip and molecular junctions, we will explore the ultrafast steering of electronic currents by optical fields, both over a nanometric gap and inside a molecule, taking advantage of the large near-field enhancement the systems offer.

My group has recently shown that attosecond physics phenomena can be observed at solids, namely at nanoscale tips [Krüger et al., Nature 2011]. Hence, in NearFieldAtto we will employ techniques well known from attosecond physics with isolated objects, like gas-phase atoms and molecules, to steer laser-emitted electrons with the electric field of few-cycle laser pulses. We will use these electrons as nanometric probes to investigate optical properties of the solid state system and compare the results with those of isolated objects in gas-phase measurements. With two tips facing each other, we will realize a nanometric junction over which we will steer electrons with the optical field. A molecule placed between two tips will enable the investigation of a novel, ultrafast switching mechanism.

NearFieldAtto will bring attosecond physics a leap forward as compared to the state-of-the-art, will introduce strong-field physics into (quantum-)plasmonics, and will open the door towards lightwave or petahertz nano-electronics in metallic and molecular nano-systems.","2012733","2014-04-01","2019-03-31"
"NEMO","New states of Entangled Matter Out of equilibrium","Pasquale CALABRESE","SCUOLA INTERNAZIONALE SUPERIORE DI STUDI AVANZATI DI TRIESTE","When an extended quantum system is suddenly brought out of thermodynamic equilibrium all excitations collectively participate in the ensuing quench dynamics, causing a plethora of unconventional and exotic effects, in particular in low spatial dimensions where the effects of interactions and integrability are enhanced. The theoretical study of the non-equilibrium dynamics is hampered by the fact that the time dependent many-body wave function is highly entangled on spatial scales which rapidly grow in time. Consequently, a satisfactory description of the quench dynamics is a timely challenge whose solution cannot prescind from a precise characterisation of the entanglement content of the systems of interest.

The ambitious goal of this proposal is to find and characterise new non-equilibrium states of matter guided by their entanglement content. Two parallel lines of research will help achieving this goal. One line concerns the study of some entanglement indicators like entanglement Hamiltonian, spectrum, negativity and relative entropies which, contrary to the entanglement entropy, are not yet widely used as tools for investigating many-body systems. The other line focuses on the study of some frontiers of non-equilibrium one-dimensional physics which include quantum quenches in spinful fermionic systems, the determination of the exact time dependence of correlation functions after a quench, and the use of integrable hydrodynamics for investigating transport in one-dimensional systems. Particular attention will be devoted to the experimental realisation of the proposed non-equilibrium protocols. The main tools to achieve these goals will be conformal field theories and integrability complemented by numerical simulations when the former two are not applicable.","1521423","2018-09-01","2023-08-31"
"NEPAL","NEw Physics searches with tAu Leptons","Justine Serrano","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","If the Standard Model (SM) of particle physics succeeds in describing the behaviour of fundamental constituents of matter and their interactions observed experimentally, it is unable to solve the most important riddles of our time such as the nature of the dark matter or the origin of the matter-antimatter asymmetry of the Universe. Manifestations of physics beyond the SM are extensively searched for, in particular through heavy flavour decays that are rare or forbidden in the SM. In this domain, final states involving electrons and muons are widely studied while channels involving tau leptons are much less known because of their challenging reconstruction. The interest of decays involving tau leptons is also dramatically reinforced by the recent anomalies reported in tests of lepton flavour universality violation and rare B decays, suggesting a special role of the third family. In particular, in the presence of physics beyond the SM, lepton flavour violating tau decays and rare B decays into tau leptons could be just below the current experimental limits.
With the NEPAL project, I propose to build a team of analysts that will exploit the world’s largest B and tau samples recorded in the clean environment of an electron/positron machine by the Belle II experiment. The full detector operation will start end 2018 and aims at recording five times more statistic than the total previous flavour-factory experiments by 2020, and a final dataset of 50 inverse attobarns by 2025. 
Thanks to the development of a common analysis framework, sophisticated machine learning techniques for signal selections, the use of a full event interpretation and the reconstruction of 95% of tau decays, my team will search for more than thirty lepton flavour violating tau decays and rare B decays into tau leptons. This will allow to set the world’s best limits in the best possible timescale, reshaping the landscape of searches for physics beyond the Standard Model.","1954831","2019-10-01","2024-09-30"
"NEST","Nanoengineering of radioactive seeds for cancer therapy and diagnosis","Tobias-Rossell Gerard","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","One of the major challenges in modern society is the early diagnosis and treatment of diseases. Cancer is one of the most relevant diseases worldwide because of its incidence, prevalence and mortality. During the past decades, considerable efforts have been devoted to understand the origin of the disease, find early detection methods that could improve the survival rate of cancer patients or develop treatments and devices that could reduce or eradicate cancer. The application of nanotechnology to medicine (nanomedicine) has become one of the most promising routes for the diagnosis and treatment of diseases. The small size of nanomaterials, large surface area and high reactivity impart unique physicochemical properties to these materials, in such a way that several therapeutics based on nanomaterials (liposomes, nanoparticles, polymers) have already been approved for clinical use in humans. However, there are still limitations that need to be overcome to obtain novel and efficient nanocarriers for oncology applications.

NEST presents an innovative approach that aims to engineer ultra-sensitive imaging and therapeutic agents. An unprecedented amount of ‘hot’ radionuclides, in the form of crystals, will be hermetically sealed in the interior of hollow nanostructures (seeds), thus preventing leakage and interaction of the radionuclides with the biological milieu. The in vivo fate will thus be merely governed by the nanocarrier and will be alien to the encaged radionuclides. Rational engineering of the nanoseeds in terms of size, shape and surface properties will be employed to tune their pharmacokinetic profile and biodistribution, including tumour targeting. The large amount of radionuclides encased in each of the seeds is expected to allow a more personalised treatment of cancer and ultra-sensitive imaging, for an early diagnosis.","1999965","2017-10-01","2022-09-30"
"NETS","Networks in Time and Space","Sofia Olhede","UNIVERSITY COLLEGE LONDON","This research programme aims to develop a new theoretical framework for modelling and analysing spatio-temporal
networks. The theory developed in this programme will underpin our ability to exactly specify the
structured form of network behaviour in time and space. This will advance statistical methodology and theory,
unifying results from stochastic processes with network theory to do so. New technical approaches to modelling
will be proposed, as well as new asymptotic large sample scenarios. As a consequence of the methodological
development, new analysis techniques for applications in real-world problems will be proposed that will improve
our ability to make defensible conclusions from real data sets.

Modelling network data and estimating such models is challenging, especially in a modern setting, because
most observed networks are very large. This leads to computational and inferential challenges. However,
handling sparse and large networks is not enough to be able to describe highly structured network data. Most
networks are coupled with secondary structure, and possess patterned behaviour in time and space. Linkages
between nodes are frequently added and removed over time, and implicit structure is generated from latent
spatial patterns.

The understanding of networks must be extended to encompass spatio-temporal patterns, to quantify such
structural aspects of network data. This will require combining theory and methods from different parts of
mathematics, and developing new statistical theory. This project therefore aims to a) model temporally evolving
networks, b) understand the characteristics of growing and decaying networks, c) model and estimate spatial
and temporal characteristics in networks and d) propose new models of spatial structure. These developments
will combine to form a new theoretical framework for families of networks with a rich and complex structure.","1587602","2016-05-01","2021-04-30"
"NEUCOS","Neutrinos and the origin of the cosmic rays","Walter Winter","STIFTUNG DEUTSCHES ELEKTRONEN-SYNCHROTRON DESY","The discovery of cosmic neutrinos is one of the major breakthroughs in science in the year 2013. These neutrinos are expected to point back to the origin of the cosmic rays, which are produced in the most powerful accelerators in the universe. In order to solve the puzzle where the highest energetic neutrinos and cosmic rays come from, the key information could be the composition of the observed cosmic ray flux. The question critical for the future development of high-energy astrophysics is especially how heavier nuclei can be accelerated and escape from the sources, such as gamma-ray bursts or active galactic nuclei, without disintegration, or what the consequences for the neutrino fluxes and cosmic ray compositions at the sources are. Neutrinos, on the other hand, may be good for surprises, such as new physics only detectable at extreme energies, distances, or densities. In addition, the possibility to measure neutrino properties in neutrino telescopes has been emerging, either using astrophysical or atmospheric neutrino fluxes, which means that the border line between neutrino physics and astrophysics applications in these experiments fades.  
The key idea of this proposal is therefore to combine the expertise from astrophysics and particle physics in a multi-disciplinary working group 1) to study the effect of heavy nuclei on the source fluxes from multiple messengers, such as a neutrinos, cosmic rays, and gamma-rays, using efficient descriptions for the radiation processes and particle interactions, and 2) to optimize future experiment infrastructure in ice and sea water for both astro- and particle physics applications. The key goals are to eventually identify the origin of the cosmic rays and cosmic neutrinos, and to solve the open questions in particle physics, such as neutrino mass hierarchy and leptonic CP violation.","1746000","2015-09-01","2020-08-31"
"NEURO-PATTERNS","How neuronal activity patterns drive behavior: novel all-optical control and monitoring of brain neuronal networks with high spatiotemporal resolution","Tommaso Fellin","FONDAZIONE ISTITUTO ITALIANO DI TECNOLOGIA","When we see an object, hear a sound or smell an odor, precise spatial and temporal patterns of electrical activity are generated within neuronal networks located in specialized brain areas. This electrical representation of the external stimulus mediates perception and sensory experience. However, this process is highly variable, and repetition of the very same sensory experience results in distinct network activity patterns. What does this variability mean for perception? Do distinct activity patterns carry different information about the stimulus? Or rather, does the brain code the same information coming from the outside world in multiple and equivalent ways? Answering these questions and determining how patterns of activity in neuronal populations are used for behavior has not been possible because of the inability to change the activity of neurons with single cell precision over large networks in an intact mammalian brain. In this ambitious proposal we will take a multidisciplinary approach to causally address these questions and decipher the computational principles of brain networks. To achieve this goal we will develop innovative optical technologies for manipulating and monitoring brain circuits with single cell resolution in the intact mouse brain. We will combine these new techniques with novel genetic manipulations and psychophysical behavioral methods that allow precise quantification of animals’ perceptual performance. Using this unique set of tools, we will unravel how the spatial (across neurons) and temporal (across time) aspects of neuronal electrical activity patterns encode information that guides behavior. In achieving our goals we will produce a new technology for stimulating and monitoring neurons in the brains of behaving animals with single-cell specificity that can be adapted to explore cellular dynamics in highly scattering biological media.","1974000","2015-10-01","2020-09-30"
"NEURO-PLASMONICS","Neuro-Plasmonics","Francesco De Angelis","FONDAZIONE ISTITUTO ITALIANO DI TECNOLOGIA","Research neuronal signaling is the subject of a very large community, but progresses face a dense multi-scale dynamics involving signaling at the molecular, cellular and large neuronal network levels. Whereas the brain capabilities are most likely emerging from large neuronal networks, available electrophysiological methods limit our access to single cells and typically provides only a fragmented observation, on limited spatial/temporal scales. Therefore, broadening the spectrum of scales for observing neuronal signaling within large neuronal networks is a major challenge that can revolutionize our capability of studying the brain and its physio-pathological functions, as well as of deriving bio-inspired concepts to implement artificial system based on neuronal circuits. We propose the development of an innovative electro-plasmonic multifunctional platform that by combining different methodologies emerging from distant fields of Science and Technology will provide a radically new path for real time neurointerfacing at different scale levels:
1. The molecular scale: 3D plasmonic nanoantennas will give access to information at molecular level by means of enhanced spectroscopies with particular regard of time resolved Raman scattering.
2. The single-neuron scale within neuronal networks: by both in-cell and extra-cell couplings with 3D nanostructures which work at the same time as plasmonic antennas and CMOS 3D nanoelectrodes.
3. The scale of large neuronal networks: by CMOS high-density electrode arrays for spatially and temporally resolving neuronal signaling form thousands of measuring sites.
This is achieved by exploiting an innovative nanofabrication method able to realize 3D nanostructures which can work at the same time as plasmonic nanoantennas and as nanoelectrodes. These structures will be integrated on CMOS multi-electrode arrays designed to manage multiscale measurements from the molecular level up to network level on several thousand of measurement sites.","1388000","2014-04-01","2018-03-31"
"NeuroAgents","Neuromorphic Electronic Agents: from sensory processing to autonomous cognitive behavior","Giacomo INDIVERI","UNIVERSITAT ZURICH","""Neural networks and deep learning algorithms are currently achieving impressive state-of-the-art results. In parallel computational neuroscience has made tremendous progress with both theories of neural computation and with hardware implementations of dedicated brain-inspired  computing platforms.
However, despite this remarkable progress, today’s artificial systems are still not able to compete with biological ones in tasks that involve processing of sensory data acquired in real-time, in complex and uncertain settings. One of the reasons is that neural computation in biological systems is very different from the way today's computers operate: it is tightly linked to the properties of their computational embodiment, to the physics of their computing elements and to their temporal dynamics. Conventional computers on the other hand operate with mainly serial and synchronous logic gates, with functions that are decoupled from their hardware implementation, and with discretized and virtual time.
In this project we will combine the recent advancements in machine learning and neural computation with the latest developments in neuromorphic computing technology to design autonomous systems that can express robust cognitive behavior while interacting with the environment, through the physics of their computing substrate. To achieve this we will embed in robotic platforms microelectronic neuromorphic processors and sensors that implement biophysically realistic neural computational primitives and dynamics. We will adopt active-sensing and on-line spike-based learning strategies, context and state-dependent computation, and probabilistic inference methods for """"programming"""" these neuromorphic cognitive agents to solve challenging tasks in real-time. 
Our results will lead to compact low-power intelligent sensory-motor systems that will have a large impact on service and consumer robotics, Internet of Things, as well as prosthetics and personalized medicine.""","1999090","2017-09-01","2022-08-31"
"NewtonStrat","Newton strata - geometry and representations","Eva VIEHMANN","TECHNISCHE UNIVERSITAET MUENCHEN","The Langlands programme is a far-reaching web of conjectural or proven correspondences joining the fields of representation theory and of number theory. It is one of the centerpieces of arithmetic geometry, and 
has in the past decades produced many spectacular breakthroughs, for example the proof of Fermat’s Last Theorem by Taylor and Wiles.

The most successful approach to prove instances of Langlands’ conjectures is via algebraic geometry, by studying suitable moduli spaces such as Shimura varieties. Their cohomology carries actions both of a linear algebraic group (such as GLn) and a Galois group associated with the number field one is studying. A central tool in the study of the arithmetic properties of these moduli spaces is the Newton stratification, a natural decomposition based on the moduli description of the space. Recently the theory of Newton strata has seen two major new developments: Representation-theoretic methods and results have been successfully established to describe their geometry and cohomology. Furthermore, an adic version of the Newton stratification has been defined and is already of prime importance in new approaches within the Langlands programme.

This project aims at uniting these two novel developments to obtain new results in both contexts with direct applications to the Langlands programme, as well as a close relationship and dictionary between the classical and the adic stratifications. It is subdivided into three parts which mutually benefit from each other: Firstly we investigate the geometry of Newton strata in loop groups and Shimura varieties, and representations in their cohomology. Secondly, we study corresponding geometric and cohomological properties of adic Newton strata. Finally, we establish closer ties between the two contexts. Here we want to obtain analogues to results on one side for the other, but more importantly aim at a direct comparison that explains the similar behaviour directly.","1202500","2018-06-01","2023-05-31"
"NICHOID","Mechanobiology of nuclear import of transcription factors modeled within a bioengineered stem cell niche.","Manuela Teresa Raimondi","POLITECNICO DI MILANO","Many therapeutic applications of stem cells require accurate control of their differentiation. To this purpose there is a major ongoing effort in the development of advanced culture substrates to be used as “synthetic niches” for the cells, mimicking the native ones. The goal of this project is to use a synthetic niche cell culture model to test my revolutionary hypothesis that in stem cell differentiation, nuclear import of gene-regulating transcription factors is controlled by the stretch of the nuclear pore complexes. If verified, this idea could lead to a breakthrough in biomimetic approaches to engineering stem cell differentiation.
I investigate this question specifically in mesenchymal stem cells (MSC), because they are adherent and highly mechano-sensitive to architectural cues of the microenvironment. To verify my hypothesis I will use a combined experimental-computational model of mechanotransduction. I will a) scale-up an existing three-dimensional synthetic niche culture substrate, fabricated by two-photon laser polymerization,  b) characterize the effect of tridimensionality on the differentiation fate of MSC cultured in the niches, c) develop a multiphysics/multiscale computational model of nuclear import of transcription factors within differentially-spread cultured cells, and d) integrate the numerical predictions with experimentally-measured import of fluorescently-labelled transcription factors.
This project requires the synergic combination of several advanced bioengineering technologies, including micro/nano fabrication and biomimetics. The use of two-photon laser polymerization for controlling the geometry of the synthetic cell niches is very innovative and will highly impact the fields of bioengineering and biomaterial technology. A successful outcome will lead to a deeper understanding of bioengineering methods to direct stem cell fate and have therefore a significant impact in tissue repair technologies and regenerative medicine.","1903330","2015-05-01","2020-04-30"
"NLL","Nonlinear Laser Lithography","Fatih Ömer Ilday","BILKENT UNIVERSITESI VAKIF","""Control of matter via light has always fascinated humankind; not surprisingly, laser patterning of materials is as old as the history of the laser. However, this approach has suffered to date from a stubborn lack of long-range order. We have recently discovered a method for regulating self-organised formation of metal-oxide nanostructures at high speed via non-local feedback, thereby achieving unprecedented levels of uniformity over indefinitely large areas by simply scanning the laser beam over the surface.

Here, we propose to develop hitherto unimaginable levels of control over matter through laser light. The total optical field at any point is determined by the incident laser field and scattered light from the surrounding surface, in a mathematical form similar to that of a hologram. Thus, it is only logical to control the self-organised pattern through the laser field using, e.g., a spatial light modulator. A simple wavefront tilt should change the periodicity of the nanostructures, but much more exciting possibilities include creation of patterns without translational symmetry, i.e., quasicrystals, or patterns evolving non-trivially under scanning, akin to cellular automata. Our initial results were obtained in ambient atmosphere, where oxygen is the dominant reactant, forming oxides. We further propose to control the chemistry by using a plasma jet to sputter a chosen reactive species onto the surface, which is activated by the laser. While we will focus on the basic mechanisms with atomic nitrogen as test reactant to generate compounds such as TiN and SiN, in principle, this approach paves the way to synthesis of an endless list of materials.

By bringing these ideas together, the foundations of revolutionary advances, straddling the boundaries of science fiction, can be laid: laser-controlled self-assembly of plethora of 2D patterns, crystals, and quasicrystals alike, eventually assembled layer by layer into the third dimension -- a 3D material synthesiser.""","1999920","2014-06-01","2019-05-31"
"NMST","New methods and interacions in Singularity Theory and beyond","Javier Jose Fernandez De Bobadilla De Olazabal","BCAM - BASQUE CENTER FOR APPLIED MATHEMATICS","""This project is centred in Singularity Theory and its interactions and applications to Complex and Algebraic Geometry, Differential/symplectic/Contact Topology, Hodge Theory and Algebraic Topology. This subject is still at the core of various developments (Mori's Theory, Symplectic and Contact Geometry, algebro-geometric Donaldson-Thomas Theory, Hodge Theory and D-modules,...) In the present project we propose several directions of development in singularity theory, designed in order to approach the solution of several classical conjectures, and explore new interactions with the latest developments in nearby areas. New problems and conjectures are formulated, which are interesting bottlenecks whose solution would open new development perspectives in the theory, and whose study will need significantly new ideas. We have taken care of finding feasible starting points and interesting classes of singularities where the initial development is less steep.  And to find links among the seemingly difernt techniques and problems which we propose.
We deal with the following specific topics: vanishing cohomology of isolated and non-isolated singularities.  Rational homotopy generalisations of Hodge Theory and rational vanishing homotopy. Applications to Equisingularity questions. Disentanglement theory and its relation with vanishing homology and homotopy. Symplectic and contact geometry of milnor fibrations. A vast programme in topological equisingularity including a multifaceted attack to Lê-Ramanujan problem. Generalisations of McKay correspondence. Banagl Intersection spaces. Topological and analytic invariants of normal surface singularities. Arc spaces and Nash correspondence. Compactified Jacobians.""","1140601","2014-05-01","2019-04-30"
"NNLOforLHC2","New level of theoretical precision for LHC Run 2 and beyond","Alexander Dimitrov Mitov","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","LHC Run 2 will operate at significantly higher centre of mass energy and could offer an unprecedented insight into the largely unexplored region of TeV physics. The usefulness of this wealth of forthcoming high-quality data would, however, be strongly dependent on the availability of theoretical predictions with matching accuracy. The current state of the art for hadron collider calculations is NNLO and calculations for the most interesting 2-to-2 processes have already been performed. The utility of these theoretical results is, however, limited: they are either incomplete or have been applied to a limited number of observables. Moreover, their flexibility is limited which prevents their widespread use in experimental analyses. The goal of this proposal is to turn high-precision NNLO results into a LHC mainstream. We propose the following multi-prong approach, which addresses all main shortcoming of currently available 2-to-2 NNLO results: First, create a library of partonic events for the processes with top quarks and jets. A user-friendly interface will allow direct analysis by the user. Such a system would be novel, especially at NNLO, and once operational could be extended to any 2-to-2 NNLO process. Second, develop matching of NNLO calculations for processes with coloured partons to parton showers. This is an outstanding problem, which naturally fits the existing fixed order/shower expertise in the Cavendish. Its solution will unleash the potential of NNLO calculations and will make them truly useful for experimental analyses. Third, work on specific phenomenological analyses that make use, and promote, the precision results developed by the group. Last but not least, pursue novel techniques for computing 2-to-3 two-loop amplitudes, which is the bottleneck for advancing beyond the current frontier in LHC processes; use this to compute the 3 jet NNLO cross-section at the LHC. Such a result will be a first-ever and a great achievement for the LHC program.","1713983","2016-10-01","2021-09-30"
"NO-ESKAPE","Addressing Antibiotic Resistance: New Strategies for Overcoming the ESKAPE Pathogens","Nathaniel Isaac MARTIN","UNIVERSITEIT UTRECHT","Antibiotic resistance poses an alarming threat to global health. Most worrisome are the so-called “ESKAPE” pathogens (E. faecium, S. aureus, K. pneumoniae, A. baumanii, P. aeruginosa, and Enterobacter species), a collection of organisms capable of escaping the effects of almost all conventional antibiotics. Key to combating drug-resistant bacteria is the identification of new antibacterial targets and the ability to exploit these targets with novel and unconventional antibiotics.

The microbial world produces a wealth of antibacterial compounds that, while not suitable for therapeutic use, operate by diverse and unique modes of action. This proposal describes innovative approaches aimed at the discovery and development of such compounds as leads towards novel antibiotics with entirely new modes of action. Using a multidisciplinary approach, firmly grounded in synthetic organic chemistry, I will prepare and validate new antibiotics that target the ESKAPE pathogens by exploiting mechanisms critical to their survival and/or resistance.

To tackle the Gram-positive ESKAPE pathogens a number of new approaches to interfering with bacterial cell wall biosynthesis will be examined. Specifically, novel (semi)synthetic compounds capable of binding to and sequestering various bacterial cell wall precursors will be prepared and their antibiotic activity assessed. To address the Gram-negative ESKAPE pathogens, inhibitors of the metallo-beta-lactamase enzymes responsible for much of their antibiotic resistance will be pursued. These inhibitors will be achieved via a combination of rational design strategies and innovative natural product screening approaches.

The 21st century threat of a post-antibiotic era makes clear the need for innovation in antibacterial drug discovery. The strategies outlined in this proposal address this threat head-on with the aim of delivering valuable lead compounds in pursuit of novel antibiotics.","2000000","2017-06-01","2022-05-31"
"No-LIMIT","Boosting Photovoltaic Performance by the Synergistic Interaction of Halide Perovskites and Semiconductor Quantum Dots","Iván MORA SERÓ","UNIVERSITAT JAUME I DE CASTELLON","Photovoltaic conversion has the extraordinary property of transforming the solar energy directly into electric power. However, the available electrical power is known to be severely limited by the so-called Shockley-Queisser (SQ) photoconversion limit. The maximum efficiency for a single absorber is limited as photons with energy lower than the bandgap (BG) cannot be absorbed, and just an energy equivalent to the BG can be used for photons with higher energy than the BG, due to thermalization. Tandem cells have overcome this SQ limit upon exploiting complex and expensive configurations. Alternative approaches, even with higher potentiality, as Intermediate Bandgap Solar Cells (IBSCs) have not reached the expected performance mainly due to the limitations introduced by the monocrystalline matrix. The incorporation of quantum dots (QD) to create the IB produces layer strain and defects that limit the cell performance. No-LIMIT proposes to revamp IBSCs concept, using polycrystalline halide perovskites (HP) host matrix in order to take benefit from the strain relaxation at polycrystalline materials and from HP benign defect physics. HPs show an outstanding performance even when they are grown in a porous structure, indicating that their excellent transport and recombination properties are preserved with embedded materials. No-LIMIT will exploit this potentiality by using the states of embedded QD as IB in IBSC with HP matrix. The project will focus on the preparation of HPs-QD systems with enhanced light collection efficiency preserving charge transport, recombination and stability. No-LIMIT will study the properties and interactions of the HP and QD materials developed, as well as injection, recombination and transport properties in the coupled system. The combination of these strategies will build a ground-breaking synergistic system able to break the SQ limit. The achievements of IBSC, together with the intermediate steps, will have a colossal impact on photovoltaics","1999072","2017-09-01","2022-08-31"
"NOC2D","Nucleation of Organic Crystals onto 2D materials","Cinzia Casiraghi","THE UNIVERSITY OF MANCHESTER","The formation of crystalline solids from liquid-phase precursor is a central idea in materials chemistry. Organic crystal structures can be found in a large number of products, including food, explosives, pigments and pharmaceuticals. Control of molecular assembly is therefore a fundamental problem for both research and industry and it involves substantial scientific and economic challenges. For example, polymorphism is crucial for drug manufacturers because the crystal structure, morphology and size, can all affect the stability, efficacy and production cost of the drug. Therefore, it is essential to achieve a deep understanding on the molecular processes happening at the early stage of crystallization. Although important results have been obtained, our understanding on how a crystal of organic molecules nucleates on a surface is still poor. To go beyond state-of-the art we need techniques able to probe rare nucleation events with nanoscale resolution and very high sensitivity, providing direct insights on the structure of the nuclei and their interaction with the environment. 
The aim of this proposal is to use 2D crystals to open new horizons in the understanding of nucleation of organic crystals by using a multi-disciplinary approach, which combines chemical engineering, material chemistry, graphene physics and sensors technology. Graphene, a single layer of graphite, will allow preparing advanced surface templates and to perform nucleation experiments that would be impossible or too difficult to achieve with other templates. In particular, graphene will be used both as surface template and as sensor to probe nucleation events in real time. We will combine electrical and optical readouts to investigate molecular interactions during nucleation with chemical recognition and nanoscale resolution. This will strongly improve our understanding of the basic phenomena which control heterogeneous nucleation from liquid-phase precursor.","1922451","2015-09-01","2020-08-31"
"NOFEAR","New Outlook on seismic faults: From EARthquake nucleation to arrest","Giulio Di Toro","THE UNIVERSITY OF MANCHESTER","""With an average toll of 80.000 deaths per year over the last decade, earthquakes remain one of the most dreadful geohazards. The advancement of earthquake risk assessment and forecasting methods (probability estimates that a mainshock may occur in terms of hypocentre location, magnitude and time) calls for a sound physical basis. The nucleation, propagation and arrest of an earthquake rupture results from the interplay of stress perturbations, micro- to macro-scale friction- and rupture-related processes and fault zone geometrical complexity. Most of the information about these parameters is out of reach of seismic waves and geophysical analysis. Here we aim at enhancing our knowledge of earthquake physics (from nucleation to arrest) by means of a multidisciplinary approach that includes:

1) experiments to investigate earthquake nucleation by reproducing crustal (pressure, temperature, presence of fluids, stress perturbations, etc.) deformation conditions with the most powerful earthquake simulator installed worldwide (SHIVA);

2) experiments to investigate rupture propagation on simulated faults using natural rocks and small-scale analogue models;

3) field studies of exhumed seismogenic sources to quantify the geometrical complexity of natural fault zones;

4) advanced numerical simulation techniques that will integrate the above information and allow up-scaling to natural faults. The numerical models will produce physically-based earthquake simulations that will be compared with high-resolution seismic data.

By reproducing crustal deformation conditions (stress, temperature, fluid pressures, etc.) in the laboratory and by monitoring acoustic emissions, gases, electromagnetic waves, etc., produced by the rock samples during deformation, a by-product of our research will be the systematic investigation of precursory phenomena (seismic, chemical, and electromagnetic) associated to earthquake nucleation processes.""","1963800","2014-07-01","2019-06-30"
"NOISE","Noise-Sensitivity Everywhere","Gabor Zoltan PETE","MAGYAR TUDOMANYOS AKADEMIA RENYI ALFRED MATEMATIKAI KUTATOINTEZET","Noise-sensitivity of a Boolean function with iid random input bits means that resampling a tiny proportion of the input makes the output unpredictable. This notion arises naturally in computer science, but perhaps the most striking example comes from statistical physics, in large part due to the PI: the macroscopic geometry of planar percolation is very sensitive to noise. This can be recast in terms of Fourier analysis on the hypercube: a function is noise sensitive iff most of its Fourier weight is on ""high energy"" eigenfunctions of the random walk operator.

We propose to use noise sensitivity ideas in three main directions:

(A) Address some outstanding questions in the classical case of iid inputs: universality in critical planar percolation; the Friedgut-Kalai conjecture on Fourier Entropy vs Influence; noise in First Passage Percolation.

(B) In statistical physics, a key example is the critical planar FK-Ising model, with noise being Glauber dynamics. One task is to prove noise sensitivity of the macroscopic structure. A key obstacle is that hypercontractivity of the critical dynamics is not known.

(C) Babai’s conjecture says that random walk on any finite simple group, with any generating set, mixes in time poly-logarithmic in the volume. Two key open cases are the alternating groups and the linear groups SL(n,F2). We will approach these questions by first proving fast mixing for certain macroscopic structures. For permutation groups, this is the cycle structure, and it is related to a conjecture of Tóth on the interchange process, motivated by a phase transition question in quantum mechanics.

We will apply ideas of statistical physics to group theory in other novel ways: using near-critical FK-percolation models to prove a conjecture of Gaboriau connecting the first ell2-Betti number of a group to its cost, and using random walk in random environment to prove the amenability of the interval exchange transformation group, refuting a conjecture of Katok.","1386364","2018-02-01","2023-01-31"
"NoLiMiTs","Novel Lifesaving Magnetic Tentacles","Pietro VALDASTRI","UNIVERSITY OF LEEDS","The aim of this project is to characterize fundamental principles at the intersection of robotics, magnetics, manufacturing and medicine, which will enable intelligent tentacle-like robots to augment the capabilities of surgeons in reaching deep into the human anatomy through complex winding pathways and treat inoperable diseases.
Magnetic tentacle robots, proposed here for the first time, have the potential to be thin, extremely soft and scalable, and to conform to curvilinear trajectories by leveraging magnetic control over their entire length. The surgeon needing to access difficult to reach targets such as peripheral nodules in the lungs, small diseased blood vessels and regions deep inside the brain, will be able to design personalised tentacles and fabricate them on demand.
My world-leading research team in surgical robotics–to be further consolidated by this grant–will define and explore new robotic architectures, as well as the design and fabrication processes integral to this novel concept. Proprioceptive sensing, combined with mathematical models, will enable intelligent robotic control. Robotic assistance will be context dependent, ranging from joystick-based operation to autonomous control along pre-planned trajectories. An integrated design environment will help systematise and streamline implementation.
The research programme consists of four work packages: 1) Robotic architectures and models; 2) Intelligence and control; 3) Rapid design, simulation and synthesis; and 4) Multi-scale experimental evaluation, embracing different scenarios where control over the entire body of the robot is crucial: lung biopsy, cardiovascular interventions and neurosurgery.
This interdisciplinary research will strengthen Europe’s position in medical robotics and improve public health by reducing patient recovery times, complication rates, and treatment costs, and ultimately saving the lives of patients suffering diseases that are inoperable—and often terminal—today.","2698136","2019-05-01","2024-04-30"
"NOMLI","NanoOptoMechanics in classical and quantum Liquids","Ivan Guilhem Daniel FAVERO","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Over a decade, the field of optomechanics has progressed to the point of enabling first quantum experiments on mesoscopic mechanical devices. This maturity culminates with nanoscale semiconductor systems, which operate at very high mechanical frequency and allow intense interaction between light and mechanical motion. On top of representing a new class of elementary quantum systems, nano-optomechanical devices can sense forces at small scale with high speed and resolution, down to the quantum limit. They could probe physical interactions in complex environments, like liquids, with a unique degree of control, and thus bring new science and applications.
 
NOMLI explores original physics at the interface of nano-optomechanics and liquids, be they classical or quantum. A first objective is to realize nano-optomechanical rheological measurements at very high frequency (GHz) and small scale (μm) in classical liquids, and investigate the solid-like behavior of liquids in previously inaccessible regimes. A second objective is to optically cool a nano-optomechanical resonator immersed in a classical liquid down to the quantum regime, and analyze mechanical decoherence in such complex environment. As third objective, a quantum liquid of light will be artificially created in a set of nonlinear photonic resonators. Its viscous force will be investigated nano-optomechanically, and monitored as the liquid undergoes the superfluid transition. Finally a new type of quantum liquid, fully optomechanical in nature, will be formed in an ensemble of resonators at ultra-low temperature. Viscosity, dynamics and superfluidity of this new phase of light and matter will be investigated, using engineered photon-photon interactions mediated by mechanical motion. 

NOMLI will build a detailed picture of physical mechanisms at play, at the quantum level and at small scale, when a miniature mechanical force probe evolves in a liquid, where chemical and biological processes usually take place.","2292068","2018-04-01","2023-03-31"
"NonlinearTopo","Nonlinear Optical and Electrical Phenomena in Topological Semimetals","Binghai Yan","WEIZMANN INSTITUTE OF SCIENCE LTD","In the past decade, the band-structure topology and related topological materials have been intensively studied mostly by revealing their unique surface states. The current proposal sets a new paradigm by focusing on nonlinear optical phenomena in topological semimetals (TSMs). I aim to investigate the photocurrent and second-harmonic generation, as well as to discover novel nonlinear effects. The strength of TSMs lies in the fact that the giant Berry curvature in their band-crossing regions (e.g., Weyl points) can strongly boost these nonlinear effects, such as inducing a colossal photocurrent. Current understanding of the photocurrent is based on a model that considers the two-band transition within a Weyl cone. In the field of nonlinear optics, however, it is known that the photocurrent largely comes from three-band virtual transitions. Unfortunately, the nonlinear optics theory cannot be simply applied to TSMs due to the unphysical divergence of the photocurrent at band-crossing points. Therefore, I propose to bring the concept of three-band transitions to TSMs by reformulating the photocurrent theory framework. The new methodology represents the challenging and ground-breaking nature of the current proposal. Beyond the optical excitation, I further propose to explore exotic nonlinear electric and thermoelectric phenomena at the zero-frequency limit. I aim to build up a diagnostic tool that explores the nonlinear phenomena in a vast number of real TSM materials and directly probe the bulk topology by investigating their nonlinear properties. For example, my recent results have exposed a new group of Weyl points in a well-known Weyl semimetal by analysing the photocurrent distribution in its band structure. External perturbations can sensitively modify the TSM band structure, hence tune the induced photocurrent. This controllable photocurrent opens the door for novel device concepts, such as an optoelectronic transistor controlled by an external magnetic field.","1721706","2019-01-01","2023-12-31"
"NONLINMAT","Functional extreme nonlinear nanomaterials","Thomas ZENTGRAF","UNIVERSITAET PADERBORN","Metasurfaces that mimic artificial order in matter have recently opened an exciting gateway to reach unprecedented properties and functionality for the modification of light propagation. The artificial “atoms” and “molecules” of the metasurface can be tailored in shape and size, the lattice constant and inter-atomic interaction can be precisely tuned. Furthermore, using symmetry and polarization state properties topological Berry phase effects can greatly enhance the functionality of such surfaces.
This project sets to explore the revolutionary physics of nonlinear optical Berry phase metasurfaces, covering nonlinear optical frequency generation and wave dispersion engineering as well as real-time reconfiguration of nonlinear optical properties. Novel unique nonlinear optical properties of metasurfaces that arise from their specific topological configurations open up exciting new venues for device development in the fields of all-optical data processing, optical meta-nanocircuits, phase conjugating perfect mirrors, and background-free nonlinear holography. The project will investigate the possibilities of strongly enhanced nonlinear light-matter interaction and novel nonlinear optical processes that are based on nonlinear topological Berry phase effects coupled to inter- and intersubband transitions of novel 2D materials. Single layers of transition metal dichalcogenides will allow reconfigurable nonlinear optical properties by changing the valley band transitions.
The proposal covers the development of innovative large scale fabrication technologies, fundamental investigations of the origin and the design of effective nonlinearities, experimental characterizations, as well as device development. The findings of the project based on highly nonlinear reconfigurable metasurfaces based on symmetry and topological effects will impact interdisciplinary research fields including condensed matter physics, optoelectronics and biophotonics.","1915000","2017-08-01","2022-07-31"
"NONSPHEREFLOW","Multiscale modelling of gas-fluidized flows of non-spherical particles","Johannes Tiemen Padding","TECHNISCHE UNIVERSITEIT DELFT","Many important products are made using fluidized bed reactors, where solid particles are suspended by a gas flow. This promotes highly efficient gas-particle contact, resulting in high heat transfer, high chemical reaction rates and high product yields. Multiscale modelling has proven to be indispensable in the design and optimisation of fluidized bed reactors. Most coarse-grained models assume that the solid particles are of spherical shape because this simplifies the treatment of gas-solid drag and particle collisions. However, many particles used in fluidized bed (bio)reactors are non-spherical. This means that anisotropic collisions, anisotropic gas-solid drag, effects of local particle alignment, and alignment by nearby internal and external walls all need to be taken into account.
I propose to pioneer a multiscale simulation methodology, backed up by validating in-house experiments, for prediction of structure formation in gas-solid flows of inelastic non-spherical particles. As a first step we focus on elongated particles. The multiscale approach consists of: 1) fully resolved simulations to obtain closures for translational and rotational gas drag tensors in crowded environments and near external and internal walls, 2) Discrete Particle Model simulations to validate the drag closures with matching experiments and to obtain statistics of angular and linear velocity changes due to inter-particle collisions between groups of particles, 3) a novel Lagrangian method based on stochastic multi-particle collisions. The collision propagation rules make maximum use of conservation laws and local symmetries of the particle configuration, orientation and deformation rates. The coarse-grained model is amenable to a parcel approach and can be coupled with heat and mass transfer models, allowing for simulation of industrial scale reactors with non-spherical particles.","1983012","2014-05-01","2019-04-30"
"NORACHEM","Novel radical chemistry for complex peptide synthesis and engineering","Olivier Berteau","INSTITUT NATIONAL DE LA RECHERCHE AGRONOMIQUE","""Natural products are a constant source of inspiration in chemistry and have played a key role in the development of medicine. Recently, thanks to the progress in genomics and metagenomics, it has appeared that the biosynthetic potential of microorganisms and the complexity of the reactions catalyzed have been largely underestimated. Notably, enzymes using radical-based chemistry have been shown to be present in a very-large amount of biosynthetic pathways and to be widely distributed among all living organisms. The highly reactive radical species they generate give access to chemistries not accessible otherwise and allow them to catalyze unique and diverse reactions. Among them, the so-called """"radical SAM enzymes"""" have attracted considerable attention in recent years. While, initially hypothesized to be a family with several hundreds of members, recent genomic analyses have revealed that there are several tens of thousands of radical SAM enzymes catalyzing more than sixty distinct biochemical processes.

Very recently, an ever increasing number of radical SAM enzymes has been discovered in the biosynthetic pathways of natural compounds. In several cases, it has been shown that, instead of involving non-ribosomal or polyketide synthases, microorganisms use radical SAM enzymes to extensively modify ribosomally synthesized peptides producing highly complex bioactive molecules. In the present project, we propose to develop a multidisciplinary approach to investigate promising radical SAM enzymes catalyzing peptide modifications and elucidate their unique mechanisms which, in many cases, have no counterparts in biochemistry and synthetic chemistry. Based on the unique and highly conserved radical SAM domain and the mechanistic insights gained, we will develop novel radical SAM enzymes as catalysts for the synthesis of new chemicals with original structures and properties using a synthetic biology approach.""","1984218","2014-04-01","2020-03-31"
"NORIA","Numerical Optimal tRansport for ImAging","Gabriel, Louis, Jean PEYRÉ","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Optimal Transport (OT) theory provides a powerful framework to manipulate probability distributions using simple and intuitive geometric principles. OT distances compare favorably to all other alternatives, notably Euclidean metrics or information divergences, whose outputs are particularly sensitive to changes in quantization and are not suitable to compare point clouds. Because of these and many more favorable properties, OT should be a standard tool in imaging sciences where probability distributions are routinely used. However, at this time, OT is but a confidential tool restricted to niche applications. OT is barely used because it is complex mathematically, which hinders its dissemination in more applied fields, and because it consumes substantial computational resources when used naively. NORIA will address these two bottlenecks and develop the next generation of theoretical, numerical and algorithmic advances to enable large-scale optimal transport computations in imag- ing sciences. The algorithms developed by NORIA will rely on several mathematical breakthroughs: highly parallelizable entropic regularization schemes, Bregman stochastic optimization and gradient flows for metric spaces. They will be implemented using fast optimization codes that will be interfaced through a high-level, easy to use, scripting language. These algorithms will have far reaching applications in imaging sciences and data science in a broad sense. In particular, they will be used in three flagship applications: color and material processing in computer graphics, texture analysis and synthesis in computer vision, and exploration of the visual cortex in neuroimaging. NORIA’s members are key players in the European mathematical school of optimal transport, which is very strong. NORIA is the unique opportunity to give a computational and practical embodiment to this wealth of theoretical knowledge.","1996720","2017-10-01","2022-09-30"
"NOSUDEP","A Wearable Electronics Approach To Reduce Mortality in Epilepsy","Esther RODRIGUEZ-VILLEGAS","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","Epilepsy is a neurological condition that affects approximately 1% of the population (or over 50 million people in the world). Europe alone is home to 6 million people that suffer from epilepsy with one new case every minute. In certain cases, healthy patients with epilepsy can die suddenly and unexpectedly. This is known as Sudden Unexpected Death in Epilepsy (SUDEP). SUDEP kills thousands of people in Europe every year. Unfortunately the mechanisms of SUDEP are not known, which makes it unpredictable Individuals with refractory tonic-clonic or complex-partial seizures are at the highest risk of SUDEP. These comprise approximately one third of the population affected by epilepsy, i.e. in the order of 2 million people in Europe.
The focus of this research project is to carry out multidisciplinary research on wearable medical technologies with the ultimate aim of helping to protect epilepsy patients from SUDEP, by automatically and reliably alerting carers of physiologically dangerous indicators that are known to be precursors of it. These technologies will also have the potential to facilitate clinical research that is not possible with existing physiological monitoring systems. This could further current understanding of the mechanisms as well as individual risks factors of SUDEP, and consequently lead to specific disease management, treatment and prevention strategies targeted to the individual patient. Additionally, the research work carried out in this project will be beneficial in a number of clinical contexts, including but not limited to: diagnosis of paediatric and adult sleep apnoea (affects 2-10% of the population, but less than 20% are diagnosed in developed countries due to lack of in-clinic resources), early warning scoring in hospitals (i.e. 80% of patients in hospital), asthma (334 million people in the world, ), Chronic Obstructive Pulmonary Disease (64 million people in the world. 4th leading cause of death), and neonatal cot death (0.41% of babies)","1999999","2017-09-01","2022-08-31"
"NPTEV-TQP2020","Uncovering New Phenomena at the TeV Scale With Top Quarks","Lucio Cerrito","UNIVERSITA DEGLI STUDI DI ROMA TOR VERGATA","Our understanding of the subatomic world and of the very fabric of the space-time is encompassed in a theory which is the result of all past experimental observations and theoretical developments: the Standard Model of Particle Physics. Yet cosmological observations and theoretical arguments lead us to conclude that new phenomenology,
new particles, forces, or a new space-time structure is waiting to be uncovered. Naturalness of the recently discovered Higgs boson suggests that new phenomena should appear at the tera-electronvolt (TeV) scale, and will be accompanied by modifications to the dynamics of the heaviest elementary particle known: the top quark.

The aim of this proposal is to perform five measurements involving top
quarks with the data that will be collected by the ATLAS experiment at the upcoming Run II (2015-18) of the Large Hadron Collider (LHC): the top quark mass, the CP violation in B hadron decays from the top, the top-Z boson couplings, the search for the top's Flavour Changing Neutral decays, and the search for heavy resonances decaying to top pairs. While measuring these properties is nothing new, the measurements are performed coherently using novel techniques beyond state-of-the-art to push the boundaries on the sensitivity of the limited Run II data, hence allowing the discovery of new phenomena at the LHC before 2020.","1971841","2015-09-01","2020-08-31"
"NSHOCK","Non classical rarefaction shock-waves in molecularly complex vapours","Alberto Guardone","POLITECNICO DI MILANO","The expansion of a dilute gas through a gasdynamics convergent-divergent nozzle can occur in three different regimes, depending on the inlet and discharge conditions and on the gas: via a fully subsonic expansion, via a subsonic-supersonic or via a subsonic-supersonic-subsonic expansion embedding a compression shock wave within the divergent portion of the nozzle. I devised an exact solution procedure for computing nozzle flows of real gases, which allowed me to discover that in molecularly complex fluids eighteen additional different flow configurations are possible, each including multiple compression classical shocks as well as non classical rarefaction ones. Modern thermodynamic models indicate that these exotic regimes can possibly occur in nozzle flows of molecularly complex fluids such as hydrocarbons, siloxanes or perfluorocarbons operating close to the liquid-vapour saturation curve and critical point. The experimental observation of one only of these eighteen flow configurations would be sufficient to prove for the first time that non classical gasdynamics phenomena are indeed possible in the vapour region of a fluid with high molecular complexity
To this purpose, a modification to the blow-down wind tunnel for dense gases at Politecnico di Milano is proposed to use mixtures of siloxane fluids. Measurements are complemented by numerical simulations of the expected flow field and by state-of-the-art uncertainty quantification techniques. The distinctive feature of the proposed experiment is the adoption of mixture of siloxanes as working fluids. Mixtures of siloxanes are well known to exhibit an higher stability limit than their pure components, due to the redistribution process occurring at high temperature.
The increased understanding of real-gas dynamics will enable to improve the design of Organic Rankine Cycle Engines, to be used in  small scale energy production from biomasses, binary geothermal systems and concentrating solar thermal power plants.","1485600","2014-03-01","2019-02-28"
"NUMASS","Neutrinos: a different portal to new physics Beyond the Standard Model","Silvia Pascoli","UNIVERSITY OF DURHAM","In the past fifteen years, neutrino physics has revolutionised our understanding of particle physics. The discovery of neutrino oscillations implies that neutrinos have masses and mix: this is the only particle physics evidence of new physics beyond the Standard Model to date. Their origin remains a major challenge.

The NuMass project will focus on new physics at low energy scales, below the one reachable at the LHC. This approach is opposite to widely studied Standard Model extensions, which invoke new physics at scales so high that they will never be tested directly, and orthogonal to TeV models accessible at the LHC. The NuMass idea is that new particles in Nature could be hidden away not because they are too heavy but because, although light, they interact too weakly with ordinary matter. Neutrinos are by far the least understood of the standard fermions: if new particles are indeed at low scales, below the electroweak one, a likely scenario is that they couple more strongly to neutrinos than to other standard particles, e.g. quarks. Therefore, neutrinos are a unique portal into low energy physics.

The NuMass project will adopt a unique approach combining particle theory, phenomenology and cosmology. It will propose low energy extensions of the Standard Model and embed them in a consistent theory. It will study their signatures in experiments and their impact in the Early Universe. It will exploit the wide experimental programme, e.g. T2K, MicroBooNE, NOvA, GERDA, which will provide new data in the near future, to constrain the properties of the models.

The NuMass ultimate goal is to unveil a new theory of particles and interactions at low energy: its success would be groundbreaking as it would open a completely new perspective on the fundamental laws of Nature. New theoretical challenges would arise to explain why the new sector is light, and new experimental ones to test the new particles and interactions, leading to new directions in particle physics.","1702663","2014-05-01","2020-08-31"
"O.M.J.","Origin and Magnetization of astronomical Jets","Asaf PE'ER","BAR ILAN UNIVERSITY","The mechanisms by which astronomical jets are launched, as well as their internal properties are fundamental in high-energy astrophysics. It is hypothesized that strong magnetic fields play a key role in the formation and properties of these outflows, seen in many different objects. If this hypothesis is correct, then (i) jets in different objects are likely to have similar properties; and (ii) magnetic fields are crucial in all aspects of jet formation, propagation and particle heating by energy dissipation. This project is aimed at testing these hypotheses, thereby obtaining a deeper insight into the physical processes involved in the formation and properties of jets in different objects, in view of the fact that jets may be the only gravitational wave counterparts expected to be observed in the foreseen future. Building on a decade-long expertise in building unique radiative-transfer codes, I will construct novel algorithms designed to handle radiative processes that occur simultaneously over many different time scales, and implement them in general-relativistic magneto-hydrodynamic (GR-MHD) numerical codes.  This will allow, for the first time, the use of observations in constraining the unknown physics of the processes involved.  In order to make maximal use of both spectral and temporal data, prime focus will be given to transient objects. I will address (i) possible roles of the mass and spin of the central black hole; (ii) the configuration and strength of the magnetic fields; (iii) the rates of magnetic energy dissipation; (iv) pair production and annihilation in shaping the high energy emission; and (v) constraining uncertain microphysics of plasma heating by non-ideal processes.","1951744","2018-10-01","2023-09-30"
"O2SENSE","Oxygen Sensing with Multimodality Imaging Probes","Sofia Ioana Pascu","UNIVERSITY OF BATH","""This programme will employ physical sciences and biomedicine techniques to develop a revolutionary approach to early cancer diagnosis and post-treatment monitoring aiming to address shortcomings in our current technology in oxygen sensing and imaging of hypoxic prostate tumours.

This proposal represents a gearing process towards the biomedical implementation of metal complexes and functionalised nanoparticles as novel synthetic platform systems for personalised diagnosis and treatment of diseases such as cancer and which can also be extended to neurodegenerative disorders. The work programme is a meeting point for interdisciplinary science that goes well beyond  state of the art. New chemical sensing devices will outstrip and supersede existing biopsy and imaging techniques used in diagnosis and treatment of diseases such as cancers.

The key advances of this programme will be:

(a) ‘smart’ all-in-one multimodal imaging probes, whose sensitivities to levels of oxygen in cells (pO2) will be tunable to respond to various levels of hypoxia in tumors as desired. Our ultra-sensitive probes will be effective at low O2 concentrations and respond to reduced levels of hypoxia and under anoxia. This will surpass the mainstay in cancer diagnosis and therapy and provide increased selectivity for a wider range of tumours.

(b) new probes suitable for interlocked Positron Emission Tomography (PET), Single Photon Emission Tomography (SPECT), and optical imaging methodologies  Simultaneous in vitro and in vivo diagnostic information from radioimaging techniques (PET, SPECT) and optical imaging will provide in depth understanding of biological processes and lead to personalised medicine.

(c) new imaging tools for the first time will monitor the cellular biolocalisation of these probes by multiphoton optical imaging in nearIR regimes. These will drive the development of time-gated microscopy and multi-photon imaging with sensitivity for various levels of tumour hypoxia.""","1886876","2014-09-01","2019-08-31"
"OMCIDC","Optical Manipulation of Colloidal Interfaces, Droplets and Crystallites","Roel Petrus Angela DULLENS","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","This multidisciplinary research programme is focussed on the optical manipulation of interfaces, droplets and crystallites in colloidal model systems. In particular, we will use holographic optical tweezing and confocal microscopy to study interfacial phenomena in three different phase separated colloid-polymer mixtures, exhibiting colloidal liquid-gas, crystal-gas and nematic-isotropic phase coexistence, respectively. First, we will determine the full potential energy landscape of the optical traps using the relation between interface fluctuations and deformed liquid-gas interfaces. This will then be used to study the complex and anisotropic interfacial properties of crystal-gas and nematic-isotropic interfaces. In addition, we envisage quantitatively investigating the nucleation of colloidal liquid droplets, crystallites and liquid crystalline droplets in optical traps positioned at well-defined heights above the interface, which is a direct and quantitative measure for the undersaturation. This allows us to systematically study the relation between the quench depth, nucleus size and nucleation times. We will furthermore nucleate multiple droplets, crystallites and liquid crystalline droplets to study their optical trapping controlled coalescence and detachment, which will shed completely new light on for instance the single particle structure and dynamics upon coalescence and detachment. Finally, we will introduce large probe particles into the phase separated colloid-polymer mixtures, which enables the study of important phenomena such as heterogeneous nucleation and capillary condensation, crystallisation and nematisation. This ambitious project opens up a huge range of exciting possibilities to gain a deep and fundamental understanding of interfacial phenomena in complex fluids by actively manipulating and controlling colloidal interfaces, droplets and crystallites.","1999892","2017-06-01","2022-05-31"
"OpaqueFlows","Flows Unveiled: Multimodal Measurement in Opaque Two-Phase Flows","Christian POELMA","TECHNISCHE UNIVERSITEIT DELFT","Dispersed multiphase flows are encountered in nearly every process in nature and industry; examples include sediment in rivers, catalysts in reactors and blood flow. Despite their relevance, it is currently difficult to accurately and efficiently model these flows. The opacity of the flows, even at moderate volume fractions, renders the common optical flow measurement tools useless. As a result, very little high-quality data is currently available to develop (numerical) models.

In this project, I lift the veil that covers multiphase flows. I do this by bringing together four flow measurement modalities, based on ultrasound, magnetic resonance, X-ray and advanced optical imaging. These are each applied to three benchmark flows, impenetrable to common (optical) techniques. This project will be the first focused effort to systematically apply these techniques to the same three benchmark flows. These benchmarks are: (1) a turbulent flow with heavy particles, (2) a laminar flow with relatively large particles and (3) a laminar flow with small particles showing non-Newtonian behaviour. These three flows represent archetypical flows from nature and industry, each pertaining to particular open questions in the field of fluid mechanics. The combined velocity and concentration field data resulting from this set of experiments will be vital in assessing and improving each of the techniques: direct comparison will allow evaluation of the performance and show the effect of acquisition and processing parameters on the accuracy. Detailed simulations using the exact same conditions will serve as further reference. Combined with the multi-modal experimental data, this will give breakthrough insight in the underlying physics of each of the benchmark flows. This in turn will lead to better multiphase flow models, which are demanded by a wide range of application areas (e.g. process technology, dredging, food and cosmetics industry, and hemodynamics research).","1955113","2017-05-01","2022-04-30"
"OPEN3GEN","Opening the Third Generation: The Search for Long-Lived Fundamental Particles","Sinead Marie FARRINGTON","THE UNIVERSITY OF EDINBURGH","The OPEN3GEN project will access an entirely new phase space to discover long-lived particles at the Large Hadron Collider.  Current data-recording algorithms (“triggers”) do not record directly this type of event at the LHC.  My team and I will maximise the experimental sensitivity by developing trigger strategies and reconstruction methods to yield the first datasets that will be sensitive to long-lived particles decaying to third generation particles. This will result, for the first time, in limits on, or observations of, long-lived particles in new lifetime regimes and signatures. In the case of a discovery, a program is proposed to measure the underlying dynamics of the New Physics by accessing information on the mass scale, lifetimes and spin information of the new particles. This proposal evidences my qualities as a creative PI applying specialised abilities to seek out orthogonal, novel activities to push back the boundaries of science.","1747286","2019-03-01","2024-02-29"
"OPERANDOCAT","In situ and Operando Nanocatalysis: Size, Shape and Chemical State Effects","Beatriz ROLDAN CUENYA","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Tailoring the chemical reactivity of nanomaterials at the atomic level is one of the most important challenges in catalysis research. In order to achieve this elusive goal, fundamental understanding of the structural and chemical properties of these complex systems must be obtained. Numerous studies have been devoted to understanding the properties that affect the catalytic performance of metal nanoparticles (NPs) such as their size, interaction with the support, and chemical state. The role played by the NP shape on catalytic performance is, however, less understood. Complicating the analysis is the fact that the former parameters cannot be considered independently, since the NP size as well as the support will have an impact on the most stable NP shapes. In addition, the dynamic nature of the NP catalysts and their response to the environment must be taken into consideration, since the working state of a NP catalyst might not be the state in which the catalyst was prepared, but rather a structural and/or chemical isomer that adapted to the particular reaction conditions. To address the complexity of real-world catalysts, a synergistic approach taking advantage of a variety of cutting-edge experimental methods must be undertaken. 
This project focuses on model heterogeneous catalysts for reactions of tremendous societal and industrial relevance, namely the gas-phase hydrogenation and electrocatalytic reduction of CO2. Important components that are missing from existing studies, and that we propose to contribute, are a systematic design of catalytically active model NPs with narrow size and shape distributions and tunable oxidation state, and in situ and operando structural, chemical, and reactivity characterization of such model catalysts as a function of the reaction environment. The results are expected to open up new routes for the reutilization of CO2 through its direct conversion into valuable chemicals and fuels such as methanol, methane and ethylene.","2000000","2017-05-01","2022-04-30"
"OPTIMA","PrOcess intensification and innovation in olefin ProducTIon by Multiscale Analysis and design","kevin VAN GEEM","UNIVERSITEIT GENT","New manufacturing techniques such as 3D printing have the potential to drastically transform the chemical industry. Novel, complex, integrated reactor designs can now be created, that will allow to unlock alternative chemical routes, such as for methane activation. Driven by process intensification and the power of high performance computing, this project will enhance heat and mass transfer in advanced chemical reactors by multiscale modelling and experimentation. OPTIMA aims to:

(1) develop in silico novel 3D reactor technologies and concepts with significantly improved selectivity and heat transfer by the use of additive manufacturing;
(2) generate new fundamental understanding of kinetics, heat transfer and mass transfer by using advanced measuring techniques for processes of both current and future importance;
(3) demonstrate the practical applicability of an open-source multiscale large eddy simulation (LES) platform in combination with finite rate chemistry for turbulent reacting flows;
(4) transform the chemical industry by valorising methane and converting it to a platform molecule through oxidative coupling of methane.

OPTIMA will focus on two olefin production processes of industrial and social importance in Europe, the exothermal oxidative coupling of methane and the endothermic steam cracking, demonstrating the universality of the proposed new paradigm. Starting from fundamental experiments and kinetic modelling (WP1), detailed chemistry will be implemented in an open-source LES multiscale modelling framework (WP2) generating in silico novel 3D reactor technologies with significantly improved selectivity (WP3). The power of the approach will be ultimately demonstrated in a novel, 3D integrated reactor, in which the studied exothermic and endothermic processes are cleverly combined (WP4). 

OPTIMA will pave the way for designing the 3D reactors of tomorrow and promote the new techniques and tools that will be driving innovation in the next decades.","1995000","2019-09-01","2024-08-31"
"OptnanoATcryo","Optical nanoscopy at 1 nm resolution: far-field fluorescence control at cryogenic temperatures","Bernd Rieger","TECHNISCHE UNIVERSITEIT DELFT","Optical nanoscopy is a powerful technique used in biology to study subcellular structures and function via specifically targeted fluorescent labels. Localization microscopy in particular offers a much better resolution (~10-50 nm) than conventional microscopy (~250 nm) while being relatively undemanding on the experimental setup and the subsequent image analysis.  The next revolution in imaging to 1 nm isotropic resolution in 3D must realize a big increase in the number of collected photons from single fluorescent emitters as well as in the labelling density. Only then can subcellular structures be imaged at the molecular level to study the molecular machinery of the cell. Notably observations of DNA conformation in 3D at such resolutions would be spectacular and enable investigation of biophysical models ranging from chromosomal DNA packaging to gene regulation.

I propose a new imaging technique based on fluorescence control at cryogenic temperatures in combination with novel data driven super-resolution reconstruction schemes employing prior knowledge that promises this unprecedented optical far-field resolution. I introduce a twofold technical leap by i) much higher photon counts due to negligible photobleaching at cryogenic temperatures while maintaining the sparsity required for single emitter localization and ii) relaxing the required labelling density using a priori information and the averaging of many identical entities. Orientational blinking ensures single emitter localization via a combination of polarization sensitive excitation, detection and stimulated depletion and triplet state shelving.
Biophysical models of cell structures and data driven priors mean that fewer samples are needed to fully describe a structure.
In a larger perspective, the outcome of this research will enable the combination of structural cryo-electron microscopy imaging at subnanometer resolutions with functional fluorescent imaging at the nanometer scale.","1911793","2015-07-01","2020-06-30"
"OSARES","Output-Sensitive Algorithms for Reactive Synthesis","Bernd Erhard Finkbeiner","UNIVERSITAT DES SAARLANDES","Reactive synthesis has the potential to revolutionize the development of distributed embedded systems. From a given logical specification, the synthesis algorithm automatically constructs an implementation that is correct-by-design. The vision is that a designer analyzes the design objectives with a synthesis tool, automatically identifies competing or contradictory requirements and obtains an error-free prototype implementation. Coding and testing, the most expensive stages of development, are eliminated from the development process. Recent case studies from robotic control and from hardware design, such as the automatic synthesis of the AMBA AHB bus controller, demonstrate that this vision is in principle feasible. So far, however, synthesis does not scale to large systems. Even if successful, it produces code that is much larger and much more complicated than the code produced by human programmers for the same specification. Our goal is to address both of these fundamental shortcomings at the same time. We will develop output-sensitive synthesis algorithms, i.e. algorithms that, in addition to optimal performance in the size of the specification, also perform optimally in the size and structural complexity of the implementation. Target applications for our algorithms come from both the classic areas of reactive synthesis, such as hardware circuits, and from new and much more challenging application areas such as the distributed control and coordination of autonomous vehicles and manufacturing robots, which are far beyond the reach of the currently available synthesis algorithms.","1995000","2016-07-01","2021-06-30"
"OutflowMagn","Magnetic fields and the outflows during the formation and evolution of stars","Wouter Henricus Theodorus Vlemmings","CHALMERS TEKNISKA HOEGSKOLA AB","The outflows of young and old stars play a crucial role in the cycle of matter in galaxies.  Stars and planetary systems are formed through complex physical processes during the collapse of gas clouds with outflows a required ingredient. At the end of a stars life, stellar outflows are the main source of heavy elements that are essential for the formation of stars, planets and life. Magnetic fields are one of the key factors governing the in particular the often observed collimated outflow. They might also be a key ingredient in driving stellar mass loss and are potentially essential for stabilizing accretion disks of, in particular, massive proto-stars. Only polarization observations at different spatial scales are able to measure the strength and structure of magnetic fields during the launching of outflows from young and old stars. Because stars in these evolutionary phases are highly obscured by dusty envelopes, their magnetic fields are best probed through observations of molecules and dust at submillimeter and radio wavelengths. In addition to its role, the origin of the magnetic field in these stellar phases is also still unknown and to determine it multi-wavelength observations are essential. The proposed research group will use state of the art submillimeter and radio instruments, integrated with self-consistent radiative transfer and magneto-hydrodynamic models, to examine the role and origin of magnetic fields during star formation and in the outflows from evolved stars. The group will search for planets around evolved stars to answer the elusive question on the origin of their magnetic field and determine the connection between the galactic magnetic field and that responsible for the formation of jets and potentially disks around young proto-stars. This fundamental new work, for which a dedicated research group is essential, will reveal the importance of magnetism during star formation as well as in driving and shaping the mass loss of evolved stars.","2000000","2014-05-01","2019-04-30"
"OXYFLUX","Oxygen flux measurements as a new tracer for the carbon and nitrogen cycles in terrestrialecosystems","Alexander Nils Knohl","GEORG-AUGUST-UNIVERSITAT GOTTINGENSTIFTUNG OFFENTLICHEN RECHTS","Atmospheric oxygen (O2) measurements have proven to be one of the most powerful tools to study the carbon cycle at global scale, quantifying the carbon dioxide (CO2) sink of terrestrial ecosystems and oceans. At ecosystem level, O2 is closely related to CO2 through photosynthesis and respiration, and is influenced by sources of nitrogen during plant uptake. O2 thus carries valuable information about ecosystem processes that cannot be learned from CO2 alone. However, the potential of O2 measurements at ecosystem level has not been exploited. The major hindrance has been the technical challenges faced to measure atmospheric O2 at ppm level against a background concentration of 21%. Motivated by the enormous insights gained from O2 measurements at global level, and with the assistance of proven experts in O2 measurement, OXYFLUX will provide pioneering breakthroughs in both measurement techniques and scientific
knowledge of terrestrial ecosystems. Specifically, OXYFLUX will perform the methodological, experimental and modelling work needed to develop O2 as a new tracer for carbon and nitrogen cycle processes at ecosystem level. We will establish the first research group worldwide to perform continuous O2 flux measurements at forest and agricultural field sites, using gas exchange chambers and micrometeorological approaches. These measurements will be utilised further in modelling
work where we will integrate O2 into two complementary terrestrial ecosystem models. This will provide the mechanistic understanding for a unique approach to (a) partition CO2 fluxes in e.g. forest ecosystems, (b) improve understanding of the carbon and nitrogen cycle in arable land, and (c) identify the sensitivity of O2 fluxes in terrestrial ecosystems to environmental change. OXYFLUX will firmly establish O2 as a new research tool that can be applied to promote further breakthroughs in a large range of scientific disciplines including environmental, forest and agricultural sciences.","1999502","2016-10-01","2021-09-30"
"P-MEM-NMR","Structure of paramagnetic integral membrane metalloproteins by MAS-NMR","Guido Pintacuda","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Integral membrane metalloproteins are involved in the transport and homeostasis of metal ions, as well as in key redox reactions that have a tremendous impact on many fields within life sciences, environment, energy, and industry. 
Most of our understanding of fine details of biochemical processes derives from atomic or molecular structures obtained by diffraction methods on single crystal samples. However, in the case of integral membrane systems, single crystals large enough for X-ray diffraction cannot be easily obtained, and the problem of structure elucidation is largely unsolved.
We have recently pioneered a breakthrough approach using Magic-Angle Spinning Nuclear Magnetic Resonance (MAS-NMR) for the atomic-level characterization of paramagnetic materials and complex biological macromolecules. The proposed project aims to leverage these new advances through a series of new concepts i) to improve the resolution and sensitivity of MAS-NMR from nuclei surrounding a paramagnetic metal ion, such as e.g. cobalt, nickel and iron, and ii) to extend its applicability to large integral membrane proteins in lipid membrane environments. With these methods, we will enable the determination of structure-activity relationships in integral membrane metalloenzymes and transporters, by combining the calculation of global structure and dynamics with measurement of the electronic features of metal ions. 
These goals require a leap forward with respect to today’s protocols, and we propose to achieve this through a combination of innovative NMR experiments and isotopic labeling, faster MAS rates and high magnetic fields. As outlined here, the approaches go well beyond the frontier of current research. The project will yield a broadly applicable method for the structural characterization of essential cellular processes and thereby will provide a powerful tool to solve challenges at the forefront of molecular and chemical sciences today.","2499375","2015-09-01","2020-08-31"
"PaDyFlow","Particle dynamics in the flow of complex suspensions","Anke Lindner","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Particle laden flows are ubiquitous in nature and industrial applications. Particle trajectories determine transport in porous media or biomedical conducts and effective suspension properties dictate flow behavior in food processing or biofluid flow. For a better control it is necessary to know how to predict these processes from the involved particle and flow properties.  However, current theory is not able to capture the complexity of the applications and experiments have been carried out on too diverse systems for a unifying picture to emerge. A systematic experimental approach is now needed to improve the present understanding. 
In this experimental project, we will use novel microfabrication and characterization methods to obtain a set of complex anisotropic microscopic particles (complemented by selected bioparticles) with tunable properties, covering size, shape, deformability and activity. The transport of these particles isolated or in small concentrations will be studied in chosen microfluidic model flows of simple fluids or polymer solutions. The many degrees of freedom of this problem will be addressed by systematically combining different relevant particle and flow properties. The macroscopic properties of dilute suspensions are particularly interesting from a fundamental point of view as they are a direct consequence of the individual particle flow interaction and will be measured using original microfluidic rheometers of outstanding resolution. 
This project will lead to a comprehensive understanding of fluid structure interactions at small Reynolds number. Our findings will constitute the basis for novel numerical approaches based on experimentally validated hypotheses.  Using our knowledge, local flow sensors, targeted delivery and novel microfluidic filtration or separation devices can be designed. Combining particles of chosen properties and selected suspending fluids allows the fabrication of suspensions with unprecedented tailored properties.","1971750","2016-09-01","2021-08-31"
"PAIDEIA","PlAsmon InduceD hot Electron extraction with doped semiconductors for Infrared solAr energy","Francesco SCOTOGNELLA","POLITECNICO DI MILANO","Earth is inhabited by an energy hungry human society. The Sun, with a global radiation at the ground level of more than 1 kW/m^2, is our largest source of energy. However, 45% of the total radiation is in the near infrared (NIR) and is not absorbed by most photovoltaic materials.
PAIDEIA focuses on two main advantages aiming to enhance the capacity of solar energy conversion: 
i) plasmon assisted hot carriers extraction from NIR plasmonic materials;
ii) linewidth narrowing in plasmonic nanoparticle films that enhances the lifetime of hot carriers and, thus, boosts the efficiency of light driven carrier extraction.
Instead of metals, which operate mostly in the visible region, we will make use of doped semiconductor nanocrystals (DSNCs) as hot electron extraction materials possessing a plasmonic response tunable in the range 800 nm – 4000 nm. Three different innovative architectures will be used for improved device performance: i) improved Schottky junctions (DSNC/wide band gap semiconductor nanocomposites); ii) ultrathin devices (DSNCs/2D quantum materials); iii) maximized interface DSNC/semiconductor bulk hetero-Schottky junctions.
By combining both concepts in advanced architectures we aim to produce a solar cell device that functions in the NIR with efficiencies of up to 10%. A tandem solar cell that combines the conventional power conversion efficiency, up to ~1100 nm, of a commercial Si solar cell (~20%) with the new PAIDEIA based device is expected to reach a total power conversion efficiency of 30% by extending the width of wavelengths that are converted to the full spectral range delivered by the Sun. PAIDEIA has a deeply fundamental character impacting several areas in the field of nanophysics, nanochemistry and materials processing and, at the same time, having a high impact on the study of solar energy conversion. Finally, PAIDEIA will provide answers to the fundamental questions regarding the physical behaviour of plasmonic/semiconductor interfaces.","1815445","2019-04-01","2024-03-31"
"PALEOGENIE","PAst Links in the Evolution of Ocean’s Global ENvIronment and Ecology","Andrew John Ridgwell","UNIVERSITY OF BRISTOL","""Species do not live in isolation, but adapt and ultimately, evolve, in relationship with other species as well as with their chemical and physical environment. In the marine environment, this interaction is intimately two-way – the surface biogeochemical environment modulates the makeup of the pelagic ecosystem, yet at the same time, the ecosystem assemblage, by setting the strength of the biological pump and ultimately, in regulating the carbon and nutrient inventory of the ocean and atmospheric pCO2, influences the surface geochemical environment. Feedbacks, both negative and positive, must therefore exist between plankton ecology and global biogeochemical cycles. This has implications for understanding the geological record and particularly the response and recovery of marine ecosystems following major environmental perturbation, but also complicates making projections of future ocean changes.
The proposed project – PALEOGENiE – will directly address these challenges via the development of a unique coupled model of past plankton ecology and global biogeochemical cycles. The geological record of planktic ecosystems – nannofossils – will be collated and analyzed across a spectrum of geological events for which evidence of major changes in climate and massive carbon release together with the response of planktic ecosystems are recorded: the Paleocene-Eocene Thermal Maximum, the end Cretaceous, and Ocean Anoxic Event 2. Both model and data will then be brought together in a unique attempt to better understanding the micropaleontological record of how sensitive marine ecosystems are to global change as well as how they recover. If successful, PALEOGENiE may help constrain the potential for adaptation as well as rates of evolutionary change, and ultimately could lead to meaningful insights and guidance for the next generation of Earth system models we need to better constrain the future response of marine ecosystems to continued fossil fuel combustion.""","1930472","2014-05-01","2019-04-30"
"PASIPHAE","Overcoming the Dominant Foreground of Inflationary B-modes: Tomography of Galactic Magnetic Dust via Measurements of Starlight Polarization","Konstantinos TASSIS","FOUNDATION FOR RESEARCH AND TECHNOLOGY HELLAS","An inflation-probing B-mode signal in the polarization of the cosmic microwave background (CMB) would be a discovery of utmost importance in physics. While such a signal is aggressively pursued by experiments around the world, recent Planck results have showed that this breakthrough is still out of reach, because of contamination from Galactic dust. To get to the primordial B-modes, we need to subtract polarized emission of magnetized interstellar dust with high accuracy.  A critical piece of this puzzle is the 3D structure of the magnetic field threading dust clouds, which cannot be accessed through microwave observations alone, since they record integrated emission along the line of sight. Instead, observations of a large number of stars at known distances in optical polarization, tracing the same CMB-obscuring dust, can map the magnetic field between them. The Gaia mission is measuring distances to a billion stars, providing an opportunity to produce, the first-ever tomographic map of the Galactic magnetic field, using optical polarization of starlight. Such a map would not only boost CMB polarization foreground removal, but it would also have a profound impact in a wide range of astrophysical research, including interstellar medium physics, high-energy astrophysics, and galactic evolution. Taking advantage of our privately-funded, novel-technology, high-accuracy WALOP optopolarimeters currently under construction, we propose an ambitious optopolarimetric program of unprecedented scale that can meet this challenge: a survey of both northern and southern Galactic polar regions targeted by CMB experiments, covering >10,000 square degrees, which will measure linear optical polarization at 0.2% accuracy of over 360 stars per square degree (over 3.5M stars, a 1000-fold increase over the state of the art), combining wide-field-optimized instruments and an extraordinary commitment of observing time by Skinakas Observatory and the South African Astronomical Observatory.","1887500","2018-06-01","2023-05-31"
"PASS","Program Analysis for Safe and Secure Software Evolution","Cristian CADAR","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","Constant evolution is an inherent property of modern software systems. Software evolves to implement new features, adapt to new hardware and platforms, fix bugs and security vulnerabilities, or improve non-functional properties such as performance and energy consumption.

While these changes have an overall positive impact, they are also responsible for a large number of critical bugs and security attacks. The reason is twofold: first, software changes are not vetted enough, due to the difficulty of reasoning about all possible new behaviours that they introduce. Second, even when critical errors in deployed changes are later discovered and fixed, users take a long time to update their software to the latest version, mostly because they are concerned about the potential negative impact of an update.

The PASS project aims to tackle both problems and help software evolve safely and securely. It takes a holistic approach to the challenges of safe and secure software evolution, by combining offline program analysis to verify or comprehensively test software changes, with runtime mechanisms for keeping the software updated and secure against potentially erroneous changes that make it into the deployed system.

This is an ambitious project, which requires fundamental advances at the intersection of program analysis, software engineering, and computer systems to develop practical cross-version specifications, scalable patch verification, in-production testing and analysis, and low-overhead reversible software updates.","1955129","2019-10-01","2024-09-30"
"PAW","Automated Program Analysis for Advanced Web Applications","Anders Møller","AARHUS UNIVERSITET","Web applications that execute in the user's web browser constitute a substantial part of modern software. JavaScript is the main programming language of the web, although alternatives are emerging, in particular, TypeScript and Dart. Despite the advances in design of languages and libraries, it is difficult to prevent errors when programming such web applications. Although the basic principles of software verification have been known for decades and researchers have developed an abundance of techniques for formal reasoning about programs, modern software has lots of errors, as everyday users can testify. 

The PAW project will create novel automated program analysis algorithms for preventing errors and improving performance of advanced web applications. The project hypothesis is that a scientific breakthrough is within reach, due to recent results in static and dynamic program analysis for JavaScript. The central idea is to combine static and dynamic analysis in new ways. In addition, the project will make program analysis algorithms and infrastructure available in a form that embraces reusability.","1977382","2015-08-01","2021-07-31"
"PCPHDX","Probabilistically Checkable Proofs, Agreement Tests,and High Dimensional Expanders","Irit DVEER DINUR","WEIZMANN INSTITUTE OF SCIENCE LTD","PCPs capture a striking local to global phenomenon in which a global object such as an NP witness can be checked using local constraints, and its correctness is guaranteed even if only a fraction of the constraints are satisfied. 

PCPs are tightly related to hardness of approximation. The relation is essentially due to the fact that exact optimization problems can be reduced to their approximation counterparts through this local to global connection.

We view this local to global connection is a type of high dimensional expansion, akin to relatively new notions of high dimensional expansion (such as coboundary and cosystolic expansion) that have been introduced in the literature recently. We propose to study PCPs and high dimensional expansion together. We describe a concrete notion of “agreement expansion” and propose a systematic study of this question. We show how progress on agreement expansion questions is directly related to some of the most important open questions in PCPs such as the unique games conjecture, and the problem of constructing linear size PCPs. 

We also propose to study the phenomenon of high dimensional expansion more broadly and to investigate its relation and applicability to questions in computational complexity that go beyond PCPs, in particular for hardness amplification and for derandomizing direct product constructions.","1512035","2018-02-01","2023-01-31"
"PEP2D","Printable Electronics on Paper through 2D materials based inks","Gianluca FIORI","UNIVERSITA DI PISA","The vision behind the PEP2D project is to pioneer the realization of fully printed electronic circuits on flexible substrates as paper, leveraging the exceptional electronic properties of inks based on novel two- dimensional materials (2DMs), and through the wide-spread and low-cost inkjet printing technology.
The development of fully printed electronic systems on flexible substrates as paper could have an unpreceded economical and societal impact on the European Union. Unleashing the potential of this technology could open new and wide applications, ranging from bio (e.g., smart patches for biometric readings), to food/medicine quality control (e.g, smart tags for checking the breaking of cold chain), or to anti-counterfeiting of valuable goods, just to cite few.
Actually, technology is endeavouring to implement the main building blocks for electronic applications in the fast-growing market of flexible electronics expected to expand to 42 B€ by 2021, but available materials are missing the long-term stability and reliability, and device performance can be further improved. From this perspective, it is compulsory to develop new materials, and device architectures able to allow the fully printing of a working electronic system. PEP2D aims at designing a library of inkjet-printed electronic devices (transistors, and all linear and nonlinear components) and circuits (digital logic, memory circuits, amplifiers, transmitters, receivers) enabled by 2DMs based inks, to be eventually obtained through the use of a single tool as the inkjet process, without the need of any additional fabrications steps (i.e., use of resists, etching etc.) and in air (not in glovebox).
Such a goal will be achieved by means of the synergic and complementary activities pursued within the project and based on advanced modelling and design of inkjet-printed devices and circuits, which will lead the activity on the realization and measurements of printed electronic systems.","1883868","2018-03-01","2023-02-28"
"PEPCo","Problems in Extremal and Probabilistic Combinatorics","Mathias DR. SCHACHT","UNIVERSITAET HAMBURG","Extremal and probabilistic combinatorics is a central and currently maybe the most active and fastest growing area in discrete mathematics. The field can be traced back to the work of Turán and it was established by Erdős through his fundamental contributions and his uncounted guiding questions. Since then it has grown into an important discipline with strong ties to other mathematical areas such as theoretical computer science, number theory, and ergodic theory.

The PI proposes a variety of extremal problems for hypergraphs and for sparse random and pseudorandom graphs. The work for hypergraphs is motivated by Turán’s problem, maybe the most prominent open problem in the area. After solving an analogous question for graphs, Turán asked to determine the maximum cardinality of a set E of three-element subsets of a given n-element set V such that for any 4 elements of V at least one triple is missing in E. This innocent looking problem seems to be out of reach by our current methods and despite a great deal of effort over the last 70 years, our knowledge is still very limited.

We suggest a variant of the problem by imposing additional restrictions on the distribution of the three-element subsets in E. These additional assumptions yield a finer control over the corresponding extremal problem. In fact, this leads to many interesting and hopefully more manageable subproblems, some of which were already considered by Erdős and Sós. We suggest a unifying framework for these problems and one of the main goals would be the development of new techniques for this type of problems. These additional assumptions on the hyperedge distribution are closely related to the theory of quasirandom discrete structures, which was pioneered by Szemerédi and became a central theme in the field. In fact, the hypergraph extension by Gowers and by Rödl et al. of the regularity lemma provide essential tools for this line of research.","1800000","2017-10-01","2022-09-30"
"PHOENEEX","Pyrolytic Hierarchical Organic Electrodes for sustaiNable Electrochemical Energy Systems","Stephan Sylvest Keller","DANMARKS TEKNISKE UNIVERSITET","The demand for compact energy systems for portable devices such as wearable sensors or mobile phones is increasing. Electrochemical systems are promising candidates for sustainable energy conversion and storage on miniaturised platforms. A recent approach to harvest green energy is biophotovoltaic systems (BPVs), where photosynthetic microorganisms are used to transform light into electrical energy. However, BPVs still provide a relatively low efficiency and are yet unable to deliver the high peak power required for sensor operation or wireless signal transmission in portable systems. In PHOENEEX, I will address these limitations by i) improving the efficiency of BPVs and ii) combining the BPVs with microsupercapacitors (µSCs) which can temporarily store the harvested electrical energy and provide a higher peak power output upon request. More specifically, I will develop highly optimised 3D carbon microelectrodes (3DCMEs) to enhance electron harvesting from cyanobacteria in BPVs and for increased energy density in µSCs. Finally, the improved BPVs and the optimised µSCs will be integrated on the BioCapacitor Microchip - a compact sustainable energy platform for portable systems. 

The fabrication of 3DCMEs with highly tailored material properties, large surface area and hierarchical architecture is achieved by pyrolysis of polymer templates in an inert atmosphere. The fundamental hypothesis of PHOENEEX is that the combination of novel precursor materials, new methods for 3D polymer microfabrication and optimised pyrolysis processes will allow for fabrication of 3DCMEs with highly tailored material properties, large surface area and hierarchical architecture impossible to obtain with any other method.","2745500","2018-05-01","2023-04-30"
"PHOENiCS","Photon-Spin Entanglement in Hybrid Cluster State Architectures","Mete Atature","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","The last decade has witnessed quantum mechanics and information science merge for the debut of experimental quantum information processing. Despite the number of promising physical systems as candidates for quantum bits, scalability via a brute force approach faces serious technical obstacles. Developing distributed quantum networks is possibly the answer to the stringent demand of controllable interaction between high quality qubits. In these systems, the requirements are on the stationary qubits – they need to be both isolated and accessible. The requirements on the flying qubits are that they need to be of reproducibly high quality, identical, and also they need to be able to interface well with the stationary qubits. We propose to realize an operational distributed solid-state quantum network relying on confined spins in quantum dots as qubits connected via a shared optical interconnection net used via single photons as flying qubits. Key milestones include high fidelity distant spin entanglement generation, implementation of spin entanglement purification, and formation of spin-photon hybrid cluster states in order to perform  one-way quantum computation protocols with incorporated memory. Significant efforts will be devoted in tandem for the grand challenge of efficient in/out coupling of light in these systems with initial investigations suggest efficiencies approaching unity can be achieved within the proposed timeline.","1739499","2014-05-01","2019-04-30"
"Phonton","Phon(t)on-induced phase transitions","Corinna Susan Kollath","RHEINISCHE FRIEDRICH-WILHELMS-UNIVERSITAT BONN","One of our dreams for the future is to control and manipulate complex materials and devices at will. This progress would revolutionize technology and influence many aspects of our everyday life.  A promising direction is the control of material properties by electromagnetic radiation leading to photo-induced phase transitions. An example of such a transition is the reported dynamically induced  superconductivity via a laser pulse.  Whereas the theoretical description of the coupling of fermions to bosonic modes in equilibrium has seen enormous progress and explains highly non-trivial phenomena as the phonon-induced superconductivity, driven systems pose many puzzles. In addition to the inherent time-dependence of the external driving field, a multitude of possible excitation and relaxation mechanisms challenge the theoretical understanding. Recently in the field of quantum optics, a much cleaner realization of a photo-induced phase transition, the Dicke transition, has been observed for bosonic quantum gases loaded in an optical cavity. Above a critical pump strength of an external laser field, the ensemble undergoes a transition to an ordered phase. 
We aim to advance the general theoretical understanding of photo-induced phase transitions both in the field of solid state physics and quantum optics. In particular, we will focus on the design and investigation of photo-induced transitions to unconventional superconductivity and non-trivial topological phases. Our insights will be applied to fermonic quantum gases in optical cavities and solid state materials.  In order to treat these systems efficiently, we will develop new variants of the numerical density matrix renormalization group (or also called matrix product state) methods and combine these with analytical approaches.","1486973","2015-09-01","2020-08-31"
"PHOROSOL","Integrating photochemistry in nanoconfined carbon-based porous materials in technological processes","Maria Concepcion Ovin Ania","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The aim of this proposal is to exploit the potentialities of confined pore spaces in technological processes related to applied photochemistry for gas sensing, energy conversion and environmental protection. I will focus on new light responsive nanoporous carbons which characteristics can be tailored at two levels (pore void at the nanometric scale and surface functionalization) during the synthesis to modulate their selectivity towards a given molecule (i.e. gas sensing) or efficiency in a given reaction (i.e. energy conversion, environmental protection).
The dual nature of the nanoporous carbons with ad-hoc designed pore architectures acting as nanoreactors (confinement) and photoactivity defined by composition (chromophoric groups) offers new perspectives in the fields of light harvesting of applied photochemistry, and shows multitude of fundamental questions that are worth investigating to exploit this concept. Understanding of the confinement effects and the light/solid/molecule interactions is the key for integrating carbon nanostructures in a whole new array of applications. An example would be the design of multifunctional spatially organized photoactive carbons with high electron mobility, multimodal pore systems and chromophoric groups. These systems are expected to show  enhanced diffusion and mass transport, with great potential in gas sensing applications where a fast, sensitivity and selective response is needed. 
I plan to work with functionalized light-responsive polymeric nanoporous carbons (mainly gels, graphene-oxide frameworks). A smart design of hybrid nanostructures introducing other confined photoactive elements will also be studied. The outcome of the proposal is to understand the fundamentals of photochemistry of carbon nanostructures for the implementation of best performing materials in different technological processes related to photochemical energy conversion for H2 and O2 generation, gas sensing and environmental protection.","1994180","2016-03-01","2021-02-28"
"PHOTOMASS","Imaging Biomolecular Self-Assembly with a Molecular Photonic Scale","Philipp KUKURA","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","We propose to transform our understanding of biomolecular interactions and self-assembly by directly visualising the associated molecular mechanisms. To achieve this, we will capitalise on our recent development of interferometric scattering mass spectrometry (iSCAMS), which enables not only the detection and imaging of single biomolecules in solution, but also the accurate determination of their molecular mass at the single molecule level. These studies, and the development of the associated technology, will bridge the gap between high-resolution structural and low-resolution solution-based methods for studies of biomolecular interactions and assembly. We will achieve these ambitious goals by pursuing five interconnected objectives chosen according to their potential to maximise scientific and societal impact by addressing fundamental questions related to biological function and health: (1) Determine the physicochemical origins of mono- and polydispersity; (2) Visualise the mechanism of viral capsid assembly; (3) Reveal the molecular basis of cytoskeletal dynamics; (4) Capture the aggregation and inhibition of amyloid aggregation. These four system-oriented objectives will be accompanied by a technological objective, (5) aimed at implementing improvements in terms of dynamic range and resolution of iSCAMS required for studying self-assembly. As a consequence of the universal applicability of our approach for characterising molecular interactions, oligomeric distributions and dynamics in a facile fashion in solution, this ambitious project opens up a broad range of exciting applications beyond molecular biophysics in fields as drug-discovery, bioanalytical and biomedical science.","1999574","2019-06-01","2024-05-31"
"PhotoMedMet","Towards Novel Inert (Photo-)toxic Ru(II) Polypyridyl Complexes","Gilles Albert Gasser","ECOLE NATIONALE SUPERIEURE DE CHIMIE DE PARIS","In this grant application, I propose to investigate in-depth the potential of novel inert Ru(II) polypyridyl complexes as novel anticancer drug candidates. Such compounds were investigated by Dwyer and Shulman in 1950s and 1960s both in vitro and in vivo with relatively promising results. This impressive seminal work was unfortunately not followed-up. This lack of additional studies was recently attributed, at least in part, to the observed neurotoxicity of the complexes. Nonetheless, over the last years, there has been a revival of important in vitro studies of such inert Ru(II) polypyridyl complexes for anticancer purposes. However, without further in vivo studies, it is reasonable to think that similar neurotoxicity to that observed by Dwyer and Shulman could be encountered. In order to tackle these (potential) drawbacks, I propose to use a prodrug approach.
Furthermore, I also intend to investigate the potential of inert Ru(II) polypyridyl complexes as photosensitizers (PSs) in photodynamic therapy (PDT). In the search for an alternative approach to chemotherapy, PDT has proven to be a promising, effective and non-invasive treatment modality. Importantly, in order to increase even further the potential of the PSs presented in this project, I propose to also excite them via simultaneous two-photon absorption (TPA) in the so-called two-photon excitation PDT (2 PE-PDT). Importantly, the newly Ru(II)-based PSs will be coupled to cancer cell-specific peptides or antibodies. This double selectivity (targeting vector and photo-activation) should limit the frequently encountered side-effects of (metal-based) anticancer drugs. Another important aim of this second part of this project will be the use of the Ru(II)-based PSs to kill bacteria. Interestingly, PDT has been recently shown to be an interesting alternative to fight bacteria. I therefore intend to couple Ru(II)-based (2PE )PSs to bacteria-specific peptides to bring bacteria specificity.","662015","2016-10-01","2021-09-30"
"PhotonICSWARM","Photonic Integrated Circuits using Scattered Waveguide elements in an Adaptive, Reconfigurable Mesh.","Wim BOGAERTS","UNIVERSITEIT GENT","In PhotonICSWARM, I will use silicon photonics technology to build general-purpose, programmable optical chips that rely on topologies of distributed waveguide circuits governed by distributed control algorithms.

In silicon photonics, optical signals are transported along waveguides on photonic integrated circuits and processed by elements that filter specific wavelengths or modulate signals. Silicon photonics is the choice technology for high-speed communication links, but also for different types of sensors. However, photonic circuits are still very simple compared to today's electronics, because they use connectivity topologies where light follows a single path. 

The optical chip concepts I propose in PhotonICSWARM start from radically different topologies, which will allow 1-2 orders of magnitude scaling in complexity. They are based on tightly interconnected, distributed optical signal paths. This high connectivity will enable much more complex optical functions, and to realise these I will apply adaptive, distributed control algorithms. I will explore different optical waveguide concepts: waveguide meshes, phased arrays, lattices of resonators, lateral leakage and 2-D holographic gratings. These will be fabricated on existing state-of-the-art technology platforms, so PhotonICSWARM will rather revolve around the theory, simulation, design and characterisation methodologies.

With these distributed photonic circuits I will create programmable photonics that can be applied for many applications, as the optical equivalent of electronic field-programmable gate arrays (FPGA). They can enable on-chip parallel optical signal processing for pattern recognition or real-time encryption of high-bitrate optical data streams. Programmable circuits can speed up the research cycle, taking much less time to test new photonic chip concepts, and over time make integrated photonics accessible to the 'Maker community'.","1990000","2017-04-01","2022-03-31"
"PhyMeBa","The Physical  Mechanics of Swimming Bacteria","Eric Jean-Marie Lauga","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Bacteria play a critical role in the life of higher organisms. Their behavior is constrained by the physical properties of their habitat: first and foremost, the presence of a surrounding fluid. Most bacteria are motile, and most motile bacteria swim in fluids using slender helical appendages called flagella rotated by specialized motors. While many bacteria have only one flagellum, most well-studied pathogenic bacteria possess multiple flagella. Why have some bacteria evolved to use many flagella when others survive with one? In order to answer this question, one needs to understand quantitatively how multiple flagella provide a fitness advantage to a cell exploring its environment. The principal difficulty in deriving rigorous models for swimming bacteria lies in the {nonlinear} nature of the underlying external physics, which involves nonlocal hydrodynamic interactions between flagella, short-range steric and electrostatic interactions, and elastic deformations of the flagella, which not only bend and twist but also undergo conformational changes. In this project, we will develop novel experimentally-testable theoretical modeling of the configurations and regimes relevant to swimming bacteria with multiple flagella with a focus on the mechanical forces at play. As a fundamental departure with past work, we will seek to exploit the slenderness and relative proximity of the flagella to incorporate all nonlocal hydrodynamic interactions between flagella analytically and to simplify the determination of elastic stresses. This will allow us, in turn, to determine precisely the distribution of flagellar forces and derive a predictive framework for the stochastic behavior of swimming cells. The project will provide first-principle understanding of the external forces at play in one of the most important processes in biology and will help answer a number of outstanding physical questions on the behavior of swimming bacteria and the interactions with their environment.","1999229","2016-09-01","2021-08-31"
"PI2FA","Partial Ionisation: Two-Fluid Approach","Olena KHOMENKO","INSTITUTO DE ASTROFISICA DE CANARIAS","PI2FA proposal’s overarching aim is to make a major breakthrough in our understanding of the magnetised solar chromosphere under a novel frame of a multi-fluid plasma theory. Future large-aperture solar telescopes, EST and DKIST, will have among their primary focus observations of chromospheric magnetic fields. The correct interpretation of solar data requires sophisticated theories. The solar atmosphere is made of strongly stratified, weakly ionised and not completely collisionally coupled plasma. In the previous PI’s ERC SPIA project we opened a new research line and performed systematic investigations of non-ideal effects due to neutrals in the solar plasma. To build the complexity step by step, we advanced a single-fluid formalism, best valid for a strongly collisionally coupled case. Nevertheless, a multi-fluid treatment is essential for the weakly coupled chromosphere because the processes of the energy transport and conversion happen at nearly collisional scales. Now it is the right moment to take advantage and consolidate the experience gained in the SPIA project and to bring our research to a new level of challenge. The ambition of the PI2FA proposal is to create and apply tools for multi-dimensional modelling of the solar chromosphere under a precise two-fluid multi-species approach. In the recent few years it has been repeatedly demonstrated that processes related to non-ideal plasma behaviour due to neutrals may be the key to solve the problem of chromospheric heating and dynamics. PI2FA project will make progress in the following questions: determination of chromospheric heating mechanisms; understanding destabilization mechanisms of prominences related to neutrals, and creation of multi-dimensional two-fluid models of the solar chromosphere. These models will include altogether complex interactions down to smallest scales and allow direct comparison to observations, as a way to prepare our community for the coming large-aperture telescopes.","1968750","2018-09-01","2023-08-31"
"PICKLE","Planetary Interiors Constrained by Key Laboratory Experiments","Daniele ANTONANGELI","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The knowledge of interiors of rocky planets of our solar system (Mercury, Venus, Earth and Mars) is important for understanding their formation, present state, and evolution. The comprehension of differences and similarities in the internal constitution and processes will shed a new light on the origin and evolution of the solar system.
Space missions are invaluable to this planetary quest. Yet, only geodesy data so far provided constraints on planetary deep interiors. Seismic observations on planetary bodies other than Earth are limited to the Apollo records for the Moon. The main objective of the forthcoming InSight mission is to place a seismometer on Mars to study its interior. However, the interpretation and full exploitation of geodesy and seismic data to produce accurate models of planetary structure and dynamics (internal convection and magnetic field generation) is critically hampered by the dearth of knowledge of key physical parameters of pertinent materials at relevant pressures (P) and temperatures (T). 
Thus this proposal aims at developing techniques and methodologies, combining innovative laboratory and synchrotron measurements, to acquire such physical properties at high pressure and temperature. I propose to measure sound velocities and acoustic attenuation of minerals and aggregates forming the mantle of telluric planets, as well as the phase diagram and melting curves of iron alloys forming their core. I will implement novel approaches to provide unprecedented determination of thermo-elastic properties of liquid iron alloys at P-T conditions directly relevant to the core of Mercury and Mars. Such information will be integrated together with geophysical data to infer new planetary models.
This interdisciplinary project will contribute to understand the processes that shaped the rocky planets of the inner solar system, addressing fundamental questions related to their past and present dynamics.","1596500","2017-10-01","2022-09-30"
"PICOMETRICS","Picometer metrology for light-element nanostructures: making every electron count","Sandra VAN AERT","UNIVERSITEIT ANTWERPEN","Understanding nanostructures down to the atomic level is the key to optimise the design of advanced materials with revolutionary novel properties. This requires characterisation methods enabling one to quantify atomic structures with high precision.

The strong interaction of accelerated electrons with matter makes that transmission electron microscopy is one of the most powerful techniques for this purpose. However, beam damage, induced by the high energy electrons, strongly hampers a detailed interpretation. To overcome this problem, I will usher electron microscopy in a new era of non-destructive picometer metrology. This is an extremely challenging goal in modern technology because of the increasing complexity of nanostructures and the role of light elements such as lithium or hydrogen. Non-destructive picometer metrology will allow us to answer the question: what is the position, composition and bonding of every single atom in a nanomaterial even for light elements?

There has been significant progress with electron microscopy to study beam-hard materials. Yet, major problems exist for radiation-sensitive nanostructures because of the lack of physics-based models, detailed statistical analyses, and optimal design of experiments in a self-consistent computational framework. In this project, novel data-driven methods will be combined with the latest experimental capabilities to locate and identify atoms, to detect light elements, to determine the three-dimensional ordering, and to measure the oxidation state from single low-dose recordings. The required electron dose is envisaged to be four orders of magnitude lower than what is nowadays used. In this manner, beam damage will be drastically reduced or even be ruled out completely.

The results of my programme will enable precise characterisation of nanostructures in their native state; a prerequisite for understanding their properties. Clearly this is important for the design of a broad range of nanomaterials.","1998750","2018-05-01","2023-04-30"
"Piko","Revealing the adaptive internal organization and dynamics of bacteria and mitochondria","Suliana MANLEY","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Bacteria cells appear to be less complex than our own cells -- yet they are better able to survive harsh conditions. Typically ~1 micron in size, they lack motor proteins; thus, they rely on fluctuations for intracellular transport. Bacteria in the environment often face starvation and exist in a non-proliferating quiescent state, which promotes antibiotic resistance and virulence. Entering quiescence, the bacterial cytoplasm displays signatures of the colloidal glass transition, with increasingly slow and heterogeneous diffusion. Also important for fitness during starvation is the formation of storage granules up to hundreds of nanometers in size. The complex state behavior of the bacterial cytoplasm is therefore important for their survival, but the physical nature of each of these processes is poorly understood. Our own cells are typically tens of microns in size and contain organelles including mitochondria, which originated from ancient bacterial endosymbionts. But little is known about the transport properties of the mitochondrial matrix, or how it responds to changes in mitochondrial membrane potential or energy production.
 The goal of this project is to elucidate the organization and dynamics of the bacterial cytoplasm and the mitochondrial matrix. A major obstacle to studying the interior of bacteria and mitochondria is the relevant length scales, which lie below the diffraction limit. Furthermore, to observe and quantify their adaptive response, many cells must be measured. Our strategy to overcome both of these technical challenges is to use high-throughput super-resolution fluorescence microscopy. We have developed new microscopes, capable of capturing thousands of super-resolved cells in each experiment. We propose to translate these developments to dynamic structured illumination and long-term molecular tracking. Broadly applicable, this will also enable the quantitative study of the subcellular properties of single bacteria cells or mitochondria.","2366835","2019-10-01","2024-09-30"
"PINQS","Photonic integrated quantum transceivers","Wolfram PERNICE","WESTFAELISCHE WILHELMS-UNIVERSITAET MUENSTER","Quantum processors are envisioned to conquer ultimate challenges in information processing and to enable simulations of complex physical processes that are intractable with classical computers. Among the various experimental approaches to implement such devices, scalable technologies are particularly promising because they allow for the realization of large numbers of quantum components in circuit form. For upscaling towards functional applications distributed systems will be needed to overcome stringent limitations in quantum control, provided that high-bandwidth quantum links can be established between the individual nodes. For this purpose the use of single photons is especially attractive due to compatibility with existing fibre-optical infrastructure. However, their use in replicable, integrated optical circuits remains largely unexplored for non-classical applications.
In this project nanophotonic circuits, heterogeneously integrated with superconducting nanostructures and carbon nanotubes, will be used to realize scalable quantum photonic chips that overcome major barriers in linear quantum optics and quantum communication. By relying on electro-optomechanical and electro-optical interactions, reconfigurable single photon transceivers will be devised that can act as broadband and high bandwidth nodes in future quantum optical networks. A hybrid integration approach will allow for the realization of fully functional quantum photonic modules which are interconnected with optical fiber links. By implementing quantum wavelength division multiplexing, the communication rates between individual transceiver nodes will be boosted by orders of magnitude, thus allowing for high-speed and remote quantum information processing and quantum simulation. Further exploiting recent advances in three-dimensional distributed nanophotonics will lead to a paradigm shift in nanoscale quantum optics, providing a key step towards optical quantum computing and the quantum internet.","1989813","2017-05-01","2022-04-30"
"PISSARRO","Photonic integrated devices for second order nonlinear optical processes","Camille Sophie BRES ep. TREMBLAY","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Second order nonlinear processes, such as second-harmonic or difference-frequency generation, are key for frequency metrology and quantum optics applications. The successful integration of such functionalities, consequential of material 2nd order nonlinear susceptibility χ(2),  is essential to obtain compact and low power devices. Unfortunately embedding 2nd order nonlinear effects on chip poses a fundamental challenge captured by the following dogma: materials with the best photonic integration capabilities exhibit negligible χ(2). Recent research by the PI proves this dogma flawed and shows that 2nd order nonlinearities can be unlocked in silicon nitride (SiN) waveguides by all-optical means, a result that is a significant departure from other existing approaches. 

PISSARRO will develop waveguides for χ(2) based effects and confront the limitations imposed by fabrication, resonant structures, or phase-matching constraints, thus seeking optimal trade-offs. By leveraging the linear properties and fabrication flexibility of SiN waveguides, the synergy between optically induced electric field from multi-photon absorption, large material 3rd order nonlinearity  and waveguide engineering will be exploited, to overcome the initial low efficiency. The objectives are far beyond the state-of-the-art by providing all-optical control, flexibility and extended operation bandwidth. 

The project will build on the in-depth optical characterization of the microscopic nature of optically-induced 2nd order nonlinearity in SiN to take integrated 2nd order nonlinear devices to new frontiers. PISSARRO promises substantial impact in the domains of communication, metrology and quantum optics by providing novel CMOS-compatible photonic devices. Designed waveguides will not only lead to the integration of stabilized octave spanning combs for precise frequency references, but also introduce a path towards dynamic on-chip quantum state generation and unconstrained frequency conversion.","1999400","2018-07-01","2023-06-30"
"PLANETESYS","The next-generation planet formation model","Anders JOHANSEN","LUNDS UNIVERSITET","The goal of this ERC Consolidator Grant proposal is to make significant contributions to our understanding of the formation of planetary systems and the chemical composition of planets. I will achieve this by developing a planet formation model that integrates the most relevant physical processes and combines the newly discovered pebble accretion mechanism with gravitational interaction between a high number of growing embryos. Exploiting the results of the computer simulations will allow me to address three major, outstanding research questions in the study of planets and their formation:

* What are the dominant physical processes that shape planetary systems?

* How are solids flash-heated in protoplanetary discs?

* What are the conditions for forming habitable planets?

I will follow the chemical composition of solid bodies in a protoplanetary disc as they grow from dust grains to fully fledged planets. This will shed light on the formation pathways of all major planetary classes – from terrestrial planets, over super-Earths to ice giants and gas giants – in orbital configurations acquired under the combined effects of planetary growth, migration and gravitational interaction between the developing planets. I will examine the role of the CO iceline as a nursery for planetary embryos that grow and migrate to form cold gas giants akin to Jupiter and Saturn in our Solar System. I will also explore the formation of the mysterious chondrules – widespread in primitive meteorites – by lightning discharge during planetesimal formation and address the role of chondrules for planet formation. Finally, I will simulate the delivery of life-essential volatiles to terrestrial planets and super-Earths in the habitable zone, considering the simultaneous growth of rocky and icy planetary embryos and gravitational stirring by migrating giant planets, for a wide range of planetary system architectures.","1985818","2017-07-01","2022-06-30"
"PLANTMOVE","Plant movements and mechano-perception: from biophysics to biomimetics","Yoel Stephane Forterre","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","How to transport fluids, move solids or perceive mechanical signals without the equivalent of pumps, muscles or nerves? This ongoing challenge, which is relevant from microfluidics to robotics, has long been solved by plants. In this project, I wish to gather my cross-disciplinary background in plant mechanics, soft matter physics and granular materials to address some of the fundamental mechanisms used by plants to perceive mechanical stimuli and generate motion. The project focuses on three major issues in plant biophysics, which all involve the coupling between a fluid (water in the vascular network or in the plant cell, cellular cytoplasm) and a solid (plant cell wall, starch grains in gravity-sensing cells): 
(i) How mechanical signals are perceived and transported within the plant and what is the role of the water pressure in this long-distance signalling. 
(ii) How plants sense and respond to gravity and how this response is related to the granular nature of the sensor at the cellular level. 
(iii) How plants perform rapid motion and what is the role of osmotic motors and cell wall actuation in this process, using the carnivorous plant Venus flytrap as a paradigm for study.  
The global approach will combine experiments on physical systems mimicking the key features of plant tissue and in situ experiments on plants, in strong collaboration with plant physiologists and agronomists. Experiments will be performed both at the organ level (growth kinematics, response to strain and force stimuli) and at the tissue and cellular level (cell imaging, micro-indentation, cell pressure probe). This multi-disciplinary and multi-scale approach should help to fill the gap in our understanding of basic plant functions and offers new strategies to design smart soft materials and fluids inspired by plant sensors and motility mechanism.","1933996","2015-07-01","2020-06-30"
"PLASMA","Running away and radiating","Tünde-Maria Fülöp","CHALMERS TEKNISKA HOEGSKOLA AB","Particle acceleration and radiation in plasmas has a wide variety of applications, ranging from cancer therapy and lightning initiation, to the improved design of fusion devices for large scale energy production. The goal of this project is to build a flexible ensemble of theoretical and numerical models that describes the acceleration processes and the resulting fast particle dynamics in two focus areas: magnetic fusion plasmas and laser-produced plasmas. This interdisciplinary approach is a new way of studying charged particle acceleration. It will lead to a deeper understanding of the complex interactions that characterise fast particle behaviour in plasmas. Plasmas are complex systems, with many kinds of interacting electromagnetic (EM) waves and charged particles. For such a system it is infeasible to build one model which captures both the small scale physics and the large scale phenomena. Therefore we aim to develop several complementary models, in one common framework, and make sure they agree in overlapping regions. The common framework will be built layer-by-layer, using models derived from first principles in a systematic way, with theory closely linked to numerics and validated by experimental observations. The key object of study is the evolution of the velocity-space particle distribution in time and space. The main challenge is the strong coupling between the distribution and the EM-field, which requires models with self-consistent coupling of Maxwell’s equations and kinetic equations. For the latter we will use Vlasov-Fokker-Planck solvers extended with advanced collision operators. Interesting aspects include non-Maxwellian distributions, instabilities, shock-wave formation and avalanches. The resulting theoretical framework and the corresponding code-suite will be a novel instrument for advanced studies of charged particle acceleration. Due to the generality of our approach, the applicability will reach far beyond the two focus areas.","1948750","2015-10-01","2020-09-30"
"PolSymAGA","Polarity and Central-Symmetry in Asymptotic Geometric Analysis","Shiri ARTSTEIN","TEL AVIV UNIVERSITY","Asymptotic Geometric Analysis is a relatively new field, the young finite dimensional cousin of Banach Space theory, functional analysis and classical convexity. It concerns the {\em geometric} study of high, but finite, dimensional objects, where the disorder of many parameters and many dimensions is ""regularized"" by convexity assumptions.   

The proposed research is composed of several connected innovative studies in the frontier of Asymptotic Geometric Analysis, pertaining to the deeper understanding of two fundamental notions: Polarity  and Central-Symmetry. 
While the main drive  comes from Asymptotic Convex Geometry, the applications extend throughout many mathematical fields from analysis, probability and symplectic geometry to combinatorics and computer science. The project will concern: The polarity map for functions, functional covering numbers, measures of Symmetry, Godbersen's conjecture, Mahler's conjecture, Minkowski billiard dynamics and caustics.
 
My research objectives are twofold. First, to progress towards a solution of the open research questions described in the proposal, which I consider to be pivotal in the field, including Mahler's conjecture, Viterbo's conjecture and Godberesen's conjecture. Some of these questions have already been studied intensively, and the solution is yet to found; progress toward solving them would be of high significance. Secondly, as the studies in this proposal lie at the meeting point of several mathematical fields, and use Asymptotic Geometric Analysis in order to address major  questions in other fields, such as Symplectic Geometry and Optimal transport theory, my second goal is to deepen these connections, creating a powerful framework that will lead to a deeper understanding, and the formulation, and resolution, of interesting questions currently unattainable.","1514125","2018-09-01","2023-08-31"
"POPCRYSTAL","Precisely Oriented Porous Crystalline Films and Patterns","Paolo FALCARO","TECHNISCHE UNIVERSITAET GRAZ","Metal-Organic Frameworks (MOFs) are nanoporous crystalline solids with narrow pore distributions and high accessible surface areas. MOFs are typically prepared in a polycrystalline form via the self-assembly of inorganic (nodes) and organic (links) building units. This bottom-up approach allows for properties such as, pore size, topology and chemical functionality to be precisely tailored. Such synthetic control has identified MOFs as promising platform material for device fabrication in the areas of microelectronics, photonics, sensing. However, current methods for fabricating MOF films and patterns cannot generate precisely oriented crystals on commercially relevant scales (i.e. cm). Thus, limiting access to applications that require anisotropic functional properties (e.g. optics, electronics, separation).

POPCRYSTAL will enable the fabrication of films and patterns composed of precisely oriented MOF crystals by exploiting crystalline ceramics to guide the aligned growth of MOF crystals.  Remarkably, the scale of these heteroepitaxially grown MOFs is solely determined by the ceramic precursor which can be easily synthesized on areas covering mm2 to cm2. 
POPCRYSTAL will advance a proof of concept study by addressing the following important research aims: the basic understanding of the formation mechanism and rules governing the heteroepitaxial relationship (WP1), the extension to different ceramic-MOF systems (WP2), the control over crystalline porous film and pattern features (WP3) and the fabrication of a proof-of-concept that will highlight the importance of aligned pores for separation (WP4).

In summary, by exploiting the heteroepitaxial growth mechanism between ceramics and MOFs  POPOCRYSTAL will fabricate unprecedented crystalline MOF films and patterns with precisely oriented nanopores and nanochannels. Thus POPCRYSTAL intercrosses and connects nanoscale chemistry, controlled self-assembly on a macroscale and nanoporous-based device fabrication.","1996315","2018-05-01","2023-04-30"
"POPSTAR","Low power consumption silicon optoelectronics based on strain and refractive index engineering","Laurent Jacques Daniel Vivien","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The POPSTAR project aims at building a new class of silicon optoelectronic devices based on nonlinear optical effects for the development of high speed multiple wavelength photonic circuits in the near-IR wavelength range for data communication applications including optical interconnects and high performance computing systems. Three major cornerstones will be developed: (i) a 40Gbit/s optical modulators based on Pockels effect with energy consumption and swing voltage lower than 1fJ/bit and 1V, respectively, (ii) a high responsivity, low dark-current, low bias voltage and high bandwidth (40Gbit/s) Si photodetector based on two-photon-absorption and (iii) a low threshold (<10dBm) tunable optical parametric oscillator source based on frequency comb generation. 
The ground-breaking concept of the project is to generate 3D strains in sub-wavelength silicon photonic nano-structures leading to significant breakthroughs in second-order nonlinearities efficiency (Pockels effect) and in the band-gap energy changes in order to increase or decrease two photon absorption process in silicon. The new approach developed here is to combine (i) strain engineering generated by functional oxide materials including YSZ, SrTiO3, SrHfO3 which exhibit more appropriate strain-induced characteristics in silicon than the use of silicon nitride and (ii) refractive index engineering using sub-wavelength silicon nanostructures. Generation of tunable strains in silicon with an active control using piezoelectric materials including PZT will be also develop to control the light dispersion.
Each of the three optoelectronic silicon building blocks would be world’s first demonstration according to the target performances and the used effects. Indeed, the performance targets cannot be achieved with the current state of scientific and technological backgrounds.
Finally, the project will open new horizons in the field of strained sub-wavelength silicon photonics in the near-IR wavelength range.","1999300","2015-10-01","2020-09-30"
"POTENT","Engineering Discoidal Polymeric Nanoconstructs for the Multi-Physics Treatment of Brain Tumors","Paolo Decuzzi","FONDAZIONE ISTITUTO ITALIANO DI TECNOLOGIA","Despite significant advances in chemotherapy, the effective treatment of malignant masses via systemically injectable agents are still limited by insufficient accumulation at the biological target (<< 10% injected dose per gram tumor) and non-specific sequestration by the reticulo-endothelial system (tumor/liver < 0.1).

The goal of this proposal is to engineer Discoidal Polymeric Nanoconstructs (DPNs) to preferentially target the malignant neovasculature for the delivery of imaging agents, controlled release of therapeutic molecules and thermal energy. The central hypothesis is that the size, shape, surface properties and stiffness (4S parameters) of the DPNs can be controlled during synthesis, and that therapeutic molecules (Temozolomide), Gd(DOTA) complexes and ultra-small Super-Paramagnetic Iron Oxide nanoparticles (USPIOs) can be efficiently incorporated within the DPN polymeric matrix.

This will be achieved by pursuing 3 specific aims: i) synthesis and physico-chemical characterization of poly(lactic-co-glycolic acid)/poly(ethylene glycol) DPNs with multiple 4S combinations; ii) in-silico and in vitro rational selection of DPN configurations with preferential tumor deposition, low macrophage uptake and high loading; and iii) in-vivo testing of the DPN imaging and therapeutic performance in mice bearing Glioblastoma Multiforme (GBM).

The innovation stays in i) using synergistically three different targeting strategies (rational selection of the 4S parameters; magnetic guidance via external magnets acting on the USPIOs; specific ligand-receptor recognition of the tumor neovasculature); ii) combining therapeutic and imaging molecules within the same nanoconstruct; and iii) employing synergistically different therapeutic approaches (molecular and thermal ablation therapies). This would allow us to support minimally invasive screening via clinical imaging and enhance therapeutic efficacy in GBM patients.","2390000","2014-07-01","2019-06-30"
"PQC","Photonic Quantum Computing","Jeremy LLoyd O'Brien","UNIVERSITY OF BRISTOL","This CoG will simultaneously address the outstanding research challenges to establishing the feasibility of large-scale photonic quantum computing by:

1.    Designing, fabricating and optimising the required hardware (WP1) components—inc. waveguides, couplers, phase shifters, delays, interconnects, spectral filters, photon sources and detectors, and control electronics.

2.    Establishing paths to the integration (WP2) of these components into complete systems.

3.    Developing accurate, exhaustive and verified model of errors (WP3) in photonic quantum systems for optimised fault tolerance strategies, and efficient large-scale architectures (WP4).

4.    Exploring and developing approaches to optimising this architecture both generally, and for specific applications (WP5).

Addressing these challenges in parallel will be essential to realising the vision because interim outputs are required to address each challenge, and an iterative approach with the flexibility to redistribute resources and effort is necessary to reach an optimal solution in minimal time.","2009429","2015-06-01","2020-05-31"
"PREP-CRYPTO","Preparing Cryptography for Modern Applications","Dennis Oliver HOFHEINZ","KARLSRUHER INSTITUT FUER TECHNOLOGIE","""Cryptography currently faces fundamentally new challenges. Modern applications like Big Data or Cloud Computing require cryptographic methods that go far beyond secure communication. Such cryptographic methods have only been invented in recent years: namely, since 2009, several unexpected and game-changing *new cryptographic building blocks* have been introduced. Most prominently, constructions of fully homomorphic encryption, code obfuscation, and multilinear maps have been proposed. These constructions have opened the door to applications that were previously believed unattainable, such as the secure outsourcing of computations.

However, the concrete schemes proposed are currently scrutinized for cryptanalytic attacks, and it appears that many of them are *considerably less secure* than initially hoped for. Moreover, most constructions of new cryptographic building blocks still constitute ""possibility results"" rather than practically relevant schemes. In fact, while being improved continuously, most existing constructions are still far too inefficient for practical use cases.

The goal of this project is to *prepare these new building blocks for modern applications*. Specifically, we will give new constructions of these new building blocks that

- are *secure in a strong sense*,

- have a *significantly extended functionality*, and

- are *efficient* when tailored to specific applications.

The technical means to achieve our goals is to *combine* these new building blocks with well-established *algebraic* cryptographic tools. For instance, we plan to mesh obfuscation with cyclic groups, in order to obtain more secure and more powerful multilinear maps. Our work prepares the ground for *practical real-life applications* from new cryptographic building blocks.""","1975814","2017-07-01","2022-06-30"
"PRESTISSIMO","Plasma Reconnection, Shocks and Turbulence in Solar System Interactions: Modelling and Observations","MINNA MARIA EMILIA Palmroth","HELSINGIN YLIOPISTO","This project combines the forefront space physics with top-tier high performance computing. Three phenomena are above others in importance in explaining plasma behaviour in the Solar-Terrestrial system, laboratories, fusion devices, and astrophysical domains: 1) magnetic reconnection enabling energy and mass transfer between magnetic domains, 2) collisionless shocks forming due to supersonic relative flow speeds between plasmas, and 3) particle acceleration associated with both. These processes are critical in understanding the scientific foundation of space weather, i.e., harmful effects caused by enhanced radiation and dynamical processes that endanger space- and ground-based technological systems or human life. Space weather forecasts require physics-based models; however, to date only simple plasma descriptions have been used in the global context. We have developed the first 6-dimensional global magnetospheric kinetic simulation in the world, Vlasiator, promising a grand leap both in understanding fundamental space plasma physics, and in improving the accuracy of present space weather models. Combining the unique Vlasiator with newest spacecraft data, local kinetic physics can be interpreted in global context in a ground-breaking fashion. We examine in the global and self-consistent context
1.     Near-Earth reconnection,
2.     Ion-scale phenomena in the near-Earth shocks,
3.     Particle acceleration by shocks and reconnection,
4.     Inner magnetospheric wave-particle processes, and the consequent particle precipitation into the ionosphere.
The proposed work is now feasible thanks to increased computational capabilities and Vlasiator. The newest space missions produce high-fidelity multi-point observations that require directly comparable global kinetic simulations offered by Vlasiator. The proposing team has an outstanding record and a leading role in global space physics modelling.","1998054","2016-06-01","2021-05-31"
"PRIME","Programming with Millions of Examples","Eran Yahav","TECHNION - ISRAEL INSTITUTE OF TECHNOLOGY","""The goal of this proposal is to make programming easier and more productive. We propose to develop novel program synthesis techniques, generating procedural code from declarative specifications.
Existing techniques apply synthesis at such a fine grain that they can never hope to generate code of the richness and complexity required by application-level programmers. In contrast, we aim to develop synthesis algorithms that leverage the collective programming knowledge captured in millions of open-source projects.
By using existing code fragments as components for synthesis, we enable synthesis to work at a higher-level of abstraction and synthesize realistic programs. Our approach represents a conceptual leap as it reduces the problem of generating code to the problem of checking whether existing code (or a combination of existing code fragments) is an appropriate solution. In some cases, this reduces the problem of synthesis to a problem of semantic code search. In other cases, it reduces the problem of synthesis over fine-grained components to synthesis as composition of coarse-grained components. The key problems are how to specify the desired behavior, how to find useful code fragments in the vast existing body of software, and the how to use synthesis to modify and assemble these fragments to form a program.

Our approach combines insights and techniques from research on program analysis, program synthesis, software engineering, and machine learning. The outcome of the project will be new research directions.""","1500000","2014-03-01","2019-02-28"
"PRO-TOOLKITS","Programmable nucleic acid toolkits for cell-free diagnostics and genetically encoded biosensing","francesco RICCI","UNIVERSITA DEGLI STUDI DI ROMA TOR VERGATA","WHY: The biological complexity of tumours and the large diversity of diagnostic biomarkers call for the development of innovative analytical tools that can detect multiple targets in a sensitive, specific and low-cost way and allow real-time monitoring of disease pathways and therapeutic effects. To provide such transformative tools creative thinking, innovative approach and the exploration of new research avenues that span different disciplines is necessary. 

WHAT: The goal of the PRO-TOOLKITS project is to address this need by developing innovative cell-free point of care diagnostic kits and genetically encodable biosensing tools. 

HOW: I oriented my independent career as a P.I. towards the design and development of synthetic nucleic acid-based nanodevices and nanomachines. With the help of an ERC Starting Grant I made ground-breaking contributions in the field of nucleic acid Nanotechnology. Motivated by these advancements I propose to challenge my know-how and expertise to explore new research avenues that will open exciting possibilities in biosensing applications. The key, ground-breaking IDEA underlying this project is to take advantage of my expertise and harness the advantageous features of RNA synthetic modules that can translate the expression of proteins in controlled in-vitro cell-free systems and can be also genetically encoded in living organisms and function inside the cells. I will develop rationally designed programmable nucleic acid modules that respond to a wide range of molecular markers and environmental stimuli through innovative nature-inspired mechanisms and that can be orthogonally wired to provide cell-free diagnostic kits and genetically encoded live-cell biosensing tools. The project will provide transformative approaches, methods and tools that will represent a genuine break-through in the fields of in-vitro diagnostics, biosensing and synthetic biology.","1999375","2019-10-01","2024-09-30"
"PROCSYS","Towards programmable cyber-physical systems: a symbolic control approach","Antoine, Sébastien GIRARD","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Cyber-physical systems (CPS) consist of computational elements monitoring and controlling physical entities. The main objective of the PROCSYS project is to propose a general framework for the design of programmable CPS that will allow engineers to develop advanced functionalities using a high-level programming language for specifying the behaviours of a CPS while abstracting the details of the physical dynamics. Controllers enforcing the specified behaviours will be generated from a high-level program using an automated model-based synthesis tool. Correctness of the controllers will be guaranteed by following the correct by construction synthesis paradigm through the use of symbolic control techniques: the continuous physical dynamics is abstracted by a symbolic model, which is a purely discrete dynamical system; an interface consisting of low-level controllers is designed such that the physical system and the symbolic model behaves identically; a high-level symbolic controller is then synthesized automatically from the high-level program and the symbolic model. We will develop a high-level programming language, based on the intuitive formalism of hybrid automata, which will enable to specify a rich set of behaviours while enabling the development of efficient controller synthesis algorithms. The project will also tackle the two main bottlenecks in the area of symbolic control, which will enable its use in challenging real-life applications. Firstly, scalability of symbolic control will be achieved by the computation of more compact symbolic models and by controller synthesis algorithms that require only partial exploration of the symbolic models. Secondly, robustness will be ensured at all levels of control by developing novel algorithms for the synthesis of robust interfaces and of symbolic controllers. The algorithms developed in the project will be implemented in a symbolic control toolbox, which will enable the use of our approach by systems engineers.","1266731","2017-09-01","2022-08-31"
"PROJESTOR","PROJECTED MEMRISTOR: A nanoscale device for cognitive computing","Abu Sebastian","IBM RESEARCH GMBH","We are entering the third era of computing: cognitive computing, which holds great promise in terms of deriving intelligence/knowledge from huge volumes of data. Today’s cognitive computers are based on the von Neumann architecture, in which the computing and the memory units are separated. Cognitive computing, however, is inherently data-centric, meaning that huge amounts of data need to be shuttled back and forth at high speeds, a task at which that architecture is highly inefficient.

It is becoming increasingly clear that to build efficient cognitive computers, we need to transition to non-von Neumann architectures where memory and logic coexist in some form. Brain-inspired neuromorphic computing and the fascinating new area of memcomputing are two key non-von Neumann approaches being researched. The critical element in these novel computing paradigms is a very-high-density, low power, variable-state, programmable and non-volatile nanoscale memory device. A technological breakthrough that will lead us to this device will be a game-changer for cognitive computing.

The goal of this project is to explore one such device concept that I co-invented at IBM Research - Zurich and which we have dubbed “projected memristor” or “projestor” for short. The projestor is indeed a memristor, i.e., a resistive element that remembers the history of the current that previously flowed through the device. The distinguishing feature of a projestor is that the physical mechanism of resistance storage is decoupled from the information retrieval process. 

In the first part of the project, we will design and fabricate projestor devices to establish the concept of projection and assess its merits and drawbacks. In the second part, we will expand the concept substantially to explore highly innovative projestor devices. In the third part, we will explore various applications of projestors in neuromorphic computing and memcomputing, with a particular focus on real-time data analytics.","2555525","2016-07-01","2021-06-30"
"ProLiCell","Engineered Protein Nanosheets at Liquid-Liquid Interfaces for Stem Cell Expansion, Sorting and Tissue Engineering","Julien GAUTROT","QUEEN MARY UNIVERSITY OF LONDON","A long standing dogma in the field of cell-based technologies is that bulk mechanical properties of solid substrates are essential to enable cell spreading, proliferation and fate decision. The use of solid materials to culture adherent cells constitutes an important hurdle for the scale up, automation and speed up of cell culture and recovery. Our recent results show that bulk solid substrates are not necessary to promote cell adhesion, growth and fate regulation as adherent stem cells spread and proliferate readily at the surface of ultra-soft materials, even liquids. In such cases, cell adhesion is enabled by the formation of a mechanically strong layer (nanosheet) of proteins at the interface between the oil (liquid substrate) and aqueous medium. This key discovery opens the door to the engineering of protein nanosheets enabling the use of liquid, free-flowing substrates sustaining cell adhesion, expansion, isolation and recovery. 

ProLiCell will design the biochemical and mechanical properties of extracellular matrix (ECM) protein nanosheets that can sustain the formation of adhesion protein complexes and support cell proliferation and culture on materials with very weak bulk mechanical properties (liquids). The engineered ECM nanosheets will be applied to: 1. the design of 3D bioreactors based on emulsions, for the culture of stem cells; 2. the formation of stem cell sheets at oil-water interfaces for tissue engineering; 3. the isolation and purification of stem cells using emulsions presenting antibody-adsorbed interfaces. ProLiCell will provide fundamental insights into ECM nanosheet design and advance our understanding of the mechanisms via which cells adhering to such interfaces sense and respond to nanoscale cues. Such fundamental understanding will enable liquid-liquid platforms to transform stem cell technologies by borrowing a wider range of processing and manufacturing concepts to the field of Chemical Engineering.","1999389","2018-09-01","2023-08-31"
"PROMOFS","Nanoengineering and Processing of Metal-Organic Framework Composites for Photonic Sensors","Jin-Chong TAN","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","The project is in the field of nanoporous materials engineering, focusing on the discovery, characterisation and application of metal-organic frameworks (MOFs) as an innovative platform to afford disruptive photonics sensing technology. Compared to the traditional material options (e.g. metal oxides and nitrides), MOFs offer several key advantages. The vast inorganic-organic (hybrid) structural diversity of MOFs implies a huge prospect to tune the desirable physical and chemical properties for engineering bespoke applications. Their 3D crystalline framework meant there is long-range periodicity, translating into continuous pathways to facilitate energy transfer and transport mechanisms. Significantly, the nanoscale pores within MOFs can be used as a vessel to host functional guests, in this context: to confine light-emitting complexes and emissive molecules creating unconventional Guest@MOF photoluminescent systems. Having established the project feasibility through pilot studies and further demonstrated the promising potential to fabricate photonic sensors, it is timely to address the outstanding challenges in this nascent field:-
(1) To establish facile processing of new Guest@MOF photonic materials and composite systems, utilising in-situ nanoscale confinement strategy in conjunction with supramolecular processing method.
(2) To characterise photophysical and photochemical properties controlling the performance of Guest@MOF systems, and, to understand fundamental mechanisms at the nanoscale.
(3) To employ ab-initio computational modelling to gain deeper insights into host-guest interactions, and, to predict structure-property relations informing the design of customised materials.
(4) To innovate in materials patterning technology for versatile materials-to-device manufacturing processes.
(5) To apply Guest@MOF materials in nanoengineering of tuneable photonics sensors.
(6) To quantify and enhance stability of Guest@MOF materials central to practical applications.","2431911","2018-04-01","2023-03-31"
"PROSINT","Multi-protein interaction kinetics by single molecule methods","Thorsten Hugel","ALBERT-LUDWIGS-UNIVERSITAET FREIBURG","Objective of this proposal is to obtain a real time picture of how components of a multi-protein complex interact to perform complex regulated tasks, in particular to see how a protein system might be more than the sum of its components. 
In living organisms many proteins work in complexes to form multicomponent protein machines and to regulate cellular processes. The function of such multicomponent machines is usually addressed by dividing them into a collection of two state systems at equilibrium. Many molecular machines work in large complexes with multiple states out of equilibrium by utilizing the energy of ATP hydrolysis. In this proposal the real time kinetics of multi-protein interactions in and out of equilibrium will be investigated using single molecule methods. 
The succession of association and dissociation steps as well as large conformational changes within the proteins will be monitored simultaneously with multicolour single molecule FRET in real time. In order to observe at the same time the folding state of proteins, a combination of optical tweezers and single molecule FRET will be developed. Finally, a combination of microfluidics for fast mixing and single pair FRET will be developed to investigate interactions of low affinity. A large part of the experiments will focus on the example of the heat shock protein Hsp90 system, which consists of co-chaperones, clients and nucleotides. 
Altogether, these interdisciplinary experiments will yield unprecedented information on multi-component interactions in equilibrium and out of equilibrium on timescales from sub milliseconds to hours. I am confident that these studies will have an impact on the understanding of the Hsp90 machinery as well as general principles of multi-component protein systems, which is the basis for understanding cellular processes.","1882500","2016-04-01","2021-03-31"
"PROTCAGE","Chemistry in the Confinement of Protein Cages","Jeroen Johannes Lambertus Maria Cornelissen","UNIVERSITEIT TWENTE","Protein cages appear to be common structures in biology, found in viruses but also in organelle-like containers discovered in bacteria. In this proposed program I aim to study chemical processes in nano-sized protein cages as mimics of bacterial organelles and to increase the general understanding of chemistry in confinement.
Towards this goal we will investigate the controlled in vivo loading of bacterial protein cages, i.e. encapsulins, with proteins and enzymes. This will allow us to study in detail the chemical conversions that take place inside such capsules and it will increase understanding about the reasons why certain processes inside these simple organisms are encased in the protein organelles.
Completely artificial protein organelles will be constructed by in vitro processes using the well-studied Cowpea Chlorotic Mottle virus cage. By employing DNA technology, cages will be loaded with a single enzyme, a sequence of enzymes or molecular probes. By obtaining this high level of control, we can not only study chemical conversions on the inside, but it will also allow us to monitor the physiochemical properties, such as internal pH, polarity and porosity of the protein mantle by encasing the relevant probes or host/guest systems.
In the ultimate stage of the proposed project the formed artificial organelles will be brought into cells in order to interact with the cell metabolism. CCMV has to be introduced by surface modification, while encapsulins can be formed inside these cells; albeit with different cargo. Such experiments have, to my knowledge, not been carried out and introducing new reactions inside these organisms can lead to new potentially interesting products or interfere with cell vitality. The latter can be of importance for the controlled disruption of bacterial cells.","1994400","2014-05-01","2019-04-30"
"PTRCSP","Phase Transitions in Random Constraint Satisfaction Problems","Konstantinos PANAGIOTOU","LUDWIG-MAXIMILIANS-UNIVERSITAET MUENCHEN","The systematic investigation of random discrete structures and processes was initiated by Erdős and Rényi in a seminal paper about random graphs in 1960. Since then the study of such objects has become an important topic that has remarkable applications not only in combinatorics, but also in computer science and statistical physics.

Random discrete objects have two striking characteristics. First, they often exhibit phase transitions, meaning that only small changes in some typically local control parameter result in dramatic changes of the global structure. Second, several statistics of the models concentrate, that is, although the support of the underlying distribution is large, the random variables usually take values in a small set only. A central topic is the investigation of the fine behaviour, namely the determination of the limiting distribution.

Although the current knowledge about random discrete structures is broad, there are many fundamental and long-standing questions with respect to the two key characteristics. In particular, up to a small number of notable exceptions, several well-studied models undoubtedly exhibit phase transitions, but we are not able to understand them from a mathematical viewpoint nor to investigate their fine properties. The goal of the proposed project is to study some prominent open problems whose solution will improve significantly our general understanding of phase transitions and of the fine behaviour in random discrete structures. The objectives include the establishment of phase transitions in random constraint satisfaction problems and the analysis of the limiting distribution of central parameters, like the chromatic number in dense random graphs. All these problems are known to be difficult and fundamental, and the results of this project will open up new avenues for the study of random discrete objects, both sparse and dense.","1219462","2018-04-01","2023-03-31"
"PULSAR","Pushing ultrafast laser material processing into a new regime of plasma-controlled ablation","Francois Courvoisier","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Ultra-intense femtosecond laser pulses promise to become a fast, universal, predictable and green tool for material processing at micro and nanometric scale. The recent tremendous increase in commercially available femtosecond laser energy at high repetition rate opens a wealth of novel perspectives for mass production. But even at high energy, laser processing remains limited to high-speed scanning point by point removal of ultra-thin nanometric layers from the material surface. This is because the uncontrolled laser-generated free-electron plasma shields against light and prevents reaching extreme internal temperatures at very precise nanometric scale.
PULSAR aims at breaking this barrier and developing a radically different concept of laser material modification regime based on free-electron plasma control. PULSAR 's unconventional concept is to control plasma generation, confinement, excitation and stability. An ambitious experimental and numerical research program will push the frontiers of laser processing to unprecedented precision, speed and predictability. PULSAR key concept is highly generic and the results will initiate new research across laser and plasma material processing, plasma physics and ultrafast optics.","1996581","2016-07-01","2021-06-30"
"PUMA","antiProton Unstable Matter Annihilation","Alexandre OBERTELLI","TECHNISCHE UNIVERSITAT DARMSTADT","One of the most fascinating quantum phenomena in nuclear physics is the occurrence of neutron halos and neutron skins in very neutron rich atomic nuclei. Thick neutron skins and halos, not yet evidenced in medium mass nuclei, would be unique low-density neutron matter accessible in the laboratory. Nuclear shell structure is also known to change with the number of protons and neutrons. The nuclear structure of very heavy nuclei at and above Z=100 is barely known, and the existence of new long-lived heavy isotopes is still an open question. The above fundamental phenomena related to the unbalance of neutron and protons in unstable nuclei are essential to understand the complex nature of nuclei and related astrophysical processes. 

We propose a new physics program to determine the neutron over proton densities at the nuclear surface for the most exotic nuclei that can be produced today, to evidence and to characterize neutron halos and skins in medium and heavy mass regions. PUMA will also allow the spectroscopy of single-particle states in heavy-nuclei above Z=100 will offer a new insight into the unknown shell structure at the top of the nuclear landscape. To address these questions, PUMA explores a new way to study radioactive nuclei produced at very low kinetic energy: the interaction of antiprotons with unstable nuclei.

PUMA is based on a new apparatus: a transportable magnetic trap to store antiprotons and maximize their interaction with slow rare isotopes in order to trigger annihilations and measure the following radiations. The PUMA methodology is based on two steps. (i) The storage of antiprotons will be performed at the new AD/ELENA facility of CERN in collaboration with the GBAR collaboration. (ii) The PUMA physics program is to take place at CERN/ISOLDE and, on a later stage beyond the ERC grant period, at the new SPIRAL2 facility in Europe. PUMA will open new horizons for nuclear structure research.","2548298","2018-01-01","2022-12-31"
"PushQChem","Pushing Quantum Chemistry by Advancing Photoswitchable Catalysis","Anne-Clémence CORMINBOEUF","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","This project exploits the synergy between the trending area of artificial molecular machines and cutting edge computational chemistry approaches. Specific emphasis is placed on photoswitchable catalysts, which respond to external stimuli with a conformational or configurational change. These controllable motions allow catalytic function to be turned ON/OFF in a switch type fashion by opening/hindering access of a substrate to a catalytic site. On one hand, the rich morphology and chemistry of these smart catalysts calls for computational insights and design principles that complement experiment and push the field forward. On the other hand, the inherent complexity of these highly fluxional molecules makes them perfect subjects for driving modern quantum chemistry out of its comfort zone. To benefit from this synergy, the latest innovations in quantum chemistry-based machine learning techniques will be combined with methods capable of thoroughly mapping the intricate chemistry of molecular actuators. Overall, we aim to bridge the gap between the current state-of-the-art, which has reached reasonable quantum chemical accuracy for rigid medium size organic molecules, and more challenging fluxional architectures. The proposed methodological toolbox will be applied to the field of smart catalysis where general strategies for improving the efficiencies and enhancing enantioselectivity will be formulated. Thus, this project involves exploiting a wide range of modern computational approaches to chemical tasks that are broadly relevant to flexible/switchable catalytic systems. The anticipated output will furnish the computational chemistry community with a comprehensive array of novel next-generation approaches with applicability beyond the field of molecular machines.","1949385","2019-10-01","2024-09-30"
"PyroTRACH","Pyrogenic TRansformations Affecting Climate and Health","Athanasios NENES","FOUNDATION FOR RESEARCH AND TECHNOLOGY HELLAS","Biomass burning (BB) is a significant contributor to global atmospheric particulate matter, with strong impacts on climate, ecosystems and public health. Yet these impacts are highly uncertain, largely owing to our inability to track BB particulate matter and the evolution of their properties throughout most of its atmospheric lifetime. PyroTRACH will provide the necessary breakthroughs in our understanding of BB particles and their impacts by: i) deriving new markers of biomass burning with an atmospheric lifetime that exceeds the current limitation of about a day, ii) measuring highly uncertain but critically-important climate- and health- relevant properties of aerosols both from wildfire events that occur during summertime and from BB for heating purposes during wintertime in highly populated urban environments, iii) applying this new knowledge to quantify the contribution of biomass burning to aerosol in the Mediterranean region, and quantify its impacts on climate and public health. Novel state-of-the-art instrumentation, portable environmental chambers and well established measurement techniques will be applied in continuous measurements as well as intensive field campaigns to study the properties and evolution of BB particulates as they age in the atmosphere. Discovering new stable chemical markers that allow detection of BBOA many days after emission, while carefully and accurately following the climate and health-related properties of freshly emitted and aged BBOA, allows for an unprecedented understanding of the evolution and impacts of biomass burning aerosol and its impact on the Earth System and public health. Considering the increasing occurrence of wildfires, along with decreased emissions from fossil fuels means that accurately predicting the health and climate effects from biomass burning aerosol is one of the most important aspects of atmospheric aerosol that needs to be studied.","1999832","2017-06-01","2022-05-31"
"QAFA","Quantum Algorithms from Foundations to Applications","Ashley MONTANARO","UNIVERSITY OF BRISTOL","""Quantum computers are designed to use quantum mechanics to go beyond the power of any standard computer based only on classical physics. Following intensive experimental efforts, it is predicted that a demonstration of so-called """"quantum computational supremacy"""" will occur in the near future. However, many urgent questions remain regarding the usefulness of quantum computers for problems of real practical interest, and the timescale on which such usefulness will be achieved. The overall goal of this project is to address the most significant near-term and long-range theoretical challenges involved in bringing quantum algorithms to practical applications.

The project comprises three programmes of work, with the following goals:
- Design quantum algorithms that accelerate general classical algorithmic frameworks; develop efficient quantum communication protocols; and characterise the features of problems that allow a quantum speedup;
- Demonstrate larger quantum-classical separations than previously known, and enable rigorous verification of quantum computational supremacy experiments;
- Find new quantum algorithms for key problems in quantum physics, including learning and testing algorithms for large quantum systems. Simulation of quantum-mechanical systems is considered the most important application area for quantum computers, yet current algorithms are still beyond the reach of near-term devices.

A unique feature of this project is its approach encompassing the full spectrum of quantum algorithms research, from underpinning mathematics through to detailed analysis of applications. Making progress on the foundations will enable progress on the more technically challenging aspects of applications, while having particular applications in mind will raise interesting new foundational questions.

""","1859312","2019-05-01","2024-04-30"
"QAffine","Representations of quantum affine algebras and applications","David Christophe Hernandez","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Quantum affine algebras are important examples of Drinfeld-Jimbo quantum groups. They can be defined as quantizations of affine Kac-Moody algebras or as affinizations of finite type quantum groups (Drinfeld Theorem).
The representation theory of quantum affine algebras is very rich. It has been studied intensively during the past twenty five years from different point of views, in particular in connections with various fields in mathematics and in physics, such as geometry (geometric representation theory, geometric Langlands program), topology (invariants in small dimension), combinatorics (crystals, positivity problems) and theoretical physics (Bethe Ansatz, integrable systems).
In particular, the category C of finite-dimensional representations of a quantum affine algebra is one of the most studied object in quantum groups theory. However, many important and fundamental questions are still unsolved in this field. The aim of the research project is to make significant advances in the understanding of the category C as well as of its applications in the following five directions. They seem to us to be the most promising directions for this field in the next years:
1. Asymptotical representations and applications to quantum integrable systems,
2. G-bundles on elliptic curves and quantum groups at roots of 1,
3. Categorications (of cluster algebras and of quantum groups),
4. Langlands duality for quantum groups,
5. Proof of (geometric) character formulas and applications.
The resources would be used for the following:
(1) Hiring of 2 PhD students (in 2015 and 2017).
(2) Hiring of 2 Postdocs (in 2015 and 2017).
(3) Invitations and travel for ongoing and future scientific collaborations.
(4) Organization of a summer school in Paris on quantum affine algebras.","1182000","2015-09-01","2020-08-31"
"QBH","Quantum Black Holes: A macroscopic window into the microstructure of gravity","Sameer Venkatesha Murthy","KING'S COLLEGE LONDON","The thermodynamic behavior of black holes is a precious clue in unravelling the microscopic structure of quantum gravity.
High precision computations of quantum black hole entropy provide a new window into the fundamental microscopic theory
of gravity and its deviations from classical general relativity. Traditional methods of quantum field theory have proved to be
not well-suited to perform these computations. Two breakthroughs in my recent work establish new ground for progress.

On one front, a new method to sum up all perturbative quantum contributions to the entropy of a large class of black holes
has been developed. This gives rise to the first exactly solvable model of a quantum black hole. On a second front, a longstanding theoretical obstacle called the wall-crossing problem has been cleared in my recent work on the microscopic
description of black holes in string theory. The newly-developed field of mock modular forms is shown to be the correct
framework to address questions of exact black hole entropy. This makes a large class of microscopic models amenable to
analytic control, many of which were previously beyond reach.

These developments open up a new line of research that I propose to pursue along two intersecting avenues. First, I aim to
extend the computations of exact quantum black hole entropy towards models of realistic black holes. Second, I aim to
advance the theoretical understanding of quantum black holes by investigating the deeper origins of mock modular
symmetry. As a concrete application, I aim to establish that newfound group-theoretical structures called “moonshine”
symmetries are physically realized in quantum black holes, thus opening up connections between two exciting fields of
research previously thought to be distinct. Together, the broad goal is to explain black hole microstructure through
systematic computations of exact quantum entropy, and to investigate its consequences on the fundamental microscopic
theory of gravity.","1759064","2016-09-01","2021-08-31"
"QBox","Quantum Gas in a Box","Zoran Hadzibabic","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","""Ultracold atomic gases offer flexible systems for fundamental studies of both equilibrium and non-equilibrium many-body problems that are relevant across many fields, from condensed matter physics to high-energy physics and astrophysics. In the long run, research on these systems could also lead to practical applications, in the development of novel materials, force sensing, navigation, and quantum information processing. 

Traditionally, an important difference between """"conventional"""" many-body systems and ultracold gases has been that the former are usually spatially uniform, while the latter were produced in harmonic traps. This difference can often be addressed using the local density approximation (LDA), but for studies of some very important problems it is a serious hindrance. In particular, LDA breaks down close to phase transitions, where the correlation length diverges, and where (due to the “critical slowing down” of the system) some of the most interesting non-equilibrium effects also emerge. 

Here we propose a comprehensive study of both equilibrium and non-equilibrium many-body phenomena in a homogeneous 39K Bose gas with dynamically tuneable interactions. The use of a homogeneous quantum gas, produced in our newly developed box-like trapping potential (in contrast to the standard setting of a harmonic trap) is a particularly important and unique aspect of this proposal, which will allow for closer connections with both other many-body systems and the theoretical calculations. 

We will specifically focus on problems in beyond-mean-field physics and on those that cannot be effectively tackled using a harmonically trapped gas. The outstanding problems we will address range from the 50-year-old equilibrium problem of the critical temperature of an interacting homogeneous gas, to the modern topics of quenches and non-equilibrium (Kibble-Zurek and beyond) critical dynamics, to the largely unexplored problem of the unitary Bose gas.
""","1943753","2016-05-01","2021-04-30"
"QGP tomography","A novel Quark-Gluon Plasma tomography tool: from jet quenching to exploring the extreme medium properties","Magdalena DJORDJEVIC","INSTITUT ZA FIZIKU","Quark-Gluon Plasma (QGP) is a primordial state of matter, which consists of interacting free quarks and gluons. QGP likely existed immediately after the Big-Bang, and this extreme form of matter is today created in Little Bangs, which are ultra-relativistic collisions of heavy nuclei at the LHC and RHIC experiments. Based on the deconfinement ideas, a gas-like behaviour of QGP was anticipated. Unexpectedly, predictions of relativistic hydrodynamics - applicable to low momentum hadron data - indicated that QGP behaves as nearly perfect fluid, thus bringing exciting connections between the hottest (QGP) and the coldest (perfect Fermi gas) matter on Earth. However, predictions of hydrodynamical simulations are often weakly sensitive to changes of the bulk QGP parameters. In particular, even a large increase of viscosity not far from the phase transition does not notably change the low momentum predictions; in addition, the origin of the surprisingly low viscosity remains unclear. To understand the QGP properties, and to challenge the perfect fluid paradigm, we will develop a novel precision tomographic tool based on: i) state of the art, no free parameters, energy loss model of high momentum parton interactions with evolving QGP, ii) simulations of QGP evolution, in which the medium parameters will be systematically varied, and the resulting temperature profiles used as inputs for the energy loss model. In a substantially novel approach, this will allow using the data of rare high momentum particles to constrain the properties of the bulk medium. We will use this tool to: i) test our “soft-to-hard” medium hypothesis, i.e. if the bulk behaves as a nearly perfect fluid near critical temperature Tc, and as a weakly coupled system at higher temperatures, ii) map “soft-to-hard” boundary for QGP, iii) understand the origin of the low viscosity near Tc, and iv) test if QGP is formed in small (p+p or p(d)+A) systems.","1356000","2017-09-01","2022-08-31"
"QITBOX","Quantum Information Theory with black BOXes","Antonio Acín","FUNDACIO INSTITUT DE CIENCIES FOTONIQUES","""With QITBOX we aim to develop a novel device-independent framework for quantum information processing. In this framework, devices are seen as black boxes that only receive inputs and produce outputs. Our main objective is to understand what can and cannot be done for information processing using only the observed correlations among the devices. We will structure our effort along three main research lines: (i) Characterization of quantum correlations: the general objective will be to characterize those correlations that are possible among quantum devices; (ii) Protocols based on correlations: the general objective will be to understand how quantum correlations can be exploited in order to construct relevant information protocols and (iii) Applications to physical setups: here the previous results to concrete physical setups will be applied, such as the quantum-optical realizations of the protocols or the study of the non-local properties of many-body systems. The expected results of QITBOX are: (i) Novel methods for the characterization of quantum correlations, (ii) Improved or novel device-independent protocols, (iii) Proposals for feasible experimental implementations of these protocols and (iv) Novel methods for the study of many-body systems based on correlations. QITBOX is a highly-interdisciplinary project with implications in Physics, Mathematics, Computer Science and Engineering. The execution of the planned research work will provide a unifying framework for a Quantum Information Theory with black BOXes (hence the acronym). Such a framework will bring quantum information processing to an unprecedented level of abstraction, in which information protocols and primitives are defined without any reference to the internal physical working of the devices. This, in turn, will lead to much more robust practical implementations of quantum information protocols, closing the mismatch between theoretical requirements and experimental realisations.""","1487505","2014-01-01","2019-12-31"
"QLev4G","Quantum control of levitated massive mechanical systems: a new approach for gravitational quantum physics","Markus Aspelmeyer","UNIVERSITAT WIEN","Quantum physics and general relativity are probably the most successful and well-tested theories of modern science. At the same time, their fundamental concepts are so dramatically different that there is disagreement on the most obvious questions such as “how does a mass in a quantum superposition state gravitate?“. Achieving progress on such foundational questions requires experiments at the interface between quantum physics and gravity, of which to date only a few of exist. The main objective of the proposed research is to establish quantum control of levitated massive objects as a new paradigm system for such experiments and to enter a hitherto inaccessible parameter regime of large mass and long quantum coherence.

The proposal builds on the enormous recent success in quantum control of the motion of solid-state mechanical resonators, which has emerged over the last decade as a new branch of interdisciplinary research in quantum and solid-state physics. Applied to optically or magnetically levitated systems this methodology promises (i) exceptional sensitivity to weak gravitational forces, hence enabling measurements of gravity between sub-millimeter objects; (ii) unprecedented levels of decoupling from the environment, thereby opening up a new route for long-lived quantum coherence of genuinely massive systems. Quantum control is achieved by coupling the motion either of optically trapped particles to an optical cavity field or of magnetically trapped particles to superconducting circuits. We will explore both methods for systematically expanding the available parameter space of macroscopic quantum systems and for first proof-of-concept experiments aimed towards addressing fundamental questions of gravitational quantum physics.

If successful, this research program will become a door-opener to the quantum regime of genuinely massive objects, where gravity of the quantum system itself may start to play a role for the correct description of a quantum experiment.","2155285","2015-06-01","2020-05-31"
"QML","Quantum Machine Learning: Chemical Reactions with Unprecedented Speed and Accuracy","Otto Anatole VON LILIENFELD-TOAL","UNIVERSITAT BASEL","Large and diverse property data sets of relaxed molecules and crystals, resulting from computationally demanding quantum calculations, have recently been used to train machine learning models of various energetic and electronic properties. We propose to advance these techniques to a level where they can also describe reaction profiles, i.e. reactive non-equilibrium processes which traditionally would require quantum chemistry treatment. The resulting quantum machine learning (QML) models will provide reaction profiles for new reactants in real-time and with quantum accuracy. The overall goal is to develop a predictive computational tool which allows chemists to easily optimize reaction conditions, develop new catalysts, or even plan new synthetic pathways.","1980500","2018-06-01","2023-05-31"
"QnanoMECA","Quantum Optomechanics with a levitating nanoparticle","Romain Roger Quidant","FUNDACIO INSTITUT DE CIENCIES FOTONIQUES","Micro- and nano-mechanical oscillators with high quality (Q)-factors have gained much interest for their capability to sense very small forces. Recently, this interest has exponentially grown owing to their potential to push the current limits of experimental quantum physics and contribute to our further understanding of quantum effects with large objects. Despite recent advances in the design and fabrication of mechanical resonators, their Q-factor has so far been limited by coupling to the environment through physical contact to a support. This limitation is foreseen to become a bottleneck in the field which might hinder reaching the performances required for some of the envisioned applications. A very attractive alternative to conventional mechanical resonators is based on optically levitated nano-objects in vacuum. In particular, a nanoparticle trapped in the focus of a laser beam in vacuum is mechanically disconnected from its environment and hence does not suffer from clamping losses. First experiments on this configuration have confirmed the unique capability of this approach and demonstrated the largest mechanical Q-factor ever observed at room temperature. The QnanoMECA project aims at capitalizing on the unique capability of optically levitating nanoparticles to advance the field of optomechanics well beyond the current state-of-the-art. The project is first aimed at bringing us closer to ground-state cooling at room temperature. We will also explore new paradigms of optomechanics based on the latest advances of nano-optics. The unique optomechanical properties of the developed systems based on levitated nanoparticles will be used to explore new physical regimes whose experimental observation has been so far hindered by current experimental limitations.","1987500","2015-10-01","2020-09-30"
"QNETWORK","Quantum networks wired by multi-spin entanglement","Ronald HANSON","TECHNISCHE UNIVERSITEIT DELFT","Entanglement is arguably the most defining and yet counterintuitive feature of quantum theory. The non-local nature of entanglement provides exciting opportunities for fundamentally new science and technologies. As a prime example, recent theoretical work has uncovered the unique potential of a future quantum network: a network of nodes consisting of multiple well-controlled quantum particles “wired” by quantum entanglement. Such a network would enable distributed quantum computing and simulation, secure communication, enhanced metrology and new fundamental studies of nature. Although recent pioneering advances in quantum control have made quantum networks a realistic prospect, remote entanglement has so far been limited to two long-lived spins in trapped ions, atoms, quantum dots and diamond defect centers.

My QNETWORK project will realize a multi-node entanglement-based quantum network. The network will have fully controlled multi-spin nodes at individual diamond defects connected by single-photon links. Using this quantum network I will demonstrate supremacy of a quantum repeater node over direct photon transmission, generate multi-spin entanglement and study its decoherence, realize quantum teleportation across multiple nodes and finally exploit the network for new scientific experiments ranging from super-activation of entanglement distillation to foundational tests to quantum secret sharing.

To achieve these ambitious goals, this proposal will capitalize on two recent breakthroughs with single electron spins trapped in diamond defects in my group. First, we have entangled electron spins on different chips (most recently over a distance >1km). Second, we have achieved full control over a handful of nuclear spins near one such electron, providing the required quantum memories. If successful, QNETWORK will yield a versatile multi-node quantum network that will serve as a novel platform for groundbreaking science and as a test-bed for a future quantum Internet.","1625000","2018-05-01","2023-04-30"
"QOM3D","Quantum Optomechanics in 3D","Gary Alexander Steele","TECHNISCHE UNIVERSITEIT DELFT","Optomechanics is a field that aims to detect and control mechanical motion with light, ultimately at the quantum level. Experiments reaching the mechanical quantum ground state established optomechanics as a rapidly growing new field. Now that the quantum ground state has been reached, what is the next step?

The current goal of the field is quantum superposition states of motion. An example of this is a mechanical “Schrodinger cat” state, in which a drum is in a quantum superposition of vibrating up and vibrating down at the same time. From a technological perspective, such states could be used as a memory for storage of quantum information, or as a quantum bit itself, performing quantum calculations with a mechanical object. From a fundamental perspective, Schrodinger cat states could be used to explore the limits of macroscopic quantum mechanics and to look for the boundary between the quantum and classical worlds. Despite their recent success, the coupling between light and motion in current implementations is too weak to achieve non-classical motion. 

Here, I propose a new optomechanical system coupling the motion of a millimeter-sized membrane to quantum microwave “light” in a three-dimensional superconducting cavity. In this new system, I will use the exceptional coherence photons in 3D cavities to strongly enhance the coupling of light and motion. To demonstrate the feasibility of this idea, I present preliminary data from a proof-of-concept device with coupling that is already close to state-of-the-art, with an outlook to scaling significantly beyond implementations shown to date.  

With the team funded by this project, I will implement these feasible but challenging steps, creating a system with optomechanical coupling that can potentially reach the strong coupling regime for a single photon. Using this new strong coupling, I will bring optomechanics to a new regime where one can create and explore quantum superpositions of massive, macroscopic objects.","1999594","2016-07-01","2021-06-30"
"Qosmology","Quantum Effects in Early Universe Cosmology","Jean-Luc LEHNERS","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Ultimately, every question in cosmology leads back to the question of initial conditions. Classical physics, even in the context of an inflationary phase, cannot address this question – this is the domain of quantum cosmology. The best known theories of initial conditions are the no-boundary and tunnelling proposals. Both were formulated somewhat heuristically, in the path integral approach to quantising gravity. And due to a lack of adequate means, progress has been relatively modest in this subject. 

Qosmology will apply new mathematical methods, based on Picard-Lefschetz theory, to define gravitational path integrals rigorously for the first time. Generalised theoretical concepts, in particular tunnelling in complex time, will lead to new types of solutions describing quantum transitions between contracting and expanding universes, effectively providing quantum resolutions of the big bang. These solutions will not only extend the scope of the existing theories of initial conditions, but may suggest entirely novel approaches. In addition Qosmology will continuously improve existing numerical methods, allowing for extensive studies of the big-bang-resolving solutions as well as of quantum tunnelling effects generally. 

Moving beyond a description of the background, the fluctuations in the universe and an observational verification of their quantum origin are of fundamental interest. Are there remnants of quantum correlations in the distribution of galaxies in our universe? Qosmology will forge new paths by exploring quantum gravitational effects, exploiting novel measures of quantumness, and focussing on the interconnectedness between background and fluctuations, dynamics and initial conditions. 

Qosmology will, for the first time since the 1980s, reach a significant advance in our understanding of quantum theory applied to the universe as a whole.","1239844","2018-09-01","2023-08-31"
"QPROGRESS","""Progress in quantum computing: Algorithms, communication, and applications""","Ronald De Wolf","STICHTING CENTRUM VOOR WISKUNDE EN INFORMATICA","""Quantum computing combines computer science, physics and mathematics to fundamentally speed up computation using effects from quantum physics. Starting in the early 1980s with Feynman and Deutsch, and gaining momentum in the 1990s with the algorithms of Shor and Grover, this very interdisciplinary area has potentially far reaching consequences. While a large-scale quantum computer has not been built yet, experimenters are getting more optimistic: a recent prediction is that it will take another 10-15 years.

However, the tasks where such a quantum computer would be able to significantly outperform classical computers are still quite limited, which lends urgency to finding new applications. This proposal will find more such tasks, and produce new insights into the strengths and weaknesses of quantum computing. It is divided into three workpackages:

1. Algorithms & complexity. Find new quantum algorithms that are more efficient than the best classical algorithms, for example for matrix multiplication and graph problems. Extend our knowledge of the ultimate limitations of quantum algorithms, and possible parallelization (which has barely been studied so far).

2. Quantum communication. Communication complexity analyzes the amount of communication needed to solve distributed computational tasks, where separate parties each hold part of the input. Find new
distributed problems where quantum communication outperforms classical communication, and explore links with fundamental physics issues like the role of entanglement and Bell-inequality violations.

3. Classical applications. Apply the newly developed mathematical tools of quantum computing to analyze problems in other areas, as we recently did for linear programs for the traveling salesman problem. This
third workpackage will have impact regardless of progress in building a quantum computer.

The PI is one of the world’s top researchers in each of these three areas.""","1453700","2014-03-01","2019-02-28"
"QRES","Transforming the limits of resolution by utilizing quantum information","Alexander RETZKER MENES","THE HEBREW UNIVERSITY OF JERUSALEM","Quantum sensing(QS) and metrology exploit physical laws governing individual quantum systems, and correlations between systems, to measure a physical quantity. Recently, an appreciation of the vast potential for a variety of applications, including magnetic and electric fields, pressure and temperature sensors, and imaging at the nanoscale, has positioned QS at the centre of quantum science and technology. QS is a rapidly growing field, with the most common platforms being spin qubits, trapped ions and flux qubits. The main resource for quantum sensing is coherence, the definite phase relation between different states. This phase can only survive until the coherence time, which limits the sensitivity of quantum sensing. For quantum sensing the decay time T1 is believed to be the ultimate limit.

QS targets a broad spectrum of physical quantities, of both static and time-dependent types. While 
the most important characteristic for static quantities is sensitivity, for time-dependent signals it is the resolution, i.e. the ability to resolve two different frequencies. This is the central subject of the proposed research.

Quantum computing has been shown to be feasible thanks to the realization that error correction can be applied to quantum operations in a fault-tolerant way. This opens up the possibility to realize quantum operations at very precise levels of accuracy and resolution.

In my planned research I will address the issue of whether this extraordinary accuracy, when combined with robust time keeping methods, can be exploited to enhance quantum sensing in general - and resolution in particular. For this purpose, I will design protocols that far surpass the state-of-the-art, with the final goal being to overcome the T1 limit. Besides the insights gained for quantum theory, the research will result in detailed proposals for experiments to be realized by experimental groups investigating Nitrogen-Vacancy color centers in diamond and trapped-ion quantum logic.","1820475","2018-04-01","2023-03-31"
"QSHvar","Quantitative stochastic homogenization of variational problems","Tuomo Kuusi","HELSINGIN YLIOPISTO","The proposal addresses various multiscale problems which lie at the intersection of probability theory and the analysis of partial differential equations and calculus of variations. Most of the proposed problems fit under the framework of stochastic homogenization, that is, the study of large-scale statistical properties of solutions to equations with random coefficients. In the last ten years, there has been significant progress made in developing a quantitative theory of stochastic homogenization, meaning that one can now go beyond limit theorems and prove rates of convergence and error estimates, and in some cases even characterize the fluctuations of the error. These new quantitative methods give us new tools to attack more difficult multi-scale problems that have until now resisted previous approaches, and consequently to solve open problems in the field.

Many of the actual goals of the proposal come from problems in calculus of variations. Apart from qualitative results, many fundamental questions in quantitative theory are completely open, and our recent results suggest a way to tackle these problems. The first one is to prove regularity properties of homogenized Lagrangian under rather general assumptions on functionals, and to solve a counterpart for Hilbert's 19th problem in the context of homogenization. The second project is to attack so-called Faber-Krahn inequality in the heterogeneous case. This is a very involved problem, but again recent development in the theory of homogenization makes the attempt plausible. The final part of the proposal involves new mathematical approaches and subsequent computational research supporting the geothermal power plant project being built by St1 Deep Heat Ltd in Espoo, Finland.","1312500","2019-08-01","2024-07-31"
"QSIMCORR","Quantum Simulation of Strongly-Correlated Systems","Lode POLLET","LUDWIG-MAXIMILIANS-UNIVERSITAET MUENCHEN","A major challenge in theoretical physics is to develop novel methods without systematic errors. The scope of this proposal is the numerical control over strongly correlated phases in the thermodynamic limit through two main developments: 
First, for bosonic systems, we aim to obtain reliable phase diagrams for optical flux lattices, combining topology with interactions. In particular, we study the competition between superfluid order and (fractional) Chern insulators, which may harbor (non-)abelian anyonic excitations. This is achieved by a major improvement on our current selfenergy-based cluster methods through non-local interactions, vertex corrections and momentum cluster extensions. This also enables access to out-of-equilibrium dynamics, relevant to study quench-type experiments. In the presence of disorder, we can then answer whether many-body-localization exists in higher dimensions and address the fundamental puzzle of how and when systems thermalize. 
Second, for fermionic systems with long-range interactions, such as warm dense matter, the electron gas, and cold gases with Rydberg interactions, the diagrammatic Monte Carlo method is uniquely situated to compute thermal exchange correlation energies over the entire density range, essential to any calculation in condensed matter physics, astro physics and plasma physics. It employs a universal language but needs further algorithmic refinements for improving its convergence and sign properties. Extensions are towards (frustrated) spin systems, providing an alternative route to the realization of strongly correlated phases. 
At all stages analytical derivations must be supplemented with coding and large-scale computation. We address what new types of quantum systems can efficiently be computed on a classical computer, and how. Simultaneously, we seek to extend the paradigm of quantum simulation by comparing the results of our novel methods with cold gas experiments in challenging regimes, where possible.","2000000","2018-03-01","2023-02-28"
"QTONE","Quantum Plasmomechanics with THz Phonons and Molecular Nano-junctions","Christophe GALLAND","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","QTONE aims at discovering new quantum phenomena involving THz vibrational modes, and at gaining control over them using novel concepts inspired from cavity quantum optomechanics and new techniques developed for nano-plasmonics and molecular break-junctions. The three main goals of the project are:

(i) Perform optomechanical quantum information processing with THz phonons in low-dimensional systems, using a combination of ultrafast spectroscopy and time-correlated photon counting to measure quantum correlations mediated by non-classical vibrational states. 

(ii) Demonstrate the feasibility of dynamical backaction amplification of THz phonons by coupling molecules and nanomaterials to plasmonic cavities and by leveraging exciton-phonon coupling to realize exciton-assisted optomechanics. 

(iii) Interrogate and drive a single-molecule inside a plasmonic nanocavity using simultaneous inelastic electron tunneling and Raman spectroscopies in a molecular break-junction with engineered plasmonic resonance. 

I anticipate that this project will have widespread impacts on our understanding of quantum phenomena in molecular-scale oscillators, and will foster the excellence of Europe in fields ranging from fundamental science to quantum technologies and molecular electronics.","2437500","2019-05-01","2024-04-30"
"QUANtIC","Quantum Nanowire Integrated Photonic Circuits","Gregor KOBLMUELLER","TECHNISCHE UNIVERSITAET MUENCHEN","Semiconductor nanowires (NW) hold very strong potential to advance fundamental and applied research towards new classes of quantized heterostructures in an inherently one-dimensional (1D) geometry. As such, they offer unique possibilities for tunable charge carrier and optical confinement, as well as significant design freedom as optical resonators and waveguides for deterministic integration of isolated emitters into photonic and quantum optical circuits with widespread functionalities. The vast potential of deterministic and ultrascaled quantum-NW optical cavities linked with integrated photonic circuits has, however, remained a widely unexplored area.

The vision of this project is to enter the ultimate regime of strongly confined semiconducting quantum NWs and exploit their advanced intrinsic properties to enable integrated photonic circuits with unprecedented functionalities in information technology and sensing. Based on  my strong track record in the field of NWs, my goals follow along the following foundational objectives: 

(A)  Realize deterministic, monolithic NWs on integrated photonic hardware with tailored properties in the quantum-confinement regime (quantum-NWs) 
(B)  Exploit quantum confinement phenomena to develop new and high-efficiency ultrascaled classical and non-classical emitters on-chip, including dielectric & metal-cavity NW-lasers (photonics), NW-quantum cascade lasers (sensing) & single and entangled photon emitters (quantum information processing).   
(C)  Explore coupling and interaction effects of quantum NW emitters on integrated SOI-based waveguides and circuits for all-optical routing, feedback and switching. 

This high-risk yet feasible project will allow for the first time to access ultra-precise semiconducting quantum NWs, where their quantized electronic structure can be mapped onto a specific quantum optical response, leading to unique discoveries in integrated photonics, quantum communication and sensing.","1743850","2019-01-01","2023-12-31"
"QUANTIVIOL","Quantifying Quantum Gravity Violations of Causality and the Equivalence Principle","Benjamin Wolf FREIVOGEL","UNIVERSITEIT VAN AMSTERDAM","Quantum gravity must violate at least one of three principles at the foundations of physics: unitarity, causality, or the equivalence principle. Recent theoretical work on black holes has shown that such violations are not limited to extremely short distances, where quantum gravity effects are expected, but also occur at distances much larger than the Planck scale. This work has revealed a huge gap in our understanding: we have no working criterion for when quantum gravity violations of the usual laws of physics are important.

This theoretical crisis is also an opportunity, since quantum gravity effects may be observable if they occur at longer distance scales.  I propose a series of concrete calculations in two theoretical situations: ordinary black holes, which evaporate due to Hawking radiation, and black holes in spacetimes with negative cosmological constant, which do not evaporate.  These calculations will quantify, for the first time, the size of these violations.The calculations make use of existing techniques and results derived by myself and others, but a focused effort is needed in order to put together all of the necessary ingredients into a coherent quantitative result.

We will then generalize our results beyond black holes to obtain a generally applicable formula. The final result will be an answer to one of the most important questions in quantum gravity: how large are quantum gravity violations of the usual laws of physics? The impact of successfully completing this project extends far beyond black hole physics.  As one application, our results will either justify existing calculations of cosmological observables, or make a prediction that quantum gravity effects can be observed.","2000000","2017-09-01","2022-08-31"
"QUANTSTRO","Quantum-Degenerate Strontium:
Mixtures, Molecules, and Many-Body Physics","Florian Schreck","UNIVERSITEIT VAN AMSTERDAM","In 2009 my research team created the first Bose-Einstein condensate of strontium. This breakthrough is the foundation of my research program, which will investigate quantum many-body phenomena with a focus on quantum magnetism and physics related to the quantum Hall effect. We are especially interested in studying unusual, strongly correlated quantum states, among them states with topological order.

The unique properties of strontium make it ideally suited to follow four different approaches to this physics.

1) We will immerse our quantum gas into artificial gauge fields, which e.g. let neutral atoms behave as if they were charged particles in a strong magnetic field. These fields will allow us to study quantum Hall states or topological insulators.

2) We will study SU(N) magnetism, which is an unusual form of magnetism not found in condensed matter, but of high interest for theory. A high degree of frustration can lead to spin liquid behaviour.

3) We will use sympathetic Pomeranchuk cooling of a potassium spin mixture by fermionic strontium to reach low entropy quantum phases. Our goal is to study magnetically ordered states and frustrated antiferromagnetism.

4) We will create RbSr ground-state molecules, which are polar, open-shell molecules. They will allow us to engineer unique quantum-many body systems with long-range interactions, e.g. lattice-spin models that can support topological states.

We will pursue this research not only on our existing Rb/Sr quantum gas mixture apparatus, but we will construct a new K/Sr quantum gas microscope. This machine will be very valuable to explore exotic quantum states. The properties of strontium will enable an innovative single-atom detection method based on shelving in a metastable state and quench cooling, which will allow us to take internal state-resolved, 3D, or super-resolution images of the lattice gas.","1799148","2014-04-01","2019-03-31"
"QuantumMagnonics","Interfacing spin waves with superconducting quantum circuits for single magnon creation and detection","Martin Peter Weides","UNIVERSITY OF GLASGOW","The proposed project will experimentally interface ferromagnets with superconducting quantum circuits to study dynamics within the magnet. To this end, magnonic elements made up by thin, structured magnetic films will be strongly coupled to the qubit. Superconducting qubits are ideal detectors due to their quantum limited back-action on the measured object and energy resolution.

Spectroscopy and coherence measurements on the hybrid system will be made in order to address fundamental aspects such as spin wave generation, detection, coherence, or wave propagation down to mK temperatures and at ultra-low power (atto-watts). Amplitude and phase noise of spin wave resonators will be determined. At the final stage of the project, the quantum limited resolution of qubits will facilitate single magnon creation and detection. Quantum states are swapped between qubit and magnon, and superpositioned and entangled states will be explored. Monitoring the qubit response to its magnetic environment the low and high-frequency flux noise spectrum of spin waves will be inferred.

The research methodology employs junctions, resonators, and qubits as research objects and detectors. The samples will be characterized at cryogenic temperatures by transport, magnetometry, resonator and qubit setups. Magnetic materials will be deposited and structured beneath or ontop the superconducting quantum circuits.

Exploring spin wave dynamics in thin films by coupling to a superconducting qubit complements conventional measurement techniques based on photon, electron or neutron scattering methods, which require highly populated excitations. The project connects to and extends research objects of ground-breaking nature to open up new horizons for quantum, magnon and spin electronics. Magnetic material physics is enhanced by new research concepts such as quantum resolved spectroscopy and coherence measurements on intrinsic dynamic states.","1996337","2015-06-01","2020-05-31"
"QUANTUMMETALINK","Quantum Metamaterials: A Theoretical and Computational Approach Towards Seamlessly Integrated Hybrid Classical/Quantum Nano-structures","Nicolae Coriolan Panoiu","UNIVERSITY COLLEGE LONDON","The overarching aim of this proposal is to initiate and advance an integrated theoretical and computational research programme in an emerging area of metamaterials research, namely Quantum Metamaterials. Thus, it is commonly believed that one of the most noteworthy developments witnessed in the last decade in physical sciences and engineering is the emergence of metamaterials. Unlike ordinary materials, which are assembled at the atomic level, metamaterials are composite materials built up from artificially engineered meta-atoms and meta-molecules. The fundamental idea in this area of research is that remarkable physical properties beyond those available in naturally occurring materials can be achieved by designing the meta-constituents of the metamaterial and structuring it at a scale comparable or smaller than the optical wavelength. In this context, a new paradigm in metamaterials research emerges when the building blocks of metamaterials are quantum resonators, e.g., quantum dots (QDs), QD molecules, graphene disks coupled to interacting QDs, and quantum nanowires, case in which the macroscopic properties of quantum metamaterials are determined by the quantum properties of their basic constituents. We have organised this research programme along three broad, synergistically integrated themes. The first will focus on the development of a general theory of the effective, macroscopic properties of quantum metamaterials. The key challenge is to build a theoretical framework in which the macroscopic properties of quantum metamaterials are derived directly from those of their quantum building blocks. The second theme will be geared towards developing a set of numerical methods and software tools for ab initio simulations of fundamental physical properties quantum metamaterials. The foundational work pertaining to the first two themes will enable us to pursue the main objective of  the third theme, which is the exploration of new science and novel applications.","1779240","2015-06-01","2020-05-31"
"QUCC","Chemistry of the Quantum Kind","Edvardas Narevicius","WEIZMANN INSTITUTE OF SCIENCE LTD","There has been a long-standing quest to observe chemical reactions at low temperatures where reaction rates and pathways are governed by quantum mechanical effects. So far this field of Quantum Chemistry has been dominated by theory. The difficulty has been to realize in the laboratory low enough collisional velocities between neutral reactants, such that the quantum wave nature could be observed. Recently we have demonstrated a new way of studying cold reactive collisions by magnetically merging two fast neutral supersonic beams. After 40 years where the reactive scattering temperature was limited to above 5 K we were able to continuously tune collision energies from hundreds of Kelvin down to 10 mK temperature, a reduction of almost three orders of magnitude [A. B. Henson et. al, Science 338, 234, 2012]. Importantly, we were able to show that at low temperatures quantum effects start dominating reactive dynamics with the first observation of orbiting resonances in a reactive collision. We propose to extend our novel method to study chemical reactions in the regime of Cold Chemistry where the reactants’s de Broglie wavelength becomes larger compared to the characteristic interaction range. Theoretical predictions at low temperatures are extremely sensitive to the parameters used, routinely differing by orders of magnitude leading to contradictions waiting to be settled by experiment.
Our ability to reach low enough collision energies and resolve scattering resonances will be used to bring a radical change to transient species spectroscopy. We believe that our work will not only test the central tenets of Quantum Chemistry, but will also provide valuable information to other fields, such as Astrochemistry helping to understand the synthesis of various molecules in interstellar space at temperatures 10 K and below.","1982908","2014-01-01","2018-12-31"
"QUEM-CHEM","Time- and space- resolved ultrafast dynamics in molecular-plasmonic hybrid systems","Stefanie Simone Gräfe","FRIEDRICH-SCHILLER-UNIVERSITAT JENA","This project aims at developing theoretical and numerical methods to simulate space- and time-resolved ultrafast dynamics in novel hybrid molecular-metal nanoparticle systems. The excitation of collective electron dynamics inside the metallic nanoparticles induced by external light fields leads to strongly re-shaped electromagnetic near-fields with complex spatial and temporal profile. The interaction of these modified and enhanced near-fields with molecules located in close vicinity to the metallic nanoparticle is the origin of many astonishing physical and chemical phenomena, such as the formation of new quasi-particles, new mechanisms for chemical reactions or the ultra-high spatial resolution and selectivity in molecular detection.. Besides being of fundamental interest, this interplay between near-fields and molecules promises great potential on the application side, potentially enabling revolutionary breakthrough in new emerging technologies in a broad range of research fields, such as nanophotonics, energy and environmental research, biophotonics, light-harvesting energy sources, highly sensitive nano-sensors etc. This necessitates a solid theoretical understanding and simulation of these hybrid systems. 
The goal of project QUEM-CHEM is the development of new approaches and methods beyond the state of the art, aiming at a synergy of existing but independently applied methods:
•	Quantum chemistry (QU) in order to calculate the quantum nature of the molecule-metallic nanoparticle moiety,
•	Electro-dynamic simulations (EM) describing the complex evolution of the light fields and the near fields around nanostructures, as well as
•	Dynamical methods to incorporate the response of the molecule to the near-fields
Thus, the possible outcome of this highly interdisciplinary project will provide new knowledge in both, physics and chemistry, and might have impact on a large variety of new arising critical technologies.","1901400","2018-05-01","2023-04-30"
"QUESS","Quantum Environment Engineering for Steered Systems","Mikko Pentti Matias Möttönen","AALTO KORKEAKOULUSAATIO SR","The superconducting quantum computer has very recently reached the theoretical thresholds for fault-tolerant universal quantum computing and a quantum annealer based on superconducting quantum bits, qubits, is already commercially available. However, several fundamental questions on the way to efficient large-scale quantum computing have to be answered: qubit initialization, extreme gate accuracy, and quantum-level power consumption.

This project, QUESS, aims for a breakthrough in the realization and control of dissipative environments for quantum devices. Based on novel concepts for normal-metal components integrated with superconducting quantum nanoelectronics, we experimentally realize in-situ-tunable low-temperature environments for superconducting qubits. These environments can be used to precisely reset qubits at will, thus providing an ideal initialization scheme for the quantum computer. The environment can also be well decoupled from the qubit to allow for coherent quantum computing. Utilizing this base technology, we find fundamental quantum-mechanical limitations to the accuracy and power consumption in quantum control, and realize optimal strategies to achieve these limits in practice. Finally, we build a concept of a universal quantum simulator for non-Markovian open quantum systems and experimentally realize its basic building blocks.

This proposal provides key missing ingredients in realizing efficient large-scale quantum computers ultimately leading to a quantum technological revolution, with envisioned practical applications in materials and drug design, energy harvesting, artificial intelligence, telecommunications, and internet of things. Furthermore, this project opens fruitful horizons for tunable environments in quantum technology beyond the superconducting quantum computer, for applications of quantum-limited control, for quantum annealing, and for simulators of non-Markovian open quantum systems.","1949570","2017-01-01","2021-12-31"
"QUINCY","Quantifying the effects of interacting nutrient cycles on terrestrial biosphere dynamics and their climate feedbacks QUINCY","Sönke Zaehle","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Nutrient availability plays a pivotal role in the response of terrestrial ecosystems to increasing atmospheric CO2 and climate change. The global role of nutrients is only poorly understood quantitatively, limiting the predictive understanding of terrestrial biosphere - climate feedbacks. The first generation of global nutrient-carbon cycle models shows strongly diverging estimates of the nutrient effect, resulting from lacking integration of ecosystem observations and fundamental uncertainties in the representation of governing processes. The objective of QUINCY is to clarify the role of the interacting terrestrial nitrogen and phosphorus cycles and their effects on terrestrial C allocation and residence times as well as terrestrial water fluxes. QUINCY will create a novel, predictive framework founded on the principle of resource optimisation, shifting the paradigm of terrestrial biosphere modelling towards an active biological control of matter flows. QUINCY’s main themes are (i) the effects of nutrient availability on plant photosynthesis and respiration, explicitly taking the energy requirement of nutrient acquisition into account, and (ii) the effects of vegetation-soil interactions, namely rhizosphere processes, on plant nutrient availability and soil C turnover. To corroborate these theoretical concepts, QUINCY will synthesise existing and ongoing ecosystem monitoring and manipulation studies. To specifically test emerging hypotheses on the effects of rhizosphere priming on soil C storage and plant nutrition - and to provide currently lacking data for soil-vegetation models - QUINCY will establish a tree mesocosm, elevated CO2 experiment. The novel model concepts will be consistently integrated to form a new general terrestrial biosphere model. For the first time, QUINCY will be able to address the multiway interactions of carbon, nitrogen, phosphorus and water cycles globally in a theoretically well-founded way commensurate with ecosystem observations.","2000000","2015-09-01","2020-08-31"
"QUMIN","Quantum magnonics in insulators","Andrew James Ferguson","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","In the QUMIN proposal we will build on recent developments in spintronics, circuit quantum electrodynamics and superconducting quantum computing in order to advance the fledgling research field of quantum magnonics. We will employ micro-scale magnonic resonators fabricated from YIG thin films and planar superconducting microwave resonators and superconducting transmon qubits. The combination of these basic elements will enable us to create hybrid magnon/photon and magnon/qubit quantum states and probe and control their joint coherence. An end goal of the project is to controllably entangle a superconducting qubit and a magnet.

The concept of circuit quantum electrodynamics, developed in superconducting quantum computing, has enabled strong light-matter coupling at microwave frequencies and has been one of the driving forces behind the advances in quantum computing. Over the same time frame there has been an intense development of microwave spintronics partly motivated by the discovery of spin-transfer torque and spin pumping. Most recently, motivated by its exceptional magnetic properties, there has been a renaissance of research in magnetic insulator YIG. Initial experiments show strong coupling between electromagnetic resonators and magnetic resonators. But this is just the start and a wide variety of increasingly sophisticated experiments are to follow.

An important aspect of our proposal is to use the non-uniform modes of micro-scale magnonic resonators, enabling experiments close to or at zero magnetic field to ensure compatibility with superconducting qubits. Furthermore we place an emphasis on the use of microwave spintronic techniques, using the spin-Hall effect in order to control and measure the magnonic resonator. As well as exploring this new quantum magnonics avenue, our proposal will further understanding into the room-temperature magnetic phenomena that make YIG an essential material for microwave electronics.","2399382","2015-06-01","2020-05-31"
"QuPoPCoRN","Quantum Particles on Programmable Complex Reconfigurable Networks","Christine Ella Silberhorn","UNIVERSITAET PADERBORN","Understanding the complex interactions and dynamics of multiple quantum particles within large networks is an extremely challenging task, but doing so reveals the underlying structure of an enormously diverse range of phenomena. Therefore, a reliable platform to investigate complex quantum network dynamics, which incorporates the rich interplay between noise, coherence and nonclassical correlations, will be an extremely powerful tool.  

Classical optical networks have been widely used to simulate a broad range of propagation phenomena across many disparate areas of physics, chemistry and biology, based on coherent interference of waves. At the quantum level, the quantized nature of light – the existence of photons – gives rise to bosonic interference effects that are completely counter-intuitive. Yet, to date, quantum network experiments remain very limited in terms of the number of photons, reconfigurability and, most importantly, network size. 

Here, we propose time-multiplexed optical networks, in combination with tailored multi-photon states as a new platform for large-scale quantum networks. Our approach allows us to emulate multi-particle dynamics on complex structures, specifically the role of bosonic interference, correlations and entanglement. 

To achieve large networks sizes, we will develop novel decoherence mitigation strategies: programmable noise, topologically protected quantum states and perpetual entanglement distillation. This approach will blend ideas from solid state physics, random media and quantum information and communication in order to pursue the following three objectives:
1. Demonstrate noise-assisted entanglement distribution
2. Demonstrate nonclassical states on topological structures
3. Demonstrate perpetual distillation of entanglement within a network
These objectives target the overall goal to understand the role of multi-particle quantum physics in complex, large-scale structures harnessing time-multiplexed photonic networks.","1963750","2017-07-01","2022-06-30"
"QuStA","Quantum State Assembler","SELIM CHANDRA DOMINIK JOCHIM","RUPRECHT-KARLS-UNIVERSITAET HEIDELBERG","The biggest challenge to using ultracold fermionic atoms to simulate strongly correlated phases is cooling the system to sufficiently low temperatures. The aim of QuStA is to tackle this challenge with a novel bottom-up approach and assemble many-body systems from individually prepared building blocks. This vision has come within reach through recent breakthroughs in our group in preparing and manipulating few-atom systems with unprecedented fidelity. Building on this experience, we will prepare multiple such few-atom systems and develop strategies to merge them adiabatically to form a many-body system.
Initially, we will focus on studying the physics of the Hubbard model, which is prototypical of strongly-correlated systems. Starting from many independently prepared double-well systems, we will assemble a finite lattice system of up to 10 x 10 sites with extremely low entropy. Since our approach will allow us full control over the parameters of the system - such as tunneling, interactions, and doping - we will be in the unique position to investigate the low-temperature phase diagram of the Hubbard model. Our quantum state assembly approach will also allow us to go beyond the Hubbard model and investigate the emergence of correlations in other interesting systems. In particular, we will take an innovative approach of preparing and merging itinerant spin chains to explore bi-layered lattice systems and spin ladders.
These experiments will have far-reaching implications beyond the field of ultracold atoms. Our systems will provide an ideal platform to benchmark theories on strongly correlated phenomena since it clearly surpasses the capabilities of modern classical computers. We envision that the insight gained from our experiments will lead to the understanding of exotic quantum phenomena, such as high-Tc superconductivity.","1958101","2017-04-01","2022-03-31"
"QUTE","Quantum Tensor Networks and Entanglement","Frank Paul Bernard Verstraete","UNIVERSITEIT GENT","One of the major challenges in theoretical physics is the development of systematic methods for describing and simulating quantum many body systems with strong interactions. Given the huge experimental progress and technological potential in manipulating strongly correlated atoms and electrons, there is a pressing need for such a better theory.
The study of quantum entanglement holds the promise of being a game changer for this question. By mapping out the entanglement structure of the low-energy wavefunctions of quantum spin systems on the lattice, the prototypical example of strongly correlated systems, we have found that the associated wavefunctions can be very well modeled by a novel class of variational wavefunctions, called tensor network states. Tensor networks are changing the ways in which strongly correlated systems can be simulated, classified and understood: as opposed to the usual many body methods, these tensor networks are generic and describe non-perturbative effects in a very natural way.
The goal of this proposal is to advance the scope and use of tensor networks in several directions, both from the numerical and theoretical point of view. We plan to study the differential geometric character of the manifold of tensor network states and the associated nonlinear differential equations of motion on it, develop post tensor network methods in the form of effective theories on top of the tensor network vacuum, study tensor networks in the context of lattice gauge theories and topologically ordered systems, and investigate the novel insights that tensor networks are providing to the renormalization group and the holographic principle.
Colloquially, we believe that tensor networks and the theory of entanglement provide a basic new vocabulary for describing strongly correlated quantum systems, and the main goal of this proposal is to develop the syntax and semantics of that new language.","1927500","2015-09-01","2020-08-31"
"RADDICS","Reliable Data-Driven Decision Making in Cyber-Physical Systems","Andreas KRAUSE","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","This ERC project pushes the boundary of reliable data-driven decision making in cyber-physical systems (CPS), by bridging reinforcement learning (RL), nonparametric estimation and robust optimization. RL is a powerful abstraction of decision making under uncertainty and has witnessed dramatic recent breakthroughs. Most of these successes have been in games such as Go - well specified, closed environments that - given enough computing power - can be extensively simulated and explored. In real-world CPS, however, accurate simulations are rarely available, and exploration in these applications is a highly dangerous proposition. 

We strive to rethink Reinforcement Learning from the perspective of reliability and robustness required by real-world applications. We build on our recent breakthrough result on safe Bayesian optimization (SAFE-OPT): The approach allows - for the first time - to identify provably near-optimal policies in episodic RL tasks, while guaranteeing under some regularity assumptions that with high probability no unsafe states are visited - even if the set of safe parameter values is a priori unknown. 

While extremely promising, this result has several fundamental limitations, which we seek to overcome in this ERC project. To this end we will (1) go beyond low-dimensional Gaussian process models and towards much richer deep Bayesian models; (2) go beyond episodic tasks, by explicitly reasoning about the dynamics and employing ideas from robust control theory and (3) tackle bootstrapping of safe initial policies by bridging simulations and real-world experiments via multi-fidelity Bayesian optimization, and by pursuing safe active imitation learning. 

Our research is motivated by three real-world CPS applications, which we pursue in interdisciplinary collaboration: Safe exploration of and with robotic platforms; tuning the energy efficiency of photovoltaic powerplants and safely optimizing the performance of a Free Electron Laser.","1996500","2019-01-01","2023-12-31"
"RADIOSTAR","Radioactivities from Stars to Solar Systems","Maria Anna LUGARO","MAGYAR TUDOMANYOS AKADEMIA CSILLAGASZATI ES FOLDTUDOMANYI KUTATOKOZPONT","RADIOSTAR will exploit radioactive nuclei produced by nuclear reactions inside stars and ejected by stellar winds and supernova explosions to fill the missing pieces of the puzzle of the origin of our Solar System: What were the circumstances of the birth of our Sun? Were they similar to those of the majority of other stars in our Galaxy, or were they special? Radioactive nuclei are the key to answer these questions because meteoritic analysis has proven that many of them were present at the time of the birth of the Sun. Their origin, however, has been so far elusive. RADIOSTAR steps beyond the state-of-the-art to answer these open questions by (i) combining the evolution of radioactive nuclei in the Galaxy and within molecular clouds and (ii) considering all the seventeen radionuclides of interest and all their stellar sources and analysing the effects of uncertainties in their stellar production. This will allow us to:
- Use the decay of radioactive nuclei produced by the chemical evolution of the Galaxy as a clock to measure the lifetime of the Sun’s parent molecular cloud prior to the Sun’s birth;
- Calculate the self-pollution of this molecular cloud from the ejecta of stars with lives shorter than such lifetime;
- Discover if such self-pollution can fully explain the abundances of radioactive nuclei present at the time of the birth of the Sun, or whether special conditions are required.
RADIOSTAR will also have a far-reaching impact on our understanding of exoplanetary systems because the heat produced by radioactivity affects the evolution of planetesimals, with implications for the amount of water on terrestrial planets in the habitable zone. RADIOSTAR will open a new window into research on the effect of radioactivity on the evolution of planetesimals outside our Solar System.","1726300","2017-09-01","2022-08-31"
"RadMag","Radical Solutions for Hysteresis in Single-Molecule Magnets","Richard Alan Layfield","THE UNIVERSITY OF SUSSEX","Single-molecule magnets (SMMs) display magnetic hysteresis that is molecular in origin, and these materials have huge potential to be developed as nano-scale devices. The big challenge is to create SMMs that function without the need for liquid-helium cooling.

This project will develop new SMMs that combine the strong magnetic anisotropy of lanthanide ions with a series of novel radical ligands. Our innovative SMMs will have controllable molecular and electronic structures, which will ultimately enable hysteresis at unprecedented temperatures.

Highly unusual di- and tri-metallic Ln-SMMs are proposed in which the metals are bridged by radicals with heavy Group 15 (phosphorus-bismuth) and Group 16 (sulphur-tellurium) donor atoms. Trimetallic SMMs will also be based on hexaazatriphenylene (HAT) radicals, and dimetallic SMMs will also be based on nindigo radicals, both of which are nitrogen-donor ligands.

The SMM field is dominated by systems with diamagnetic ligands. Our radical ligands have never been used in SMM studies: their diffuse unpaired spin provides a way of switching off the quantum tunnelling mechanisms that otherwise prevent hysteresis. We will exploit the rich electrochemistry of the target ligands: heavy p-block radicals have huge spin densities on the donor atoms; HAT radicals can have up to three unpaired electrons; reduced or oxidized nindigo radicals allow access to redox-switchable SMMs. In the HAT-bridged SMMs, the use of ligands with more than one unpaired electron is unprecedented. The heavy p-block ligands are themselves are novel.

The PI’s approach to SMMs has already established new directions in lanthanide chemistry and in molecular magnetism. He now proposes a new, radical approach to SMMs with potential to re-define the state of the art, and to extend the frontiers of a vibrant multi-disciplinary field. Achieving the aims will provide a major step towards using SMMs for applications at practical temperatures.","1584202","2015-09-01","2020-08-31"
"RAMSES","Reactivity and Assembly of Multifunctional, Stimuli-responsive Encapsulation Structures","Guido Heinrich Clever","TECHNISCHE UNIVERSITAT DORTMUND","In biochemical systems, combinations of specialized molecular entities are precisely arranged to give highly complex architectures. Sophisticated functionality, such as the selective chemical transformation of substrates in enzymes, emerges from the interplay of the individual components that are often grouped around a nanoscopic cavity. Control mechanisms based on the cooperative binding of signal substances regulate the enzyme’s action, and complicated feedback loops may apply.
Since the advent of supramolecular chemistry, scientists construct artificial systems with ever increasing complexity and functionality that promise to serve as the basis for future developments in bottom-up nanotechnology with applications in medicine (drug delivery), diagnostics, catalysis, material science and molecular photonics/electronics.
Self-assembly of functional entities with pre-programmed connectivities has produced an impressive line-up of nanoscopic architectures such as coordination cages that recognize and transform molecular substrates. Most of these systems are based on one sort of ligand, joined by one kind of metal ion. My group has reported a number of cages, each equipped with a unique, single function such as chirality, redox-activity, light-switching, allosteric regulation or endohedral binding sites.
While all these mono-functionalized cages contribute to the progress of supramolecular architecture, nature demonstrates that the key to the most sophisticated systems lies in multi-functionalized structures.
As breakthrough strategies for achieving this level of complexity with artificial systems we propose:
1) Heteroleptic coordination of ligands by a [Pd2Ligand4]-platform-specific way of steric fine-tuning
2) Biopolymer-inspired folding of a modular chain of covalently joined building blocks
Combined with our recent achievements in host-guest switching, we aim at adjustable receptors, controllable molecular reaction chambers and multifunctional photo/redox systems","1982500","2016-12-01","2021-11-30"
"RARE","Dipolar Physics and Rydberg Atoms with Rare-Earth Elements","Francesca Ferlaino","UNIVERSITAET INNSBRUCK","Strongly magnetic rare-earth atoms are fantastic species to study few- and many-body dipolar quantum physics with ultracold gases. Their appeal leans on their spectacular properties (many stable isotopes, large dipole moment, unconventional interactions, and a rich atomic spectrum). In 2012 my group created the first Bose-Einstein condensate of erbium and shortly thereafter the first degenerate Fermi gas. My pioneering studies, together with the result on dysprosium by the Lev´s group, have triggered an intense research activity in our community on these exotic species. 
The RARE project aims at converting complexity into opportunity by exploiting the newly emerged opportunity provided by magnetic rare-earth atoms to access fascinating, yet rather unexplored, quantum regimes. It roots into two innate properties of magnetic lanthanides, namely their large and permanent magnetic dipole moment, and their many valence electrons. With these properties in mind, my proposal targets to obtain groundbreaking insights into dipolar quantum physics and multi-electron ultracold Rydberg gasses:
1) Realization of the first dipolar quantum mixtures, by combining Er and Dy. With this powerful system, we aim to study exotic states of matter under the influence of the strong anisotropic and long-range dipole-dipole interaction, such as anisotropic Cooper pairing and superfluidity, and weakly-bound polar ErDy molecules.
2) Study of non-polarized dipoles at zero and ultra-weak polarizing (magnetic) fields, where the atomic dipole are free to orient. In this special setting, we plan to demonstrate new quantum phases, such as spin-orbit coupled, spinor, and nematic phases.
3) Creation of multi-electron ultracold Rydberg gases, in which the Rydberg and core electrons can be separately controlled and manipulated.  
This innovative project goes far beyond the state of the art and promises to capture truly new scientific horizons of quantum physics with ultracold atoms. 
for later","1992368","2016-07-01","2021-06-30"
"RAVEN","Rapid mass loss of debris covered glaciers in High Mountain Asia","Francesca PELLICCIOTTI","EIDGENOESSISCHE FORSCHUNGSANSTALT WSL","The research proposed uses an integrated data-modelling approach to elucidate the role that debris-covered glaciers play in the water cycle of High Mountain Asia (HMA) and establish how future HMA glacier and runoff will evolve. Debris-covered glaciers are of great significance for the hydrology of HMA, with large contributions to headwater streamflow. Despite this, their mass balance, hydrological role and future changes are poorly constrained, challenging model predictions of future water resources. Debris mantles insulate the ice and reduce ablation, but large-scale research indicates that HMA debris-covered glaciers are losing mass at rates similar to debris-free glaciers. This anomalous behaviour has profound implications for future glacier mass balance and runoff, but has not been reproduced with models, a fundamental limitation to a global assessment. I aim to establish that: 1) supraglacial cliffs and ponds are responsible for higher than expected mass losses of HMA debris-covered glaciers, because they act as windows of energy transfer through the debris; and that 2) their inclusion into models of glacier evolution will provide essential new estimates of glacier changes and future water availability in HMA. RAVEN will achieve these aims through combination of high-resolution satellite observations, field data and physically-based models in four sites along the Himalayan arc. This unprecedented setup captures the variety of climate and glaciers across HMA. Using satellite images I will investigate the spatial distribution and temporal evolution of cliffs and ponds; the insights will be used to develop physically-based models of cliff and pond ablation, which will be included in a glacio-hydrological model. Future glacier and runoff response will be projected using downscaled climate scenarios, allowing new estimates of glacier changes and future runoff for a data-starved region where millions of people depend on the water resources from glaciers and snow.","2000000","2018-05-01","2023-04-30"
"ReactiveFronts","Mixing interfaces as reactive hotspots of porous media flows: theoretical upscaling, experimental imaging and field scale validation","Tanguy Eugene Le Borgne","UNIVERSITE DE RENNES I","In porous media, mixing interfaces such as contaminant plume fringes or boundaries between water bodies create highly reactive localized hotspots of chemical and microbiological activity, whether in engineered or natural systems. These reactive fronts are characterized by high concentration gradients, complex flow dynamics, variable water saturation, fluctuating redox conditions and multifunctional biological communities. The spatial and temporal variability of velocity gradients is expected to elongate mixing interfaces and steepen concentration gradients, thus strongly affecting biochemical reactivity. However, a major issue with porous media flows is that these essential micro-scale interactions are inaccessible to direct observation. Furthermore, the lack of a validated upscaling framework from fluid- to system-scale represents a major barrier to the application of reactive transport models to natural or industrial problems. 
The ambition of the ReactiveFronts project is to address this knowledge gap by setting up a high level interdisciplinary team that will provide a new theoretical understanding and novel experimental imaging capacities for micro-scale interactions between flow, mixing and reactions and their impact on reactive front kinetics at the system scale. ReactiveFronts will develop an original approach to this long-standing problem; combining theoretical, laboratory and field experimental methods.The focus on reactive interface dynamics, which represents a paradigm shift for reactive transport modelling in porous media, will require the development of original theoretical approaches (WP1) and novel microfluidic experiments (WP2). This will form a strong basis for the study of complex features at increasing spatial scales, including the coupling between fluid dynamics and biological activity (WP4), the impact of 3D flow topologies and chaotic mixing on effective reaction kinetics (WP3), and the field scale assessment of these interactions (WP5).","1998747","2015-10-01","2020-09-30"
"REALISM","Reproducing EArthquakes in the Laboratory: Imaging, Speed and Mineralogy","Alexandre Jean-Marie Schubnel","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","We propose a simple idea: to reproduce earthquakes in the laboratory. Because earthquakes are spectacular examples of uncontrollable catastrophes, the opportunity to study them under controlled conditions in the laboratory is unique and is, in fact, the only way to understand the details of the earthquake source physics.

The aim of the project is interdisciplinary, at the frontiers between Rock Fracture Mechanics, Seismology, and Mineralogy.  Its ultimate goal is to improve, on the basis of integrated experimental data, our understanding of the earthquake source physics. We have already shown that both deep and shallow laboratory earthquakes are not mere `analogs’ of earthquakes, but are real events – though very small [Passelègue et al. 2013, Schubnel et al. 2013]. During laboratory earthquakes, by measuring all of the physical quantities related to the rupturing process, we will unravel what controls the rupture speed, rupture arrest, the earthquake rupture energy budget, as well as the common role played by mineralogy in both shallow and deep earthquakes. We will also perform some experiments on rock samples drilled from actual active fault zones. Our work will provide insights for earthquake hazard mitigation, constrain ubiquitously observed seismological statistical laws (Omori, Gutenberg-Richter) and produce unprecedented data sets on rock fracture dynamics at in-situ conditions to test seismic slip inversion and dynamic rupture modelling techniques. 

The new infrastructure we plan to install will reproduce the temperatures and pressures at depths where earthquakes occur in the crust as well as in the upper mantle of the Earth, with never achieved spatio-temporal imaging resolution to this day. This will be a valuable research asset for the European community, as it will eventually open the door to a better understanding of all the processes happening under stress within the first hundreds of kilometres of the Earth.","2748188","2016-10-01","2021-09-30"
"REALNANO","3D Structure of Nanomaterials under Realistic Conditions","Sara BALS","UNIVERSITEIT ANTWERPEN","The properties of nanomaterials are essentially determined by their 3D structure. Electron tomography enables one to measure the morphology and composition of nanostructures in 3D, even at atomic resolution. Unfortunately, all these measurements are performed at room temperature and in ultra-high vacuum, which are conditions that are completely irrelevant for the use of nanoparticles in real applications! Moreover, nanoparticles often have ligands at their surface, which form the interface to the environment. These ligands are mostly neglected in imaging, although they strongly influence the growth, thermal stability and drive self-assembly.

I will develop innovative and quantitative 3D characterisation tools, compatible with the fast changes of nanomaterials that occur in a realistic thermal and gaseous environment. To visualise surface ligands, I will combine direct electron detection with novel exit wave reconstruction techniques. 

Tracking the 3D structure of nanomaterials in a relevant environment is extremely challenging and ambitious. However, our preliminary experiments demonstrate the enormous impact. We will be able to perform a dynamic characterisation of shape changes of nanoparticles. This is important to improve thermal stability during drug delivery, sensing, data storage or hyperthermic cancer treatment. We will provide quantitative 3D measurements of the coordination numbers of the surface atoms of catalytic nanoparticles and follow the motion of individual atoms live during catalysis. By visualising surface ligands, we will understand their fundamental influence on particle shape and during self-assembly.

This program will be the start of a completely new research line in the field of 3D imaging at the atomic scale. The outcome will certainly boost the design and performance of nanomaterials. This is not only of importance at a fundamental level, but is a prerequisite for the incorporation of nanomaterials in our future technology.","2000000","2019-05-01","2024-04-30"
"RECAP","constRaining the EffeCts of Aerosols on Precipitation","Philip STIER","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","Precipitation is of fundamental importance so it is vital to understand its response to anthropogenic perturbations. Aerosols have been proposed to significantly affect precipitation [e.g. Ramanathan et al., 2001]. However, despite major research efforts evidence for a systematic aerosol effect on precipitation remains “ambiguous” [IPCC AR5, Stocker et al., 2013].

The vast majority of prior research [even an entire World Meteorological Organisation assessment report: Levin and Cotton, 2009] has taken a process-driven approach: trying to infer aerosol effects on precipitation through modelling/observing the chain of microphysical processes: from aerosols acting as cloud condensation / ice nuclei via cloud microphysics to precipitation formation of individual clouds. However, this relies on a complete understanding of a very complex and uncertain process chain and there exist no clear strategies to scale the response of individual clouds or cloud systems to larger scales. 

RECAP will break this deadlock, introducing a radically different approach to aerosol effects on precipitation. RECAP will systematically constrain the energetic control of aerosol effects on precipitation across scales, delivering the first comprehensive and physically consistent assessment of the effect of aerosols on precipitation across scales, uniting energetic and process-driven approaches.","2225713","2017-05-01","2022-04-30"
"RECEPT","Real-time precision tests of lepton universality","Vladimir GLIGOROV","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The Standard Model (SM) of Particle Physics is the most accurate available description of nature at microscopic scales, yet it is in fundamental contradiction with cosmological observations and models which describe the macroscopic universe. For this reason, it is postulated that the SM is incomplete, and that additional particles and/or forces are needed in order to describe both microscopic and macroscopic reality in a coherent and self-consistent manner. If such additional New Physics does exist, precision measurements of the ways in which SM particles transform into each other should simultaneously disagree with certain SM predictions, and agree with the given New Physics model.

Within this project, I will build a team of researchers dedicated to measuring one of the SM's most precise predictions, lepton universality (LU), with unprecedented experimental precision using the LHCb detector at the Large Hadron Collider (LHC) at CERN. In the current run, the LHC will deliver proton-proton collisions to LHCb until the end of 2018, allowing my team to make the world's most precise measurements of LU in the decays of beauty hadrons. Subsequently, the LHC will shut down for two years, and during this time the LHCb detector will be upgraded to allow it to collect five times more data per calendar year. This upgrade will allow my team to make the world's most precise measurements of LU in strange decays with data taken in 2021, significantly extending LHCb's physics programme.

To make these measurements possible and take full advantage of the LHCb upgrade, my team will also optimize the reconstruction of the upgraded LHCb detector, making it possible to fully reconstruct and analyze the data produced in the detector in real-time. This approach, completely novel in High Energy Physics, will not only improve the sensitivity to LU in strange decays by up to an order of magnitude, but greatly expand the general physics programme of the upgraded LHCb detector.","1986000","2017-06-01","2022-05-31"
"REINS","Responsible Intelligent Systems","Johannes Maria Broersen","UNIVERSITEIT UTRECHT","I propose to develop a formal framework for automating responsibility, liability and risk checking for intelligent systems. The computational checking mechanisms have models of an intelligent system, an environment and a normative system (e.g., a system of law) as inputs; the outputs are answers to decision problems concerning responsibilities, liabilities and risks. The goal is to answer three central questions, corresponding to three sub-projects of the proposal: (1) What are suitable formal logical representation formalisms for knowledge of agentive responsibility in action, interaction and joint action? (2) How can we formally reason about the evaluation of grades of responsibility and risks relative to normative systems? (3) How can we perform computational checks of responsibilities in complex intelligent systems interacting with human agents? To answer the first two questions, we will design logical specification languages for collective responsibilities and for probability-based graded responsibilities, relative to normative systems. To answer the third question, we will design suitable translations to related logical formalisms, for which optimized model checkers and theorem provers exist. Success of the project will hinge on combining insights from three disciplines: philosophy, legal theory and computer science.","1968057","2014-03-01","2019-02-28"
"REMINISCENCE","REflection Matrix ImagiNg In wave SCiENCE","Alexandre AUBRY","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","In wave imaging, we aim at characterizing an unknown environment by actively probing it and then recording the waves reflected by the medium. It is, for example, the principle of ultrasound imaging, optical coherence tomography for light or reflection seismology in geophysics. However, wave propagation from the sensors to the focal plane is often degraded by the heterogeneities of the medium itself. They can induce wave-front distortions (aberrations) and multiple scattering events that can strongly degrade the resolution and the contrast of the image. Aberration and multiple scattering thus constitute the most fundamental limits for imaging in all domains of wave physics. 

However, the emergence of large-scale sensors array and recent advances in data science pave the way towards a next revolution in wave imaging. In that context, I want to develop a universal matrix approach of wave imaging in heterogeneous media.  Such a formalism is actually the perfect tool to capture the input-output correlations of the wave-field with a large network of sensors. This matrix approach will allow to overcome aberrations over large imaging volumes, thus breaking the field-of-view limitations of conventional adaptive focusing methods. It will also lead to the following paradigm shift in wave imaging:  Whereas multiple scattering is generally seen as a nightmare for imaging, the matrix approach will take advantage of it for ultra-deep imaging. Besides direct imaging applications, this project will also provide a high-resolution tomography of the wave velocity and a promising characterization tool based on multiple scattering quantification. Based on all these advances, the ultimate goal of this project will be to develop an information theory of wave imaging. Throughout this project, I will apply all these concepts both in optics (for in-depth imaging of biological tissues), ultrasound imaging (for medical diagnosis) and seismology (for monitoring of volcanoes and fault zones).","1999705","2019-06-01","2024-05-31"
"ReNewHydrides","Renewable Hydride Donors and Their Utilization in Catalytic Reduction and Deoxygenation Reactions","Thibault CANTAT","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","The production of chemicals, plastics, solvents, etc., contributes to 20 % of the Gross Value Added in the EU, where sales have doubled over the last 20 years. Despite this dynamism, the chemical industry is energy intensive and 95 % of organic chemicals derive from fossil oil and natural gas. To sustain the growth of this industry, the replacement of fossil feedstocks with renewable carbon, phosphorus and silicon sources should be encouraged. Nonetheless, such a sourcing shift represents a paradigm shift: while the development of petrochemistry has relied on the selective oxidation of hydrocarbons, the conversion of renewable feedstocks (e.g. CO2, phosphates, silicates or biomass) requires efficient reduction methods and catalysts to overcome their oxidized nature.
Today, no reduction method meets the criteria for a versatile and energy efficient reduction of oxidized feedstocks and the aim of the ReNewHydrides project is to design novel reductants and catalytic reactions to achieve this important aim. At the crossroads of main group element chemistry, organometallic chemistry, electrochemistry and homogenous catalysis, I propose to develop innovative and recyclable reductants based on silicon and boron compounds, and to utilize them to tackle catalytic challenges in the reduction of C–O,  P–O and Si–O bonds. The overarching principle is to build a balanced synthetic cycle, where the electrochemical reduction of functionalized and oxidized substrates is ensured by silicon and boron based hydride donors, with a high energy efficiency and selectivity.
This project will foster innovative routes in the utilization of renewable carbon, phosphorus and silicon feedstocks. It is therefore of high risk, but ultimately extremely rewarding. The results will also also open-up new horizons in silicon and boron chemistry and they will finally serve the scientific community involved in the fields of organic and inorganic chemistry, sustainable chemistry and energy storage.","1999838","2019-10-01","2024-09-30"
"RENOS","Rare earth doped novel on-chip sources","Sonia Maria Garcia blanco","UNIVERSITEIT TWENTE","The development of compact, low cost, power efficient, tunable lasers and frequency combs spanning large bandwidths, exhibiting excellent output beam characteristics, such as the ones achieved in solid-state sources, and expanding the wavelength ranges of by typical solid-state materials, will greatly benefit application fields such as optical sensing, spectroscopy, metrology and telecommunications.
In this research program, I propose to study the generation of novel frequencies and frequency combs by stimulated Raman scattering and four-wave mixing in high-contrast waveguides in rare-earth-doped potassium double tungstates materials (RE:KYW) by exploiting both their excellent optical gain properties as well as their large non-linear index of refraction.
We have recently demonstrated an enormous modal gain in an Yb3+:KYW waveguide amplifier (i.e., ~1000 dB/cm) as well as very efficient (>80%) high power (~1.6 W) laser generation in a Tm3+:KYW waveguide, with broad tunability. However, the low-contrast waveguides utilized have a large modal area (>25 um2) and high bend losses. High-contrast waveguides in RE:KYW have negligible bend losses for radii over 5 um. The introduction of a thin metal layer underneath the dielectric core reduces the total bend losses for very sharp bends. The higher field intensity together with the use of resonant structures (i.e., microrings), makes this waveguide platform ideal to study non-linear phenomena. 
The great technological challenges lie on the development of very low-loss microring resonators with highly controlled vertical coupling to passive bus waveguides, with the correct chromatic dispersion and very confined modal field and their combination with plasmonics.
A successful development of this technology will pave the road to great scientific advancements as well as a new generation of compact on-chip solid-state laser sources that will open new horizons in the aforementioned application fields.","2000000","2015-10-01","2020-09-30"
"REPLICOLL","Self-replicating Colloidal Assemblies","Alexander Andreas Reinhard Klaus Böker","FRAUNHOFER GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V.","Self-replication is the preeminent property of living systems and natural materials. Nature builds and repairs by self-replication. Purely synthetic materials so far lack this important ability. An indispensable prerequisite is the multi-directional control of interactions between the building blocks of materials. In order to generate colloidal building blocks, which are able to self-replicate in a non-biological two-step process, i.e. without the use of DNA, we propose to create a new class of patchy colloidal particles bearing three patches of two different chemical functionalities. The new production process will yield precise control over the patch location and chemistry and thus also gives particles that go well beyond known ABA- or ABC-type Janus particles. 
For synthesis and replication of colloidal superstructures (e.g. particle strands), the colloids will carry two patches that allow irreversible crosslinking of the self-assembled master-strand and one patch that serves for the recognition and reversible attachment of the single particles along the colloidal chain for the replication process. Thus, in analogy to the polymerase chain reaction (PCR) for DNA replication, single tri-valent colloids will reversibly attach to the colloidal master strand, followed by inter-particle crosslinking of the newly formed strand, which then is detached form the master by opening the bonds between the strands. The released chain copy will then serve as template for further replication processes in which the number of copies will double after each cycle.
With this approach we aim to establish a technology platform for the production of sufficient quantities of simple and complex colloidal assemblies, where a well-defined or complex master-structure can only be produced and isolated in small amounts due to a difficult and tedious synthetic procedure.","1907325","2015-07-01","2020-06-30"
"RESCUE","REsistive-Switch CompUting bEyond CMOS","Daniele IELMINI","POLITECNICO DI MILANO","Digital computers rely today on CMOS (complementary metal-oxide-semiconductor) technology, which improves its performance every generation thanks to the Moore’s law of downscaling. As CMOS transistor size approaches few nm, alternative logic switches with better scaling capability must be identified to prolong Moore’s law beyond CMOS. Among the emerging switching concepts, resistive switching (RS) devices can change their resistance by electrically-induced redox reactions. RS provides the basis for the resistive memory (ReRAM) technology which is currently investigated as future computer memory and storage technology. The objective of this project is to design, develop and demonstrate a novel computing paradigm based on RS devices. The project will pursue this objective at 3 levels of increasing complexity, namely the device fabrication, the design of new logic gates and the demonstration of computing circuits. RS logic will be finally compared to CMOS and other approaches to identify the strength and the potential applications of RS logic in the computing scenario.","1998113","2015-08-01","2020-07-31"
"RESOURCE Q","Efficient Conversion of Quantum Information Resources","Matthias Christandl","KOBENHAVNS UNIVERSITET","This proposal explores the power of quantum information in two respects. The first is the technological power of quantum information in a communication infrastructure, and the second is its descriptive power in many-particle quantum systems. My point of departure is to view quantum information as a resource that can be processed and converted.
In quantum communication, a famous resource conversion is provided by the quantum teleportation protocol, which allows us to send one quantum bit (1 qubit) through the transmission of two classical bits (2 cbits) and the use of one entangled pair of quantum bits (1 ebit):
  1 ebit + 2 cbits > 1 qubit.
Casting quantum protocols in such resource inequalities has proven useful, since the algebraic manipulation of inequalities results in new protocols, but this approach has hitherto largely been limited to point-to-point communication. It is the first goal of this project to overcome this limitation and characterise resource conversion in larger quantum networks. This will result in more efficient communication protocols that will have an impact on the use and design of quantum communication networks, which are currently being built around the globe.
A quantum network involving distant communicating labs is mirrored at the small scale by a set of interacting quantum particles. The quantum state arising from pairwise interactions can be strongly entangled, with an underlying entanglement structure given by a graph with entangled pairs along the edges. There is a surprising and close connection between such entanglement structures and tensor research in the context of algebraic complexity theory. The second goal of the project is to exploit this connection and characterise the resource conversion of entanglement structures. The research will lead to more efficient tensor network representations of many-particle quantum states, and to progress on the computational complexity of matrix multiplication, a long-standing unsolved problem.","1953750","2019-12-01","2024-11-30"
"RESPONDER","Resolving subglacial properties, hydrological networks and dynamic evolution of ice flow on the Greenland Ice Sheet","Poul Christoffersen","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","The Greenland Ice Sheet is losing mass at a growing rate and has since 2010 caused sea level rise of 1 mm/year. The most severe changes occur in the drainage basins of marine-terminating glaciers, which flow rapidly and drain 88% of the ice sheet. The latest report by the Intergovernmental Panel on Climate Change concluded that the widespread acceleration of these glaciers in recent years was a response to interaction with the ocean and unrelated to basal lubrication of ice flow; yet, observations have since shown that many of these glaciers respond to the growing volume of surface meltwater, which reaches the bed when surface lakes drain. This basal lubrication mechanism is unknown, but exhibits contrasting control on ice flow at the coast and in the interior where surface melting increasingly forms lakes. This lack of vital knowledge is a major source of uncertainty in the current generation of ice sheet models used to predict sea level change.

The fundamental goal of RESPONDER is to understand how hydrological networks at the base of the Greenland Ice Sheet evolve over seasons and over multiple years, and how this evolution impacts on ice flow in the interior and at the coast. The project has the following aims:
AIM 1 is to identify glaciological ‘hotspots’ and sites for subglacial access drilling and borehole exploration by tracking hydrological pathways beneath Store Glacier, a large marine-terminating glacier in Uummannaq Fjord, using novel geophysical imaging techniques and unmanned aerial vehicles (UAVs).
AIM 2 is to observe and quantify the hydrological networks of Store Glacier while measuring basal slip and strain within ice with probes and sensors installed in boreholes drilled at ‘coastal’ and ‘interior’ targets.
AIM 3 is to predict the co-evolution of ice flow and hydrological networks in the Store Glacier drainage basin, and assess the vulnerability of the Greenland Ice Sheet, by integrating field observations in state-of-the-art ice sheet models.","2443800","2016-10-01","2021-09-30"
"RetroNets","Reverse Engineering Gene Regulatory Networks","Sebastian Josef MAERKL","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Gene regulatory networks (GRNs) are an important cellular signal processing mechanism for translating input signals into
appropriate phenotypes by modulating expression of the genome. The quantitative details of how cells process information
through GRNs are still poorly understood, but of central importance in a large number of biological processes. Considerable
progress has been made in mapping the topology of GRNs and more recently in deciphering the relationship between
promoter sequence and function. Nonetheless, it is not yet possible to computationally predict the output of most native
promoters, nor is it trivial to build promoters that integrate signals in a novel and predictive manner. Developing a
quantitative understanding of transcriptional regulation, ultimately leading to the ability to predict entire GRNs will be a
significant achievement and a prerequisite for our ability to engineer biological systems.
I propose a multi-disciplinary approach incorporating biology, engineering, and computational modelling to improve our
quantitative understanding by reverse engineering GRNs in S. cerevisiae. My research group has developed a powerful set
of unique, high-throughput microfluidic technologies that enable the quantitative analysis of GRNs in vitro and in vivo.
Specifically I propose to quantitatively investigate the yeast phosphate regulatory network and to develop a master model
capable of predicting output of the network under various inorganic phosphate concentrations, to develop novel approaches
for modulating GRNs using engineered Zn-finger transcription factors (TF) and CRISPR/Cas, to link GRN output to fitness
in order to develop an understanding of how networks are optimized and evolve, and to reverse engineer an exact
functional copy of the native phosphate regulatory network with orthogonal components.","1993858","2017-04-01","2022-03-31"
"RiboDisc","Discovery of novel orphan riboswitch ligands","Jörg Hartig","UNIVERSITAT KONSTANZ","Riboswitches are mRNA-based gene-regulatory elements triggered by direct interactions with small molecular ligands. They are exciting targets for novel antibiotic strategies. Many putative riboswitches have been identified using bioinformatics. However, ligand identification is getting more complicated since many motifs are not expected to be involved in simple feedback regulation mechanisms. For such “classical” riboswitches ligands have been assigned in the past based on testing metabolites selected by educated guesses guided by the associated gene contexts. We are convinced that this approach limits the identification of riboswitches that play regulatory roles in more complex bacterial processes such as virulence, detoxification, communication, and life style adaptations. Within this project, new riboswitch classes will be identified and characterized, paving the way for the development of antibiotics with novel modes of action.

We will establish a systematic, robust and unbiased approach for identifying intracellular RNA ligands by fishing small molecules from lysates as well as screening fractionated cellular extracts. The methodology shows great potential for assigning novel riboswitch classes since in preliminary experiments we have successfully isolated a small molecular activity that specifically triggers the ykkC orphan riboswitch motif. A range of analytical and preparative methods will be applied in order to identify the nature of this and further activities. By synthesizing ligands and derivatives thereof we will scout the antibiotic potential of novel riboswitch ligands. The proposed research is highly relevant for one of the major biomedical challenges of the coming decades: Since riboswitches are effective antibacterial targets, the identification of novel riboswitch / ligand interactions has immediate implications for establishing future antibiotic strategies necessary to keep in check the progressing problem of bacterial drug resistance.","1918600","2016-04-01","2021-03-31"
"RIFT-O-MAT","Magma-Assisted Tectonics: two-phase dynamics of oceanic and continental rifts","Richard Katz","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","There is widespread recognition of the central role of magma at divergent plate boundaries. However in almost all models, magmatism is treated as a by-product and is excluded from the dynamics. A thorough understanding of continental rifts and mid-ocean ridges, which are fundamental to plate tectonics, requires consistent models of magma intrusion into the lithosphere and crust. This is a proposal to develop models in which magmatism is an integral thermal, chemical, and mechanical component, and hence to better understand the basic functioning of plate tectonics.

Diverse insight and constraints on divergent boundaries come from decades of careful observation. But lacking adequate models of magmatism, old and new issues remain unresolved. For continents, a comparison of available tectonic force to inherent lithospheric strength indicates that magmatic intrusion is required to weaken plates sufficiently for rifting. For mid-ocean ridges, bathymetric analysis suggests that modest variation in the magma supply may be recorded by crustal emplacement and faulting. These phenomena cannot be understood and modelled in the context of single-phase flow. The proposed work breaks new ground in applying a theory that is innately two-phase; one where interpenetrating liquid and solid continua are governed by conservation of mass, momentum, and energy.

This theory will incorporate a viscoelastic-plastic/frictional rheology, modelling rock failure under tensile effective stress. Hence it will allow for dikes that interact consistently with faults. The open-source code will be validated by comparison with measurements of surface deformation/relief, products of seismic tomography, and geochemistry of lavas. In collaboration with distinguished project partners, models will be tailored to investigate the East African Rift System and Juan de Fuca ridge. Outreach will support mathematics in Africa. The proposed research will transform our understanding of magma-assisted tectonics.","2000000","2019-03-01","2024-02-29"
"RIGIDITY","Rigidity and classification of von Neumann algebras","Stefaan Vaes","KATHOLIEKE UNIVERSITEIT LEUVEN","""Sorin Popa's deformation/rigidity theory has lead to an enormous progress in our understanding of von Neumann algebras coming from discrete groups and their actions on probability spaces. In a five year long collaboration with Sorin Popa, we solved many long-standing open problems in this area, including superrigidity theorems for group measure space II_1 factors, results on the possible fundamental groups of II_1 factors, and uniqueness theorems for Cartan subalgebras.

In the first part of the project, we want to establish new unique Cartan decomposition theorems for II_1 factors coming from hitherto intractable groups. Using methods coming from Lie groups, ergodic theory and geometric group theory, we want to reach such results for lattices in higher rank simple Lie groups, and for countable groups with nonvanishing L^2-Betti numbers. An important intermediate step will be the unique Cartan decomposition of Bernoulli crossed products.

Secondly we want to prove classification theorems for type III factors that are equally strong as the existing results for the type II_1 case. This includes a complete classification of the noncommutative Bernoulli shifts of the free groups and will require an intricate combination of Tomita/Takesaki and deformation/rigidity theory.

The methods developed so far bring within reach an attack on two of the most important open problems in operator algebras and functional analysis: the free group factor problem and Connes's rigidity conjecture. The exact progress on these problems is of course unforeseeable, but it is sure that the research on these problems will lead to an even deeper interaction between diverse areas of mathematics as operator algebras, group theory, functional analysis, ergodic theory, and descriptive set theory. Intermediate goals are the classification of natural classes of group von Neumann algebras, including those coming from Baumslag-Solitar groups, wreath product groups, and other families of discrete groups.""","1446660","2014-07-01","2019-06-30"
"Rotational Waves","Controlling and resolving rotational quantum states in a molecule-surface collision: Matter-wave magnetic interference experiments with ground state molecules.","Gil Nathan ALEXANDROWICZ","SWANSEA UNIVERSITY","The interaction between a molecule and a solid surface is fundamental to a huge variety of research fields and applications, ranging from industrial heterogeneous catalysis and atmospheric chemistry on ice particles, to ultra-cold astrochemical reactions on cosmic dust. One molecular property that is essential for molecule surface interactions, but also particularly difficult to control and resolve, is the orientation & alignment of the rotational axis of the molecule i.e. the quantum rotation projection states. The existing paradigm is that control over this molecular property can be obtained either by photo-excitation schemes and/or by deflecting experiments using strong electric or magnetic fields. Using these approaches valuable insight was obtained, and the crucial role the rotation projection states have on the outcome of molecule-surface collision was demonstrated. However, the two approaches mentioned above can only be applied to a very small sub-group of systems, (typically on excited/paramagnetic species). Here, we propose a completely different approach which utilizes the rotational magnetic moment, which is a general molecular property, to control and resolve the projection rotation states of ground-state molecules. Our matter-wave approach involves passing a molecular beam through a specific series of magnetic fields, where the different wave components interfere and produce Rabi-oscillations characteristic of the molecular wave function before and after scattering. We present proof-of-principle results demonstrating the validity of our general approach, and describe the novel molecular interference and molecular spin echo measurements we will perform to obtain the much-awaited experimental benchmarks in this field.","2230400","2018-08-01","2023-07-31"
"RSM","Rich, Structured Models for Scene Recovery, Understanding and Interaction","Carsten Curt Eckard Rother","RUPRECHT-KARLS-UNIVERSITAET HEIDELBERG","Computer vision has gained considerable momentum in recent years – both in industry and academia. There seems to be a spirit that the time is ripe to realize grand goals and to bring computer vision from the lab into real life. But is a vision system already as good as a human is? The answer is: “Unfortunately, not yet.” Given a single image, a child can describe the objects and their relationships in a much more detailed manner than any computer can. Also, humans can quite effortlessly “visually extract” an object from its background, even in the presence of fine details such as hair. Computers cannot yet achieve this automatically. But, for many real-world applications it is absolutely necessary to reach such levels of rich output, accuracy, quality, robustness, and system autonomy. In this proposal we try to get closer to this overarching goal. We believe that the key to success is a richer representation. Here “rich” stands for rich, detailed output, modelling rich, physical and semantic constraints, and learning rich, statistical relations between different aspects of a scene. Towards this end we propose the Rich Scene Model (RSM), which is one joint statistical, structured model of many physical and semantic scene aspects that can take full advantage of the synergy effect between all its components. This effort goes beyond previous attempts, in many respects. However, it is simple to say “We will build the best ever joint, rich scene model”. Accordingly, the crux of this proposal is to design novel models, learning and inference techniques to make the RSM a reality. This proposal addresses not only theoretical questions such as, “What can we infer from a few images of a dynamically changing 3D scene?”, and “Is our RSM rich enough to make statistical learning “work better” than deterministic learning?” we also propose a model that can give new forms of output, better deal with challenging real world scenarios, and can adapt nicely to human and application needs","1998281","2015-10-01","2020-09-30"
"RSPDE","Regularity and Stability in Partial Differential Equations","Alessio FIGALLI","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","""This project focuses on several problems in Partial Differential Equations (PDEs) and the Calculus of Variations. These include:

- Optimal transport and Monge-Ampère equations.
In the last 30 years, the optimal transport problem has been found to be useful to several areas
of mathematics. In particular, this problem is related to Monge-Ampère type equations, and understanding the regularity properties of solutions to such equations is an important question with applications to several other fields.

- Stability in functional and geometric inequalities.
Whether a minimizer of some inequality is """"stable'' in some suitable sense
is an important issue in order to understand and/or predict the evolution in time of a physical phenomenon.
For instance, quantitative stability results allow one to quantify the rate of convergence of a physical system to some steady state, and they can also be used to understand how much the system changes under the influence of exterior factors.

- Di Perna-Lions theory and PDEs.
The study of transport equations with rough coefficients is a very active research area. In particular, recent developments have been used to obtain new results on the semiclassical limit for the Schr\""""odinger equation and on the Lagrangian structure of transport equations with singular vector-fields (for instance, the Vlasov-Poisson equation). 

These problems, although apparently different, are actually deeply interconnected.
The PI aims to use his expertise in partial differential equations and geometric measure theory to introduce ideas and techniques that will lead to new groundbreaking results.
""","1742428","2017-02-01","2022-01-31"
"RTFT","Random Tensors and Field Theory","Razvan-Gheorghe GURAU","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The large-N limit in field theory restricts the perturbative expansion to specific classes of Feynman diagrams. For vectors the restricted class of diagrams is simple, and one can analytically solve the models. For matrices, the large-N limit is simple in zero dimensions but is exceedingly complicated in higher dimensions. I proved that going one step up in the rank and considering tensor fields things simplify again, but not to the level of the vectors. I established the 1/N expansion of random tensors and discovered a new (and the last possible) universality class of large-N field theories: the melonic theories. As pointed out by Witten, these theories yield nontrivial, strongly coupled conformal field theories in the infrared. The aim of this project is to perform an exhaustive study of the melonic universality class of tensor field theories and their infrared conformal field theories. I aim to extend maximally the melonic universality class, study the renormalization group flow in melonic theories and apply them to the AdS/CFT correspondence and quantum critical metals.","1672084","2019-09-01","2024-08-31"
"RustBelt","Logical Foundations for the Future of Safe Systems Programming","Derek Dreyer","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","""A longstanding question in the design of programming languages is how to balance safety and control. C-like languages give programmers low-level control over resource management at the expense of safety, whereas Java-like languages give programmers safe high-level abstractions at the expense of control.

Rust is a new language developed at Mozilla Research that marries together the low-level flexibility of modern C++ with a strong """"ownership-based"""" type system guaranteeing type safety, memory safety, and data race freedom. As such, Rust has the potential to revolutionize systems programming, making it possible to build software systems that are safe by construction, without having to give up low-level control over performance.

Unfortunately, none of Rust's safety claims have been formally investigated, and it is not at all clear that they hold. To rule out data races and other common programming errors, Rust's core type system prohibits the aliasing of mutable state, but this is too restrictive for implementing some low-level data structures. Consequently, Rust's standard libraries make widespread internal use of unsafe blocks, which enable them to opt out of the type system when necessary. The hope is that such unsafe code is properly encapsulated, so that Rust's language-level safety guarantees are preserved. But due to Rust's reliance on a weak memory model of concurrency, along with its bleeding-edge type system, verifying that
Rust and its libraries are actually safe will require fundamental advances to the state of the art.

In this project, we aim to equip Rust programmers with the first formal tools for verifying safe encapsulation of unsafe code. Any realistic languages targeting this domain in the future will encounter the same problem, so we expect our results to have lasting impact. To achieve this goal, we will build on recent breakthrough developments by the PI and collaborators in concurrent program logics and semantic models of type systems.
""","1946250","2016-04-01","2021-03-31"
"RYD-QNLO","Quantum nonlinear optics through Rydberg interaction","Sebastian HOFFERBERTH","SYDDANSK UNIVERSITET","Optical photons, for all practical purposes, do not interact. This fundamental property of light forms the basis of modern optics and enables a multitude of technical applications in our every-day life, such as all-optical communication and microscopy. On the other hand, an engineered interaction between individual photons would allow the creation and control of light photon by photon, providing fundamental insights into the quantum nature of light and allowing us to harness non-classical states of light as resource for future technology. Mapping the strong interaction between Rydberg atoms onto individual photons has emerged as a highly promising approach towards this ambitious goal. In this project, we will advance and significantly broaden the research field of Rydberg quantum optics to develop new tools for realizing strongly correlated quantum many-body states of photons. Building on our successful work over recent years, we will greatly expand our control over Rydberg slow-light polaritons to implement mesoscopic systems of strongly interacting photons in an ultracold ytterbium gas. In parallel, we will explore a new approach to strong light-matter coupling, utilizing Rydberg superatoms made out of thousands of individual atoms, strongly coupled to a propagating light mode. This free-space QED system enables strong coupling between single photons and single artificial atoms in the optical domain without any confining structures for the light. Finally, we will experimentally realize a novel quantum hybrid system exploiting the strong electric coupling between single Rydberg atoms and piezo-electric micro-mechanical oscillators. Building on this unique coupling scheme, we will explore Rydberg-mediated cooling of a mechanical system and dissipative preparation of non-classical phonon states. The three complementary parts ultimately unite into a powerful Rydberg quantum optics toolbox which will provide unprecedented control over single photons and single phonons.","1993793","2018-05-01","2023-04-30"
"S-CAGE","Smart Coordination Polymers with Compartmentalized Pockets for Adaptive Guest Entrance","Guillermo MINGUEZ ESPALLARGAS","UNIVERSITAT DE VALENCIA","The S-CAGE project aims to develop a new generation of crystalline solids with periodically-organized discrete voids, or compartments, that would benefit from the combination of the high stability and robustness of dense materials with the structural diversity and versatility (and therefore large applicability) of open frameworks. These coordination polymers (CPs) will be capable of interacting with guest species in the absence of large channels or permanent pores due to the presence of dynamic entrances. This could open new horizons towards the design of unprecedented materials as an enhanced interplay between the guests and the frameworks will be achieved resulting from the confined space of the compartmentalized pockets.

The main goals of S-CAGE will be:

i) Chemical design of compartmentalized 1D, 2D and 3D coordination polymers. These materials will be designed in such a way that they will provide ideal room to accommodate different guest molecules, which can be easily tuned depending on the target guest.

ii) Advanced structural characterization, including modern diffraction studies under pressure of gas and volatile guests. This strategy will provide unequivocal prove of the location of the guest molecules in the internal voids and gain insights of the mechanism of entrance. The direct visualization of the modes of interactions of different gases will permit a deep comprehension of the nature of their interaction.

iii) Gas separation studies. My goal will be the development of materials that could specially serve for gas separation and improve the performances of zeolites and MOFs by implementation of dynamic entities into the framework.

iv) Sensing capabilities through changes in magnetic properties. The chemical design followed in S-CAGE will result in magnetic CPs with confined spaces which should enhance the interaction of the guest molecules with the framework, and thus a change in their magnetism is expected.","1998750","2017-05-01","2022-04-30"
"S4F","Setting the Stage for Solar System Formation","Jes Kristian Jørgensen","KOBENHAVNS UNIVERSITET","Low-mass stars like our Sun are formed in the centers of dark clouds of dust and gas that obscure their visible light. Deep observations at infrared and submillimeter wavelengths are uniquely suited to probe the inner regions of these young stellar objects and unravel their structures, as well as the physical and chemical processes involved. These earliest stages are particularly interesting because the properties of the deeply embedded objects reflect the star formation process itself and how it relates to its environment. It is for example during this stage that the final mass of the star and the properties of its disk – and thus ability to form planets – are determined. It is also during these stages that the first seeds for the chemical evolution of the protoplanetary disk are planted and where some complex organic, possibly prebiotic, molecules may be formed. I here apply for an ERC Consolidator Grant that will support an ambitious program to map the physics and chemistry of the early Solar System. The proposed research program intends to use new high resolution, high sensitivity observations from the Atacama Large Millimeter Array (ALMA) - including a number of recently approved large programs – coupled to state-of-the-art radiative transfer tools and theoretical simulations to address some of the key questions concerning the physics and chemistry of the earliest stages of the Solar System: How is the chemistry of the earliest protostellar stages related to the physical structure and evolution of the young stellar object and its surrounding environment? Which complex organic molecules are present in the inner regions of low-mass protostars? What are the chances the rich chemistry of the earliest stages is incorporated into planetary systems such as our own?","1999659","2015-08-01","2020-07-31"
"SARF","Single-Atom Radio Frequency Fingerprinting","Stefan MUELLEGGER","UNIVERSITAT LINZ","""Precise investigation tools for analyzing and manipulating matter down to the scale of single atoms are the eyes, ears and fingers of nanoscience and -engineering. SARF takes these nano-analytical """"senses"""" one next step beyond the present state of the art. SARF is breaking new grounds by enabling spectral fingerprinting of single atoms for elemental identification and intra-molecular chemical analytics with sub-nanometer spatial resolution and operating in vacuum- as well as liquid-phase environments. This presently impossible combination of analytical capabilities simultaneously in a single tool is highly desirable to many diverse fields of nanoscience and technology, where decisive functionality originates from single individual atoms and molecules (e.g. spintronics, sensors, catalysis, medicinal drug development, surface physics, biology, etc.). SARF realizes resonance spectroscopy at giga-Hertz frequencies combined with scanning tunneling microscopy for specific single-atom fingerprinting. Characteristic resonance signals are locally detectable by the probe tip as small changes of conductance that indeed enable elemental and chemical identification. SARF conceives and develops single-atom fingerprinting on a manifold of different systems including magnetic and nonmagnetic metals, semiconductors and, exemplarily, tetrapyrrole-based metal-organic functional molecules. If successful, SARF will provide a controlled, versatile, fast and readily applicable """"atom-by-atom"""" matter analysis, where single atoms are selected and identified one by one in real time and space.""","1998000","2018-04-01","2023-03-31"
"SARLEP","Simulation and Understanding of the Atmospheric Radical Budget for Regions with Large Emissions from Plants","Hendrik Fuchs","FORSCHUNGSZENTRUM JULICH GMBH","Atmospheric pollutants emitted by natural and anthropogenic sources influence significantly the quality of life on our planet. Their removal in the atmosphere is controlled by their reactions with photochemically produced hydroxyl radicals. Recent findings from experimental studies and quantum-chemical calculations suggest that an important part of atmospheric radical chemistry, which is directly linked to the self-cleansing ability of our atmosphere, has been overlooked. This causes considerable uncertainty in our understanding of the couplings between the biosphere, atmospheric chemistry and climate. The greatest impact of this lack of understanding has been found for regions with large emissions of organic compounds from plants in remote or rural areas.
Within this project, the oxidation of organic compounds will be comprehensively investigated for the most important, biogenic organic compounds. The innovative experimental approach will quantify the radical destruction and production rates in experiments in the unique atmosphere simulation chamber SAPHIR at the host institution. These experiments aim to close the gap between laboratory and field studies. The advantages are: (1) Experiments will be conducted under atmospherically relevant conditions. (2) Radical recycling efficiency will be quantified for the entire chemical system, not just for single reactions. (3) The complexity of the chemical system studied will be increased from single compounds to natural plant emissions.
New innovative instrumentation will be developed for accurate and precise measurements of radical species and oxidized organic compounds. These are also of great interest beyond this project. The results of this project will improve our understanding of atmospheric radical chemistry required for accurately predicting the atmospheric radical budget, the formation of harmful secondary pollutants such as ozone, acids and aerosol and the lifetime of greenhouse gases affecting climate change.","1850000","2016-03-01","2021-02-28"
"SCALE-HALO","Multiscale chemical engineering of functional metal halides","Maksym KOVALENKO","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","SCALE-HALO proposes a research program that will advance the development of highly luminescent molecular and solid-state compounds by focusing on the emerging, vast, and rather underexplored compositional and structural spaces comprised of metals and halogens, i.e., metal halides (MHs). SCALE-HALO is motivated by the eventual utility of MHs as versatile photonic sources in modern appliances (e.g., displays and lighting) and in future quantum technologies. The recent success of lead halide perovskites in optoelectronics inspires broader exploration of the chemistry and photophysics of MHs. The clear objective is to determine factors controlling the spectral widths and emission peak wavelengths, Stokes shifts, radiative lifetimes, and quantum efficiencies. In addition to the need to discover new chemically robust and nontoxic MH emitters, there is also a critical need to engineer material morphologies suitable for specific applications (e.g., thin films, nanocrystals, composites, etc.) Ensuring the thermal and environmental stabilities are especially important efforts. SCALE-HALO will therefore encompass the chemical engineering of MHs at the atomic scale (e.g., new compounds), nanoscale (e.g., synthesis of nanostructures and their surface chemistry), and mesoscale (e.g., nanostructure superlattices and composites). Furthermore, modern exploratory syntheses will be accelerated with automated high-throughput methods (e.g., robotics and microfluidics). The characterization toolbox for probing the local atomistic structure will be expanded with multinuclear NMR spectroscopy. The individual and collective optical properties of MH nanostructures and their periodic assemblies will be established and rationalized. Toward diverse real-world applications, first trials will be undertaken to evaluate the potentials of novel MH materials for LCD displays, solid-state lighting and light-emitting diodes.","1999950","2019-06-01","2024-05-31"
"ScaleCell","Scalable Kinetic Models: From Molecular Dynamics to Cellular Signaling","Frank NOE","FREIE UNIVERSITAET BERLIN","Biological processes are inherently multi-scalar: exchanging a single amino acid of a protein can affect the macroscopic behavior of a cell. A computational model that can cover these scales and simulate the time evolution of locations, interactions, and atomistic structures of biomolecules in a cell would be transformative for the understanding of biology and the optimization of biotechnological processes. This ERC project will lay the methodological groundwork for such a model.
Recent breakthroughs in the long-standing problem of sampling rare transition events in molecular dynamics (MD) simulation have enabled us to simulate biomolecular processes such as folding and binding with atomistic models. The PI has co-pioneered the widely-used Markov State Models (MSMs) that combine extensive distributed MD simulations towards models of the molecular kinetics. Using these methods, we have demonstrated that protein-protein association can be simulated and timescales of seconds can be reached in all-atom models of small protein systems.
However, these methods have fundamental limitations to scale to the large biomolecules and the long length-scales involved in cellular signaling. To address these limitations, we will develop the following key technologies and disseminate them in open software:

1. A model that describes protein kinetics as a network of local switches which will overcome scaling limitations of MSMs that suffer from an exponential increase of parameters for large systems.
2. An “effective force field for cells” that predicts structure and kinetics of multi-body protein interactions based on simulations of relatively few protein interactions.
3. A multi-scale method to embed atomistic kinetic models in whole-cell reaction-diffusion simulations. 

We will employ these methods and, in collaboration with leading experimentalists, investigate how the mechanochemical protein dynamin couples atomic-detail structure changes to membrane constriction in endocytosis.","1987500","2018-05-01","2023-04-30"
"SCALPEL","A Single Cell AnaLysis and Sorting Platform based on Lensfree digital imaging techniques applied to Rapid Detection of Cancer","Liesbet Lagae","INTERUNIVERSITAIR MICRO-ELECTRONICA CENTRUM","""Metastasis is responsible for > 90% of cancer-related deaths. Billions of dollars have been spent trying to cure primary tumors but very little was spent in trying to detect or kill the highly aggressive tumor cells that cause disease spreading.  One of the reasons is that single cell studies of rare cells in blood still present a large challenge.  Single cell analysis remains tedious with many different instruments and protocols, typically taking a few days of hands-on work.  This slows down research, but also hinders the translation to application in future clinical practice.  In SCALPEL, we envisage a high-content, high-throughput cell imaging and sorting platform, more compact and easier to use than any existing single cell analyzer.   The high content results from lensfree digital imaging of single cells on a high speed CMOS active optical pixel matrix to analyze the morphology of cells.  The high throughput results from a highly parallelized fluidic matrix that steers cells at high speed over the CMOS imaging blocks.  Lensfree cell sorters can be realized in a cheap and compact platform, as all optomechanical components (lenses, detectors, nozzles,...) are replaced by nanoelectronics, advanced imaging and signal processing technology.

SCALPEL aims to perform a full feasibility study of this concept and will require to investigate the ultimate limits in:  1) maximizing image resolution and sensitivity to single cell morphological features obtained via lensfree holographic imaging; 2) maximizing cell manipulation speed in microfluidic systems via a high degree of parallelization; and 3) digital image signal processing with extremely low latency at reasonable power consumption. If this multidisciplinary complexity can be understood, we will have built the components for different versions of compact cytometers that can be used at hand of pathologist, surgeons, and nurses for improving the individualized follow-up and survival rate of cancer patients.""","1999840","2014-11-01","2019-10-31"
"SCATAPNUT","Scattering and tapping on soft-hard-open nuts","Notburga Gierlinger","UNIVERSITAET FUER BODENKULTUR WIEN","Seeds enclosed in maternal tissue are an important evolutionary plant development as they protect the embryo in many different environments. The protecting coverings are very heterogeneous in structure and origin due to different seed dispersal strategies and environments designed for. The ones having hard outer coverings are commonly called nuts and their shells have recently become of interest for biomimetic research as they represent hard and tough lightweight structures with biological and environmental resistance.
Biological materials are optimized at numerous length scales. To unravel the design principles on the micro- and nano scale and their assembly are a big challenge in biomimetic research. Thus the objectives of this project are threefold: 1) develop in-situ methods for in-depth characterization at the micro- and nano level, 2) reveal the heterogeneity and common design principles by investigating different species and 3) follow development (soft), maturation (hard) and germination (open).
By measuring the inelastic scattering of laser light (RAMAN microscopy), tapping with a tip (Atomic force microscopy AFM, pulsed force mode) and combining both (Scanning near field optical microscopy-SNOM, Tip enhanced Raman spectroscopy-TERS) sophisticated applications for imaging natural packaging structures will be developed. This will enable us to gain new insights into micro- and nanochemistry as well as nanomechanics in the context of tissue and cell organization. Furthermore in-depth knowledge on the developmental processes of cell assembly, maturation and germination will be obtained. This will lead to a better understanding of the underlying design principles, which is important in order to extract structure-function relationships and identify features that contribute e.g. to the high strength and cracking resistance and longevity. Such information is important for biology (agriculture) and will give new input in intelligent biomimetic material design.","1993606","2016-09-01","2021-08-31"
"SCATTERERID","Analysis and synthesis of wideband scattered signals from finite-size targets – aspect-independent RF analog footprint","Etienne Francois Noël Perret","INSTITUT POLYTECHNIQUE DE GRENOBLE","The need for information identification and capture is a matter of prime importance in modern societies. Every sectors of society rely on the identification of data exchanged, the updating of the data recorded on a tag and the measurement of physical parameters. The ability to make objects interact with one another or with humans is an important factor in many applications, all the more so if this interaction can occur without human presence. The way to reduce power consumption, improve the communication quality-of-service and enhance connectivity has become key issues for lots of industries. Researchers need to consider the multiple factors simultaneously to design state-of-the-art RF devices for the next generation of identification services. One important direction is to develop low-power, low cost tags for wireless identification and sensing. Lots of improvements have been done today on communication systems based on electronic devices where an integrated circuit is at the heart of the whole system. The democratisation of these chipped based systems like the RFID one will give rise to environmental issues in the future. However, these improvements pave the way for the development of new concepts based on approaches where the presence of the chip is not mandatory. These approaches are based on radar or reflectometry principles; these are non-invasive techniques but they require specific theoretical and practical developments. The difficulty is to be able to retrieve a small signal coming from a totally passive label placed in an unknown and movable environment. The objective of this project is to introduce the paradigm of RF communication system based on chipless labels, i.e. tags without any chip, bringing an ID, able to communicate with radio waves and having extremely low costs. This project aims at showing that it is possible to associate the paper based chipless label ID with other features like the ability to write and rewrite the ID, or a sensor function.","1997656","2018-09-01","2023-08-31"
"ScienceGraph","Knowledge Graph based Representation, Augmentation and Exploration of Scholarly Communication","Sören AUER","GOTTFRIED WILHELM LEIBNIZ UNIVERSITAET HANNOVER","Despite an improved digital access to scientific publications in the last decades, the fundamental principles of scholarly communication remain unchanged and continue to be largely document-based. The document-oriented workflows in science have reached the limits of adequacy as highlighted by recent discussions on the increasing proliferation of scientific literature, the deficiency of peer-review and the reproducibility crisis.
In ScienceGRAPH we aim to develop a novel model for representing, analysing, augmenting and exploiting scholarly communication in a knowledge-based way by expressing and linking scientific contributions and related artefacts through semantically rich, interlinked knowledge graphs. The model is based on deep semantic representation of scientific contributions, their manual, crowd-sourced and automatic augmentation and finally the intuitive exploration and interaction employing question answering on the resulting ScienceGRAPH base.
Currently, knowledge graphs are still confined to representing encyclopaedic, factual information. ScienceGRAPH advances the state-of-the-art by enabling to represent complex interdisciplinary scientific information including fine-grained provenance preservation, discourse capture, evolution tracing and concept drift. Also, we will demonstrate that we can synergistically combine automated extraction and augmentation techniques, with large-scale collaboration to reach an unprecedented level of knowledge graph breadth and depth.
As a result, we expect a paradigm shift in the methods of academic discourse towards knowledge-based information flows, which facilitate completely new ways of search and exploration. The efficiency and effectiveness of scholarly communication will significant increase, since ambiguities are reduced, reproducibility is facilitated, redundancy is avoided, provenance and contributions can be better traced and the interconnections of research contributions are made more explicit and transparent.","1996250","2019-05-01","2024-04-30"
"SCION","""Scalability, Control,  Isolation on Next-generation Networks""","Adrian Markus Perrig","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","""The Internet has been successful beyond even the most optimistic expectations. It permeates and is intertwined with almost all aspects of our government, economy, and society.

From a security perspective, we observe is the tremendous dependency on communication that is being created. Many of the processes we describe above would grind to a halt should communication become unavailable. Although we cannot conclusively
answer what the impact of a 1-minute, 1-hour, 1-day, or 1-week lack of Internet communication on our society would be, but anecdotal evidence
indicates that even short outages have a profound negative impact on governmental, economic, and societal processes. We can only surmise
what the impact of a week-long Internet outage would look like after witnessing the almost complete halt in productivity of a major institution that lost email connectivity for 2 days.

Unfortunately, the current Internet is quite brittle, and has not been designed for high availability in the face of malicious adversaries. Recent patches to
improve Internet security and availability have been constrained by the current Internet architecture and business processes.
Consequently, the current state of safety and availability of the Internet is not commensurate with its importance. Numerous aspects of our society depend on a brittle network that runs with a relatively
small investment compared to its importance.

The goal of this project is to follow a methodological scientific approach to design, analyze, and implement a prototype of a next-generation Internet that is secure, available, and private by design, that provides appropriate incentives for a transition to the new architecture, and that considers economic and policy issues at the design stage.""","1889684","2014-01-01","2018-12-31"
"SCPs","Developing sequence controlled polymers for organization, templation and recognition","Rachel Kerry O'reilly","THE UNIVERSITY OF WARWICK","Nature‘s toolbox for replication uses DNA and RNA which are nucleic acids capable of templating new copies of themselves. Nature‘s ability to replicate has led to the evolution of a wide variety of forms and functions for biological materials which cannot be achieved using current synthetic approaches. It seems likely that if we were able to teach plastics or other polymers how to template new copies of themselves that we would similarly be able to make new, impossible materials and hence further expand the potential function and properties of these materials. These new materials would provide enhanced properties and function (such as replication and evolution) that are not currently available to material chemists. This would allow for a best-of-both-worlds scenario with the development of robust synthetic materials, with tuneable properties including crystallinity, thermal properties, shape memory, and self-healing. Most importantly, by developing an empirical and perhaps even model-based connection between polymer sequence / composition and polymer properties it would be possible to begin to design new materials in a rational and knowledge-based way. Indeed, it could be argued that this advance would ultimately solve one of the major problems in materials science, multiscale modelling of polymer properties. It seems certain that achieving even a portion of these goals would open up a completely new area of material science. Hence, following the model of DNA, we propose developing a number of new routes for the preparation of sequence controlled polymers (SCPs) and specifically a new class of SCPs which are capable of replication and ultimately evolution. This will produce polymers and self-assembled structures with unprecedented physical properties and the ability to functionally interact and communicate with biological materials. Realizing this goal will allow us to bring new function to chemistry, through expanding chemical space to access new precision polymers","2324271","2014-04-01","2020-01-31"
"SCrIPT","Stable Chromium Isotopes as a Productivity Tracer","Samuel JACCARD","UNIVERSITAET BERN","The overall concept of this proposal is to investigate the main biogeochemical processes modulating spatial and temporal changes in marine export productivity, and assess their role in regulating atmospheric carbon dioxide (CO2) concentrations, both under present conditions and in the geological past. The exchange of CO2 between the atmosphere and ocean interior mediated by the oceanic ecosystem is a pivotal mechanism modulating the global carbon cycle, and thus, a substantial driver of the Earth’s climatic evolution. 

The overarching objective of this research proposal is to develop a novel proxy to trace changes in the global strength of the marine biological carbon pump (BCP) based on stable Chromium (Cr) isotopes. Despite its significance for the global carbon cycle, the BCP is still poorly constrained. This project will explore a tracer that has recently been developed to investigate the rise of atmospheric oxygen in the early history of the Earth and develop it thoroughly through a comprehensive, multidisciplinary calibration program and apply it to the much more subtle redox variations associated with organic matter remineralization in the ocean. The proposed approach includes phytoplankton culture experiments, water-column investigations and sedimentary analysis and will aim at elucidating the mechanisms governing the reduction of Cr and its associated isotopic fractionation. The proxy will subsequently be used to reconstruct export production variability in the past and assess its role in modulating glacial/interglacial climate oscillations. These past changes tended to be much slower than the current, anthropogenic change. Nonetheless, they can help to appraise sensitivities and point toward potentially dominant mechanisms of change. The observations gathered within the framework of this research program will enable refining the evolution of the marine carbon cycle and the rapidly declining buffering capacity of the ocean.","1997625","2019-05-01","2024-04-30"
"Sea2Cloud","Are marine living microorganisms influencing clouds?","Karine SELLEGRI","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Earth, as a whole, can be considered as a living organism emitting gases and particles in its atmosphere, in order to regulate its own temperature (Lovelock, 1988). In particular oceans, which cover 70% of the Earth, may respond to climate change by emitting different species under different environmental conditions. At the global scale, a large fraction of the aerosol number concentration is formed by nucleation of low-volatility  gas-phase compounds, a process that is expected to ultimately determine the concentrations of Cloud Condensation Nuclei (CCN). Nucleation occurrence over open oceans is still debated, due to scarce observational data sets and instrumental limitations, although our recent findings suggest biologically driven nucleation from seawater emissions. Marine aerosol can also be emitted to the atmosphere as primary particles via bubble bursting, among which living microorganisms are suspected to act as excellent ice nuclei (IN) and impact clouds precipitation capacities. The main goal of this proposal is to investigate how marine emissions from living microorganisms can influence CCN, IN and ultimately cloud properties. We will investigate the whole process chain of gas-phase emissions, nucleation and growth through the atmospheric column, and impact on the CCN population. We will also quantify marine primary bioaerosol emissions and evaluate how they impact IN and cloud precipitation capabilities. Experiments will be performed in the Southern Hemisphere, especially sensitive to the natural aerosol concentration variability. We will use an original approach of field mesocosms enclosing the air-sea interface, to link marine emissions to the biogeochemical properties of natural seawater, combined with ambient aerosol measurements simultaneously at low and high altitude sites. At last, a modelling study will help merging process studies and ambient measurements, and assess the role of biologically driven marine emissions on cloud properties.","1999329","2018-07-01","2023-06-30"
"SEAL","Sound and Early Assessment of Leakage for Embedded Software","Maria Elisabeth OSWALD","UNIVERSITY OF BRISTOL","Side channel attacks use, alongside information such as plaintexts or ciphertexts, leakage about the (secret) key-dependent intermediate state(s), and deliver a `key ranking' as a result. Kocher's attacks [15] [16] showed that for many practical implementations, observing a few encryptions made complete key recovery possible in practice.  The academic research into combating these attacks so far has largely focused on approaches and tools to equip specialised cryptographic engineers with access to a specialist lab and tools. 

The research hypothesis of this CoG is that one can make meaningful statements about the leakage behaviour of arbitrary implementations on small devices by utilising a-priori derived (instruction level) leakage models. Our vision is to enable developers with limited domain-specific knowledge to perform side channel evaluations at design time without access to a fully equipped lab, by creating tools and methodologies that integrate a priori derived instruction-level leakage models into a standard compiler. 

This vision is articulated in three overarching research objectives:

1. Designing novel profiling strategies (WP1) including novel leakage acquisition techniques to generate leakage models for a specific target device.

2. Developing fast and comprehensive methods to support rapid evaluations (WP2).

3. Integration (WP3) of semantics, syntax and tools capable of using profiling information into a standard compiler with the aim to evaluate and improve the side channel resilience of the target code.

Addressing these goals simultaneously is required to make substantial progress towards the overall vision of this project. 

As a final result, we will make demonstrators available (WP4): using a off-the shelf components, we supply the necessary tools and compiler enhancements including samples of cryptographic implementations to conduct analyses and demonstrate improvements regarding side channel resilience.","1946995","2017-09-01","2022-08-31"
"SEARCHLIGHT","A new communication paradigm for future very high speed wireless networks","Joerg Carsten Widmer","FUNDACION IMDEA NETWORKS","""Due to the tremendous growth in mobile devices such as smartphones, tablet PCs, and laptops over the past years, a larger and larger fraction of Internet traffic is delivered wirelessly. Dealing with this vast increase in traffic is one of the most important challenges for future wireless networks. State-of-the-art wireless communication already operates close to Shannon capacity. The only viable option to further increase data rates is to use high bandwidth channels in the very high frequency part of the radio spectrum. However, this spectrum suffers from high attenuation and signal absorption, restricting communication primarily to line-of-sight (LOS) scenarios. This in turn requires a radical rethinking of wireless networking. We envision that future wireless networks will consist of many highly directional LOS channels for communication between access points (APs) and end devices. Such an environment is extremely dynamic, in particular for mobile devices. At the same time, such channels experience very little interference and resources that would otherwise be used to handle interference can now be used to further increase achievable data rates.

We propose to build a wireless network architecture that maintains directional LOS channels between several APs and (mobile) end devices. Data is transmitted via all of these channels and end device uses multiple antennas to receive and decode several such data streams simultaneously. The main complexity of the design lies in the selection of APs as well as the beamforming directions of their antennas, given the large number of end devices that future wireless networks will have to support. To speed up this decision process, the system maintains a map of the radio environment and learns likely sequences of beamforming patterns and APs. This further allows to intelligently switch off APs to improve energy efficiency. We believe that such a design is the key element for the scalability of future wireless networks.""","1719960","2014-04-01","2019-03-31"
"SEDAL","Statistical Learning for Earth Observation Data Analysis.","Gustau Camps-Valls","UNIVERSITAT DE VALENCIA","SEDAL is an interdisciplinary project that aims to develop novel statistical learning methods to analyze Earth Observation (EO) satellite data. In the last decade, machine learning models have helped to monitor land, oceans, and atmosphere through the analysis and estimation of climate and biophysical parameters. Current approaches, however, cannot deal efficiently with the particular characteristics of remote sensing data. In the coming few years, this problem will largely increase: several satellite missions, such as the operational EU Copernicus Sentinels, will be launched, and we will face the urgent need to process and understand huge amounts of complex, heterogeneous, multisource, and structured data to monitor the rapid changes already occurring in our Planet.

SEDAL aims to develop the next generation of statistical inference methods for EO data analysis. We will develop advanced regression methods to improve efficiency, prediction accuracy and uncertainties, encode physical knowledge about the problem, and attain self-explanatory models learned from empirical data. Even more importantly, we will learn graphical causal models to explain the potentially complex interactions between key observed variables, and discover hidden essential drivers and confounding factors. This project will thus aboard the fundamental problem of moving from correlation to dependence and then to causation through EO data analysis. The theoretical developments will be guided by the challenging problems of estimating biophysical parameters and learning causal relations at both local and global planetary scales.

The long-term vision of SEDAL is tied to open new frontiers and foster research towards algorithms capable of discovering knowledge from EO data, a stepping stone before the more ambitious far-end goal of machine reasoning of anthropogenic climate change.","1716954","2015-09-01","2020-08-31"
"See-1D-Qmatter","Unravelling Fragile 1D Quantum States of Matter Through Ultra-sensitive Imaging","Shahal Ilani","WEIZMANN INSTITUTE OF SCIENCE","In condensed matter physics there are several iconic predictions that have evaded experimental discovery for many decades. Well-known examples include the proposed fractionally-charged quasiparticles in one-dimension, the theorized quantum crystal of electrons, and the elusive Kondo cloud. These sought-after many-body states all share two key aspects underscoring why they are so hard to discover: They each involve a fragile quantum state of matter that is destroyed easily by disorder or elevated temperatures, and in each case the distinguishing fingerprint is encoded in their real-space structure, which is often difficult to probe directly. The discovery of such phases therefore requires two challenging experimental components: A superb material system in which these phases can be generated, and a novel real-space probe that can image their spatial structure, yet is minimally invasive as not to destroy them.
Recently, we have developed a radically new approach for creating the state-of-the-art in both material systems and scanning probes, based on carbon nanotube devices of unprecedented complexity and cleanliness. With these components in place, we are poised to make the next quantum leap in technology by building a conceptually new experimental platform in which fragile quantum states of matter can be realized and studied microscopically: We will use a nanotube single-electron-transistor as a high-resolution, ultrasensitive scanning charge detector to non-invasively image an exotic quantum state within a second pristine nanotube.  With this new platform we will thus be able to address several foundational questions in condensed matter physics (including those mentioned above) and unravel their underlying physics.","2475000","2016-01-01","2020-12-31"
"SEED","Learning to See in a Dynamic World","Cristian Sminchisescu","LUNDS UNIVERSITET","The goal of SEED is to fundamentally advance the methodology of computer vision by exploiting a dynamic analysis perspective in order to acquire accurate, yet tractable models, that can automatically learn to sense our visual world, localize still and animate objects (e.g. chairs, phones, computers, bicycles or cars, people and animals), actions and interactions, as well as qualitative geometrical and physical scene properties, by propagating and consolidating temporal information, with minimal system training and supervision.  SEED will extract descriptions that identify the precise boundaries and spatial layout of the different scene components, and the manner they move, interact, and change over time. For this purpose, SEED will develop novel high-order compositional methodologies for the semantic segmentation of video data acquired by observers of dynamic scenes, by adaptively integrating figure-ground reasoning based on bottom-up and top-down information, and by using weakly supervised machine learning techniques that support continuous learning towards an open-ended number of visual categories. The system will be able not only to recover detailed models of dynamic scenes, but also forecast future actions and interactions in those scenes, over long time horizons, by contextual reasoning and inverse reinforcement learning. Two demonstrators are envisaged, the first corresponding to scene understanding and forecasting in indoor office spaces, and the second for urban outdoor environments. The methodology emerging from this research has the potential to impact fields as diverse as automatic personal assistance for people, video editing and indexing, robotics, environmental awareness, augmented reality, human-computer interaction, or manufacturing.","1999412","2016-01-01","2020-12-31"
"SEEWHI","Solar Energy Enabled for the World by High-resolution Imaging","Jens Wenzel Andreasen","DANMARKS TEKNISKE UNIVERSITET","THE GOAL
We will derive new and fundamental insight in the relation between nano-scale structure and the performance of 3rd generation solar cells, and determine how to apply this in large-scale processing.
THE CHALLENGES
We currently have a superficial understanding of the correlations between structure and performance of photovoltaic heterojunctions, based on studies of small-scale devices and model systems with characterization techniques that indirectly probe their internal structure. The real structures of optimized devices have never been “seen”, and in devices manufactured by large-scale processing, almost nothing is known about the formation of structures and interfaces.
THE SCIENCE
We will take a ground-breaking new approach by combining imaging techniques where state of the art is moving in time spans on the order of months, with ultrafast scattering experiments and modelling. The techniques include high resolution X-ray phase contrast and X-ray dark-field tomography, in situ small and wide angle X-ray scattering, resonant scattering and imaging and time resolved studies of charge transport and transfer. To relate our findings to device performance, we will establish full 3D models of charge generation and transport in nano-structured solar cells.
THE FOCUS
Solution cast solar cells is the only technology that promises fast and cheap industrial scaling, and it is consequently the focus of our efforts. They require a tight control of processing conditions to ensure that the proper nano-structure is formed in the photoactive layers, with optimal contacts to charge transport layers and interfaces. The prime contenders are non-toxic polymer and kesterite solar cells.
THE IMPACT
Our results may advance 3rd generation, solution-cast solar cells to meet the “unification challenge” where high efficiency, stability and cheap processing combines in a single technology, scalable to the level of gigawatts per day, thus becoming a centrepiece in global energy supply.","2000000","2016-05-01","2021-04-30"
"SELDOM","Search for the electric dipole moment of strange and charm baryons at LHC","Nicola NERI","UNIVERSITA DEGLI STUDI DI MILANO","""SELDOM explores a new experimental method to decisively boost the study of the electric dipole moment (EDM) and magnetic dipole moment (MDM) of  baryons at the LHCb experiment at CERN. 
We will be able to guide the first search of charm baryons EDM: any observation would represent a signature of new physics. With the strange baryon EDM measurement, we will push forward the sensitivity on the Lambda baryon EDM to an unprecedented precision. Thus, we will set new constraints to extensions of the Standard Model of particle physics. 
To date no search was performed for short-lived charm baryon EDM, as it must be determined studying the spin precession in intense magnetic fields before the decay - a major challenge for these unstable particles. SELDOM will overcome this limitation, using as key ingredient a bent crystal attached to a fixed target. Short-lived charm baryons produced in the target will be channelled into the crystal: the intense electromagnetic field between its atomic planes will induce fast spin precession; events are reconstructed with the LHCb detector. 
Conversely, spin precession in long-lived strange baryons (produced from charm baryon decays from beam-beam collisions), will be induced by the magnetic field of the LHCb tracking system. Strange baryons decaying at the end of the magnet will be reconstructed with “ad-hoc"""" tracking algorithms developed in SELDOM.  Together with the experimental setup itself, this is one of the major challenges of the project. 
Our experimental approach will also unlock measurements of the charm baryon MDM and of the strange baryon and anti-baryon MDM, allowing a test of CPT symmetry.    
SELDOM will be a crucial piece in the puzzle to explain the absence of antimatter in the Universe, and it has the potential to shorten the path to new physics discoveries opening up new research opportunities.""","1933750","2018-04-01","2023-03-31"
"SeleCHEM","Overcoming the Selectivity Challenge in Chemistry and Chemical Biology via Innovative Tethering Strategies","Jerome WASER","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","In the last two centuries, synthetic organic chemistry has undergone an unprecedented revolution. The ability to understand and modify the molecular structure of matter has changed our life in many areas, such as medicine, agriculture or commodity materials. These major successes gave the impression that synthetic chemistry is a mature field. However, this impression is completely misleading, as current synthetic methods still lack the selectivity needed for the modification of complex molecules. Both selecting between different reactive groups and functionalizing inert bonds in their presence represent formidable challenges. 
In this project, we propose to develop highly selective “molecular tethers” for the functionalization of both natural/synthetic organic compounds and biomolecules. The envisioned tethers are bifunctional small organic molecules having three fundamental properties:
1) A “biting end” with unique reactivity to be selectively installed in situ onto naturally occurring thiols, alcohols and amines. We will use tethers based on acetals and hypervalent iodine reagents.
2) A “functional end”, whose reactivity can be revealed “at will” to functionalize bonds that cannot be accessed with the current state of the art of synthetic chemistry, especially inert C-H and C=C bonds.
3) Being traceless, meaning that they can be removed easily once the desired functionalization has been achieved.
The main impact of this project will be in fundamental synthetic organic chemistry, as it will contribute to overcoming major selectivity hurdles in the functionalization of complex molecules. It will therefore result in faster progress in all the fields depending on synthetic molecules, such as medicine, agriculture or materials. A more efficient functionalization of biomolecules will allow us to soften the boundaries between synthetic chemistry and biology, leading to major progress in our understanding of living systems and our ability to modify them.","2000000","2019-01-01","2023-12-31"
"SEMICOMPLEX","Divide and conquer ab initio semiclassical molecular dynamics for spectroscopic calculations of complex systems","Michele Ceotto","UNIVERSITA DEGLI STUDI DI MILANO","Given the continuing revolution in “nano” and “bio” technologies, it is urgent for chemists to be able to carry out reliable quantum dynamics simulations of complex molecular systems. The goal of this project is to fill the gap between theory and experiment and provide the community with a user-friendly computational tool for nuclear spectra (IR, vibro-electronic, etc.) calculations of very complex systems.
Present theoretical methodologies are hampered either by artificial nuclear potential interactions or by local potential perturbation assumptions. The semiclassical molecular dynamics method that I have been pioneering is not affected by these limitations because it is based on ab initio classical trajectories. The nuclear forces can be calculated by any electronic structure software and trajectories can explore the entire potential surface. The remaining challenge is to overcome the exponential scaling of computational power.
I will adopt a divide-and-conquer strategy to beat the curse of dimensionality. Firstly, the ab initio classical molecular dynamics is performed for the entire complex system. Then, partial spectra are calculated by using the semiclassical information derived by the projection of the trajectories onto lower dimensional spaces. Vibrational modes are not artificially decoupled. Finally, the entire spectrum is reconstructed piece by piece. This method allows chemists to have a more reliable spectral interpretation in a wider context up to the nanoscale. With the help of my own previous experience and my collaborations, I will simulate pollutant photodegradation for environmental remediation and the vibro-electronic spectra of carcinogenic molecules adsorbed on TiO2. I will also reproduce the spectroscopic properties of molecular nano-texturing of titania films for outdoor cultural heritage preservation. 
A new generation of semiclassical fellows will be educated to put Europe on the leading edge of quantum simulations for spectroscopy.","1899973","2015-11-01","2020-10-31"
"SEQUOIA","Robust algorithms for learning from modern data","Francis, René, Julien BACH","INSTITUT NATIONAL DE RECHERCHE ENINFORMATIQUE ET AUTOMATIQUE","Machine learning is needed and used everywhere, from science to industry, with a growing impact on many disciplines. While first successes were due at least in part to simple supervised learning algorithms used primarily as black boxes on medium-scale problems, modern data pose new challenges. Scalability is an important issue of course: with large amounts of data, many current problems far exceed the capabilities of existing algorithms despite sophisticated computing architectures. But beyond this, the core classical model of supervised machine learning, with the usual assumptions of independent and identically distributed data, or well-defined features, outputs and loss functions, has reached its theoretical and practical limits.

Given this new setting, existing optimization-based algorithms are not adapted. The main objective of this proposal is to push the frontiers of supervised machine learning, in terms of (a) scalability to data with massive numbers of observations, features, and tasks, (b) adaptability to modern computing environments, in particular for parallel and distributed processing, (c) provable adaptivity and robustness to problem and hardware specifications, and (d) robustness to non-convexities inherent in machine learning problems.

To achieve the expected breakthroughs, we will design a novel generation of learning algorithms amenable to a tight convergence analysis with realistic assumptions and efficient implementations. They will help transition machine learning algorithms towards the same wide-spread robust use as numerical linear algebra libraries. Outcomes of the research described in this proposal will include algorithms that come with strong convergence guarantees and are well-tested on real-life benchmarks coming from computer vision, bioinformatics, audio processing and natural language processing. For both distributed and non-distributed settings, we will release open-source software, adapted to widely available computing platforms.","1998750","2017-09-01","2022-08-31"
"SHINE","Seeing hydrogen in matter","Baptiste GAULT","MAX PLANCK INSTITUT FUR EISENFORSCHUNG GMBH","Observing hydrogen (H) in matter is a formidable challenge. Despite being ubiquitous in nature, it is elusive to scientific scrutiny like no other element. It is often portrayed as either a blessing or a curse. Certainly, it is a prime candidate for producing low-carbon emission power. But no less important is the effect of hydrogen embrittlement which has resulted in many catastrophic failures of engineering alloys. In aid of this, SHINE will realise multiple ambitions. It will facilitate the direct imaging and quantification of H atoms in candidate metallic alloys and metal-organic frameworks for gaseous storage, allow the discovery of new solid-state hydrides with controlled release, and help the improvement of fuel cell materials for energy generation. All these applications have relevance to a ‘low-carbon-emission economy’ that humanity must develop in the 21st century. SHINE will exploit a novel and entirely unique infrastructure, designed and currently implemented in the PI’s group. It will directly provide three-dimensional hydrogen mapping at the near-atomic scale. By connecting and relating this fundamental knowledge and observed physical properties, we will enable unprecedented precision in the prediction of material behaviour and so resolve to unlock control over the behaviour of hydrogen in such materials. Atom probe tomography will be the principal method of a correlative microscopy and spectroscopy approach to investigate materials where precise knowledge of the distribution of H is crucial. Informed by experimental data, modelling and simulations will provide a mechanistic understanding of the behaviour of H in materials. Novel hardware and data-treatment approaches will be developed to maximise data quality and provide new insights of the behaviour of H in the complex and dynamic microstructures of engineering materials, thereby allowing us to devise manufacturing strategies to enhance their performance and durability.","2000000","2018-02-01","2023-01-31"
"SIMDAMA","Strong-interaction matter coupled to electroweak probes and dark matter candidates","Harvey Byron MEYER","JOHANNES GUTENBERG-UNIVERSITAT MAINZ","For decades, the Standard Model of particle physics has successfully
predicted the outcome of experiments probing the laws of nature on the
smallest distances. Its last missing ingredient, the Higgs particle,
was discovered at the Large Hadron Collider at CERN in 2012. A vast
experimental program is now underway to complete its description of weakly interacting particles called neutrinos.

For all its successes, the Standard Model does not provide an
explanation for the nature of dark matter, which is thought to account for a
quarter of the energy in the universe. This project, based on the
`lattice QCD' framework, will enable a more stringent test of the
Standard Model, contribute to narrowing down the list of
dark-matter candidate particles, and reduce uncertainties in neutrino
detection.

The strong interaction, which binds protons and neutrons together to
form atomic nuclei, is described by the sector of the Standard Model
called Quantum Chromodynamics (QCD). The complexity of the strong interaction
is often the limiting factor in testing the Standard Model and in
searching for new fundamental particles and forces. Strong-interaction
matter is also of tremendous intrinsic interest because it exhibits
many emerging phenomena such as spontaneous symmetry breaking,
quantum-relativistic bound states, and a high-temperature `quark-gluon
plasma' phase, to name a few. By replacing space and time by a
lattice, QCD becomes amenable to an ab initio treatment via
large-scale computer simulations.

The subproject of testing `sterile' neutrinos as dark-matter
constituents depends on understanding aspects of hot QCD matter, since
they would have been produced in the early, hot universe. This goal is
thus connected to present-day heavy-ion collision experiments, where
tiny droplets of hot QCD matter are produced in the laboratory.","1685500","2018-04-01","2023-03-31"
"SINGWAVES","Singularity formation in nonlinear evolution equations","PIERRE HENRI ALEXANDRE RAPHAEL","UNIVERSITE DE NICE SOPHIA ANTIPOLIS","""Non linear wave equations are central in the description of many canonical models in physics from nonlinear optics to fluid mechanics. A phenomenon of particular interest is singularity formation which corresponds to the concentration of the energy of the wave packet. The existence and description of such dynamics is still mostly mysterious, but fundamental progress have been made in the past ten years on canonical models like nonlinear wave and Schr\""odinger equations, with in particular the discovery of the fundamental role played by a specific class of nonlinear wave packets: the solitary waves. These very recent works open up a huge field of investigation on problems which were considered out of reach ten years ago. The aim of the SINGWAVES project is to strenghten our research group in the setting of an intense international activity with two main directions of investigation: the construction and classification of singular bubbles for some canonical models like non linear Schr\""odinger equations, the exploration of new deeply nonlinear dynamics in connection with classical models at the frontier of current research.""","1211055","2015-08-01","2020-07-31"
"SIRFUNCT","Chemical Tools for Unravelling Sirtuin Function","Christian Adam OLSEN","KOBENHAVNS UNIVERSITET","It was recently realized that lysine acetylation affects a wide variety of cellular processes in addition to the initially recognized histone related gene regulation. Together with recent groundbreaking results, revealing the presence of additional acyllysine modifications, the basis for a paradigm shift in this area was formed. Examples of enzymes formerly thought to be lysine deacetylases, have been shown to cleave these new types of lysine modification and members of the sirtuin class of enzymes play a central role.
   Development of new tools to investigate the importance of these new modifications as well as the sirtuins that cleave them is required. We therefore propose to adopt an interdisciplinary approach by developing selective inhibitors and so-called activity-based probes (ABPs) and applying these to the investigation of proteins recognizing novel post-translational acylations of lysine residues in cells. Such ABPs will be powerful tools for providing insight regarding this rapidly evolving area of biochemistry; however, the current state-of-the-art in ABP design is endowed with severe limitations because the modifications are inherently cleaved by various hydrolases in human cells. Thus, in the present project, I propose that novel designs accommodating non-cleavable modifications are warranted to maintain structural integrity during experiments. 
   Furthermore, I propose to apply similar mechanism-based designs to develop potent and isoform-selective sirtuin inhibitors, which will serve as chemical probes to investigate links between cancer and metabolism, and may ultimately serve as lead compounds for pre-clinical pharmaceutical development. 

AIM-I. (a) Development and (b) application of collections of chemical probes for activity-based investigation of enzymes that interact with post-translationally acylated proteins.

AIM-II. Utilization of structural and mechanistic insight to design potent and selective inhibitors of sirtuin enzymes.","1758742","2017-04-01","2022-03-31"
"SIRPOL","Strongly interacting Rydberg slow light polaritons","Hans Peter Büchler","UNIVERSITAET STUTTGART","A fundamental property of optical photons is their extremely weak interactions, which can be ignored for all practical purposes and applications. This phenomena forms the basis for our understanding of light and is at the heart for the rich variety of tools available to manipulate and control optical beams. On the other hand, a controlled and strong interaction between individual photons would be ideal to generate non-classical states of light, prepare correlated quantum states of photons, and harvest quantum mechanics as a new resource for future technology. Rydberg slow light polaritons have recently emerged as a promising candidate towards this goal, and first experiments have demonstrated a strong interaction between individual photons. The aim of this project is to develop and advance the research field of Rydberg slow light polaritons with the ultimate goal to generate strongly interacting quantum many-body states with photons. The theoretical analysis is based on a  microscopic description of the Rydberg polaritons in an atomic ensemble, and combines well established tools from condensed matter physics for solving quantum many-body systems, as well as the inclusion of dissipation in this non-equilibrium problem. The goals of the present project addresses questions on the optimal generation of non-classical states of light such as deterministic single photon sources and Schrödinger cat states of photons, as well as assess their potential for application in quantum information and quantum technology. In addition, we will shed light on the role of dissipation in this quantum many-body system, and analyze potential problems and fundamental limitations of Rydberg polaritons, as well as address questions on equilibration and non-equilibrium dynamics. A special focus will be on the generation of quantum many-body states of photons with topological properties, and explore novel applications of photonic states with topological properties.","1505750","2016-06-01","2021-05-31"
"Skye","A programming language bridging theory and practice for scientific data curation","James Robert Cheney","THE UNIVERSITY OF EDINBURGH","Science is increasingly data-driven. Scientific research funders now routinely mandate open publication of publicly-funded research data. Safely reusing such data currently requires labour-intensive curation. Provenance recording the history and derivation of the data is critical to reaping the benefits and avoiding the pitfalls of data sharing. There are hundreds of curated scientific databases in biomedicine that need fine-grained provenance; one important example is GtoPdb, a pharmacological database developed by colleagues in Edinburgh. 

Currently there are no reusable methodologies or practical tools that support provenance for curated databases, forcing each project to start from scratch. Research on provenance for scientific databases is still at an early stage, and prototypes have so far proven challenging to deploy or evaluate in the field. Also, most techniques to date focus on provenance within a single database, but this is only part of the problem: real solutions will have to integrate database provenance with the multiple tiers of web applications, and no-one has begun to address this challenge.

I propose research on how to build support for curation into the programming language itself, building on my recent research on the Links Web programming language and on data curation. Links is a strongly-typed language that provides state-of-the-art support for language-integrated query and Web programming. I propose to build on Links and other recent language designs for heterogeneous meta-programming to develop a new language, called Skye, that can express modular, reusable curation and provenance techniques. To keep focus on the real needs of scientific databases, Skye will be evaluated in the context of GtoPdb and other scientific database projects. Bridging the gap between curation research and the practices of scientific database curators will catalyse a virtuous cycle that will increase the pace of breakthrough results from data-driven science.","1995181","2016-09-01","2021-08-31"
"SLIDEQUAKE","Detection and understanding of landslides by observing and modelling gravitational flows and generated earthquakes","Anne Mangeney","INSTITUT DE PHYSIQUE DU GLOBE DE PARIS","The goal of the project is to take a major step in improving the detection and understanding of landslides and their modelling at the field scale through the analysis of generated seismic waves. The seismic signal generated by landslides (i. e. landquakes) provides a unique tool to estimate the properties of the flow and its dynamics. Indeed, the stress applied by the landslide to the ground, which generates seismic waves, is highly sensitive to the flow history and therefore to the physical properties during mass emplacement. The strategy will be to combine a very accurate description of the landslide source, and the simulation and measurements of landquakes from the laboratory to the natural scale, by leading an ambitious interdisciplinary project involving numerical modelling, laboratory experiments and observation. The methodology will be to (1) develop thin layer models for granular flows over a complex 3D topography to alleviate the high computational costs related to the description of the real topography, taking into account the static/flowing transition and the fluid/grains mixture, both playing a key role in natural flows; (2) simulate the generated seismic waves by coupling landslide models to state-of-the-art wave propagation models. An ambitious objective will be to develop efficient coupling methods; (3) develop laboratory experiments of seismic emissions generated by granular flows to test the models and understand the physical processes at work; (4) analyse, simulate and invert natural landquakes making use of underexploited high-quality seismic and geomorphological data, in particular on volcanoes.
An ultimate objective will be to design a new generation of landslides models, reliable methods and operational tools for detection of gravitational flows, and interpretation of seismic data in terms of landslide properties. This tools will be transferred to the scientific community and to the observatories in charge of monitoring landslide activity.","1999241","2014-05-01","2020-04-30"
"SLING","Efficient algorithms for sustainable machine learning","lorenzo ROSASCO","UNIVERSITA DEGLI STUDI DI GENOVA","This project will  develop and integrate the latest optimization and statistical advances into a new generation of  resource-efficient algorithms for large-scale machine learning. State-of-the-art machine learning methods provide impressive results, opening new perspectives for science, technology, and society. However,  they  rely on massive computational resources to process huge manually annotated data-sets. The corresponding costs in terms of energy consumption and human efforts are not sustainable.
This project builds on the idea that   improving efficiency is a key to scale the ambitions and applicability of machine learning. Achieving efficiency requires overcoming the traditional boundaries between statistics and computations, to   develop new theory and algorithms.
 Within a multidisciplinary approach, we will establish  a new regularization theory of efficient machine learning.
We will  develop models that incorporate budgeted computations, and  numerical solutions with resources tailored to the statistically accuracy allowed by the data. Theoretical advances will provide the foundations for novel and sound algorithmic solutions.  Close collaborations in diverse applied fields
 will  ensure  that  our research results and solutions will be apt and immediately applicable to real world scenarios.
 The new algorithms  developed in the project will contribute to boost the possibilities of Artificial Intelligence, modeling and decision making in a world of data with ever-increasing size and complexity.","1977500","2019-11-01","2024-10-31"
"SLOW_SOURCE","Finding the Origin of the Slow Solar Wind","Alexis ROUILLARD","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The origins and release mechanisms of stellar winds are long-lasting open challenges in astrophysics. Stellar winds play a fundamental role in the long-term evolution of stars and the habitability of their orbiting planets.  In the solar case, the wind is observed in at least two states, fast and slow winds, that differ in their bulk properties and composition, pointing to different coronal origins. A theoretical explanation for the slow wind must explain both its variable bulk properties and its peculiar composition. This includes the measured high charge states of minor ions, the abundance variation of Helium during the solar cycle and the high abundance of elements with low first ionisation potential (so called FIP effect) reaching four times the photospheric abundance. SLOW_SOURCE is a comprehensive research project that will use current and upcoming observations as well as completely novel models of the solar atmosphere to determine the origin of the slow wind. We will develop plasma transport models coupling major and all known important minor constituents along realistic coronal magnetic field lines. This model will be the first of its kind producing modelled observations (spectroscopy, imagery) and expected in situ signatures directly from the modelled minor constituents.  Combined with data from space and ground-based observatories, our new multi-species, multi-temperature 3-dimensional modelling of coronal plasma will provide new ways to infer the properties of stellar winds and tools to study the fundamental transport and heating processes of stellar plasmas. Determining the enigmatic release mechanism(s) of the slow solar wind constitutes a key objective of the upcoming Parker Solar Probe mission that will obtain radically new observations right from the start of the project. The project (2019-2024) will also be an excellent preparation for the Solar Orbiter mission that should obtain its first data during the second half of the project (2022-2024).","1995902","2019-04-01","2024-03-31"
"SMAC-MC","Small Molecule Activation by Main-Group Compounds","Heikki Markus Tuononen","JYVASKYLAN YLIOPISTO","Many basic chemical processes involve the activation of small unreactive molecules, such as hydrogen, nitrogen, ammonia, water and carbon dioxide, by transition-metal-based catalysts or by enzymes. This proposal focusses on the interesting and recently observed possibility to perform similar transformations with main-group compounds that consist entirely of cheap earth-abundant elements. The proposed research is split into four work packages of which the first investigates the mechanisms by which different main-group singlet diradicaloids activate small molecules and how their reactivity correlates with their radical character. The second work package focusses on small molecule activation using main-group metalloid clusters, a new emerging field that we have recently pioneered, and compares the reactivity determined for main-group species with that known for related transition-metal clusters. Investigations in the third work package concentrate on the electrochemical reduction of carbon dioxide and on the possibility to lower the required overpotential with frustrated Lewis pairs that readily form adducts with small molecules. The fourth work package revolves around activating small molecules by diborenes and, in particular, observing novel reactivity in situ, that is, before the reactive diborene is trapped with a suitable Lewis base. Considered as a whole, the planned initiatives will enable significant breakthroughs in the design of novel main-group element based compounds for the activation of small molecules. The research is not only of fundamental scientific importance but also of potential practical value as many main-group systems, such as frustrated Lewis pairs, are currently being examined as novel catalysts. An ERC consolidator grant would significantly strengthen my position in this interesting subfield of inorganic chemistry and give my research group practical means to continue performing cutting-edge research.","1424190","2018-07-01","2023-06-30"
"SMART-DNA","Single Molecule Analytical Raman Tools based on DNA nanostructures","Ilko BALD","UNIVERSITAET POTSDAM","The monitoring of single molecule reactions promises unrivalled insight into chemical reaction mechanisms, but represents one of the most challenging tasks in chemistry. Surface-enhanced Raman scattering (SERS) is a particularly attractive single molecule (SM) technique due to its high chemical specificity, which allows to directly detect relevant intermediates and molecular subpopulations. However, SM-SERS is still at a premature state due to the highly challenging task to place single molecules precisely in nanoscale gaps of plasmonic nanostructures. These are required to provide sufficiently high electromagnetic field enhancement to reach SM sensitivity. The aim of SMART-DNA is to exploit artificial DNA nanostructures to provide sufficient structural control to assemble both, nanoparticles and target molecules, with nanometer precision. By means of novel DNA origami nanostructures the distance between two nanoparticles will be controlled, and at the same time target molecules will be placed at the positions of highest Raman enhancement through DNA aptamers. 
Apart from Raman enhancement the excitation of the localized surface plasmon resonance of the metallic nanostructures results in other plasmonic effects such as heating and possibly the transfer of hot electrons. This can lead to diffusion, conformational changes or even dissociation of the target molecules. These issues do not only concern SM-SERS, but also make quantitative SERS and the SERS analysis of complex (bio)molecules very challenging. By the improved structural control achieved by SMART-DNA, nanoscale heating and hot electron transfer and their effect on SERS spectra will be studied on an ensemble and a SM level. Finally, reactions induced by plasmonically generated electrons in DNA and DNA modified with electrophilic molecules will be studied by SERS with the aim to develop novel strategies to improve cancer radiation therapies such as the photothermal therapy.","1996476","2018-04-01","2023-03-31"
"SmartCells","Smart Lab-On-Chips for the Real -Time Control of Cells","PASCAL RENE SEBASTIEN HERSEN","UNIVERSITE PARIS DIDEROT - PARIS 7","Cells are complex, autonomous genetic machines with rich information processing capabilities. Synthetic Biology builds on these properties to design novel, synthetic genetic programs in cells with the aim of benefiting humans. Yet, safety and efficiency issues require creation of synthetic circuits that are reliable over a large range of operating conditions and stable to all sorts of perturbations. This is a tremendous challenge for synthetic biologists, as the robustness of any circuit is limited by their high dependence on the cellular host machinery and the fundamental stochastic nature of gene expression. Taking inspiration from physics and engineering we have imagined a computer-based feedback loop that can remotely, in real-time, control the state of a synthetic genetic program running in cells. Here, we will combine microfluidics, optogenetics, structured illumination, inference methods and control algorithm into such a real time control device of gene expression for yeast cells. We will then study how cells can be controlled at different scales and with increasing levels of complexity from a simple circuit to a simple multicellular ecosystem. Specifically, we aim at:

(1) Understanding the potential and limits of such a control method. We will ask to what extent robust control can be achieved at the single cell level over a broad range of operating conditions.
(2) Taking control of complex circuits. In particular, we will take control of key genes of the large regulatory network in charge of yeast adaptation to osmotic stress and dissect their roles in setting the mechano-biology properties of yeast.
(3) Taking control of multicellular systems. We will control the collective dynamics of a population of cells via single cell control at selected locations. 

This framework will establish solid scientific and technological foundations of a novel research area combining physics, engineering and synthetic biology to take control of living systems.","2198151","2017-04-01","2022-03-31"
"SmartGraphene","Graphene based smart surfaces: from visible to microwave","Coskun Kocabas","THE UNIVERSITY OF MANCHESTER","The aim of this proposal is to develop adaptive camouflage systems using graphene-enabled smart surfaces. We propose a new class of active surfaces capable of real-time electrical-control of its appearance in a very broad spectrum ranging from visible to microwave covering 6 orders of magnitude in wavelength. The proposed method relies on controlling electromagnetic waves by tuning density of high-mobility charges on single or multilayers of atomically thin graphene electrodes. We will realize this goal by efficient gating of large-area graphene using ionic liquids which yields unprecedented ability to control intensity and phase of the reflected and transmitted electromagnetic waves from the surface. Based on underlying physical mechanisms and applications, the proposed research plan is structured in 3 main directions; (1) Active surfaces in microwave and THz, (2) Active thermal surfaces, and (3) Active surfaces in the visible. 

The core idea of the proposal is based on a mutually-gated capacitor structure consisting of ionic liquid electrolyte sandwiched between two large area graphene. The voltage applied between the electrodes polarizes the ionic liquid and accumulates high-density of charges. Combining large scale chemical synthesis of graphene, novel device architectures and ionic liquid electrolyte we will develop new tools to understand and control light-matter interaction in a very broad spectrum. Then we will use these tools to fabricate new camouflage and display technologies on flexible polymers and paper substrates which cannot be realized by conventional semiconducting materials. We will challenge specific applications, such as THz compressive imaging, reconfigurable thermal shields, and electronic paper display.

 At the basic science level, this project revisits and challenges our basic understanding of light-matter interaction, in parallel, the proposed graphene-based smart surfaces will serve as a tool for developing new enabling technologies.","1995625","2016-05-01","2021-04-30"
"SMARTIES","Scattering Media as a Resource Towards Information Processing and Sensing","Sylvain Herve GIGAN","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Scattering of light in complex environments has long been considered a nuisance and an inescapable limitation to imaging and sensing alike, ranging from astronomical observation, biomedical imaging, spectroscopy, etc. In the last decade, wavefront shaping techniques have revolutionized this view, by allowing light focusing and imaging even deep in the multiple scattering regime. This principle is embodied in the possibility—that I pioneered—to access the transmission matrix of a complex medium.
In SMARTIES, I will go one major conceptual step further, by exploiting directly the inherent property of a complex medium to mix perfectly and deterministically the information carried by the light. This mixing is actually a processing step. Along this general idea, SMARTIES will explore two synergistic directions:  
—Classical and quantum optical computing:  Thanks to the highly multimode nature and the strong mixing properties of complex material, I will aim at demonstrating high performance classical computing tasks in the context of randomized algorithms. As a platform for quantum information processing, this will be relevant for high dimension quantum computing algorithms, and quantum machine learning.
—Generalized imaging and sensing: Rather than tediously focusing and imaging through a scattering material, computational approaches can significantly improve and simplify the imaging process. I also aim to show that the relevant information can be directly and optimally extracted from the scattered light without imaging, using machine-learning algorithms. 
From a methodological standpoint, SMARTIES will require bridging knowledge from mesoscopic physics, light-matter interaction, linear and non-linear optics, with algorithms and signal processing concepts. It will deliver a whole new class of optical methods and devices, based on disorder. Its applications range from big data analysis, quantum technologies, to sensors and deep imaging for biology and neuroscience.","1999891","2017-04-01","2022-03-31"
"SMPFv2.0","Next generation single molecule protein fluorescence","Edward Anton Lemke","JOHANNES GUTENBERG-UNIVERSITAT MAINZ","Fluorescence techniques provide powerful means to study single protein machineries. Single molecule observation of Fluorescence Resonance Energy Transfer (FRET) has become an important tool for probing structure, distances, dynamics, physicochemical properties and size of purified (in vitro) protein complexes. Super-resolution techniques provide complementary spatial information about proteins in live (in vivo) specimen. Although these techniques have become very popular because of their high sensitivity, their throughput is limited by large statistical sampling requirements, complex sample preparation procedures and/or laborious data acquisition workflows. Here, I propose to design a unified single molecule approach by engineering ultrafast, semi-synthetic protein modification techniques and fluorescent readouts into nano/microfluidic hybrid devices. The development of an automated all-in-one Lab-on-a-Chip platform will dramatically improve throughput of single molecule fluorescence techniques. The technology will provide a multiparameter readout of molecular protein mechanisms across time, resolution and complexity scales in a generalised workflow. To demonstrate the power of the new platform, I will apply it to a mechanistic study of the multifunctionality of intrinsically disordered proteins (IDPs), which are vital to cellular function and associated with many disease mechanisms. The polymeric properties of IDPs enable them to populate a variety of states and engage with various cellular binding partners, thus exceeding the sampling limit of existing single molecule technologies. The new method will blur the boundaries between in cell superresolution microscopy and biochemical single molecule studies and unleash the true power of single molecule protein science for a range of applications in analytical sciences, drug discovery, biotechnology, systems biology and fundamental biomedical research.","1996990","2015-09-01","2020-08-31"
"SOFT WETTING","Soft Wetting","Jacobus Hendrikus Snoeijer","UNIVERSITEIT TWENTE","The physics of wetting, where a thin layer of fluid covers a solid substrate, finds numerous applications both in nature and industry. While one usually considers the substrate to be perfectly rigid, in many practically important circumstances the surface exhibits strong elastic deformations. Examples of such “Soft Wetting” phenomena are drops spreading on a gel, or roller bearings under heavy loads. Given the increasing technology to control and tune properties of soft matter, there is a strong need for better understanding of: (i) interaction of surface forces (capillarity) and elasticity, and (ii) coupling between fluid flow and visco-elastic dissipation in the solid. The central objective of the proposed research is to establish the governing principles for Soft Wetting and to develop tools for describing practically relevant situations.

The current approach to elastocapillary interactions is almost exclusively based on macroscopic descriptions, leading to contradictory results. I propose to change this by employing truly microscopic methods, namely Molecular Dynamics simulations and (simplified) Density Functional Theory. This will reveal how elastic stresses – induced by liquid interactions on a molecular level – are transmitted in the superficial layers of the solid. From a macroscopic perspective, there is mounting evidence that the visco-elastic rheology of the solid is very important for the dynamics of Soft Wetting: for example, drops spread much more slowly than expected on soft elastomeric surfaces. My goal is to reveal the connection between macroscopic motion and the rheology of the substrate. Experimentally, we combine high-speed visualization of drop spreading with a complete characterization of the substrate rheology. These experiments are complemented by Lattice Boltzmann simulations that account explicitly for visco-elastic substrates. As a whole, the project will provide basic knowledge and methods for a broad class of Soft Wetting phenomena.","1782000","2014-05-01","2019-04-30"
"SOFTBREAK","From bond breaking to material failure in soft polymer networks","jasper Van der gucht","WAGENINGEN UNIVERSITY","The microscopic mechanisms that lead to mechanical failure of soft polymer materials are still poorly understood. The main reason for this is a lack of experimental tools to prepare well-controlled model systems and to observe the failure process in real time at the microscopic scale. Here, I propose to fill this gap by taking a multidisciplinary approach that combines innovative chemical tools with state-of-the art physical experiments and modelling. Previous work in my group has led to the development of polymer networks with extremely well-controlled architecture and bond strength, and of various tools to study their structure and mechanics. Here, I will take advantage of this expertise to systematically unravel the microscopic physics of failure of polymer networks. 
To visualize how the failure process proceeds, we will make use of recently developed mechanosensors, molecules that change colour in response to a force or that emit light when they break. These chemical tools will allow us to map in real time the spatial distribution of both strains and bond rupture events. Together with computer simulations carried out in parallel, this will give us unprecedented insight in the microscopic processes that occur during failure of the material, from the very first bonds that rupture, to the gradual accumulation of damage, all the way to macroscopic failure. We will use this to address the following unresolved questions about failure of polymer networks:
1. What is the microscopic mechanism that leads to delayed failure of polymer networks at subcritical loads? 
2. How does the initiation of failure depend on the material's heterogeneity? 
3. How does failure occur in a network with transient (viscoelastic) bonds?
The project will not only provide detailed insight in the physics of failure of polymer networks, but it will also shed light on fracture physics in general. Finally, it will help material scientists to design new materials with superior properties.","2000000","2016-06-01","2021-05-31"
"SOFTCHARGE","Charge Carrier Transport in Soft Matter: From Fundamentals to High-Performance Materials","Jochen Blumberger","UNIVERSITY COLLEGE LONDON","Charge transport (CT) in soft condensed matter is at the heart of many exciting and potentially revolutionising technologies ranging from organic photovoltaic cells to nanobioelectronic transistors. Tremendous progress has been made on these research frontiers over the last twenty years. Yet, our fundamental understanding of CT in organic and biological semiconductors (OBS) that could rationalise experimental observations and guide further advances in the field is still very limited. These materials are characterised by strong, anharmonic thermal fluctuations and small energy barriers for CT, which renders standard theories such as band theory or activated electron hopping in many cases entirely inadequate. Here, I propose the development of a disruptive computational method‚ based on non-adiabatic molecular dynamics (NAMD), that will open the door for ground-breaking new insight into this problem. The method will be able to access length and time scales that are presently unreachable with existing NAMD methods through an ultrafast yet error-controlled estimation of Hamiltonian matrix elements and derivatives. Applications will focus on (1) ultrapure single crystalline organic semiconductors (OS) to help uncover the true nature of charge carriers and their transport mechanism (2) structurally heterogeneous OS containing crystalline/amorphous interfaces to establish structure-charge mobility relationships (3) Ti-modified OS to aid the design of high dielectric-high mobility hybrid inorganic/organic semiconducting materials for next-generation photovoltaic devices (4) bacterial nanowire proteins to support the development of future bionanoelectronic devices. The work will (i) result in a user-friendly open software tool freely available for the scientific community (ii) yield important guidelines informing the development of high-performance OBS materials that have the potential to transform emerging technologies of the 21st century.","1989988","2016-10-01","2021-09-30"
"Sol-Pro","Solution Processed Next Generation Photovoltaics","Choulis","TECHNOLOGIKO PANEPISTIMIO KYPROU","The profound advantages of printed photovoltaics (PVs), such as their light weight, mechanical flexibility in addition to the small energy demand, and low cost equipment requirements for roll-to-roll mass production, characterise them as a dominant candidate source for future electrical power. Over the last few years, the discovery of novel solution processed electronic materials and device structures boosted PV power conversion efficiency values. Despite that, power conversion efficiency is not a 'stand-alone' product development target for next generation PVs. Lifetime, cost, flexibility and non-toxicity have to be equally considered, regarding the technological progress of solution processed PVs. The ambit of the Sol-Pro research programme is to re-design solution processed PV components relevant to the above product development targets. Based on this, processing specifications as a function of the electronic material properties will be established and provide valuable input for flexible PV applications.  Adjusting the material characteristics and device design is crucial to achieve the proposed high performance PV targets. As a consequence, a number of high-level objectives concerning processing/materials/electrodes/interfaces, relevant to product development targets of next generation solution processed PVs, are aimed for within the proposed ERC programme.","1840940","2015-07-01","2020-06-30"
"SOLACYLIN","A preparative approach to geometric effects in innovative solar cell types based on a nanocylindrical structure","Julien Bachmann","FRIEDRICH-ALEXANDER-UNIVERSITAET ERLANGEN NUERNBERG","The ERC Consolidator Grant project SOLACYLIN aims at providing experimental insight into the function of 'third-generation' photovoltaic systems by generating materials stacks structured in a well-defined, accurately tunable, nanocylindrical geometry.
To this goal, we will develop and exploit advanced preparative methods based on two fundamental ingredients: (a) ordered 'anodic' porous oxides and (b) atomic layer deposition (ALD). The former solids will be generated as templates providing ordered arrays of straight, cyclindrical pores, the diameter and length of which can be varied between 20 nm and 300 nm and between 0.5 microns and 50 microns, respectively. The latter method will be used to coat the inner pore walls with one or several layers of the photovoltaic stack, each with a thickness set to values chosen between 1 nm and 30 nm.
We will invent and characterize novel surface reaction schemes for the deposition in ALD mode (from the gas phase and from solutions) of functional materials (doped semiconductors and intrinsic light absorbers) with tailored chemical and physical properties. We will investigate the experimental conditions in which they can be combined in a way that optimizes the quality of their interfaces.
Finally, we will quantify the electrical and photovoltaic performance of p-i-n junctions prepared with our methods. We will have the unique capability of describing in a systematic, accurate manner how the experimental photovoltaic parameters depend on the individual thicknesses of the individual layers and on the length of the cylinders. This direct experimental handle on the amount of light absorbed, on the one hand, and the charge carrier transport distances to the electrical contacts, on the other hand, will be correlated with the relevant material parameters (absorption coefficients, carrier mobilities). This information will unveil the phenomena limiting the efficiency of each type of solar cell, and suggest avenues to remedy them.","1938655","2015-09-01","2020-08-31"
"SolarALMA","ALMA – The key to the Sun’s coronal heating problem.","Sven Wedemeyer","UNIVERSITETET I OSLO","How are the outer layers of the Sun heated to temperatures in excess of a million kelvin?  A large number of heating mechanisms have been proposed to explain this so-called coronal heating problem, one of the fundamental questions in contemporary solar physics. It is clear that the required energy is transported from the solar interior through the chromosphere into the outer layers but it remains open by which physical mechanisms and how the provided energy is eventually dissipated. The key to solving the chromospheric/coronal heating problem lies in accurate observations at high spatial, temporal and spectral resolution, facilitating the identification of the mechanisms responsible for the transport and dissipation of energy. This has so far been impeded by the small number of accessible diagnostics and the challenges with their interpretation. The interferometric Atacama Large Millimeter/submillimeter Array (ALMA) now offers impressive capabilities. Due to the properties of the solar radiation at millimeter wavelengths, ALMA serves as a linear thermometer, mapping narrow layers at different heights. It can measure the thermal structure and dynamics of the solar chromosphere and thus sources and sinks of atmospheric heating. Radio recombination and molecular lines (e.g., CO) potentially provide complementary kinetic and thermal diagnostics, while the polarisation of the continuum intensity and the Zeeman effect can be exploited for valuable chromospheric magnetic field measurements. 
I will develop the necessary diagnostic tools and use them for solar observations with ALMA. The preparation, optimisation and interpretation of these observations will be supported by state-of-the-art numerical simulations. A key objective is the identification of the dominant physical processes and their contributions to the transport and dissipation of energy. The results will be a major step towards solving the coronal heating problem with general implications for stellar activity.","1995964","2016-09-01","2021-08-31"
"SOLARYS","Composition of solar system small bodies","Pierre BECK","UNIVERSITE GRENOBLE ALPES","The small bodies population (comets, asteroids, KBOs) is today central to Solar System studies. These objects are used to reconstruct the dynamical scenarios of Solar System formation and evolution, and are expected to have played a key role in the habitability of terrestrial planets. Because they are rich in volatile and organics, comets and dark asteroid types (C-, D-) are under intense scrutiny by the Planetary Science community.
 The objective of this project is to determine the composition of these primitive small bodies and whether or not we have samples available from their surfaces in the form of meteorites and extra-terrestrial dusts (IDPs, micrometeorites). Several decades of research have focused on comparing meteorites laboratory spectra to small bodies observations to decipher composition. The originality of my approach will be to focus on determining the optical properties of extra-terrestrial dusts and confront with already available observations of the small bodies populations. 
Since available dusts are tiny particles, they are not optically thick, and it is not possible to determine directly the optical signature of a surface covered by such material. My approach will be first to characterize the constituents of IDPs, micrometeorites and meteorites matrices, with groundbreaking infrared spectroscopy techniques. Using AFM-IR, I will be able to characterize at the 50 nm scale the nature of the individual constituents of each particle in situ (organic and mineral), without destroying the textural relation between components. From there, I will have an understanding of the grain structure and composition, which I will use to prepare an optically thick analogue made of sub-µm particles and characterize its optical properties. Last, I will confront these results to small bodies observations, in order to search for possible parent bodies, providing somehow a sample return mission without the cost of a space mission.","2421180","2018-04-01","2023-03-31"
"SOLID","Search for a new form of matter: the sterile neutrino","Antonin Vacheret","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","The goal of this proposal is to search for an entirely new kind of matter. This type of matter called a sterile neutrino doesn’t
interact with known particles and can only manifest itself through quantum mixing with the three neutrinos of the standard
model, the prevailing theory of particle physics. The known neutrinos are by far the most abundant massive particles in the
Universe. More than 70 years after the postulation of the existence of the neutrino, its nature and fundamental properties
remain, paradoxically, poorly known. The discovery of the quantum mixing of neutrinos: neutrino oscillations, was a major
surprise as it implied that neutrinos have mass which they do not have in the standard model. In this context the existence of
a sterile neutrino is a natural extension but the discovery of this new state of matter would a profound challenge for the
theory to explain. Several new anomalous experimental results have appeared which could be accounted for by the
presence of a light sterile neutrino but each result taken separately is not statistically significant. New oscillation patterns in
the neutrino energy spectrum would be a clear signature of the new state but are difficult to measure due to experimental
and background limitations. We propose the most sensitive search to date for this oscillation signature using two key assets:
The SCK•CEN BR2 reactor which offers a unique low background environment combined with a novel detector technology
invented by the PI capable of discriminating signal and background with greater sensitivity that any previous technique. We
present an experimental program that includes the construction of a detector module and its precise calibration, the
programming of a new type of electronic trigger and implementation of state of the art reconstruction techniques and
analysis. The results that this proposal will deliver are far reaching both in science and in the development of a new
technology for detecting anti-neutrinos.","1818553","2016-06-01","2021-05-31"
"SolMAG","Unravelling The Structure and Evolution of Solar Magnetic Flux Ropes and Their Magnetosheaths","Emilia KILPUA","HELSINGIN YLIOPISTO","Coronal Mass Ejections (CMEs) are spectacular stellar eruptions that carry huge amounts of plasma and magnetic flux into the space. The interests in their origin, structure, and dynamics reach from fundamental plasma physics to paramount impact on their parent stars and the surrounding planets. One of the most outstanding problems in the studies of CMEs is the lack of reliable information on their magnetic field properties until observed directly. This severely limits our understanding of many aspects in the lifespan of CMEs and their far-reaching consequences. SolMAG will deliver realistic and detailed information of the magnetic fields in CMEs. We will further use this knowledge to obtain significant breakthroughs in CME research, including unravelling physical processes that control CME initiation and evolution, and characterizing formation and interaction of key CME structures. A unique opportunity is provided by recent advances in data-driven and time-dependent numerical simulations and state-of-the-art high-quality remote-sensing solar observations. We will form an unprecedented synthesis of a revolutionary coupled coronal simulation my group is now developing and innovative cross-scale observational analyses. UH space physics team is exceptionally well-placed to carry out this challenging project: We have an unusually versatile background in CME research and strong experience both in numerical simulations and data analysis covering the whole Sun to Earth chain. SolMAG is also particularly timely now when our society is becoming increasingly dependent on technology that solar eruptions have potential to damage and the role of CMEs influencing planetary and stellar evolution is being emphasized. In addition, this project will be an important contribution to European Space Agency’s activities, including the future Solar Orbiter and BebiColombo missions, which also provides a natural exit strategy for this project.","1934876","2017-06-01","2022-05-31"
"SOLWET","Electron Transfer Across Solid/Liquid Interfaces: Elucidating Elementary Processes from Femtoseconds to Seconds","Richard Kramer CAMPEN","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Building fuel cells, electrolyzers or photoelectrochemical cells based on water (photo)electrolysis is extremely challenging. One origin of this challenge is the complexity of the underlying physical chemistry. Most such devices require transfer of electrons between solid(s) and water and thus building the best possible devices requires understanding the link between transient changes in bulk solid electronic structure, interfacial electronic structure and interfacial chemistry. Essentially all existing approaches address only part of this picture: e.g. they only probe electronic structure (optical absorption), or extracted current or provide elemental insight but are insensitive to the presence of hydrogen (x-ray absorption). 

In SOLWET, I will address this gap using interface-specific optical spectroscopies, in the visible and infrared, to probe interfacial electronic and vibrational transitions and their coupling. By combining these probes with an additional intense laser pulse I will watch (photo)electrolysis of water in real time as it happens. In particular, I will directly probe the coupling of transiently perturbed solid electronic structure to interfacial electronic structure and watch how this perturbation drives water’s oxidation, for a hematite photoanode, or reduction, for a Pt cathode, through the interfacial vibrational response. By describing how these couplings change with solid modification (e.g. an alumina overlayer on hematite) or changes in aqueous solution composition (e.g. changing the pH in contact with Pt) the results of SOLWET will offer the physical insights necessary to build the best possible hematite and Pt containing photoelectrochemical devices. Moreover, because the novel all-optical tools developed in SOLWET are not system-specific, the approach demonstrated in this work will be widely applicable.","2250000","2018-08-01","2023-07-31"
"SONORA","The Spatial Dynamics of Room Acoustics","Toon Jos M. VAN WATERSCHOOT","KATHOLIEKE UNIVERSITEIT LEUVEN","The SONORA project aims to increase the general understanding of how complex sound scenes are impacted by the spatial dynamics of room acoustics. This knowledge is crucial in the design of signal processing algorithms for audio acquisition and reproduction problems in real-life situations, where moving sound sources and observers interact with room acoustics in a complicated manner.
A major part of the project will be devoted to the development of novel room acoustics models and to the unification of existing models. The room acoustics models developed in this project will be data-driven models with a physically motivated structure, and are expected to fill the existing gap between geometric and wave-based models. This will be achieved by formulating existing and novel models in a dictionary-based mathematical framework and introducing a new concept coined as the equivalent boundary model, aimed at relaxing the prior knowledge required on the physical room boundary.
A second part of the project will focus on the development of a protocol for measuring spatiotemporal sound fields. This protocol will be rooted in a novel sound field sampling theory which exploits the spatial sparsity of sound sources by invoking the compressed sensing paradigm.
Thirdly, novel signal processing algorithms capable of handling spatiotemporal sound fields will be designed. By employing recent advances in large-scale optimization and multidimensional scaling, fast and matrix-free algorithms will be obtained that do not require prior knowledge of the sound scene geometry. 
The SONORA research results are anticipated to have a notable impact in various audio acquisition and reproduction problems, including acoustic signal enhancement, audio analysis, room inference, virtual acoustics, and spatial audio reproduction. These problems have many applications in speech, audio, and hearing technology, hence a significant benefit for industry and for technology end users is expected in the long run.","1999825","2018-05-01","2023-04-30"
"SOPHIA","Securing Software against Physical Attacks","Stefan Mangard","TECHNISCHE UNIVERSITAET GRAZ","More than 15 years ago, several seminal publications showed that cryptographic keys can be revealed by analysing the power consumption or by inducing faults to devices like smart cards. The publication of these so-called physical attacks sparked off research on all kinds of attack techniques and countermeasures to secure implementations of cryptographic schemes. 

However, a system can still be attacked easily if only the execution of cryptographic schemes is secured. An attacker can for example induce a fault to bypass an authentication or to jump to a privileged function directly. The system might also leak the key before the execution of a cryptographic scheme starts.

Today, there is almost no research on securing systems and software execution against physical attacks. Products like smart cards rely on proprietary best-practice countermeasures. Also countless devices of the Internet of Things are exposed to physical attacks and lack protection. 

Our goal is to close this fundamental gap in system security and to establish the scientific foundation for executing software securely and efficiently in the presence of physical attacks. We aim to address research questions that range from the modelling of the attacks at the hardware level up to system-level questions like how changing properties of programming languages can support achieving protection against physical attacks. 

This project brings together research on physical attacks, cryptography, system architectures, fault tolerant design as well as formal methods. Combining the fields, we pursue novel approaches to securing the control flow, CPU computations and memories. We in particular aim to find efficient methods in hardware and software that allow building systems where critical parts of the overall software can be secured against physical attacks without affecting or trusting the rest of the system. Our research also includes automated generation and verification techniques for the secured software.","1964750","2016-09-01","2021-08-31"
"SOPHY","The role of Softness in the Physics of  Defects: Probing Buried Interfaces in Perovskites Optoelectronic Devices","Annamaria PETROZZA","FONDAZIONE ISTITUTO ITALIANO DI TECNOLOGIA","SOPHY will develop the tools and knowledge to probe optoelectronic processes at buried interfaces, in devices, at operating conditions,  delivering a long time pursued target in many fields of nanotechnology. Semiconducting metal halide perovskites, and devices based on them, will be the primary technology under investigation, given its potential to represent the merging point between the efficient inorganic and the chameleonic organic electronics.  The presence of various types of chemical  interactions in such complex ionic solids gives them a characteristic “soft” fluctuating structure, prone to a wide set of defects which span from lattice  distortions to the presence of mobile ions. These are sensitive to the device operating conditions, thus, the control of structure-properties relationship, especially at interfaces, becomes elusive, and the prediction of device operation, necessary to engineer reliable systems, is not possible without an “in vivo” approach. SOPHY addresses the above challenge combining fundamental investigations, material processing, devices fabrication. It will understand the role of structural deformations in determining the “defectiveness” of perovskites and its link to the optoelectronic materials properties. It will put in place an experimental tool which will map in space, with a resolution below 50nm, electronic structures and their excitations, and how they evolve in time over a timescale from fs to microseconds to follow a wide set of cascade phenomena. Such approach, implemented for the first time on diodes’ cross-sections, will allow their study at different operation conditions. The broad impact of this approach will be demonstrated in a series of case studies selected from different key technologies.  Finally, SOPHY will model, for the first time, the operating mechanisms of perovskite based diodes, by being able to take into account the structural and energetic transformations each interface will undergo during operation","2150000","2018-09-01","2023-08-31"
"SPACE TIE","Unifying the three pillars of Geodesy using space ties","Adrian JÄGGI","UNIVERSITAET BERN","""Terrestrial Reference Frames (TRFs) are the basis to which all positions on the Earth’s surface and all satellite orbits in the near Earth space have to refer to. The changes in the Earth's shape, rotation, and gravity field, the so-called """"three pillars"""" of geodesy, provide the conceptual and observational basis for the TRFs. For today’s TRF realizations, four space geodetic techniques are combined and linked by co-location sites on the Earth’s surface (“Earth’s shape”) and by common Earth orientation parameters (“Earth rotation”). The third pillar (“Earth’s gravity field”) is today only contributing to the TRF determination via its associated center-of-mass. In SPACE TIE we will pave the way to unify the “three pillars” of Geodesy in future TRF realizations. We propose to use two satellite geodetic techniques, namely Global Navigation Satellite Systems (GNSS) and Satellite Laser Ranging (SLR), to connect them by co-location sites in space. These so-called space ties shall be realized on satellites of the currently existing space infrastructure, as well as on satellites due for launch in the near future. This includes the Medium Earth Orbits (MEO) of the GNSS satellites and, in particular, all satellites in Low Earth Orbits (LEO) with GNSS and SLR co-located on-board. To maximize the sensitivity to the Earth’s gravity field, the ultra-precise inter-satellite ranging between LEO satellites of dedicated gravity missions shall be added as a third satellite geodetic technique. One and the same state-of-the-art space geodetic software package will be used to ensure that standards, background models, and processing strategies are consistently applied across all co-location satellites and measurement techniques. The outcome of SPACE TIE will allow it to assess the geometric and gravimetric impact of mass transport in the atmosphere, oceans, and ice caps in a most consistent way to globally quantify the mass exchange between the different components of the system Earth.""","1999563","2019-05-01","2024-04-30"
"SPADE","Speleothems paleoclimate: accounting for isotopic disequilibrium","Hagit Pnina AFFEK","THE HEBREW UNIVERSITY OF JERUSALEM","Understanding and quantifying the impacts of climate change at the regional and hemispheric scales are particularly difficult with respect to changes in rainfall and temperature patterns that lead to extended droughts and flooding events. Isotopic records in speleothems are increasingly used to determine climate variability on land and for data-model comparisons. However, transferring speleothem records into quantitative climate parameters suffers from a major limitation: speleothem formation processes result in geochemical disequilibrium and there is currently no way to correct for it in paleoclimate data. SPADE will shift the treatment of paleoclimate archives from regarding them as recorders of slow geological processes to consideration of geological material as recording much faster chemical reactions. As such, they cannot be assumed to form at equilibrium. SPADE will create a new framework, based on one classic and two novel isotopic tracers in carbonates (δ18O-Δ17O-Δ47) to quantify disequilibrium in cave records and overcome this underlying limitation. SPADE’s unique approach is based first on laboratory experiments that isolate chemical processes of speleothem formation, to test their respective effects on isotopic disequilibrium. Then speleothem analog experiments and modern cave material are combined to create speleothem specific calibrations for these isotopic proxies. These SPADE results will then be applied to classic paleoclimate records of dryland hydrology, such as Soreq Cave (Israel) and Devils Hole (Nevada). SPADE will address long standing climatic hypotheses regarding the interplay between temperature, amount of rainfall, surface evaporation, moisture sources, and regional climate connections in these drought vulnerable regions, and will make these records much more useful. A detailed understanding of disequilibrium will enable the use of these innovative geochemical tools in speleothems and more broadly, in other paleoclimate carbonate archives.","2000000","2017-09-01","2022-08-31"
"SPANC","Evolution and Variability of Climate Sensitivity and Polar Amplification during CeNozoic Warm Climates SPANC","Appy SLUIJS","UNIVERSITEIT UTRECHT","Forecasting the magnitude of future global warming is among the great scientific challenges. Model estimates of long-term warming resulting from a doubling of the CO2 concentration relative to the pre-industrial era range between 1.5 and 4.5 °C. The large uncertainty in this Equilibrium Climate Sensitivity (ECS) may represent the difference between the melting or conservation of large continental ice sheets, and between habitable and inhabitable regions. SPANC will quantify ECS through accurate reconstructions of past climate change. Existing ECS studies largely focus on periods that were colder than present. Importantly, however, my development of a reliable method to reconstruct past CO2 concentrations now allows for estimates of past warm climates that can serve as analogs for the future. 
First, I will calibrate the new CO2 proxy for high CO2 levels. Uniquely, my new approach allows CO2 and temperature reconstructions to be based on the same samples, implying optimal time control. This provides the outstanding opportunity to generate high-quality coupled CO2 and temperature reconstructions for the ice-free early Eocene and the warm but glaciated middle Miocene at unprecedented resolution. This allows ECS to be calculated based on long and short-term variability in CO2 and temperature. The combination of ice-free and glaciated periods will also determine the extent to which the presence of ice governs climate response to CO2. Study locations will be carefully selected across pole-equator transects. This allows for quantification of the amplification of temperature changes towards polar regions, crucial for ice sheet extent and volume and hence global sea levels.
SPANC will provide a breakthrough regarding the ECS of warm climates. It will provide crucial new constraints on the ability of climate models to correctly simulate warm climates and climate variability forced by changes in CO2 concentrations, which is vital for reliable future climate projections.","2000000","2018-09-01","2023-08-31"
"SPCND","Supernovae: Physics and Cosmology in the Next Decade","Mark Sullivan","UNIVERSITY OF SOUTHAMPTON","Exploding stars, or supernovae, impact upon many diverse areas of astrophysics, from galaxy formation, to stellar evolution, to cosmology and studies of dark energy. I am playing a leading role in new, wide-field, high-cadence optical surveys that are revolutionising the study of supernovae, searching vast volumes of space, locating hundreds of events to study their demographics in detail, and uncovering new and bizarre types of explosions. In concert with a major European Southern Observatory public spectroscopic survey, PESSTO, these imaging surveys will provide an extraordinary dataset for understanding all facets of the supernova and explosive transient population. My work will perform several tests of the progenitors and physics of the classical type Ia supernovae in an attempt to understand how these crucial standard candles depend on their progenitor stellar populations. I will use these results to inform a new generation of models of type Ia supernovae. I will this distill these results to make a detailed measurement of the dark energy that powers the accelerating universe in which we live, greatly improving upon existing measurements of the variation of dark energy over the last ten billion years. A final aspect of my research is an innovative search for superluminous supernovae: a new class of supernova explosion a hundred times brighter than traditional supernovae, capable of being studied in the very distant universe. These objects may become cosmology's new standard candle, visible far beyond the reach of type Ia supernovae. My new search will significantly increase both the quantity and quality of superluminous supernova observations, allowing us to further our understanding of these enigmatic objects and use them in a cosmological setting for the first time.","1970745","2014-06-01","2019-05-31"
"SpecMAT","Spectroscopy of exotic nuclei in a Magnetic Active Target","Riccardo Raabe","KATHOLIEKE UNIVERSITEIT LEUVEN","SpecMAT aims at providing crucial experimental information to answer key questions about the structure of atomic nuclei:

- What are the forces driving the shell structure in nuclei and how do they change in nuclei far from stability?
- What remains of the Z = 28 and N = 50 “magic numbers” in 78Ni?
- Do we understand shape coexistence in nuclei, and what are the mechanisms controlling its appearance?

The position of natural and “intruder” shells will be mapped in two critical regions, the neutron-rich nuclei around Z = 28 and the neutron-deficient nuclei around Z = 82. The centroids of the shell strength are derived from the complete spectroscopy of those systems in nucleon-transfer measurements. This method will be applied for the first time in the region of neutron-deficient Pb nuclei.

In SpecMAT (Spectroscopy of exotic nuclei in a Magnetic Active Target) a novel instrument will overcome the present challenges in performing such measurements with very weak beams of unstable nuclei. It combines high luminosity, high efficiency and a very large dynamic range and allows detection of both charged-particle and gamma-ray radiation. The instrument owns its remarkable performances to a number of advanced technologies concerning the use of electronics, gaseous detectors and gamma-ray detectors in a magnetic field.

The SpecMAT detector will be coupled to the HIE-ISOLDE facility for the production and post-acceleration of radioactive ion beams in construction at CERN in Geneva. HIE-ISOLDE will provide world-unique beams thanks to the use of the proton injector of the CERN complex.

If successful, SpecMAT at HIE-ISOLDE will produce specific results in nuclear structure which cannot be reached by other programmes elsewhere. Such results will have a significant impact on the present theories and models of the atomic nucleus.","1944900","2014-06-01","2019-05-31"
"SPECTRACON","Materials Engineering of Integrated Hybrid Spectral Converters for Next Generation Luminescent Solar Devices","Rachel EVANS","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Solar energy conversion will play a key role in our transition to a carbon-neutral society. However, single junction photovoltaic (PV) cells fail to achieve their theoretical efficiency due to an inability to harness all wavelengths of the solar spectrum. Spectral losses may be overcome through the addition of a spectral converter coating to the surface of a finished PV cell, which, through a photoluminescence process, converts solar photons into wavelengths suitable for use. Nonetheless, spectral converters currently fail to deliver their promise to significantly boost PV cell performance due to the difficulties of translating luminescent molecules (lumophores) from solution into efficient solid-state materials.

By considering the lumophore-host material as an integrated unit, rather than discrete components, in SPECTRACON, I take a radically new approach to the design of spectral converters. Organic-inorganic hybrid polymer hosts incorporating covalently-grafted lumophores will be rationally engineered to deliver spectral converters with the tailored optical, structural, viscoelastic and mechanical properties needed for high performance solid-state conversion, which has so far been unattainable. Using cheap materials and a solution-based process suitable for scalable manufacturing, these spectral converters will be integrated with PV cells to realise next generation luminescent solar devices which display record levels of efficiency and reduced costs.

A scientific breakthrough that demonstrates efficient solar spectral conversion in the solid-state would enable immediate deployment of luminescent solar devices to the commercial market, thus accelerating progress to an all-renewables society and delivering unprecedented impact on the quality of life of future generations. Moreover, the fundamental knowledge gleaned on the design of efficient solid-state emitters will open up new frontiers for application in light-emitting displays, optical storage and sensing.","2124593","2019-05-01","2024-04-30"
"SpeedInfTradeoff","Speed-Information Tradeoffs: Beyond Quasi-Entropy Analysis","Nir Yosef Ailon","TECHNION - ISRAEL INSTITUTE OF TECHNOLOGY","The starting point of this research proposal is a recent result by the PI, making progress in a half century old,
notoriously open problem. In the mid 1960’s, Tukey and Cooley discovered the Fast Fourier Transform, an
algorithm for performing one of the most important linear transformations in science and engineering, the
(discrete) Fourier transform, in time complexity O(n log n).
In spite of its importance, a super-linear lower bound has been elusive for many years, with only very limited
results. Very recently the PI managed to show that, roughly speaking, a faster Fourier transform must result
in information loss, in the form of numerical accuracy. The result can be seen as a type of computational
uncertainty principle, whereby faster computation increases uncertainty in data. The mathematical argument
is established by defining a type of matrix quasi-entropy, generalizing Shannon’s measure of information
(entropy) to “quasi-probabilities” (which can be negative, more than 1, or even complex).
This result, which is not believed to be tight, does not close the book on Fourier complexity. More importantly,
the vision proposed by the PI here reaches far beyond Fourier computation. The computation-information
tradeoff underlying the result suggests a novel view of complexity theory as a whole. We can now revisit
some classic complexity theoretical problems with a fresh view. Examples of these problems include better
understanding of the complexity of polynomial multiplication, integer multiplication, auto-correlation and
cross-correlation computation, dimensionality reduction via the Fast Johnson-Linednstrauss Transform (FJLT;
also discovered and developed by the PI), large scale linear algebra (linear regression, Principal Component
Analysis - PCA, compressed sensing, matrix multiplication) as well as binary functions such as integer multiplication.","1515801","2016-06-01","2021-05-31"
"SPICE","Spectroscopy in cells with tailored in-vivo labelling strategies and multiply addressable nano-structural probes","Malte DRESCHER","UNIVERSITAT KONSTANZ","This project proposes to combine complementary spectroscopic approaches and push the domain of molecular spectroscopy for structural biology and biophysics into the living cell. 

Non-invasive molecular spectroscopy to probe protein dynamics and structures at the molecular level is essential for unravelling one of the most challenges in Chemical Biology - the complex physical mechanism of life. Of particular interest are electron paramagnetic resonance (EPR) distance measurements in the nanometer range, especially, when they will be combined with complementary spectroscopic techniques. By now, different spectroscopic approaches require specific labelling strategies and probes. In this project, we will develop multiply-addressable nano-structural probes that are in parallel suitable for various spectroscopic techniques, e.g.  magnetic resonance spectroscopy (NMR and EPR), vibrational spectroscopy, and optical (including single molecule) spectroscopy and microscopy. This enables obtaining information on all relevant length and time scales for the very same sample. Labelling will be performed directly in the native intracellular environment, where the proteins are folded, modified, transferred and degraded. Corresponding spectroscopic experiments can be combined or re-arranged for novel experiments even in cellula.

Current characterization methods for structure and dynamics of proteins are generally applied in vitro. In the cell, posttranslational modifications, crowding effects, organelle specific localization, or non-specific or specific interactions with cellular components significantly affect structure and conformational equilibria of proteins. We will demonstrate that novel in-cell spectroscopy approaches developed within the SPICE-project using multiply-addressable nano-structural probes and in vivo labelling strategies will open up possibilities to explore larger and more complex biological structures at the molecular level in cellula, which has hitherto been","1988698","2018-06-01","2023-05-31"
"SPIN","Symmetry Principles in Nature","Mukund Rangamani","UNIVERSITY OF DURHAM","Symmetries have traditionally played a very important role in our understanding of physics, both classical and quantum. As we move towards the next frontier of defining a quantum theory of gravity, it is clear that they will continue to play a predominant role. The current project is aimed at obtaining a comprehensive  understanding of the dynamics of strongly coupled quantum systems, exploiting various symmetry properties that one expects on physical grounds. Specifically, the aim is to come up with effective descriptions of a wide class of quantum dynamics in gravitational and non-gravitational theories using the holographic gauge/gravity correspondence.

One of the primary strands of the proposed research involves a critical examination of gravitational theories with higher spin symmetry. We will investigate the phase structure of such theories, the nature of gravitational solutions and notions of classical geometry in the presence of the enlarged gauge symmetry. Using appropriate generalizations of the gauge/gravity correspondence we will try to give gauge invariant characterizations of these concepts and further explore how such higher spin theories can be realized in string theory. A related strand of research concerns a deeper understanding of the gauge/gravity correspondence itself,  with focus on figuring out how collective behaviour of strongly coupled field theories leads to the emergence of extra symmetries, such as local diffeomorphisms in the dual description. Along the way we will also develop effective descriptions for collective dynamics of strongly coupled quantum degrees of freedom, both in and out of equilibrium.","1400758","2014-05-01","2019-04-30"
"SPIN-PORICS","Merging Nanoporous Materials with Energy-Efficient Spintronics","Jordi Sort Vinas","UNIVERSITAT AUTONOMA DE BARCELONA","This Project aims to integrate engineered nanoporous materials into novel energy-efficient spintronic applications. Magnetic storage and magneto-electronic devices are conventionally controlled by means of magnetic fields (via electromagnetic induction) or using spin-polarized electric currents (spin-transfer torque). Both principles involve significant energy loss by heat dissipation (Joule effect). The replacement of electric current with electric field would drastically reduce the overall power consumption. Strain-mediated magneto-electric coupling in piezoelectric-magnetostrictive bilayers might appear a proper strategy to achieve this goal. However, this approach is not suitable in spintronics because of the clamping effects with the substrate, need of epitaxial interfaces and risk of fatigue-induced mechanical failure. The exciting possibility to control ferromagnetism of metals and semiconductors directly with electric field (without strain) has been recently reported, but most significant effects occur below 300 K and only in ultra-thin films or nanoparticles. This Project tackles the development of a new type of nanocomposite material, comprising an electrically conducting or semiconducting nanoporous layer filled with a suitable dielectric material, where the magnetic properties of the metal/semiconductor will be largely tuned at room temperature (RT) by simply applying a voltage, via electric charge accumulation. The porous layer will consist of specific alloys (Cu-Ni or Fe-Rh) or oxide diluted magnetic semiconductors, where surface magnetic properties have been recently reported to be sensitive to electric field at RT. Based on these new materials, three technological applications are envisaged: electrically-assisted magnetic recording, voltage-driven switching of magnetic random-access memories and spin field-effect transistors. The obtained results are likely to open new paradigms in the field of spintronics and could be of high economic transcendence.","1794380","2015-09-01","2020-08-31"
"SPINAPSE","Creating complexity: toward atomic spin-based neural hardware","Alexander KHAJETOORIANS","STICHTING KATHOLIEKE UNIVERSITEIT","The growing trend in global electricity consumption has created a new challenge for materials-based science: to find computational paradigms toward ICT that are not only smaller and faster, but also energy-efficient. A new source of inspiration is the human brain, which consumes a mere 20 W of energy, while a supercomputer consumes about 10 MW. The emerging field of brain-inspired hardware aims at utilizing physical phenomena in high-quality materials toward pattern recognition and energy- efficient ICT. The goal of this project is to adapt the principles of magnetism toward brain-inspired hardware, utilizing individual and coupled atomic spins. The ultimate aim of SPINAPSE is to probe the feasibility and create proof-of-concept systems, which demonstrate computational principles such as pattern recognition. I define three objectives, which address understanding magnetism in the three most prominent neural models: (1) Hopfield model, (2) Perceptron, (3) Reservoir computing. The strategy is to utilize the so-called spin workbench, based on low-temperature scanning tunneling microscopy, as a platform to create tailored spin arrays with atomic-scale control. This method combines single atom magnetic imaging and atom-scale fabrication, enabling the control of the magnetic interactions and dynamics between ensembles of atoms, atom by atom. We will construct bottom-up magnetic nanostructures to implement all-spin and atomic-scale based neural hardware. We will deliver a new state of the art in magnetic imaging, including (a) developing the spin workbench with a newly built 30 mK magnetic STM facility, defining a new state of the art in magnetic imaging worldwide, and (b) time-resolved imaging to probe the magnetization dynamics of stochastic spin arrays at milliKelvin temperatures. The outcome of SPINAPSE will deliver a new state of the art, new fundamental understandings, and create proof-of-concept technologies for atomic-scale brain-inspired hardware.","2357390","2019-03-01","2024-02-29"
"SPINBEYOND","Spin Transport Beyond Electrons","Rembertus Abraham Duine","UNIVERSITEIT UTRECHT","Spintronics is motivated by the quest for the next-generation beyond-Moore electronics. The conventional approach that is based on single-electron spin currents does, however, not solve the thermodynamic bottleneck that is caused by the dissipation associated with moving electrons. A revolutionary new approach to electronics is based on information processing and transfer by means of magnons, i.e., quanta of the collective spin-wave excitations in magnets, so that the electrons do not move at all. On top of this application perspective, magnons give rise to completely new physical phenomena that arise due to magnonic collective effects and that do not fit the paradigm of single-electron spintronics.
This shift from single-electron to collective degrees of freedom to carry spin current – in large part substantiated by a 2015 experimental breakthrough involving the PI – calls for the formulation of a new basic model that includes these novel collective phenomena on equal footing with single-particle spin currents. It is the central and unifying scientific goal of this theoretical-physics proposal to develop this model. We focus on three material systems: ferromagnetic insulators, ferromagnetic metals, and antiferromagnets, and for each of these the objective is to bring out the new physics that arises due to i) coupled spin-heat transport in the linear-response regime, ii) collective effects in spin valves, and iii) magnon Bose-Einstein condensation and spin superfluidity. The latter paves the way for “magnon superspintronics”, the integration of room-temperature spin superfluidity with spintronics. In terms of methodology the proposed research spans the spectrum from phenomenological hydrodynamic theory to evaluation of the various bulk and interface parameters from microscopic descriptions. Our recent work gives us, combined with our background in cold-atom systems, a head start to carry out the proposed research.","1617500","2017-09-01","2022-08-31"
"SPIRE","Stars: dynamical Processes driving tidal Interactions, Rotation and Evolution","Stephane Frédéric Noël Paul Mathis","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","The rotational dynamics of stars strongly impacts their evolution and those of their planetary and galactic environment. Space helio- and asteroseismology recently allowed an observational revolution in this domain. They revealed, e.g., that the core of the Sun is close to a uniform rotation while those of subgiant and red giant stars slow down drastically during their evolution. These important results demonstrate that powerful dynamical mechanisms (internal waves, magnetic fields, turbulence) are in action to extract angular momentum all along the evolution of stars.

Simultaneously, a very large diversity of stellar systems has been discovered and their number will strongly increase thanks to new space missions (K2, TESS, PLATO). It is thus urgent to progress on our understanding of star-planet and star-star interactions: highly complex dynamical processes leading to tidal dissipation in stars play a key role to shape the orbital architecture of their systems and they may deeply modify their evolution.
  
To interpret these observational breakthroughs, it is necessary to develop now new frontier theoretical and numerical long-term evolution models of rotating magnetic stars and of their systems. To reach this ambitious objective, the SPIRE project will develop new groundbreaking equations, prescriptions, and scaling laws that describe coherently all dynamical mechanisms that transport angular momentum and drive tidal dissipation in stars using advanced semi-analytical modeling and numerical simulations. They will be implemented in the new generation dynamical stellar evolution code STAREVOL and N-body code ESPER. This will allow us to provide state-of-the-art ab-initio integrated and coupled models for the long-term evolution of stars and of their systems, which cannot be directly simulated in 3D yet. SPIRE will thus provide key inputs for the whole astrophysical community: understanding the dynamics of stars is a fundamental step to understand our Universe.","1839634","2015-09-01","2020-08-31"
"SPOOC","Automated Security Proofs of Cryptographic Protocols: Privacy, Untrusted Platforms and Applications to E-voting Protocols","Steve Kremer","INSTITUT NATIONAL DE RECHERCHE ENINFORMATIQUE ET AUTOMATIQUE","The rise of the Internet and the ubiquity of electronic devices has deeply changed our way of life. Many face to face and paper transactions have nowadays digital counterparts: home banking, e- commerce, e-voting, etc. The security of such transactions is ensured by the means of cryptographic protocols. While historically the main goals of protocols were to ensure confidentiality and authentication the situation has changed. The ability of people to stay connected constantly combined with ill-conceived systems seriously threatens people’s privacy. E-voting protocols need to guarantee privacy of votes, while ensuring transparency of the voting process; RFID and mobile telephone protocols have to guarantee that people cannot be traced. Moreover due to viruses and malware, personal computers and mobile phones must not be considered anymore to be trustworthy; yet they have to be used to execute protocols that need to achieve security goals. To detect flaws, prove the security of protocols and propose new design principles the Spooc project will develop solid foundations and practical tools to analyze and formally prove security properties that ensure the privacy of users as well as techniques for executing protocols on untrusted platforms. We will

- develop foundations and practical tools for specifying and formally verifying new security properties, in particular privacy properties;

- develop techniques for the design and automated analysis of protocols that have to be executed on untrusted platforms;

- apply these methods in particular to novel e-voting protocols, which aim at guaranteeing strong security guarantees without need to trust the voter client software. 

The Spooc project will significantly advance formal verification of security protocols and contribute to the development of a rich framework that provides techniques and tools to analyze and design security protocols guaranteeing user’s privacy and relaxing trust assumptions on the execution platforms.","1903500","2015-09-01","2020-08-31"
"SPRINT","Ultra-Short Pulse laser Resonators IN the Terahertz","Miriam Serena Vitiello","CONSIGLIO NAZIONALE DELLE RICERCHE","""Ultra-short light pulses with large instantaneous intensities can probe light-matter interaction phenomena, capture snapshots of molecular dynamics and drive high-speed communications. In a semiconductor laser, mode-locking is the primary way to generate ultrafast signals. Despite the intriguing perspectives, operation at Terahertz (THz) frequencies is facing fundamental limitations: engineering ""ultrafast"" THz semiconductor lasers from scratch or finding an integrated technology to shorten THz light pulses are currently two demanding routes. 
SPRINT aims to innovatively combine the groundbreaking quantum cascade laser (QCL) technology with graphene, to develop a new generation of passive mode-locked THz photonic laser resonators, combined with unexplored electronic nanodetectors for ultrafast THz sensing and imaging.
To achieve these ambitious objectives, the versatile quantum design of QCLs will be exploited to engineer the laser gain spectrum on purpose. Resonators of unusual symmetry and shape, like photonic quasi-crystals or random patterns, will be implemented, offering the flexibility to control and guide photons and the lithographic capability to embed miniaturized intra-cavity passive components to probe and modulate light. Graphene, owing to its gapless nature and ultrafast, gating-tunable carrier dynamic, will lead to a major breakthrough: integration in the THz QCL cavity will allow superbly manipulating its functionalities. Antenna-coupled quantum-dot nanowires will be also devised to sense and probe ultra-short THz pulses.
The project will target radically new concepts and interdisciplinary approaches encompassing unconventional THz QCL micro-resonators, graphene and polaritonic THz saturable absorbers, non-linear ultra-low dimensional detection architectures. 
Pushing forward the understanding of ultrafast dynamics in complex THz electronic and photonic systems, SPRINT prospects new directions and long-term impacts on fundamental and applied science.""","1990011","2016-09-01","2021-08-31"
"SSBD","Small Summaries for Big Data","Graham Cormode","THE UNIVERSITY OF WARWICK","A fundamental challenge in processing the massive quantities of information generated by modern applications is in extracting suitable representations of the data that can be stored, manipulated and interrogated on a single machine.  A promising approach is in the design and analysis of compact summaries: data structures which capture key features of the data, and which can be created effectively over distributed data sets.  Popular summary structures include the Bloom filter, which compactly represents a set of items, and sketches which allow vector norms and products to be estimated.  These are very attractive, since they can be computed in parallel and combined to yield a single, compact summary of the data. Yet the full potential of summaries is far from being fully realized. 

The Principal Investigator will lead a team, working on important problems around creating Small Summaries for Big Data.  The goal is to substantially advance the state of the art in data summarization, to the point where accurate and effective summaries are available for a wide array of problems, and can be used seamlessly in applications that process big data.  Several directions will be pursued, including: designing and evaluating new summaries for fundamental computations such as tracking the data distribution;  summary techniques for complex structures, such as massive matrices, massive graphs, and beyond;  and summaries that allow the verification of outsourced computation over big data.  Success in any one of these areas could lead to substantial impact on practice, as evidenced by the influence of existing summary
techniques. 

Support in the form of a five-year research grant will allow the PI to consolidate his research in this area, and build an expert team to focus on these challenging algorithmic questions.","1565502","2015-05-01","2020-04-30"
"SSS","Scalable Similarity Search","Rasmus Pagh","IT-UNIVERSITETET I KOBENHAVN","Similarity search is the task of identifying, in a collection of items, the ones that are “similar” to a given
query item. This task has a range of important applications (e.g. in information retrieval, pattern
recognition, statistics, and machine learning) where data sets are often big, high dimensional, and
possibly noisy. State-of-the-art methods for similarity search offer only weak guarantees when faced with
big data. Either the space overhead is excessive (1000s of times larger than the space for the data itself),
or the work needed to report the similar items may be comparable to the work needed to go through all
items (even if just a tiny fraction of the items are similar). As a result, many applications have to resort to
the use of ad-hoc solutions with only weak theoretical guarantees.

This proposal aims at strengthening the theoretical foundation of scalable similarity search, and
developing novel practical similarity search methods backed by theory. In particular we will:

- Leverage new types of embeddings that are kernelized, asymmetric, and complex-valued.

- Consider statistical models of noise in data, and design similarity search data structures whose
performance guarantees are phrased in statistical terms.

- Build a new theory of the communication complexity of distributed, dynamic similarity search,
emphasizing the communication bottleneck present in modern computing infrastructures.

The objective is to produce new methods for similarity search that are: 1) Provably robust, 2) scalable
to large and high-dimensional data sets, 3) substantially more resource efficient than current state-ofthe-
art solutions, and 4) able to provide statistical guarantees on query answers.

The study of similarity search has been an incubator for techniques (e.g. locality-sensitive hashing and
random projections) that have wide-ranging applications. The new techniques developed in this project
are likely to have significant impacts beyond similarity search.","1889712","2014-05-01","2019-04-30"
"StabCondEn","Stability Conditions, Moduli Spaces and Enhancements","Paolo STELLARI","UNIVERSITA DEGLI STUDI DI MILANO","I will introduce new techniques to address two big open questions in the theory of derived/triangulated categories and their many applications in algebraic geometry.

The first one concerns the theory of Bridgeland stability conditions, which provides a notion of stability for complexes in the derived category. The problem of showing that the space parametrizing stability conditions is non-empty is one of the most difficult and challenging ones. Once we know that such stability conditions exist, it remains to prove that the corresponding moduli spaces of stable objects have an interesting geometry (e.g. they are projective varieties). This is a deep and intricate problem.

On the more foundational side, the most successful approach to avoid the many problematic aspects of the theory of triangulated categories consisted in considering higher categorical enhancements of triangulated categories. On the one side, a big open question concerns the uniqueness and canonicity of these enhancements. On the other side, this approach does not give a solution to the problem of describing all exact functors, leaving this as a completely open question. We need a completely new and comprehensive approach to these fundamental questions.

I intend to address these two sets of problems in the following innovative long-term projects:

1. Develop a theory of stability conditions for semiorthogonal decompositions and its applications to moduli problems. The main applications concern cubic fourfolds, Calabi-Yau threefolds and Calabi-Yau categories.

2. Apply these new results to the study of moduli spaces of rational normal curves on cubic fourfolds and their deep relations to hyperkaehler geometry.

3. Investigate the uniqueness of dg enhancements for the category of perfect complexes and, most prominently, of admissible subcategories of derived categories.

4. Develop a new theory for an effective description of exact functors in order to prove some related conjectures.","785866","2018-02-01","2023-01-31"
"STAMFORD","Statistical Methods For High Dimensional Diffusions","Mark Podolskij","AARHUS UNIVERSITET","In the past twenty years the availability of vast dimensional data, typically referred to as big data, has given rise to exciting challenges in various fields of mathematics and computer sciences. The increasing need for getting a better understanding of such data in internet traffic, biology, genetics, and economics, has lead to a revolution in statistical and machine learning, optimisation and numerical analysis. Due to high dimensionality of modern statistical models, parameter estimation is a difficult task and statisticians typically investigate estimation methods under sparsity constraints. While an abundance of estimation algorithms is now available for high dimensional discrete models, a rigorous mathematical investigation of estimation problems for high dimensional continuous-time processes is completely undeveloped.

The aim of STAMFORD is to provide a concise statistical theory for estimation of high dimensional diffusions. Such high dimensional processes naturally appear in modelling particle interactions in physics, neural networks in biology or large portfolios in economics, just to name a few. The methodological part of the project will require development of novel 
advanced techniques in mathematical statistics and probability theory. In particular, new results will be needed in parametric and non-parametric statistics, and high dimensional probability, that are reaching far beyond the state-of-the-art. Hence, a successful outcome of STAMFORD will not only have a tremendous impact on statistical inference for continuous-time models in natural and applied sciences, but also strongly influence the field of high dimensional statistics and probability.","1655048","2019-09-01","2024-08-31"
"stardust2asteroids","Stardust to asteroids: Unravelling the formation and earliest evolution of a habitable solar system","Martin Bizzarro","KOBENHAVNS UNIVERSITET","As far as we know, our solar system is unique. It could, in principle, be the only planetary system in the Universe to harbor intelligent life or, indeed, life at all. As such, attempting to reconstruct its history is one of the most fundamental pursuits in the natural sciences. Whereas astronomical observations of star- forming regions provide a framework for understanding the formation of low-mass stars and the early evolution of planetary systems in general, direct information about the earliest solar system can only come from primitive meteorites and their components and some differentiated meteorites that record the birth of the solar system. The main objective of this proposal is to investigate the timescales and processes – including the role of supernovas – leading to the formation of the solar system by measurement of isotopic variations in meteorites. To achieve our objectives, we will integrate long-lived and short-lived radioisotope chronometers with the presence/absence of nucleosynthetic anomalies in various meteorites and meteoritic components. Our isotopic measurements will be obtained using state-of-the-art technologies such as second-generation mass spectrometers housed in laboratories directed by the PI and fully dedicated to cosmochemistry. This will allow us to: 1) define the mechanism and timescale for the collapse of the protosolar molecular cloud and emergence of the protoplanetary disk, 2) constrain the source and locale of chondrule-forming event(s) as well as the nature of the mechanism(s) required to transport chondrules to the accretion regions of chondrites, and 3) provide robust estimates of the timing and mechanism of asteroidal differentiation. We aim to understand how the variable initial conditions imposed by the range of possible stellar environments and protoplanetary disk properties regulated the formation and assemblage of disk solids into asteroidal and planetary bodies comprising our solar system.","1910889","2014-02-01","2019-01-31"
"STARKEY","Solving the TP-AGB STAR Conundrum: a KEY to Galaxy Evolution","Paola Marigo","UNIVERSITA DEGLI STUDI DI PADOVA","""Models of the Thermally Pulsing Asymptotic Giant Branch (TP-AGB) stellar evolutionary phase play a critical role across astrophysics, from the chemical composition of meteorites belonging to the pre-solar nebula up to galaxy evolution in the high-redshift Universe. In spite of its importance, the modelling of TP-AGB  is still affected by large uncertainties that propagate into the field of extragalactic astronomy, degrading the predicting power of current population synthesis models of galaxies. The major goal of this proposal is to remedy this persistent condition of uncertainty and controversy. The solution to the TP-AGB star conundrum will be provided by a new approach, which stands on the optimised integration of a) state-of-the-art theoretical tools to account for the complex physics of TP-AGB stars (evolution, nucleosynthesis, pulsation, winds, dust formation, etc.), and b) exceptionally high-quality observations of resolved TP-AGB stellar populations in stars clusters and nearby galaxies (Magellanic Clouds, M31, dwarf galaxies up to 4 Mpc) with reliable measurements of their star formation histories. We will adopt a global calibration method, in which TP-AGB evolution models are required to simultaneously reproduce a set of well-defined observational constraints (distributions of luminosities, colours, pulsation periods, dust mass-loss rates, expansion velocities of dusty envelopes, etc.). This project will deepen our understanding of TP-AGB physics profoundly, and provide wide-spread community benefits as well. We will publicly release well-tested and reliable ``TP-AGB products'', including stellar tracks, isochrones in all photometric systems, and chemical yields for both gas and dust. Eventually these products will be embedded in the stellar population synthesis models that are routinely used to analyse the integrated galaxy observables that probe the extragalactic Universe.""","1930628","2014-05-01","2019-04-30"
"STEEPclim","Spatiotemporal evolution of the hydrological cycle throughout the European continent during past abrupt climate changes","Dirk Sachse","HELMHOLTZ ZENTRUM POTSDAM DEUTSCHESGEOFORSCHUNGSZENTRUM GFZ","With global temperatures on the rise due to anthropogenic greenhouse gas emissions, one of the largest short-term threats to societies comes from a changing water cycle: changing ocean currents and atmospheric circulation patterns, increased periods of drought or extreme precipitation events directly affect the socio-economic foundation of communities. However, one of the great unknowns in state-of-the art climate models predicting future changes is the spatial distribution of changing precipitation patterns. This lack of knowledge severely limits implementation of mitigation and adaptation options to divert the most severe consequences of climate change.
I propose a fundamentally new approach to understand spatial patterns and mechanisms of hydrological changes on the European continent by reconstructing such changes during past abrupt temperature and ocean circulation changes. We will develop an innovative research program integrating ideas and methods from diverse disciplines: organic geochemistry, plant physiology, event stratigraphy and geostatistical data analysis. We will generate quantitative paleohydrological data by developing a dual biomarker approach as a novel and direct proxy for fluxes in the hydrological cycle from 10 of the most precisely dated terrestrial climate records encompassing the European continent.
STEEPclim will enter uncharted territory and establish master records of continental climate change, comparable in resolution and quality to the polar ice cores. We will identify continental-scale feedback mechanisms and particularly vulnerable regions in European hydroclimate relevant for the evaluation of the consequences of ongoing climate change. These mechanistic insights will be essential to validate future generations of climate models, ensuring more accurate predictions of regional effects of anthropogenic climate changes and as such enable a targeted mitigation and adaptation policy.","1847546","2015-08-01","2020-07-31"
"STERCP","Synchronisation to enhance reliability of climate predictions","Noel Sebastian Keenlyside","UNIVERSITETET I BERGEN","Climate prediction is the next frontier in climate research. Prediction of climate on timescales from a season to a decade has shown progress, but beyond the ocean skill remains low. And while the historical evolution of climate at global scales can be reasonably simulated, agreement at a regional level is limited and large uncertainties exist in future climate change. These large uncertainties pose a major challenge to those providing climate services and to informing policy makers.

This proposal aims to investigate the potential of an innovative technique to reduce model systematic error, and hence to improve climate prediction skill and reduce uncertainties in future climate projections. The current practice to account for model systematic error, as for example adopted by the Intergovernmental Panel on Climate Change, is to perform simulations with ensembles of different models. This leads to more reliable predictions, and to a better representation of climate. Instead of running models independently, we propose to connect the different models in manner that they synchronise and errors compensate, thus leading to a model superior to any of the individual models – a super model. 

The concept stems from theoretical non-dynamics and relies on advanced machine learning algorithms. Its application to climate modelling has been rudimentary. Nevertheless, our initial results show it holds great promise for improving climate prediction. To achieve even greater gains, we will extend the approach to allow greater connectivity among multiple complex climate models to create a true super climate model. We will assess the approach’s potential to enhance seasonal-to-decadal prediction, focusing on the Tropical Pacific and North Atlantic, and to reduce uncertainties in climate projections. Importantly, this work will improve our understanding of climate, as well as how systematic model errors impact prediction skill and contribute to climate change uncertainties.","1999389","2015-09-01","2020-08-31"
"STEREOPOL","Stereocontrolled Polymerisation: New Frontiers in Synthesis and Supramolecular Self Assembly","Andrew Peter Dove","THE UNIVERSITY OF BIRMINGHAM","Nature has evolved the ability to create large and complex molecules in which the 3-dimensional orientation of the atoms is critical to their performance. The essential nature of stereochemistry to the structure, and hence performance, of biopolymers makes it reasonable to expect such aspects of synthetic materials to be equally important. This area has however received little study, which is partially a consequence of the significant challenges of creating large macromolecules with well-defined stereochemistry at each repeat unit. This proposal is inspired by nature, to design polymers with exquisite structural control in which the behaviour and properties of the resultant materials will be dependent on their stereochemistry. Specifically, it will address the limitations in synthetic methodology for creating complex, functional stereocontrolled polymers and demonstrate the true potential of harnessing polymer materials with controlled stereochemistry. We will achieve this by focussing on the development of new methodologies for stereocontrolled ring-opening polymerisation of cyclic esters such that we will be able to readily access stereoregular, functional polymers, including achieving unique sequence controlled materials. While one focus will be on utilising renewable resources and green polymer synthesis methodologies, we will also take the first steps to demonstrating the utility of these novel materials by investigating the effects of stereochemistry on the bulk properties of materials as well as its ability to drive crystallisation-driven self-assembly and stereo-responsive nanoparticle behaviour for delivery applications. Achieving these goals promises to take polymers into the 3rd dimension and lead to significant technological breakthroughs in nanotechnology, medicine and sustainable materials among other areas of key future technological importance.","2074731","2016-09-01","2021-08-31"
"STORM","Signal Transduction in Organic Materials","Rienk EELKEMA","TECHNISCHE UNIVERSITEIT DELFT","It is the overall aim of this project to use responsive catalysts to introduce signal transduction cascades in soft materials, enabling autonomous, programmable and amplified response of soft materials to chemical signals from their environment. 'Smart' soft materials could find many important applications ranging from personalized therapeutics to soft robotics. However, as most molecular materials are unable to communicate, or even respond to, changes in their environment, truly smart materials are still far out of reach. Signal transduction is one of the primary processes used by living cells to react to events taking place in their environment, often involving a signal triggering enzymatic activity, leading to a cellular response. Such rudimentary communication is entirely non-existent in synthetic materials. I here propose the introduction of catalysis-based signal transduction between chemical systems to enable synthetic materials to respond autonomously to events taking place in their environment. Key to achieving this objective will be the development of switchable catalysts, using signals originating from chemical events to change catalytic activity, and coupling changes in catalytic activity to responses in soft materials. In achieving these objectives, I will develop new design strategies for responsive soft materials, enabling control over material formation and response in time and space, through autonomous reaction to chemical signals. This will allow the development of new actuators, self-healing materials, sensors, therapeutics and self-regulation and self-correction of material assembly. It will also constitute an entirely new role for catalysis, as catalysis will be engaged to constitute a first step towards achieving communication between artificial chemical systems.","1998985","2017-04-01","2022-03-31"
"STRIGES","Escaping from the Franck-Condon region : a theoretical approach to describe molecular STructural ReorganIzation for reversible EnerGy and information storage at the Excited State","ilaria Ciofini","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","STRIGES is a theoretical project aimed at developing new computational approaches and descriptors essentially rooted on Density Functional Theory enabling to design new single molecule architectures able to undergo to significant light induced electronic and structural reorganization.
In this respect the present project concerns beside fundamental goals, such as the development of new theoretical approaches for the description of photochemical and photophysical processes in molecular systems,  the description and prediction of photoinduced phenomena  which is indeed of fundamental importance also in many research fields of technological relevance, ranging from artificial photosynthesis to molecular electronics.
To this end, we will develop, implement and apply suitable theoretical tools enabling the accurate description of potential energy surfaces of the lowest lying excited states not exclusively within the Franck-Condon region. From the application point of view, the end point of this project is the in-silico design and optimization of two new classes of photomolecular devices.","1202500","2015-11-01","2020-10-31"
"STRINGFLATION","Inflation in String Theory - Connecting Quantum Gravity with Observations","Alexander Westphal","STIFTUNG DEUTSCHES ELEKTRONEN-SYNCHROTRON DESY","This project aims at predicting the energy scale of cosmological inflation and the strength of the inflationary gravitational wave signal from string theory. Observations of the cosmic microwave background (CMB) temperature fluctuations have drastically changed cosmology into quantitative science. The results provide strong evidence for two phases of accelerated expansion in our Universe. The late-time phase of acceleration, termed ’dark energy’, is consistent with an extremely small positive cosmological constant, while the evidence for a very early phase of acceleration increasingly supports cosmological inflation. Very recently, the BICEP2 experiment reported the detection of B-mode polarization in the CMB. Pending future corroboration, this may correspond to a detection of primordial gravitational waves with a fractional power of about 10% of the CMB temperature fluctuations. In the context of inflation this implies an inflationary energy scale close to the scale of Grand Unification, and a large field excursion of the inflationary scalar field. Hence, the inflationary scalar potential needs symmetries to protect it from dangerous quantum corrections. These features strongly motivate the study of high-scale inflation in string theory as a candidate theory of quantum gravity. We will determine the range of predictions for large-field high-scale inflation in string theory driven by the mechanism of axion monodromy, which was co-discovered by the PI. For this purpose, we will establish a catalog of primary sources for large field ranges from axion monodromy in combination with assistance effects from multiple axion fields. We will analyze the generic effects of the interplay between large-field models of inflation in string theory with its necessary prerequisite, moduli stabilization. Finally, we will study the distribution of inflation mechanisms among the many vacua of string theory. In combination, this gives us a first chance to make string theory testable.","1854750","2015-10-01","2020-09-30"
"Stringlandscape","Deconstructing the string landscape","Mariana GRANA","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","Despite its uniqueness, string theory has a “landscape” of low-energy solutions with very different observable physics. These solutions are usually found using low-energy effective theories which, in order to satisfy all the experimental constraints, require a number of exotic ingredients whose string theory origin is unclear. Thus, finding a solution within the effective theory compatible with experiments is far from the same as showing that such a solution is stable in string theory, to say nothing of whether it even exist. Without a string realization, there is neither a known ultraviolet completion of the effective action, nor any guarantee of its existence or consistency. The primary objective of this proposal is to deconstruct the string theory landscape, and determine what parts of it can be promoted to full-fledged string theory solutions, thus resolving the question of their consistency, and what parts are inconsistent. If the outcome of the project is that most of the phenomenologically interesting models are consistent, the landscape paradigm will be put on solid ground. Proving that most models are inconsistent would shatter it, weakening the case for a multiverse explanation of our universe, while restoring the quest for predictability in string theory. The most drastic possible outcome would be to show that none of the existing models survive consistency checks.  Such a verdict would force us to search for more inventive alternatives, such as going away from the realm of geometry, and so this project will also pioneer the construction of a “non-geometric landscape”.","1669465","2018-09-01","2023-08-31"
"StrongCoPhy4Energy","Strongly Correlated Physics and Materials for Energy Technology","Luca DE' MEDICI","ECOLE SUPERIEURE DE PHYSIQUE ET DECHIMIE INDUSTRIELLES DE LA VILLE DEPARIS","""Materials where conduction electrons experience strong correlation in their dynamics, are both a challenge to the current quantum theories of matter and a mine for possible technological applications. High-temperature copper- and iron-based superconductors and heavy-fermions with large thermoelectric responses are examples of materials with high potential impact on energy transmission and storage technologies or high-magnetic field applications. 

Recently, the discovery that the well known atomic """"Hund's rules"""" have a surprisingly great and diversified influence on the conduction electrons in d-electron materials changed the traditional view of electronic correlation as a competition between kinetic energy and Coulomb repulsion, adding Hund's exchange energy as a third axis. 

This project, by using state-of-the-art computational techniques for correlated materials, aims at clarifying the influence of the new Hund's driven mechanisms as possible enhancers of high-Tc superconductivity and of thermoelectric and thermomagnetic properties.
In particular Hund's coupling can induce the coexistence of weakly and strongly correlated conduction electrons, culminating in orbital-selective Mott insulating states or in heavy-fermionic physics. 
We then aim at the creation of a new class of transition-metal (d-electron) compounds reproducing the properties of the more exotic rare-earth (f-electron) heavy-fermion materials, in a tunable way. Iron-based superconductors exhibit some of these properties and will be used as a starting point for the search and exploration of new and enhanced high-temperature superconductors and thermoelectric/thermomagnetic d-electron materials.  

An exciting application is also proposed, motivating a possible resurgence of technological attention towards thermomagnetic materials: the coating of high-power cables in thermomagnetic materials for self-cooling, and potentially room-temperature superconduction.""","1656250","2017-04-01","2022-03-31"
"STRUBA","Computational modelling of structural batteries","Angelo Simone","TECHNISCHE UNIVERSITEIT DELFT","Competition in consumer electronics has pushed the boundaries of technological development towards miniaturization, with weight/size limitations and increasing power demands being the two most stringent requirements. Although almost all the components of any portable device become smaller, lighter and more powerful by the months, electrochemical technology is far from presenting us with the ideal battery. From a different perspective, the equation mobile device = casing + electronics + battery could be simplified by merging the structural function of the casing with that of the energy source of the battery into a structural battery. This approach would immediately reduce weight and size of our mobile devices.

This project aims at investigating the effect of electrochemical-mechanical interactions on the mechanical performance of structural batteries. Understanding and controlling mechanical degradation in structural batteries is of prime importance given the dual structural-electrical function of these devices. In fact, the main concern when dealing with structural batteries is whether the internal stresses caused by external loads will influence the performance of the battery, and, conversely, whether the functioning of the battery will have a detrimental effect on its mechanical properties.  The complexity of these processes can only be addressed with dedicated computational techniques. This project offers a unique opportunity for the design and implementation of the first multiphysics and multiscale computational framework for the analysis of structural batteries. Macroscale processes originating at the level of a basic components will be elucidated through physically-based constitutive laws.

The overall impact of this project will be felt across many research communities. Apart from the energy storage community, the developed tools and procedures will influence research and development related to many fibre-reinforced composites.","1968053","2014-06-01","2019-05-31"
"StrucLim","Limits of discrete structures","Balazs Szegedy","MAGYAR TUDOMANYOS AKADEMIA RENYI ALFRED MATEMATIKAI KUTATOINTEZET","Built on decades of deep research in ergodic theory, Szemeredi's regularity theory and statistical physics, a new subject is emerging whose goal is to study convergence and limits of various structures.
The main idea is to regard very large structures in combinatorics and algebra as approximations of infinite analytic objects. This viewpoint brings new tools from analysis and topology into these subjects. The success of this branch of mathematics has already been demonstrated through numerous applications in computer science, extremal combinatorics, probability theory and group theory. The present research plan addresses a number of open problems in additive combinatorics, ergodic theory, higher order Fourier analysis, extremal combinatorics and random graph theory. These subjects are all interrelated through the limit approach.","1175200","2014-02-01","2019-01-31"
"STRUGGLE","Statistical physics of immune-viral co-evolution","Aleksandra Maria WALCZAK","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","The immune system within each individual host destroys viruses, which manage to escape immunity on the global scale. Recent experiments show population-level responses of both immune repertoires and viruses, and a history dependence of their functional phenotypes. This constrained long-term co-evolution of immune receptor and viral populations is a stochastic many-body problem occurring at many scales, in which the response emerges based on the past states of both the repertoire and viral populations. STRUGGLE infers the details of viral-immune receptor interactions from functional datasets to obtain a predictive statistical model of co-evolution between immune repertoires and viruses.

STRUGGLE covers the many scales of immune-virus interactions: from the molecular level, analyzing high-throughput mutational screens of libraries of antibodies binding a given antigen, through the population-level response of immune repertoires, analyzing next-generation sequencing of vaccine-stimulated whole repertoires, to the population level, modeling the long term co-evolution of both repertoires and viruses.

STRUGGLE combines a statistical data analysis approach with cross-scale many-body physics to: 
- build a molecular model for antigen-receptor binding;
- learn statistical models for repertoire-level response to viral antigen stimulation;
- validate dynamical models of interactions between antigen and immune receptors;
- theoretically evaluate the predictive power of the immune system and viruses;
- and predict virus strains and immune responses based on past infections.

The outcomes of STRUGGLE include the quantitative characterization of the human T-cell response to flu vaccines, with implications for vaccination strategies, and the trout B-cell response to life-threatening rhabdoviruses, which aids vaccine design for fish, with wide use in agriculture. The statistical properties of the co-evolutionary process are needed for informed development of immunotherapies.","1909750","2017-11-01","2022-10-31"
"SULFOSOL","Sulfur-based solutions for the selective functionalization of organic substrates","Manuel ALCARAZO VELASCO","GEORG-AUGUST-UNIVERSITAT GOTTINGENSTIFTUNG OFFENTLICHEN RECHTS","The increasing demand of complex organic molecules, either by their biological activity or technical interest, and the need for the development of sustainable chemical processes are opening a new period in Organic Synthesis, which is mainly focused on the discovery of novel transformations that more intensively explore concepts such as atom-economy and redox-neutrality. As part of this trend, the development new reagents capable to transfer new functional groups at the desired positions of advanced synthetic intermediates is winning a crucial role. Areas such as crop science and drug discovery make extensive use of this working methodology for the identification of new targets.
Several families of “Group Transfer Reagents” are known, the most prominent ones being arguably those based on hypervalent I(III) structures. However, their transfer ability is confined to a restricted number of functionalities, and in addition, their implementation in industrial processes is seriously limited by their highly reactive nature. Hypervalent iodine (III) compounds are known to be potentially explosive and for this reason, they usually require working in relatively small scale and under restricted safety conditions. 
To circumvent these drawbacks, I present in SULFOSOL a novel and general approach for the straightforward preparation of electrophilic group transfer reagents based on the use of sulphur-containing platforms. The low prize and chemical stability of these reagents make their use feasible at any step of a synthetic sequence, and render them highly appealing for large-scale applications. In addition, the combination of these new reagents with the power of actual metal catalysis will lead to an array of useful synthetic routes that will decisively enrich the toolbox of the synthetic chemist.","1997500","2018-05-01","2023-04-30"
"SUMMIT","Site-specific Ultrasensitive Magnetic resonance of Mixtures for Isotopic Tracking","Patrick Giraudeau","UNIVERSITE DE NANTES","There is a high demand to design approaches capable of tracking the origin of biomarkers in complex biological environments, in the areas of life, environmental, food and forensic sciences. Metabolomics and Fluxomics show great promises towards this aim, and a high potential arises from their combination with Isotopic fingerprinting at natural abundance. The resulting isotopomics approach requires cutting-edge analytical tools, and Nuclear Magnetic Resonance (NMR) is currently the only generic technique giving access to the site-specific isotope content at natural abundance. The detection of very small relative variations between samples originating from different (bio)chemical pathways is possible through 13C isotopic NMR, which can however only be applied to simple and concentrated samples, due to its low sensitivity. Consequently, numerous applications are out of reach. To tackle the current limitations of 13C isotopic analysis, SUMMIT will develop a groundbreaking analytical workflow relying on two of the most powerful NMR methods: dissolution dynamic nuclear polarization and ultrafast 2D NMR. This cutting-edge approach will allow the simultaneous measurement of 13C fingerprints from multiple low-concentrated biomarkers in complex mixtures, which is impossible with existing methods. The high potential of this analytical strategy will be demonstrated on a relevant biological study, the investigation of breast cancer cell metabolism, through applications with gradually increasing risk levels. These approaches will make it possible to identify (i) new biomarkers to discriminate between cell lines expressing different hormonal receptors; (ii) novel potential therapeutic targets from the elucidation of metabolic pathways. Beyond this application, the project will have a high impact on a wide community of academic and industrial researchers, covering unmet needs from life sciences, food industry and forensic analysis.","1999768","2019-10-01","2024-09-30"
"SunCatChem","Sustainable Light - Driven Catalytic Chemistry","Magnus Rueping","RHEINISCH-WESTFAELISCHE TECHNISCHE HOCHSCHULE AACHEN","Innovative fundamental research is key to facing challenges posed by our current societal, environmental and economic needs. Catalysis is a vital component of many potential solutions to contemporary global issues and breakthroughs in catalysis would inevitably bring about change.
Among the most prominent challenges of the 21st century is the functionalization of abundant but unreactive C-H bonds as development of these transformations would enable the sustainable formation of new carbon-carbon or carbon-heteroatom bonds, needed for the construction of vitally important complex molecules. Even more challenging is the direct, enantioselective functionalization of unreactive C-H and C-C double bonds which would lead to valuable, optically active products which are highly desirable for the pharmaceutical, agrochemical and fine chemical industries.
The general objective of this proposal is to redefine the synthetic methodology for obtaining highly valuable, optically active products, used in life science applications, by using novel strategies, involving three unprecedented concepts which employ visible light available from the sun.
Successful validation of our three innovative, light-driven, catalysis concepts will have great impact on catalysis, organic synthesis and fundamental science in general. As a key enabling technology, we will also devise unprecedented reaction concepts which will allow fast and autonomous self-optimization without the need for any manual interaction, resulting in increased practicability and high acceptance from the scientific community.
By both designing and matching synthetic methodology with innovative technology we aim to enhance the environmental credentials and improved economic feasibility of the resulting reactions and systems, leading to wide acceptance and implementation and, thus, make a significant contribution towards the paradigm shift to sustainable chemistry.","1997982","2014-02-01","2019-01-31"
"SUPER-2D","Many-body physics and superconductivity in 2D materials","Alexander Grueneis","UNIVERSITAET ZU KOELN","The goal of this project is to prepare and functionalize layered materials and then to characterize them in-situ using a novel combination of electrical transport, photoelectron and optical spectroscopy. This approach provides a solution to the intense research efforts in trying to engineer, probe and unravel many-body physics and the superconducting coupling mechanism in layered solids. The materials under investigation are based on the families of graphene, dichalcogenides and iron based superconductors. Chemical functionalization using dopants and strain allows for an unprecedented control over their physical properties. The proposed material systems provide a new arena to explore diverse condensed matter phenomena such as electron correlation, electron-phonon coupling and superconductivity. The groundbreaking aspects of this proposal are as follows: (1) development of a unique setup where electrical transport, angle-resolved photoemission (ARPES) and optical spectroscopy is measured in-situ on the same sample, (2) large-area deterministic layer-by-layer growth by chemical vapour deposition (CVD) and molecular beam epitaxy, (3) the effects of mechanical strain and hence large pseudomagnetic fields on the electronic band structure will be investigated using ARPES, (4) the effects of alkali metal doping on the superconducting transition temperature and the spectral function will be investigated using transport, ARPES and optical spectroscopies shining light onto the superconducting pairing mechanisms in different classes of materials. The proposal's feasibility is firmly grounded on the pioneering work of the PI’s group on superconducting coupling in functionalized graphene and the in-situ ARPES measurements of a CVD grown graphene/BN heterostructure.","1928750","2015-06-01","2020-05-31"
"SUPERCELL","Single-Use paPER-based fuel CELLs","Maria De Les Neus Sabate Vizcarra","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","The advances in paper microfluidics taking place in recent years show that the new generation of paper-based devices will be able to overcome the limitations of traditional lateral flow tests and offer more accurate and specific information. However, the quantification of paper devices signals by colorimetry, electrochemistry or fluorescence entails the use of sensors and electronic components that require energy to function. Up to now, this has been solved by the use of battery-powered bulky readers, but this is only cost-effective when the reader is meant to be used thousands of times (hospital, care rooms, etc). It is becoming clear that the proliferation of paper-based sensors and their enormous potential impact when applied to personalized healthcare ask for innovative solutions that provide affordable readout. Despite dedicated on-chip solutions that integrate all the required components within a disposable test seem to be the most promising approach, available examples of realization are still scarce. 
The SUPERCELL project aims to develop a new generation of disposable and low environmental impact  fuel cells. The approach presented in this proposal will be a major breakthrough in the fuel cell field, as these devices are conceived for the first time as single-use and disposable power sources. It will also have an enormous impact in the point-of-care diagnostics domain, as it will provide simple, reliable and clean power sources to an upcoming generation of smart paper-based sensors and allow them to be energetically autonomous. Fuel will be harvested from the biological sample to be analyzed – in case of urine and blood – or taken from hydrogen produced in situ upon the addition of any liquid in the paper platform.  The proposal is very innovative in conception as well as in technology as these devices will be developed by means of a smart integration of paper microfluidics, printed electronics and electrocatalysis technologies.","1920738","2015-07-01","2020-06-30"
"SuPerCom","Sustainable Performance for High-Performance Embedded Computing Systems","Francisco Javier Cazorla Almeida","BARCELONA SUPERCOMPUTING CENTER - CENTRO NACIONAL DE SUPERCOMPUTACION","Computers increasingly intervene in critical aspects of our life related to health, safety, and security, resulting in (critical) software controlling functionalities or services with humans in the loop. This trend towards critical-function digitization brings huge benefits for society and rests two pillars: the use of high-performance parallel hardware as the only viable option to cover the highest-ever critical software’s performance needs; and the ability to provide sustainable (guaranteed) performance, instead of average unreliable performance. Failing to support both pillars prevents embedded computers from safely executing critical software potentially causing unacceptable risks or threats to human life.
SuPerCom goes beyond current solutions, which face either major scalability limitations or cannot provide performance guarantees, and proposes a holistic multidisciplinary approach that addresses the challenge of providing high and sustainable performance with future embedded computers comprising high-performance hardware with unprecedented complexity levels.
SuPerCom synergistically combines for the first time performance analysis, hardware design and statistical and machine learning techniques. With SuPerCom performance predictability and performance observability become first-class citizen hardware requirements, rather than being considered at the end of the design. SuPerCom also proposes statistical and machine-learning techniques to (i) deal with big amounts of performance data coming from hardware sensors and (ii) provide on-line optimizations to increase sustainable performance.
SuPerCom breakthrough can have significant economic and societal impact by allowing embedded computers to use high-performance hardware with strong guarantees of sustainable performance. This, in turn, will allow executing a wide-variety of performance-demanding critical software like advanced driver assistance systems in cars or advanced medical devices with sound guarantees.","1998919","2018-06-01","2023-05-31"
"SUPERNEMS","Superconducting Diamond Quantum Nano-Electro-Mechanical Systems","Oliver Aneurin Williams","CARDIFF UNIVERSITY","In this project, the fabrication and characterisation of all diamond superconducting Nano-Electro-Mechanical Systems (NEMS) is proposed for the investigation of macroscopic quantum states. This involves state of the art Chemical Vapour Deposition (CVD) of diamond, doping, nanofabrication and modelling of devices. The fundamental properties of superconducting diamond, the associated mechanical properties of diamond NEMS and the characterisation of low temperature and low dimensional quantum effects will be investigated. 

Critically, the unprecedented resonant frequencies of diamond cantilevers allow the possibility of cooling cantilever devices down to the ground state. Coupled with its superconducting-based read out possibilities, this material offers new opportunities for challenging the Standard Quantum Limit, the study of quantum entanglement and the fabrication of superconducting diamond Qubits. This work is highly ambitious, as it aims to manipulate systems by exploiting fundamental quantum limits. However, the applicant has already demonstrated the individual constituents of this approach and thus it is not reckless to propose to integrate them.","2734049","2015-07-01","2020-06-30"
"SuperRepel","Superslippery Liquid-Repellent Surfaces","Robin Henk A. RAS","AALTO KORKEAKOULUSAATIO SR","I aim to progress substantially the understanding and applications of extremely non-wetting surfaces, tying together basic research and attractive technological advancements. The first part focuses on robust synthesis methods for superslippery liquid-repellent (SS-LR) surfaces. Furthermore, using new types of ultrasensitive force measurement for droplets, I will investigate in depth the dissipation dynamics of mobile water droplets and adhesion of droplets to surfaces, to promote understanding on low-friction surfaces. The second part aims at applying these SS-LR surfaces in droplet actuation with potential to outperform existing technologies. Additionally, the potential of SS-LR surfaces for anti-icing and for preventing bio-fouling will be investigated. The research results will have a major impact on liquid-repellent technology and will explore the fundamental physical limits of non-wetting.","1999468","2017-06-01","2022-05-31"
"Supramol","Towards Artificial Enzymes: Bio-inspired Oxidations in Photoactive Metal-Organic Frameworks","Wolfgang Schmitt","THE PROVOST, FELLOWS, FOUNDATION SCHOLARS & THE OTHER MEMBERS OF BOARD OF THE COLLEGE OF THE HOLY & UNDIVIDED TRINITY OF QUEEN ELIZABETH NEAR DUBLIN","Metal-organic frameworks (MOFs) are key compounds related to energy storage and conversion, as their unprecedented surface areas make them promising materials for gas storage and catalysis purposes. We believe that their modular construction principles allow the replication of key features of natural enzymes thus demonstrating how cavity size, shape, charge and functional group availability influence the performances in catalytic reactions. This proposal addresses the question of how such novel, bio-inspired metallo-supramolecular systems can be prepared and exploited for sustainable energy applications. A scientific breakthrough that demonstrates the efficient conversion of light into chemical energy would be one of the greatest scientific achievements with unprecedented impact to future generations. We focus on the following key aspects:

a) MOFs containing novel, catalytically active complexes with labile coordination sites will be synthesised using rigid organic ligands that allow us to control the topologies, cavity sizes and surface areas. We will incorporate photosensitizers to develop robust porous MOFs in which light-absorption initiates electron-transfer events that lead to the activation of a catalytic centre. In addition, photoactive molecules will serve as addressable ligands whereby reversible, photo-induced structural transformations impose changes to porosity and chemical attributes at the active sites. 

b) Catalytic studies will focus on important oxidations of alkenes and alcohols. These reactions are relevant to H2-based energy concepts as the anodic liberation of protons and electrons can be coupled to their cathodic recombination to produce H2. The studies will provide proof-of-concept for the development of photocatalytic systems for the highly endergonic H2O oxidation reaction that will be explored using most stable MOFs.  Further, gas storage and magnetic properties that may also be influenced by light-irradiation will be analysed.","1979366","2015-09-01","2020-08-31"
"SUPRAVACC","Supramolecular engineering of glycan-decorated peptides as synthetic vaccines","Pol BESENIUS","JOHANNES GUTENBERG-UNIVERSITAT MAINZ","The main and most important feature of vaccines is the induction of an immunological memory response, which is key to providing long-term protection against pathogens. The current strategies for potent antibacterial and antiviral vaccines employ conjugation of pathogen specific entities onto carrier proteins, and are limited to formulations that suffer from low stability and short shelf-lives, and are thus not viable in developing countries. Strategies for the development of new vaccinations against endogenous diseases like cancer further remain an unmet challenge, since current methodologies suffer from a lack of a modular and tailored vaccine-specific functionalisation. I therefore propose a radically new design approach in the development of fully synthetic molecular vaccines. My team will synthesise carbohydrate and glycopeptide appended epitopes that are grafted onto supramolecular building blocks. These units can be individually designed to attach disease specific antigens and immunostimulants. Due to their self-assembling properties into nanoscaled pathogen mimetic particles, they serve as a supramolecular subunit vaccine toolbox. By developing a universal supramolecular polymer platform, we will construct multipotent vaccines from glycan-decorated peptides, that combine the activity of protein conjugates with the facile handling, precise composition and increased stability of traditional small molecule pharmaceutical compounds.
SUPRAVACC will pioneer the design of minimalistic and broadly applicable vaccines, and will evaluate the supramolecular engineering approach for immunisations against antibacterial diseases, as well as for applications as antitumour vaccine candidates. The fundamental insights gained will drive a paradigm shift in the design and preparation of vaccine candidates in academic and industrial research laboratories.","2000000","2019-04-01","2024-03-31"
"SUSPINTRONICS","Magnetic, electric-field and light induced control of spin-polarized supercurrents: fundamentals for an offbeat electronics","Javier Eulogio Villegas Hernandez","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","This project aims at establishing the basis for high-temperature superconducting spintronics. The innovative idea is to use spin-polarized superconducting pairs -instead of normal electrons- to convey and manipulate information, taking advantage of the coherent transport inherent to superconductivity. To further increase the potential of this approach, we intend to create multiple control knobs: magnetic field, the classical one in spintronics, as well as the knobs customary in conventional electronics: electric field and light.  This will endow superconducting spintronics with a magnetic and electric memory, as well as with photosensitivity. The basic ingredient for this ambitious project is complex-oxide heterostructures.  The approach consists of combining the following fundamental effects:
(a)  Superconducting proximity effects, in order to transfer superconductivity into ferromagnets.
(b) Ferroelectric field-effects, in order to modulate the superconductor/ferromagnet interactions and tune Josephson coupling. 
(c) Spin-torque and ferromagnetic resonance effects, in order to couple superconductivity and magnetization dynamics.
(d) Photoconductivity and photoelectric effects, in order to manipulate the interactions between superconductors and ferroics.
This research is essentially fundamental, but the novel concepts pursued will increase the technological possibilities of superconductivity and spintronics -whose applications are at present completely disconnected.","1997729","2015-10-01","2020-09-30"
"SWORD","Security Without Obscurity for Reliable Devices","FRANCOIS-XAVIER LESLIE A STANDAERT","UNIVERSITE CATHOLIQUE DE LOUVAIN","Cryptographic implementations are traditionally evaluated based on a trade-off between security and efficiency. However, when it comes to physical security against attacks exploiting side-channel leakages or fault insertions, this approach is limited by the difficulty to define the adversaries (e.g. their knowledge about the target implementation) and to specify sound physical assumptions. Quite naturally, the problem becomes even more challenging in contexts where implementations can be maliciously modified during design or fabrication via so-called hardware Trojans. To a large extent, these vulnerabilities echo the general challenge of restoring trust that is faced by cryptographic research in view of the recent Snowden revelations. In this context, we believe that the design of small components able to perform secure computations locally will be an important building block of future information systems. For this purpose, the SWORD project envisions a paradigm shift in embedded security, by adding trust as an essential element in the evaluation of physically secure objects. Our two main ingredients to reach this ambitious goal are a good separation between mathematics and physics, and improved transparency in security evaluations. That is, we want cryptographic implementations to rely on physical assumptions that can be empirically verified, in order to obtain sound security guarantees based on mathematical proofs or arguments. And we want to make the empirical verification of physical assumptions more transparent, by considering open source hardware and software. By allowing adversaries and evaluators to know implementation details, we expect to enable a better understanding of the fundamentals of physical security, therefore leading to improved security, efficiency and trust in the longer term. That is, we hope to establish security guarantees based on a good understanding of the physics, rather than the (relative) misunderstanding caused by closed systems.","1997661","2017-09-01","2022-08-31"
"SYMBIOSYS","Symbolic Analysis of Temporal and Functional Behavior of Networked Systems","Klaus Wehrle","RHEINISCH-WESTFAELISCHE TECHNISCHE HOCHSCHULE AACHEN","The goal of SYMBIOSYS is to assure the reliability and interoperability of networked (software) systems, a crucial requirement in today’s networked information society. To this end, we devise a software and systems analysis methodology that – for the first time – considers the vital influence factors that determine the behavior of networked systems, especially including input and temporal uncertainty of network interactions. With SYMBIOSYS, we will be able to automatically
and effciently explore and analyze the vast amount of distributed execution paths in networked systems in a highly structured manner inspired by Symbolic Execution (SE).

The combination of the benefits of model checking (rigorous exploration) and of dynamic software testing (analyzing real systems’ code) represents a quantum leap in the field of network analysis. Orthogonal to and complementing formal model-based approaches, which target the design of reliable systems on an abstract (model-) level, we also address system- and
implementation-level aspects of (typically heterogeneous) implementations that interact via unpredictable networks. To achieve this, we introduce the fundamentally new approaches Symbolic Distributed Execution (SDE), Symbolic Temporal Execution (STE) and their symbiosis (SDTE). This is a breakthrough in the symbolic analysis of real systems and significantly widens the scope of SE to new analysis domains.

Our novel approach raises the issue of complexity and path explosion. Yet, our experience from early work on SDE strongly suggests that the use of domain-specific knowledge and further general optimization strategies allow to significantly reduce this complexity and enable an efficient analysis. SYMBIOSYS also enables and fosters the design of new methods and tools to ensure reliability, interoperability, and other vital properties of networked systems. We demonstrate our new methodology through examples from Cyber-Physical Systems and low-latency communication.","1988750","2015-08-01","2020-07-31"
"Symmetries-Cosmology","Duality Symmetries, Higher Derivatives, and their Applications in Cosmology","Olaf HOHM","HUMBOLDT-UNIVERSITAET ZU BERLIN","The goal is to uncover symmetries and dualities of string theory including \alpha' corrections, to describe massive string states, and to investigate applications in cosmology. This will be done using double field theory and exceptional field theory and generalizing it to the non-local interactions of genuine stringy states and/or an infinite number of higher-derivative \alpha' corrections. So far these frameworks were mainly used to describe the low-energy effective field theories of the massless states in string/M-theory in a manifestly duality invariant way. The anticipated generalizations require a significant deformation or extension, of which we have only recently obtained first glimpses. 

Specifically, the higher-derivative corrections are constrained by gauge symmetries. These include the Green-Schwarz transformations, but are far more general and determine all corrections to first order in \alpha'. There was also recent progress on the problem of including massive string states: Sen proved that the sub-sector of string theory consisting of massless fields together with their Kaluza-Klein and winding modes provides a consistent truncation. The resulting theory must be governed by L_{\infty} algebras, which are generalizations of Lie algebras that so far have played little role in conventional field theories but now give us a concrete clue of how to construct a `true double field theory'. 

Various string cosmology scenarios have been suggested that aim to utilize stringy features for, say, the early universe. 
However, given our ignorance about the precise `stringy' Einstein equations, it has been impossible to test and verify such ideas, even theoretically. In view of the recent and forthcoming PLANCK data it has become particularly urgent to find a useful formulation of string theory in which problems of this type can be addressed and analyzed. If successful, this research program would be ground-breaking in that it would allow us to do precisely this.","1793550","2018-09-01","2023-08-31"
"SymplecticEinstein","The symplectic geometry of anti-self-dual Einstein metrics","Joel Fine","UNIVERSITE LIBRE DE BRUXELLES","This project is founded on a new formulation of Einstein's equations in dimension 4, which I developed together with my co-authors. This new approach reveals a surprising link between four-dimensional Einstein manifolds and six-dimensional symplectic geometry. My project will exploit this interplay in both directions: using Riemannian geometry to prove results about symplectic manifolds and using symplectic geometry to prove results about Reimannian manifolds.

Our new idea is to rewrite Einstein's equations using the language of gauge theory. The fundamental objects are no longer Riemannian metrics, but instead certain connections over a 4-manifold M. A connection A defines a metric g_A via its curvature, analogous to the relationship between the electromagnetic potential and field in Maxwell's theory. The total volume of (M,g_A) is an action S(A) for the theory, whose critical points give Einstein metrics. At the same time, the connection A also determines a symplectic structure \omega_A on an associated 6-manifold Z which fibres over M.

My project has two main goals. The first is to classify the symplectic manifolds which arise this way.  Classification of general symplectic 6-manifolds is beyond current techniques of symplectic geometry, making my aims here very ambitious. My second goal is to provide an existence theory both for anti-self-dual Poincaré--Einstein metrics and for minimal surfaces in such manifolds. Again, my aims here go decisively beyond the state of the art. In all of these situations, a fundamental problem is the formation of singularities in degenerating families. What makes new progress possible is the fresh input coming from the symplectic manifold Z. I will combine this with techniques from Riemannian geometry and gauge theory to control the singularities which can occur.","1162880","2015-09-01","2020-08-31"
"synMICs","Exploiting Synergistic Properties of Mesoionic Carbene Complexes: Teaching Rusty Metals Challenging Catalysis","Martin Albrecht","UNIVERSITAET BERN","The non-innocence of specific ligands in transition metal complexes is well-documented. For example, mesoionic carbenes engage in bond activation processes via reversible hydrogen capture. Such cooperativity between the metal center and the ligand flattens the potential energy surface of a catalytic reaction and hence rises the competence of the catalyst, thus entailing higher turnover numbers as well as the conversion of more challenging substrates. Likewise, such cooperativity is expected to enhance the catalytic activity of metal centers that are typically not considered to be catalytically very active, such as the ‘rusty’ first row transition metals (Mn, Fe, Ni). Surprisingly, however, this concept has largely been overlooked when designing catalytic transformations based on these earth-abundant and low-cost transition metals. This project will exploit the synergistic potential of mesoionic carbenes as synthetically highly versatile and actively supporting ligands to access a new generation of sustainable high-performance catalysts based on Me, Fe, and Ni for challenging redox transformations such as dehydrogenative oxidations. Specificlly, 1,2,3-triazolylidenes, which support ligand-metal cooperativity through their mesoionic character, will be utilized for (transient) storage/release of protons and electrons. Apart from enabling challenging transformations — with obvious impact on synthetic methodology, energy conversion, and molecular electronics — this project will break into new grounds in catalyst design that will be widely applicable as a new paradigm. Furthermore, this project will capitalize on the unique synthetic versatility of triazolylidene precursors and the opportunity to combine different functional entities such as carbohydrates, surfactants, or dyes with an organometallic entity, thus providing a straightforward approach to new classes of multifunctional materials for application in therapeutics and diagnostics, or as smart surfaces.","2111111","2015-02-01","2020-01-31"
"SYSTEMATICGRAPH","Systematic mapping of the complexity landscape of hard algorithmic graph problems","Dániel MARX","MAGYAR TUDOMANYOS AKADEMIA SZAMITASTECHNIKAI ES AUTOMATIZALASI KUTATOINTEZET","Graph-theoretical models are natural tools for the description of road networks, circuits, communication networks, and abstract relations between objects, hence algorithmic graph problems appear in a wide range of computer science applications. As most of these problems are computationally hard in their full generality, research in graph algorithms, approximability, and parameterized complexity usually aims at identifying restricted variants and special cases, which are at the same time sufficiently general to be of practical relevance and sufficiently restricted to admit efficient algorithmic solutions. The goal of the project is to put the search for tractable algorithmic graph problems into a systematic and methodological framework: instead of focusing on specific sporadic problems, we intend to obtain a unified algorithmic understanding by mapping the entire complexity landscape of a particular problem domain.

Completely classifying the complexity of each and every algorithmic problem appearing in a given formal framework would necessarily reveal every possible algorithmic insight relevant to the formal setting, with the potential of discovering novel algorithmic techniques of practical interest. This approach has been enormously successful in the complexity classifications of Constraint Satisfaction Problems (CSPs), but comparatively very little work has been done in the context of graphs. The systematic investigation of hard algorithmic graph problems deserves the same level of attention as the dichotomy program of CSPs, and graph problems have similarly rich complexity landscapes and unification results waiting to be discovered. The project will demonstrate that such a complete classification is feasible for a wide range of graph problems coming from areas such as finding patterns, routing, and survivable network design, and novel algorithmic results and new levels of algorithmic understanding can be achieved even for classic and well-studied problems.","1532000","2017-07-01","2022-06-30"
"T2DCP","Development of Thiophene Based Conjugated Polymers in Two Dimensions","Xinliang FENG","TECHNISCHE UNIVERSITAET DRESDEN","The proceeding inexorable digitalisation of modern economics and society creates a steadily increasing demand on smart devices in the context of the industrial internet and the internet of things. To meet future requirements, organic electronics is a disruptive technology featuring low-cost, robust, lightweight, flexible and affordable devices based on organic small molecules and polymers. In contrast to the boosting development of linear conjugated polymers and their applications in organic electronics, the successive increase of dimensionality by connecting multiple strands towards two-dimensional (2D) conjugated polymers remains largely unexplored. In this project, we will develop unprecedented thiophene-based double- and triple-strand conjugated polymers to 2D conjugated polymers (T2DCPs) for organic electronics with tailorable electronic band gap at the molecular level for superior performance in terms of charge carrier mobility, and defect tolerance enabled by the increased dimensionality. In this respect, we aim to establish versatile but also reliable solution-based synthesis strategies (one-pot solvothermal, two-step metal-templating reaction and interfacial soft-templating route) employing thiophene monomers rendering T2DCPs with entirely C=C/Ar-Ar backbone. We will further establish ground-breaking one-pot synthesis of donor-acceptor type T2DCPs featuring lower band gap and unique charge transport behavior. By employing designed thiophene-based monomers and linkage topologies, we will accomplish optical and energy gap engineering, control of the molecular weight (or crystalline domain size), and conjugation channel densities. The consequence is that we will explore the key functions of this intriguing class of semiconducting polymers. As the key achievements, we expect to establish a novel solution-based chemistry, delineation of reliable structure-property relationships and superior device performance of T2DCPs for organic field effect transistors.","2000000","2019-03-01","2024-02-29"
"TAME-Plasmons","a Theoretical chemistry Approach to tiME-resolved molecular Plasmonics","Stefano Corni","UNIVERSITA DEGLI STUDI DI PADOVA","Ultrafast spectroscopy is a powerful tool able to disclose the atomistic real-time motion picture of the basic chemical events behind technology and Life, such as catalytic reactions or photosynthetic light harvesting. Nowadays, by cleverly harnessing the interaction of the studied molecules with plasmons (collective electron excitations supported, e.g., by metal nanoparticles) it is becoming possible to focus these investigations on specific nanoscopic regions, such as a portion of a catalytic surface or of a photosynthetic membrane. This coupling can also produce new quantum effects such as molecule-plasmon hybrid excitations. On the other hand, it makes the real-time molecular evolution and its perturbation by light more complex, and thus calls for new theoretical treatments. The available ones are unable to tackle this complexity, because they consist of phenomenological models focused on field enhancements or on generic features of the various plasmon-molecule coupling regimes. The goal of TAME-Plasmons is to develop a theoretical chemistry approach to directly simulate the real time evolution of molecules interacting with plasmons and light. Our approach lifts the current theoretical limitations by coupling a real-time quantum chemical description of the molecules with a time-dependent electromagnetic description of plasmons, rooted in our previous work on steady-state molecular plasmonics. We will implement this approach in an open-source software, accessible also to non-specialists. We will address current open issues such as the controversial nature of plasmon-aided frequency up-conversion by noble gases and the interpretation of sub-molecularly resolved photoemission induced by scanning tunneling microscopy. We will also anticipate questions that may arise along with progress in the field, for example how to engineer energy transfer paths in photosynthetic light harvesting proteins by exploiting the coupling to plasmons.","1432890","2016-04-01","2021-03-31"
"TEDE","Transient Engine Driven Explosions","Andrew James LEVAN","THE UNIVERSITY OF WARWICK","The nature of many of the most energetic explosions in the Universe remains a central unanswered question in contemporary astrophysics. While progress has been made towards the origins of many of the more commonly observed transients – including “normal” core collapse supernovae and long-duration gamma-ray bursts – there remain important mysteries, both new and old. Recent studies suggest that many of the most energetic explosive transients are powered by a central engine that is either an accreting black hole or a highly magnetic neutron star (a magnetar). These engines input energy into the explosion and transform the later emission, as well as having a profound impact on metal yields, feedback into the interstellar medium, remnant evolution, particle acceleration (e.g. high energy cosmic rays) and neutrino production. The creation of the engine may also produce strong gravitational wave transients, which are likely to be discovered (if they have not already been) by the new generation of ground-based interferometers. I propose a detailed study of engine driven transients throughout the Universe, utilizing insights from both the transients themselves and their local and wider environments. In particular, my work will; a) search for evidence of long-lived engines in the longest gamma-ray bursts, and determine the effects these engines have on the appearance of associated supernovae, b) determine the properties of engines in very long gamma-ray transients thought to be tidal disruption flares, and determine if these are indeed tidal flares or unusual supernovae c) map the properties of the engines seen in short-GRBs, allowing us to hone our expectations for d) the identification and study of the first electromagnetic counterparts to GW sources, and their environments. I will achieve this by the creation of an experienced team of postdoctoral fellows and senior staff with a skills-set tuned to address these central questions.","1987299","2017-04-01","2022-03-31"
"TempoQ","Temporal Quantum Correlations","Otfried Gühne","UNIVERSITAET SIEGEN","Correlations are central for our modern view on the foundations of quantum theory and applications like quantum information processing. So far, research concentrated on correlations between two or more particles. Indeed, for this situation it is well established that spatial quantum correlations are a useful resource for tasks like quantum cryptography and quantum metrology. There are, however, other types of correlations in quantum mechanics, which arise if a sequence of measurements on a single quantum system is made. These temporal quantum correlations have recently attracted attention, because they are central for the understanding of some differences between the quantum and the classical world. Moreover, due to experimental progress their observation has become feasible with trapped ions, polarized photons, or other quantum optical systems.

This project aims at a full understanding and characterization of temporal quantum correlations. For that, we will derive criteria and measures for temporal quantum correlations and investigate their connection to information theory. Then, we will elucidate to which extent temporal correlations can be used to prove that a system is quantum and not classical. Finally, we consider implementations of temporal quantum correlations using continuous variable systems like nanomechanical oscillators and applications in quantum information processing.","1673875","2016-05-01","2021-04-30"
"TERAMAG","Ultrafast spin transport and magnetic order controlled by terahertz electromagnetic pulses","Tobias Kampfrath","FREIE UNIVERSITAET BERLIN","In order to fully exploit the electron spin as a signal carrier in future information processing, spins need to be transported and flipped as fast as possible. Spintronics research aims at implementing these operations by electric fields in circuitry, but has so far been limited to frequencies below ~10 GHz. The much faster complementary femtomagnetism approach employs femtosecond laser pulses (carrier frequency ~400 THz), but is not compatible with microelectronics technology.

In the TERAMAG project, I will apply intense terahertz (THz) electromagnetic pulses to solids to realize 1) ultrafast transport of spins and magnons, and 2) ultrafast control over magnetic order. Our strategy relies on extending concepts from the fields of spintronics (electronics) and femtomagnetism (optics) to the elusive THz frequency gap (0.3 to 30 THz), thereby combining the benefits of both worlds.

To realize spin operations and open up new pathways to their implementation, it is essential to understand the underlying microscopic processes. THz radiation is an ideal tool for this task as it directly and uniquely interacts with many fundamental modes and couplings of solids at their natural frequencies. For example, by using ultrashort THz pulses, we will obtain unprecedented insights into the energetic structure of spin-orbit coupling of equilibrium and nonequilibrium conduction electrons (e.g. in metals and two-dimensional semiconductors) and into the unexplored but highly relevant interaction of optical phonons with spins, including magnons. Novel measurement schemes (e.g. of the spin Hall effect from ~0.3 to 30 THz) and applications (such as spintronic THz emitters and detectors) will emerge.","1984375","2016-07-01","2021-06-30"
"TERAMICROSYS","Terahertz microsystems - Enabling the large-scale exploitation of the terahertz gap","Joachim Oberhammer","KUNGLIGA TEKNISKA HOEGSKOLAN","This project envisions the wide-spread use of THz technology in various applications in our society, which is enabled by the proposed THz microsystems, providing an unprecedented way of creating highly-integrated, volume-manufacturable, cost and energy-efficient, reconfigurable and thus adaptive submillimeter-wave and THz systems. Advanced three-dimensional micromachining is used as the key enabling fabrication technology. In connection with the technology convergence of advancing microwave semiconductor technology according to international technology programmes and roadmaps, the findings of this project are expected to comprise a significant contribution towards the large-scale exploitation of the heavily sought-after frequency space between 100 GHz and 1 THz, the so-called ‘terahertz gap’.
Primary application fields with high impact of the proposed technology are wireless short-range communication links to interconnect future small-cell clouds replacing the current macro-basestation radio access network, and submillimeter-wave/THz sensing with application fields including medical diagnosis, food quality control, agriculture and industrial sensors.
The proposed THz microsystems are based on rectangular waveguide-technology integrated into a multi-wafer stacked silicon substrate, which integrates all passive components needed for completing a submillimeter-wave/THz system around the monolithic-microwave integrated circuits (MMIC). Novel key building blocks investigated in this proposal include platform-integrated sensor and antenna interfaces, micro-electromechanically tuneable filters, phase-shifters, impedance-matching networks and non-galvanic microsystem-to-IC interfaces. The micro-mechanical reconfigurability enables unprecedented adaptive THz systems.
Key outcomes of this project are proof-of-concept prototypes of all key building blocks up to 650 GHz, and of complete THz microsystems implemented for the two key applications telecom links and medical sensors.","1727189","2014-04-01","2019-03-31"
"TeraSHAPE","Terahertz Waveform Synthesis and Analysis Using Hybrid Photonic-Electronic Circuits","Christian Gunter KOOS","KARLSRUHER INSTITUT FUER TECHNOLOGIE","Generation, detection, and processing of electromagnetic waveforms is one the most important tech-nical foundations of modern society. Digital signal processing, in particular, has revolutionized many areas of science and engineering. By exploiting massively parallel processing with tens of billions of transistors at comparatively low internal clock speed, CMOS circuits can provide output data rates of hundreds of gigabit per second, corresponding to effective clock rates of several hundred GHz. In contrast to that, the analog bandwidth of electronic circuits is much more difficult to scale due to limited switching speed of semiconductor devices, strongly increased transmission line losses at high frequencies, and the considerable complexity associated with high-speed circuit packaging and as-sembly.
TeraSHAPE aims at overcoming these limitations by establishing the foundations of novel signal processing concepts at T-wave frequencies between 100 GHz and 1 THz. Capitalizing on cutting-edge results in the fields of photonic integration and optical frequency comb generation, TeraSHAPE will combine massively parallel processing in digital electronic circuits with synthesis and analysis of broadband waveforms in the optical domain. To convert waveforms between optical and T-wave frequencies, TeraSHAPE will explore novel concepts for ultra-fast devices such as silicon-organic hybrid electro-optic modulators and silicon-plasmonic photodetectors with bandwidths of hundreds of GHz. Advances on the device level will be complemented by scalable assembly concepts, where TeraSHAPE will exploit 3D printing on the micro- and nanoscale both for hybrid photonic integration and for realizing sub-mm THz waveguides. The viability of the TeraSHAPE concepts will be experimentally demonstrated in applications of high relevance such as high-speed wireless communications at data rates of up to 1 Tbit/s or signal processing in high-field electron paramagnetic resonance (EPR) spectroscopy.","2498954","2018-05-01","2023-04-30"
"TeX-MEx","Time resolved X-ray probing of Matter under Extreme conditions","Stuart Peter David Mangles","IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE","The unique properties of a new type of X-ray source produced by a compact laser-plasma accelerator will be used to probe the ultra-fast dynamics of the electronic structure of matter under extreme conditions.

The TeX-MEx project will study: 1) hot dense matter, such as that found at the centre of the Sun; 2) warm dense matter such as that found at the centre of Jupiter and 3) photo-ionized plasmas far from equilibrium such as is found in the exotic environment of an accretion disk surrounding a black hole. These extreme conditions will be created in the laboratory using 1) direct laser heating, 2) proton heating and laser driven shock heating and 3) intense X-ray pumping using the betatron source itself and the extraordinary X-ray fluxes available with a free electron laser.

Using the unique combination of a few-femtosecond duration and broad spectral coverage that the X-rays produced by a laser wakefield accelerator possess, the TeX-MEx project will explore new physics in each of these regimes.  For example we will be able to directly measure the rates of ionization of hot dense matter for the first time; we will observe the onset of ion motion in warm dense matter and how this affects the electron energy levels; we will make the first observations of non-collisional photo-ionized plasmas. These will allow us to accurately test and develop models used to describe matter under extreme conditions in the laboratory and in astrophysics. 

This integrated program of innovative experiments and new approaches to modeling will open up a new field of femtosecond time-resolved absorption spectroscopy of matter under extreme conditions and will drastically improve our understanding of how matter behaves throughout our Universe. It will, for the first time, bring to our laboratories on Earth the ability to probe some of Nature's most violent processes, to date only hinted at in data from a new generation of astronomical instruments.","1996316","2016-07-01","2021-06-30"
"TheHiggsAndThe7Tops","Mirror Mirror on the Wall, which Higgs is the oddest of them all: Exploring the Top-Higgs Interconnection with ATLAS","Yvonne PETERS","THE UNIVERSITY OF MANCHESTER","With the ground-breaking discovery of a new scalar particle, the Higgs boson, in 2012 by ATLAS and CMS, the standard model (SM) of particle physics has been completed. Despite this success, many open questions on the fundamental laws of nature remain unanswered. Among these are how exactly particles acquire their mass and why there is more matter than antimatter in the universe.

One of the most promising avenues to approach these questions is to explore the relation between the Higgs boson and the heaviest known elementary particle: the top quark. Due to its large mass, the top is expected to play a special role in the mechanism of electroweak symmetry breaking. In order to shed light onto this mechanism, understanding the coupling between the top and the Higgs in great detail and exploring the charge and parity (CP) nature of the Higgs are essential. While the SM Higgs boson is CP-even, many models beyond the SM require a CP-odd component. Higgs-top couplings are expected to provide an unambiguous probe of CP-mixed states.

I will explore for the first time all processes in which a direct determination of the top-Higgs interconnection is feasible, in particular events where the Higgs is produced in association with 1, 2 and 4 top quarks. These are among the most challenging channels at the LHC. I will pioneer a comprehensive programme, consisting of the development of powerful event-reconstruction methods and improved boosting techniques, allowing the first exploitation of novel variables in a beyond-state-of-the-art cross-process analysis, thus unravel the CP-properties in the top-Higgs interaction.

The ultimate goal of the project is the precise direct measurement of the top-Higgs Yukawa coupling, and the first determination of the CP-nature of the Higgs boson in fermion interactions. Confronting these results with the SM and models that go beyond the SM will yield an unprecedented insight into the origin of mass of elementary particles.","1999998","2019-10-01","2024-09-30"
"THEMODS","Theories and Models of the Dark Sector: Dark Matter, Dark Energy and Gravity","Constantinos Skordis","FYZIKALNI USTAV AV CR V.V.I","Modern cosmology assumes that General Relativity (GR) is the correct description of gravity on large scales. With this assumption and according to current data, the cosmological model needs in addition the existence of a Dark Sector: Dark Matter (DM) and Dark Energy (DE). We know very little about the nature of DM and it is yet to be detected experimentally. The simplest form of DE compatible with the data, a cosmological constant, has a value incompatible with our understanding of Quantum Field Theory. Given that the extrapolation of GR to cosmological scales has not been tested it is possible that the inference of the Dark Sector also needs to be revised.

I propose to (i) determine the nature of DM and DE to a level not achieved before, (ii) test gravity on cosmological scales and (iii) test the screening of new gravitational degrees of freedom in the solar system. The first two goals will require the use of my general framework to parameterize field equations [Skordis, PRD 79, 123527 (2008); Baker, Ferreira & Skordis, PRD 87, 024015 (2013)]. My team will use this framework to construct simple models and observations to place limits on their parameters. We will employ the Cosmic Microwave Background (CMB) observations from ESA's Planck Surveyor and the Atacama Cosmology Telescope. We will determine the sensitivity of the CMB lensing to the properties of DM and theories of gravity. To break possible degeneracies these data will be supplemented with large-scale structure data, weak lensing and red-shift space distortions. We will also perform forecasting for ESA's EUCLID mission which will give us a handle on how well we will constrain GR with cosmology in the future. For the final goal (iii) we will employ the method of [Padilla & Saffin, JHEP 1207, 122 (2012)] to construct a perturbative expansion of theories that exhibit screening, inside the screening radius. We will determine the compatibility of such theories with solar system and other strong-field data.","1150691","2014-08-01","2019-07-31"
"TheONE","The Janus-face of the localized carrier in cuprates: Generating the pseudogap and high temperature superconductivity","Neven, Zitomir BARISIC","TECHNISCHE UNIVERSITAET WIEN","The phenomenon of high-temperature (high-Tc) superconductivity (SC) is one of the most exciting, thoroughly investigated yet still unresolved problems in physics. A major difficulty in understanding high-Tc systems lies in the complexity of the materials and phase diagram. The delicate balance between material specific properties, disorder and the number of electronic phases superimpose makes it hard to identify the leading interactions. Consequently, theoretical models attempting to describe the high-Tc SC are significantly disparate and identifying the mechanism of SC at elevated temperatures is full of hardship.
Due to the proximity of the antiferromagnetic phase, the strong electronic interactions, the appearance of a pseudogap etc., the electronic phase is considered to be exotic, a non-Fermi Liquid and the coupling mechanism for Cooper pairs strange. Based on my recent experiments, here I propose a change of paradigm:
•that the charge carriers which couple to give high temperature superconductivity follow the well-known Fermi-liquid behavior
•that the pseudogap phenomenon corresponds to a gradual (Mott-like) localization of exactly ONE charge carrier per unit cell
•the “Glue” for pairing stems from a bosonic excitation of ONE localized carrier leading to a novel excitonic mechanism for SC.
These hypotheses will be tested primarily on the model compound Hg1201, which features a simple tetragonal structure, minimal disorder effects, and the highest Tc in its class of single-layer compounds. Fermi-liquid aspects will be probed by novel approaches to (magneto)transport, optical conductivity. The relation between SC and The ONE will be explored by unique experimental setups that combine uniaxial-pressure with local/structural probes.
If the above conjectures are indeed confirmed it would give an enormous boost to this field. Beyond finding the solution of a 30-year-old enigma, it would enable an educated search for new materials with potentially even higher Tc's.","2133950","2017-09-01","2022-08-31"
"THERA","Timing of Holocene volcanic eruptions and their radiative aerosol forcing","Michael SIGL","UNIVERSITAET BERN","Volcanic eruptions play a dominant role in driving climate, in ways beyond the established short-term influence on surface air temperatures. In order to mitigate and adapt to the climate effects of future large volcanic eruptions we need to better quantify the risk of these eruptions including 1) the probability of their occurrence and 2) their expected climatic impact. The observational record of the timing of volcanic eruptions, their locations, magnitudes of sulphate aerosol injection is incomplete which limits our understanding of the sensitivity of the Earth system to volcanism and the vulnerability of social and economic systems to the climate impact of past and future eruptions. 

The primary goal of this proposal is to extract data on the timing, magnitudes and source locations of all major volcanic eruptions occurring during the Holocene (i.e., the past 12,000 years) to answer the questions: What is the likelihood of a stratospheric sulfur injection as large as that from the colossal eruption of Tambora in 1815 to occur somewhere on the globe within the next 100 years? What is the role of effusive eruptions on past, present and future climate?
 
This will be achieved by employing novel, precisely dated, high-time resolution aerosol measurements from bipolar ice-core arrays. New tools will be used to constrain source parameters of the eruptions (location, plume injection height) that control their effects on climate. THERA will constrain recurrence rates for one of the largest global-scale natural hazards, while also assessing linkages between volcanic perturbations and key components of the climate systems (e.g., atmospheric circulation, droughts, ice-sheets and sea-level) through interdisciplinary case studies. As a final goal, THERA will generate global-scale, space-and-time resolved stratospheric aerosol properties for climate models to simulate the volcanic influence on Holocene climate evolution.","1978923","2019-03-01","2024-02-29"
"THIRST","Third Strategy in Tissue Engineering – Functional microfabricated multicellular spheroid carriers for tissue engineering and regeneration","Aleksandr Ovsianikov","TECHNISCHE UNIVERSITAET WIEN","The field of tissue engineering (TE) pursues a noble goal, driven by the urgent need for tissue and organ repair. It is represented by a fairly large and extremely interdisciplinary scientific community. However, so far TE was not able to deliver to the expectations, with only a few examples of successful clinical translation mostly restricted to a particular disease or tissue type. Despite the fact that all major fundamental bottlenecks of conventional TE strategies have long been identified, a universal solution does not seem to be in sight.
In this project I propose to launch a radically new approach, a third strategy in tissue engineering (THIRST), which holds the potential to produce a desperately needed technological breakthrough. THIRST relies on a tissue self-assembly from multicellular spheroids encaged within robust 3D printed microscaffolds. THIRST is enabled by a number of cutting-edge methods, some of which became relevant in the context of TE only recently. In combination, these methods offer a variety of new technological possibilities for the area of TE. 
The objectives of this project are focussed on establishing the means for automated large-scale production of tissue modules, protocols for microscaffold biofunctionalisation, and demonstrating THIRST potential with highly relevant clinical examples - cartilage, representing avascular tissue, and vascularized bone tissue. 
A distinct feature of THIRST is its universal applicability, meaning that such a tool-box can be further expanded to encompass other types of tissues without substantial adjustments to the basic tissue assembly procedure. The latter is particularly inspiring, taking into account the considerable regulatory hurdles associated with the development of new TE therapies. Due to its unconventional nature, realization of THIRST relies on overcoming several considerable technological challenges addressed by this project.","1999963","2018-05-01","2023-04-30"
"THREEDCELLPHYSICS","The physics of three dimensional chromosome and protein organisation within the cell","Davide Marenduzzo","THE UNIVERSITY OF EDINBURGH","Understanding the fundamental mechanisms behind the functioning of cells and their interior has long been a biology-only enterprise. This view has radically changed in the last decade or so, culminating in the invention of a whole new field, named 'cell physics', which uses the tools of physics to gain a more quantitative and deeper understanding of the inner working of a cell. The aim of my research fits broadly in this new field, although the scale of the computational studies which I plan are thus far unprecedented. I will focus my programme on the spatial organisation of DNA and chromosomes, proteins, and DNA-protein networks within the intracellular environment. I will therefore aim to answer questions such as: How is DNA organised in living cells, such as bacteria and eukaryotic nuclei? What is the role of proteins in DNA and chromosome folding in vivo? How does genome organisation differ in healthy and sick nuclei? How do proteins and RNA move around and self-organise into supramolecular structures in the crowded intracellular environment? I propose to work on the simulation and theoretical side of these problems, while maintaining very close collaborations with key experimental players in these fields who will provide me with a large number of experimental data (obtained by more sophisticated version of the original well-known 'chromosome conformation capture' technique) to maximise the impact and output of the modelling work.","1499236","2015-07-01","2020-06-30"
"TIAMO","Trapping Ions in Atoms and Molecules Optically","Tobias Johannes Jakob Boris Christoph Schätz","ALBERT-LUDWIGS-UNIVERSITAET FREIBURG","Isolating ions and atoms from the environment is essential in experiments on a quantum level. For decades, this has been achieved by trapping ions with radiofrequency (rf) fields and neutral particles with optical fields. Our group demonstrated the trapping of ions by interaction with light. We see these results and our proposal as starting point for finally combining the advantages of optical trapping and ions. In particular, ions provide individual addressability, high fidelities of operations and long-range Coulomb interaction, significantly larger compared to those of atoms and molecules
The aim of this proposal is to (i) study and establish optically trapping of ions and atoms in general, to (ii) demonstrate the substantial improvement of our approach in the context of interaction and reaction at ultra-low temperatures and to (iii) explore further perspectives by adapting methodology of quantum optics to gain control and state-sensitive detection on the level of individual quanta within the merged ion-atom system. 
The field of ultra cold chemistry is perfectly suited as a showcase for this purpose. We will embed optically trapped ions into quantum degenerate gases to reach temperatures, 4-5 orders of magnitude below the current state of the art. Our approach circumvents the currently inevitable excess kinetic energy in hybrid traps, where ions are kept but also driven by rf-fields. It permits to enter the temperature regime where quantum effects are predicted to dominate, (i) in many-body physics, including the potential formation and dynamics of mesoscopic clusters of atoms of a Bose-Einstein-Condensate, binding to the “impurity ion”, as well as (ii) the subsequent two-particle s-wave collisions, the ultimate limit in ultra-cold chemistry.

Further development of our novel and generic tools for “quantum engineering can be expected to propel several other striving fields of research, such as, experimental quantum simulations","1792500","2015-08-01","2020-07-31"
"TICTOCGRAV","Exploring Gravity with Ultracold Cadmium and Strontium Optical Clocks and Bragg Interferometers","Nicola POLI","UNIVERSITA DEGLI STUDI DI FIRENZE","The main aim of the TICTOCGRAV is to explore the limits of contemporary physics with a new generation of atomic quantum sensors, namely optical atomic clocks and atomic gravimeters.

After 100 years of General Relativity and Quantum Mechanics, both theories have been tested at an unprecedented level.  Direct detection of gravitational waves is a great success and represents another impressive confirmation of the present theory of gravitation GR. Indeed, we are living a “Quantum Revolution”, in which advanced quantum concepts are at the heart of several devices, from precision navigation and location on Earth to secure communication protocols based on entangled photons.
Despite all these great success in both areas, unfortunately, we still lack a full comprehension at the fundamental level. As a matter of fact, a full quantum treatment of space-time is still under discussion in the community. While several theoretical attempts have been pursued, a clear solution to the problem does not exist yet. Very likely, an answer to this problem will come from high precision experiments capable of measuring tiny gravitational effects on quantum systems as atomic clocks and quantum inertial sensors. 
TICTOCGRAV will address this questions experimentally by performing ultimate precision tests of gravity with fountains of alkali-earth metals, namely Cadmium and Strontium atoms. 

Specifically, TICTOCGRAV will perform the highest precision tests so far of:
-the weak equivalence principle (WEP) below 10^-13 with quantum probes, exploring also possible tests of spin-gravity couplings at the same level;
- quantum interference of high precision clocks in a gravitational potential; demonstrating for the first time gravity induced decoherence mechanisms, opening the way towards a possible explanation of quantum to classical transition in macroscopically entangled quantum systems.","1999011","2018-06-01","2023-05-31"
"TiDrugArchitectures","Highly Competent and Safe Titanium(IV) Therapeutic Frameworks that are Cancer Targeted based on Complex 1, 2, and 3D Chemical Architectures","Edit Yehudit Tshuva Goldberg","THE HEBREW UNIVERSITY OF JERUSALEM","This proposal aims to develop custom designed anticancer therapeutic frameworks that are effective, stable, safe, and tumor targeted, based on the biocompatible TiIV metal. The Tshuva group has established that water stable phenolato TiIV complexes are especially effective as anticancer agents both in vitro and in vivo, with markedly reduced side effects. Optimal derivatives will be developed to combine activity, stability, and biological accessibility, by maintaining small steric bulk while incorporating strong binding donors and hydrophilicity. The mechanism of action will be investigated by chemical and biological methods, including analyzing bio-distribution, cellular pathways and targets, and interaction with bio-molecules. Specifically, the active metal centers will be linked to bioactive moieties through redox-sensitive S–S bonds to enable tumor targeting. Cell penetrating peptides will facilitate cellular penetration for redox-dependent release of the active species selectively in cancer cells; steroid moieties will direct selectivity to hormone-dependent cancer cell types. Since the combination of TiIV- with Pt-based drugs has shown synergistic effects, multi-active entities will include two or more metal centers, possibly also linked to a transport unit. In addition to linear conjugates, polymeric and dendritic assemblies, exploiting the enhanced permeability of cancer cells, will be constructed with theoretically unlimited options for targeted delivery of multiple active sites. Most importantly, flexible well-defined redox-sensitive cages, as well as rigid pH sensitive complex cages, constructed with customized 3D geometries, will enable specific targeting of any active compound or conjugate and selective dissociation only where desired. This study should yield superior anticancer drugs, while unraveling the mystery of their complex biochemistry, and will contribute to the development of novel chemical and medicinal research directions and applications.","2000000","2016-06-01","2021-05-31"
"time-data","Time-Data Trade-Offs in Resource-Constrained Information and Inference Systems","Volkan CEVHER","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Massive data poses a fundamental challenge to learning algorithms, which is captured by the following computational dogma: The running time of an algorithm increases with the size of its input data. The available computational power, however, is growing slowly relative to data sizes. Hence, large-scale problems of interest require increasingly more time to solve. 
Our recent research demonstrates that this dogma is false in general, and supports an emerging perspective: Data should be treated as a resource that can be traded off with other resources such as running time. For data acquisition and communications, we have also shown related sampling, energy, and circuit area trade-offs.
A detailed understanding of time-data and other analogous trade-offs, however, requires interdisciplinary studies that are currently in their infancy even for basic system models. Existing approaches are too specialized, and crucially, they only aim at establishing a trade-off, but not characterizing its optimality or its technological feasibility.
TIME-DATA will confront these challenges by building unified mathematical foundations on how we generate data via sampling, how we set up learning objectives that govern our fundamental goals, and how we optimize these goals to obtain numerical solutions. We will demonstrate our rigorous theory with task-specific, end-to-end trade-offs (e.g., samples, power, computation, and statistical precision) in broad domains, by not only building prototype analog-to-information conversion hardware, but also accelerating scientific and medical imaging, and engineering new tools of discovery in materials science.
Our goal of systematically understanding and expanding on this emerging perspective is ambitious: Our mathematical sampling framework, in tandem with new universal primal-dual algorithms and geometric estimators, are expected to change the way we treat data in information systems, promising substantial flexibility in the use of limited resources.","1931574","2017-09-01","2022-08-31"
"TIMED","Testing the role of Mediterranean thermohaline circulation as a sensor of transient climate events and shaker of North Atlantic Circulation","Eva Isabel CACHO LASCORZ","UNIVERSITAT DE BARCELONA","The Mediterranean Sea is an excellent sensor of transient climate conditions at different time scales. Changes in Mediterranean water properties result from complex interactions between the Atlantic inflow, local climate and north and south atmospheric teleconnections. In turn, Mediterranean outflow waters spill into the Atlantic Ocean, thus acting as a net salt and heat source for the Atlantic Meridional Overturning Circulation (AMOC). Climate models anticipate changes in these circulation systems within decades; thus it becomes critical to understand the natural range of variations in the Mediterranean Thermohaline Circulation (MedTHC) and whether these can alter the AMOC. An innovative approach, based on both well-established and newly-developed analytical methods will be applied to characterize, qualitatively and quantitatively, past changes in the MedTHC dynamics. Specific time windows representing very different transient periods (18-14 ka BP; 9.5-6.5 ka BP and the last 2 kyr) will be targeted in order to understand the distinctive role that individual forcing mechanisms exerted in controlling MedTHC changes. Particular emphasis will be placed on building robust regional chronologies and proxy records with unprecedented high-resolution. This approach will combine proxy data from sediment cores and deep-sea corals along the main paths of water masses as they cross the Mediterranean basins and exit into the North Atlantic. This paleo-data analysis will be complemented with novel climate model paleo-simulations to test the sensitivity of the AMOC to changes in Mediterranean outflow under varying AMOC conditions. The main goals are to identify: (1) The natural range of MedTHC variability;  (2) The forcings and inter-regional teleconnections driving MedTHC changes; (3) The associated impact onto the AMOC. The assessment of the forcings controlling MedTHC and the ensuing impact on the AMOC will allow us to gauge the consequences of future Mediterranean changes.","2400000","2017-01-01","2021-12-31"
"TIMING","Time-Resolved Nonlinear Ghost Imaging","Marco PECCIANTI","THE UNIVERSITY OF SUSSEX","This project addresses major challenges in Terahertz (THz) sensing at the forefront of the experimental and theoretical investigation. The results will have far-reaching implications in complex science. They will target the next generation of THz imagers, acknowledged as unique diagnostic tools in cross-disciplinary fields in light of the THz’s distinctive ability to unambiguously discriminate molecular compounds.

 The project objectives are:

(i) to explore the consequences of modern approaches to imaging with structured illumination in the THz domain.

(ii) to introduce a novel approach to THz microscopy.

TIMING will explore a novel form of single-pixel imaging that boosts the performance of the state-of-the-art. It exploits concepts cross-disciplinary inherited from fields like complexity and nonlinear-physics. 

The newly developed background will directly impact transverse fields like acoustic, microwaves and optics where related forms of imaging are strongly investigated. The sought results aim to enable applications in several scenarios in biology, medicine, material science, quality inspection and security. In all those fields, active THz imaging is still challenged by the poor general resolution, low brightness and relatively long acquisition time, aspects directly targeted by this project. 

TIMING is at the same time a project and novel imaging concept that will unveil real applications in transversal and interdisciplinary fields where imaging and material discrimination are strategic.","1979270","2017-06-01","2022-05-31"
"TIMP","Ultrahigh-speed nanometer-scale microscopy","oren COHEN","TECHNION - ISRAEL INSTITUTE OF TECHNOLOGY","Ultrahigh-speed microscopy at Tera-scale frames per second frame-rate is essential for various applications in science and technology. In particular, it is critical for observing ultrafast non-repetitive events, for which the pump-probe technique is inapplicable. The spatial resolutions of such microscopes is to date limited to the micrometer scale.

I propose to develop such microscopes with nanometric resolution.
The Tera-scale frames per second frame rate microscopes with nanometric resolution will be based on a new approach for ultrahigh-speed imaging that we recently proposed: time-resolved imaging by multiplexed ptychography (TIMP). In TIMP, multiple frames of the object are recovered algorithmically from data measured in a single CCD exposure of a single-shot ptychographic microscope. The frame rate is determined by the light source (burst of pulses) and it is largely uncoupled from the microscope spatial resolution, which can be sub-wavelength. Also important, TIMP yields movies of both the amplitude and phase dynamics of the imaged object. It is simple and versatile, thus it can be implemented across the electromagnetic spectrum, as well as with other waves.

I aim to develop TIMP-based microscopes, in the visible, extreme UV and x-ray spectral regions with Tera-scale frames per second frame rate and nanometric resolution. We will utilize the unprecedented imaging capabilities in applications, including exploring ultrafast phase transitions, ultrafast dynamics in nanostructures, and tracking the spatiotemporal dynamics during passive mode-locking build-up in lasers and Kerr micro-resonators.

This program, if successful, will bring the field of imaging into a new era, where ultrafast dynamics of non-repetitive transient complex-valued objects can be viewed at nanometric resolution.","2381700","2019-03-01","2024-02-29"
"TissueMaps","Integrating spatial and genetic information via automated image analysis and interactive visualization of tissue data","Ewa Asa Carolina Wahlby","UPPSALA UNIVERSITET","Digital imaging of tissue samples and genetic analysis by next generation sequencing are two rapidly emerging fields in pathology. The exponential growth in digital imaging in pathology is catalyzed by more advanced imaging hardware, comparable to the complete shift from analog to digital images that took place in radiology a couple of decades ago: Entire glass slides can be digitized at near the optical resolution limits in only a few minutes’ time, and fluorescence as well as bright field stains can be imaged in parallel. 

Genetic analysis, and particularly transcriptomics, is rapidly evolving thanks to the impressive development of next generation sequencing technologies, enabling genome-wide single-cell analysis of DNA and RNA in thousands of cells at constantly decreasing costs. However, most of today’s available technologies result in a genetic analysis that is decoupled from the morphological and spatial information of the original tissue sample, while many important questions in tumor- and developmental biology require single cell spatial resolution to understand tissue heterogeneity.

The goal of the proposed project is to develop computational methods that bridge these two emerging fields. We want to combine spatially resolved high-throughput genomics analysis of tissue sections with digital image analysis of tissue morphology. Together with collaborators from the biomedical field, we propose two approaches for spatially resolved genomics; one based on sequencing mRNA transcripts directly in tissue samples, and one based on spatially resolved cellular barcoding followed by single cell sequencing. Both approaches require development of advanced digital image processing methods. Thus, we will couple genetic analysis with digital pathology. Going beyond visual assessment of this rich digital data will be a fundamental component for the future development of histopathology, both as a diagnostic tool and as a research field.","1738690","2016-04-01","2021-03-31"
"Tmol4TRANS","Efficient electronic transport at room temperature by T-shaped molecules in graphene based chemically modified three-terminal nanodevices","Nuria ALIAGA-ALCALDE","AGENCIA ESTATAL CONSEJO SUPERIOR DEINVESTIGACIONES CIENTIFICAS","Tmol4TRANS aims to create operative molecular systems that will efficiently be inserted in three-terminal nanodevices to function as transistors at room temperature (RT). 
In the front-line of molecular electronics, the implementation of functional nanodevices in present technologies is mainly hampered by crucial unresolved issues like: a) reliability of RT experiments on molecular transistors; b) absence of controlled methodologies to deposit single molecules at specific sites; c) low conductance values and d) difficulties in achieving effective three-terminal devices (BJTs/FETs). Such hindrances involve the nature of the molecules, the absence of controlled deposition methodologies at the nanoscale and the poor stability/contacts between molecules and electrodes. 
Stable two-terminal nanodevice based on few-layer graphene and containing a Curcuminoid molecule (CCMoid) that I made has shown reasonable molecular conductance at RT, where the CCMoid anchors to the electrodes by pi-pi stacking. The specific goals of Tmol4TRANS are: 1) to synthesize multifunctional molecules base on “T-shaped” CCMoids and Porphyrin derivatives (PPDs) allowing efficient attachments to electrodes; 2) to fabricate chemically functionalized hybrid graphene transistors; 3) to establish a reliable methodology for positioning the molecules between the electrodes; 4) to investigate the conductance enhancement of the final systems, and 5) to provide the possibility of spin-dependent transport properties by binding such molecules to magnetic metals. Here, the preparation of nanodevices involves feedback-controlled burning technique for the formation of the few-layer graphene electrodes (source/emitter and drain/collector) and the chemical functionalization of the gate/base, where T-shaped molecules will be fixed by click-chemistry. Tmol4TRANS would have a direct impact in Molecular Electronics and Spintronics, as well as in the broader scope of nanoelectronics.","1998879","2017-03-01","2022-02-28"
"TOCNeT","Teaching Old Crypto New Tricks","Krzysztof Zbigniew Pietrzak","INSTITUTE OF SCIENCE AND TECHNOLOGYAUSTRIA","The bulk of the research in modern cryptography goes into constructing new schemes for which stronger security guarantees can be proven. However, often it is not clear if simple existing schemes already provide the required security, and we just don’t know how to prove it. As these new schemes are usually less efficient, they are not being applied resulting in a large discrepancy between the security that applied schemes are supposed to provide and what is actually proven. This project aims at closing this gap in different contexts: we will revisit simple schemes (including widely deployed ones) using new tools, developed by us and others in the last years, towards proving much stronger security properties than what is currently known. Three research directions in which we have already made substantial progress and which we will further investigate are: 
Adaptive Security: Often we can prove a scheme secure against selective adversaries, while in practice stronger adaptive security is required. Until recently this was the case for constrained PRFs, the popular LKH multicast encryption and all known proxy re-encryption schemes. Last year we introduced the “nested hybrids” proof technique, which allowed us to prove adaptive security of these schemes. We will further develop and apply this technique. 
Symmetric Cryptography: Although symmetric schemes are the work horses of crypto, for most of them we only have non-tight security proofs which leave a huge gap to the best known attacks. We recently proved tight security bounds for HMAC (used for authentication in SSL/TLS, SSH and IPsec) and the Sponge family used in the SHA3 standard. 
Pseudoentropy: Computational notions of entropy have found many applications in the last few years. The tools available to manipulate pseudoentropy yield poor quantitative bounds, resulting in impractical schemes. We will continue our research towards establishing the exact necessary security degradation for manipulating pseudoentropy.","1882244","2016-04-01","2021-03-31"
"TOPCHARM","The LHC Battle for Naturalness on the Top Charm Front","Gilad Perez","WEIZMANN INSTITUTE OF SCIENCE LTD","Now that a Higgs-like particle has been discovered naturalness becomes the most pressing and fundamental question within the reach of the Large Hadron Collider (LHC).  The main contribution that destabilises the electroweak scale comes from a top-quark loop. The key for addressing the naturalness problem is thus identifying the top partners that are stabilizing the weak scale.
We consider the following two general possibilities in which the partners have escaped detection:
(I) the top partners are light but elusive, this calls for a theoretical explanation as well as for new innovative experimental techniques for signal exhumation;
(II) the partners are  relatively heavy and the signal would consist of energetic (boosted) top from the decay of its partner. I plan to carry out a comprehensive research program designed to attack these challenges, and I believe that I am uniquely prepared to do this.  Regarding (I), as proven below, current searches have not considered the impact of non-trivial flavor physics, e.g. splitting between the first two generation partner masses, as well as the mixing between the top-partners and other flavors. The consequences are: (i) significantly weaker mass bounds on some of the partners (e.g. the scharm, charm-supersymmetric-partner);  (ii) improved naturalness as even the stops (or fermion partners) can be lighter; and (iii) modified Higgs rates in composite models.
Regarding (II), with collaborators I have been the first one to understand the difficulties of dealing with highly boosted top jets, and since then I was intensively involved in developing theoretical as well as novel techniques to study them, including coauthoring two important papers with the CDF and ATLAS collaborations.
To uncover these new possibilities, expertise in collider phenomenology and flavor physics is required. I have a proven record in these frontiers and thus, given the required support, am well positioned to pursue this quest to save naturalness.","1434154","2014-07-01","2019-06-30"
"TopCoup","Determination of top couplings in associated top pair events using ATLAS data","Markus Cristinziani","RHEINISCHE FRIEDRICH-WILHELMS-UNIVERSITAT BONN","The discovery of a new particle, compatible with the Higgs boson, at the Large Hadron Collider, marked a major triumph of the Standard Model of particle physics. However, many fundamental questions remain and direct or indirect evidence of new physics can be probed with the large number of proton-proton collision data, collected in 2011 and 2012 at 7 and 8 TeV centre-of-mass energy.

With this proposal we plan to exploit the large sample of top-quark pair events that is already recorded, and the sample that will be collected from 2015 onwards, at the ultimate energy of 14 TeV. In particular we plan to study the coupling of top quarks to neutral bosons, by measuring the production of associated tt̄γ, tt̄Z and tt̄H. Anomalous electromagnetic or weak couplings could be uncovered by studying kinematic properties of the resulting photon or Z-boson, once the signal is established. By studying the tt̄H production in detail the mechanism of Yukawa coupling of the Higgs boson to fermions will be tested, possibly providing important confidence in the characterisation of the new boson.

In all measurements we plan to include the tt̄ dilepton channel, that, despite the smaller branching fraction has typically superior signal-to-noise ratios. An essential part of the programme will be the calibration of the b-tagging algorithms, where we plan to use tt̄ events. For associated Higgs production we will explore the decays H→ bb̄ and H→ γγ.","1964088","2014-01-01","2018-12-31"
"topDFT","A topological approach to electron correlation in density-functional theories","Andrew TEALE","THE UNIVERSITY OF NOTTINGHAM","Density-functional theory (DFT) is the most widely used method to study the electronic structure of complex molecules, solids, and materials. Its use across chemistry, solid-state physics and materials science is a testament to its black-box nature and low cost. However, many important areas remain inaccessible to DFT simulations, including applications to strongly correlated materials and systems in electromagnetic fields. The topDFT project will deliver new conceptual approaches to design the next generation of density-functional methods. This will be achieved by pursuing three parallel strategies: i) Developing new strategies for the design of functionals ii) Implementing topological DFT, a new computational framework iii) Developing extended density-functional theories. 

A new approach to the exchange–correlation problem, based on a perspective from the kinetic energy of the electrons, will be developed – leading to new practical density-functional approximations (DFAs). A new framework for computation will be developed by combining techniques from topological electronic structure methods with DFT, allowing for the identification of correlation ‘hotspots’. This idea is chemically intuitive; electrons close together interact in a fundamentally different way to those far apart. Recognising these hotspots, and adapting dynamically to them, will lead to new DFAs with substantially greater accuracy. 

Extended-DFTs will open the way to study strongly correlated systems (e.g. high-Tc superconductors, transition metal oxides, Mott insulators) of importance in chemistry and materials science and magnetic systems (e.g. molecular magnets, spin glasses, spin frustrated systems) of importance in nano-science, advanced materials and spintronics applications. The topDFT project will have wide impact on areas including chemical synthesis, materials design and nano-science that underpin key areas such as manufacturing and medicine of benefit to all sections of society.","1998649","2018-05-01","2023-04-30"
"TopMechMat","Topological Mechanical Metamaterials","Sebastian HUBER","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","Mechanical metamaterials are man-made structures with tailored vibrational properties geared towards applications such as earth-quake protection, energy harvesting, or medical imaging. Recently, we promoted a new design principle for such materials: topological band-theory known from quantum condensed matter physics. To date, the use of topology in mechanical materials has been largely restricted to one or two dimensions, a central shortcoming for applications. The objective of TopMechMat is to address this challenge (i) by establishing a theoretical framework for topological mechanical metamaterials in three dimensions, (ii) by developing a novel algorithm enabling the sample design, and (iii) by experimentally validating the proposed materials.
The current approach to topological mechanical systems is based on lcoal symmetries unnatural to classical mechanics. Crystalline symmetries, on the other hand, are ubiquitous in metamaterials and are known to stabilize topological phases. Using group cohomology techniques we will establish a theoretical framework for topological phonons in three dimensions. 
Translating a theoretical model into an actual sample requires extensive finite element simulations. However, the complexity of topological phonon models precludes the application of known design algorithms.  We plan to use a neural network to address this challenge. This will allow us to exploit the power of genetic algorithms in executing the required large-scale parameter scans. The successful implementation of this design algorithm will present us with an exciting opportunity: Mechanical systems might enable the discovery of yet unobserved topological phases of matter.
We plan to build a three-axis scanning vibrometer to investigate additively manufactured metamaterial samples. This will allow us to validate our ideas and to provide proof-of-principle results emphasizing the feasibility of our designs for concrete applications.","1999264","2018-02-01","2023-01-31"
"TOPOLOGICAL","Topological Light at Structured Surfaces","Shuang Zhang","THE UNIVERSITY OF BIRMINGHAM","By using metamaterials and metasurfaces as the platform, this proposal focuses on the novel topological physics and applications introduced by Berry phase. The flexibility in engineering the artificial ‘atoms’ and ‘molecules’ of metamaterials provides unlimited possibilities to create new structural effect where symmetry (or symmetry breaking) and topology play critical roles. We are particularly interested in the role Berry phase plays in various nontrivial surface optical effects, including topological surface states and spin Hall effect of light. The investigation of the scattering immune surface states in a topological metamaterial, i.e. an effective medium approach, acts to unify the spin Hall effect of light with the more unconventional scheme of topological orders and protected surface states. We will further exploit Berry phase in the nonlinear regime, in particular harmonic generations, to control the nonlinear coefficients to an unprecedented level. Hence our study on Berry phase in the nonlinear regime will point to a new research direction on nonlinearity coefficient engineering, which will have important impact in the area of nonlinear optics. The proposal also investigates into practical applications brought by a novel type of geometrical metasurfaces, where the phase and hence the wavefront are finely controlled by the Berry phase in a highly robust manner. The proposal involves the development of innovative synthesis technologies, theoretical analysis, numerical simulations, experimental characterizations, and device development. The new symmetry and topological effects in this research will greatly impact a number of disciplines including material science, condensed matter physics and photonics.","1997600","2015-12-01","2020-11-30"
"TOPONANOP","Topological nano-photonics","Frank Henricus Louis Koppens","FUNDACIO INSTITUT DE CIENCIES FOTONIQUES","One of the most fascinating phenomena in nature is the interplay between quantum mechanics and the flow of electrons in solids. A tangible example is the quantum hall effect, where electrons flow with virtually zero dissipation. That is because electrons can flow only in one direction, which makes them move around objects without scattering, representing robustness by topological protection. Essential for this effect is the magnetic field that breaks time-reversal symmetry.

Recently, however, with the advent of novel exotic quantum materials, completely new concepts for topological and non-reciprocal phenomena have appeared on the horizon, without the need to apply any magnetic field. These materials exhibit intrinsic topological character due to quantum mechanical interferences. TOPONANOP’s vision is to exploit these extraordinary quantum properties in order to control light at the nanoscale in a radically new way. One of the main objectives is to generate nanoscale optical fields (plasmons) that propagate in only one direction and implement topologically protected plasmons such that they move around defects and corners. At the same time, visualizing and controlling electromagnetic excitations will be used as a tool to unravel extraordinary phenomena in exotic quantum materials. 

To this end, TOPONANOP will apply novel low-temperature, THz and infrared, near-field imaging and spectroscopy techniques to directly spatially visualize the plasmon non-reciprocity and topological character.
Topological nano-photonics is a new paradigm for novel quantum materials and will enable novel future applications in miniaturized photonic isolators, diodes and logic circuits and could lead to completely new concepts for communication systems, optical transistors and optical information processing.","2748437","2017-11-01","2022-10-31"
"TOPOTRONICS","Topological Josephson devices as a novel platform for creating and controlling non-Abelian anyons","Alexander Brinkman","UNIVERSITEIT TWENTE","Surprisingly, in two-dimensional systems quasi-particles may exist that are neither fermions nor bosons. When these particles are interchanged, their joint quantum mechanical wave function is predicted to pick up any phase in between 0 (as for bosons) and pi (as for fermions), hence the name anyons.

Even more intriguing is the class of non-Abelian anyons where interchange of particles completely changes the ground state of the system. This phenomenon lays at the heart of a wealth of theoretical proposals for new types of quantum statistics and topological quantum computation that is robust against decoherence. While theory has well advanced, experimental realizations possess their own challenges and are seriously lacking behind.

It is the objective of this proposal to experimentally realize a platform to detect and control non-Abelian anyons. We propose to combine the particle-hole symmetry of a superconductor with the spin-momentum locking at the surface of a topological insulator. Topological Josephson junctions are predicted to host Majorana type bound states at vortices. We propose to artificially create Josephson vortices at the junction of three phase-biased superconducting islands and to control and braid multiple Majorana states to prove their non-Abelian anyon character.

In preliminary experiments we have shown, as one of the first groups in the world, to be able to induce superconductivity in a topological insulator by the proximity effect. This puts our group in a unique position to open up the field of topological Josephson physics. The great technological challenges of the present proposal lay in the development of topological insulator materials with higher surface mobility and their integration into Josephson electronic circuitry with multiple phase biased superconducting islands. For the phase biasing as well as the read-out of the Majorana states after braiding on-chip SQUID based current amplifiers will be developed.","1999200","2014-03-01","2019-02-28"
"TOPSIM","Topology and symmetries in synthetic fermionic systems","Leonardo Fallani","UNIVERSITA DEGLI STUDI DI FIRENZE","Topology and symmetry are two fundamental and intertwined concepts driving the behavior of fermionic systems in both condensed-matter and high-energy physics. The goal of the TOPSIM project is to address open problems concerning topological states of fermionic matter from an experimental point of view, by taking advantage of novel possibilities of quantum control on synthetic systems formed by ultracold neutral atoms. We will investigate the behavior of fermionic matter under strong gauge fields in order to study quantum Hall physics and the emergence of topological order in a fully tunable experimental geometry. We will also synthesize fermionic systems exhibiting enlarged interaction symmetries beyond the SU(2) symmetry of electrons, which will allow us to experimentally realize, for the first time, SU(N) models that have no other experimental counterpart in physics, and to use them to study the emergence of long-sought topological states of matter. With these ambitious goals, the TOPSIM project will considerably advance our understanding of topological fermionic matter, paving the way to new methods of investigation of open questions in both high- and low-energy physics, by approaching many-body problems with metrological quantum control.","1595000","2016-11-01","2021-10-31"
"TORCH","ThermoacOustic instabilities contRol in sequential Combustion cHambers","Nicolas NOIRAY","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","A new type of combustor architecture for large gas turbines has emerged in recent years: sequential combustion systems operated at constant pressure. This major technology change results from the need for more operationally and fuel flexible gas turbines, for future sustainable energy networks. As for regular gas turbines, the risk of combustor breakdown due to thermoacoustic instabilities is a major challenge. While the harmful consequences of these instabilities in novel sequential combustors can be as dramatic as in conventional systems, the associated physics is considerably complexified, because the two flames not only “talk” together via sound waves, but also via entropy waves. Our aim is to propose, investigate and develop novel active and passive control technologies, tailored for this new generation of combustors, in order to suppress their thermoacoustic instabilities. It brings significant scientific challenges in fluid mechanics, acoustics, combustion, nonlinear dynamics and control theory. We will address the problem of controlling these instabilities on two unexplored fronts: First, we intend to significantly move forward the state-of-the-art in passive control of combustion instabilities, by creating acoustic metamaterials with unprecedented acoustic damping properties, and capable of long term operation in harsh environments. Second, we plan to address scientific challenges, required to successfully achieve active combustion control in sequential combustors, by distributing non-equilibrium plasma discharges to locally and dynamically enhance the autoignition chemistry. To achieve these ambitious goals, a combination of experimental, numerical and theoretical methods will be applied with the aim to ultimately establish the potential and limitations of these novel technologies. This research deals with new areas in the field of thermoacoustics, and builds upon the PI’s scientific expertise in combustion and acoustics and on his technological know-how.","2585170","2019-09-01","2024-08-31"
"TouchDesign","A Computational Design Approach to Haptic Synthesis","Miguel Angel OTADUY TRISTAN","UNIVERSIDAD REY JUAN CARLOS","We use touch permanently to explore, manipulate and interact with the world around us, but also to feel and transmit affection. Haptic synthesis, i.e., the ability to design and control what we feel, either on a computer application or with a consumer product, bears an immense scientific, industrial, and social impact. However, touch is still poorly understood and underexploited in today’s digital era. The state of the art in computational haptic synthesis lags well behind the technological and scientific progress in additive manufacturing, computational design for fabrication, virtual reality displays, or cutaneous haptic interfaces.

TouchDesign will define a formal and comprehensive computational design methodology for haptic synthesis, applied to both tactile digital communication and to computational design and fabrication of objects with desired tactile properties. Haptic synthesis will be formulated as an optimization problem, with the objective function defined based on haptic perceptual metrics, and with the design space defined by the high-dimensional parameter space of a fabrication process or a haptic interface.

We will introduce multiple breakthroughs in four major scientific pillars.
(i) In contact biomechanics: develop measurement-based and data-driven models that enable interactive evaluation of the deformations undergone by skin mechanoreceptors.
(ii) In perceptual modeling: establish a connection between high-resolution biomechanics, mechanoreceptor activation fields, and psychophysics, through machine-learning analysis of exhaustive simulated and experimental data.
(iii) In numerical optimization: design methods that optimize perceptual metrics through robust and efficient search of the high-dimensional design space of haptic fabrication and haptic display problems.
(iv) In computational design: introduce methods and interfaces to visualize, explore, and define perceptual objective functions and haptic design spaces.","1968812","2018-09-01","2023-08-31"
"TOUGHIT","Tough Interface Tailored Nanostructured Metals","Daniel KIENER","MONTANUNIVERSITAET LEOBEN","The ideal structural material should excel in strength and toughness. Strength describes the capability of a defect free component to carry load during operation, while toughness defines the load-bearing capability and ductility in the presence of a crack. For an energy-efficient and safe design, both quantities should be simultaneously high. Unfortunately, they are mutually exclusive, rendering their combination a Holy Grail in materials science.
The reason for this incompatibility is rooted in the inverse strength-ductility paradigm. Focussing on metals, the strength is enhanced via microstructure refinement to the nanometer scale, but ductility and damage tolerance simultaneously drop dramatically. Safety-related or highly stressed components are thus made from rather soft metals, indicating tremendous economic impact conceivable.
The objective of this project is to design new bulk materials that uniquely combine high strength and toughness.
Severe plastic deformation will be employed to create novel nanostructured bulk metals and nanocomposites, utilizing atomistically informed alloy and interface design to promote plastic deformation. The largely unknown nanoscale processes that limit fracture toughness of nanostructured materials will for the first time be directly identified by quantitative nanomechanical fracture experiments performed in-situ in high resolution electron microscopes. Correlation of these unique insights with ab-initio calculations and energy-based elastic-plastic fracture mechanics computations will guide paths for further improvement of the fracture resistance.
By combining a versatile synthesis technique with highly advanced in-situ nanomechanical testing permitting unique atomistic-level insights into nanoscale fracture processes and a scale-bridging modelling approach, new mechanism-based strategies to tailor innovative nanostructured metals and composites with unprecedented strength and toughness will be established.","1960985","2018-05-01","2023-04-30"
"TRACES","Tracing ancient microbial cells embedded in silica","Mark Adriaan Van Zuilen","INSTITUT DE PHYSIQUE DU GLOBE DE PARIS","Reconstructing the nature and habitat of early life is a difficult task that strongly depends on the study of rare microfossils in the ancient rock record. The preservation of such organic structures critically depends on rapid entombment in a mineral matrix. Throughout most of Earth’s history the oceans were silica-supersaturated, leading to precipitation of opal deposits that incorporated superbly preserved microbial cells. As we trace this record of life back in deep time, however, three important obstacles are encountered; 1) microorganisms lack sufficient morphologic complexity to be easily distinguished from each other and from certain abiologic microstructures, 2) the ancient rock record has been subjected to increased pressures and temperatures causing variable degradation of different types of microorganism, and 3) early habitats of life were dominated by hydrothermal processes that can generate abiologic organic microstructures. TRACES will study the critical transformations that occur when representative groups of microorganisms are subjected to artificial silicification and thermal alteration. At incremental steps during these experiments the (sub)micron-scale changes in structure and composition of organic cell walls are monitored. This will be compared with fossilized life in diagenetic hot spring sinters and metamorphosed Precambrian chert deposits. The combined work will lead to a dynamic model for microfossil transformation in progressively altered silica-matrices. The critical question will be answered whether certain types of microorganisms are more likely to be preserved than others. In addition, the critical nano-scale structural differences will be determined between abiologic artefacts – such as carbon coatings on botryoidal quartz or adsorbed carbon on silica biomorphs – and true microfossils in hydrothermal cherts. This will provide a solid scientific basis for tracing life in the oldest, most altered part of the rock record.","1999250","2015-05-01","2020-04-30"
"TRANS-NANO","Advancing the Study of Chemical, Structural and Surface Transformations in Colloidal Nanocrystals","Liberato Manna","FONDAZIONE ISTITUTO ITALIANO DI TECNOLOGIA","Colloidal inorganic nanocrystals (NCs) are among the most investigated nanomaterials in Nanoscience due to their high versatility. Research on NCs went through much advancement lately, especially on synthesis, assembly and on the study of their transformations, most notably via cation exchange (all fields in which the PI has contributed already). However, the integration of NCs with fabrication tools that employ conditions such as irradiation, etching and annealing is at a very early stage since we do not have a systematic knowledge of what transformations are triggered in the NCs under those conditions. Also, an issue related to the incorporation of NCs in materials/devices is whether, over time, the NCs will remain as they are, or they will transform into other structures. Plus, these transformations in NCs are poorly studied as they require fast recording techniques. This proposal will embark on an ambitious investigation of post-synthetic transformations in solution-grown NCs: by advancing the understanding of various aspects of chemical, structural and surface transformation of NCs, we will uncover new fabrication techniques that will employ such nanostructures as the key ingredients. This in turn will have a strong impact in opto-electronics, as several electronic components entirely made of NCs will be delivered. Four objectives are targeted: i) developing radically new sets of experimental tools for the investigation of chemical transformations in NCs, above all the ability to monitor in real time these transformations; ii) developing solution-grown nanostructures able to undergo programmed transformations under a defined stimulus; iii) understanding the role of irradiation on the fate of surface ligands and on cation exchange reactions in NCs; iv) combining chemical, structural and surface transformations towards NC-based opto-electronics. The success of the proposal hinges on the proven capabilities of the PI, with ample support from the host Institution.","2430720","2014-03-01","2019-02-28"
"TRANSHOLOMORPHIC","New transversality techniques in holomorphic curve theories","Chris M WENDL","HUMBOLDT-UNIVERSITAET ZU BERLIN","""In the study of symplectic and contact manifolds, a decisive role has been played by the theory of pseudoholomorphic curves, introduced by Gromov in 1985.  One major drawback of this theory is the fundamental conflict between """"genericity"""" and """"symmetry"""", which for instance causes moduli spaces of holomorphic curves to be singular or have the wrong dimension whenever multiply covered curves are present.  Most traditional solutions to this problem involve abstract perturbations of the Cauchy-Riemann equation, but recently there has been progress in tackling the transversality problem more directly, leading in particular to a proof of the """"super-rigidity"""" conjecture on symplectic Calabi-Yau 6-manifolds.  The overriding goal of the proposed project is to unravel the full implications of these new transversality techniques for problems in symplectic topology and neighboring fields. Examples of applications to be explored include: (1) Understanding the symplectic field theory of unit cotangent bundles for manifolds with negative or nonpositive curvature, with applications to the nearby Lagrangian conjecture and dynamical questions in Riemannian geometry; (2) Developing a comprehensive bifurcation theory for Reeb orbits and holomorphic curves in symplectic cobordisms, leading e.g. to a proof that planar contact structures are """"quasiflexible""""; (3) Completing the analytical foundations of Hutchings's embedded contact homology (ECH), a 3-dimensional holomorphic curve theory with important applications to dynamics and symplectic embedding problems; (4) Developing new refinements of the Gromov-Witten invariants based on super-rigidity and bifurcation theory; (5) Defining higher-dimensional analogues of ECH; (6) Proving integrality relations in the setting of 6-dimensional symplectic cobordisms, analogous to the Gopakumar-Vafa formula for Calabi-Yau 3-folds.""","1624500","2018-09-01","2023-08-31"
"TRANSITION","""Large Deviations and Non Equilibrium Phase Transitions for Turbulent Flows, Climate, and the Solar System""","Freddy Bouchet","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","""The aim of this project is to predict and compute extremely rare but essential trajectories in complex physical systems. We will compute rare transitions trajectories, first between two different turbulent attractors in models of planetary jet dynamics, and second between two configurations of ocean currents for a model of the thermohaline circulation. We will compute the dynamics and the probability for collisions between two planets in the solar system, on time scales of order of billions of years. We will evaluate rare events that lead to extremely large drags or torques on objects embedded in turbulent flows, directly from the dynamics. Because of the huge range of time scales, all those trajectories are not accessible through direct numerical simulations.

The project's unity stems from the methodology based on large-deviations theory. Large deviation rate functions generalize the concept of entropy or free energy in non-equilibrium extended systems: they provide a global characterization of their most probable state, their large fluctuations and their phase transitions. Impressive explicit computations of large deviation rate functions have been recently performed in simple non-equilibrium systems. The main aim of this project is to bridge the gap between those extremely interesting new concepts and algorithms, and complex dynamical systems such as turbulent flows, semi-realistic models of fluids related to climate dynamics, or the long time behavior of the solar system.

In order to achieve this goal, we will use macroscopic fluctuation theory, instanton theory, and other analytical methods in order to compute explicitly large deviation rate functions for essential macroscopic quantities (the velocity or density fields). We will also develop and use algorithms specifically dedicated at computing the statistics of extremely rare trajectories, based on the generalization of importance sampling implemented through cloning or multilevel splitting methods.""","1178760","2014-03-01","2019-02-28"
"TransModal","Translating from Multiple Modalities into Text","Maria Lapata","THE UNIVERSITY OF EDINBURGH","Recent years have witnessed the development of a wide range of computational methods that process and generate natural language text.  Many of these have become familiar to mainstream computer users such as tools that retrieve documents matching a query, perform sentiment analysis, and translate between languages. Systems like Google Translate can instantly translate between any pair of over fifty human languages allowing users to read web content that wouldn't have otherwise been available. The accessibility of the web could be further enhanced with applications that translate within the same language, between different modalities, or different data formats.  There are currently no standard tools for simplifying language, e.g., for low-literacy readers or second language learners. The web is rife with non-linguistic data (e.g., databases, images, source code) that cannot be searched since most retrieval tools operate over textual data. In this project we maintain that in order to render electronic data more accessible to individuals and computers alike, new types of models need to be developed. Our proposal is to provide a unified framework for translating from comparable corpora, i.e., collections consisting of data in the same or different modalities that address the same topic without being direct translations of each other. We will develop general and scalable models that can solve different translation tasks and learn the necessary intermediate representations of the units involved in an unsupervised manner without extensive feature engineering. Thanks to recent advances in deep  learning, we will induce  representations for different modalities, their interactions, and correspondence to natural language. Beyond addressing a fundamental aspect of the translation problem, the proposed research will lead to novel internet-based applications that simplify and summarize text, produce documentation for source code, and meaningful descriptions for images.","1900778","2016-09-01","2021-08-31"
"TransPhorm","Single molecule imaging of transmembrane protein structure and function in their native state","Melissa Louise Mather","UNIVERSITY OF KEELE","TransPhorm will pioneer a transformative technology platform based on Nitrogen Vacancy (NV) magnetometry to enable the structure and function of transmembrane proteins (TMPs) to be studied in their native state with unprecedented sensitivity and resolution. TMPs reside in the membrane of biological cells and are critical to cellular function and communication. It is essential that TMPs are characterised in their native state as their structure and function is dependent on their interaction with the local environment. This is technically demanding and despite previous attempts using a multitude of complementary techniques no single method has provided a suitable solution. Here a breakthrough approach will be taken to demonstrate in situ TMP characterisation with single molecule sensitivity, nanoscale spatial resolution and millisecond measurement speed.

The concepts proposed in TransPhorm are distinct from current implementations of NV magnetometry for detection and mapping of weak magnetic fields originating from external nuclear spins. Here magnetic field mapping will be achieved using a totally new approach based on widefield, high speed structured illumination total internal reflection microscopy. The concepts TransPhorm are built on will also enable structural and functional single molecular characterisation with high specificity by exploiting the outstanding sensitivity to the local environment of fluorine-19 Nuclear Magnetic Resonance (NMR) reporters and the ion selectivity of sodium-23 and potassium-39 NMR spectroscopy. 

In short, TransPhorm will deliver a ground-breaking technology to far surpass current state-of-the-art techniques and provide the extreme sensitivity needed to understand the molecular scale dynamic changes that underpin TMP function. Overall the strategy and technologies proposed here will pave an untravelled path to the realisation of nanoscale NMR imaging and deliver tremendous scientific gains.","2434650","2016-09-01","2021-08-31"
"TriboKey","Deformation Mechanisms are the Key to Understanding and Tayloring Tribological Behaviour","Christian Greiner","KARLSRUHER INSTITUT FUER TECHNOLOGIE","Tribology, the science of interacting surfaces in relative motion, is crucial for many aspects of modern life. Friction and wear decisively impact the lifetime and durability of many products-from nanoelectromechanical systems to gears and engines. In the USA alone, an estimated 1E18 joules of energy could be saved each year through improved tribological practices.
During sliding of a metallic contact, a mutated surface layer forms, carries most further plastic deformation and largely determines friction and wear. The origin and evolution of this distinct subsurface layer remains elusive, since our knowledge of the elementary mechanisms promoting these changes is limited. Only this knowledge however will allow for a strategic tailoring of tribologically loaded metals.
In this project, we will elucidate these elementary mechanisms for a wide range of alloys and strain rates. We will develop ground-breaking new strategies for probing the subsurface microstructure during the tribological test itself with non-destructive testing sensors like ultrasound and eddy current, resulting in subsurface in situ tribology. The data from these sensors will be analysed online, during the tribological experiment, relying on cutting edge data science methods as they have already been applied for fatigue testing. Based on these analyses, implemented on a Field Programmable Gate Array, we will interrupt the test exactly when the dominating elementary mechanisms manifest themselves. These mechanisms will then be revealed by sophisticated electron microscopy and be visualized in deformation mechanism maps for unidirectional and reciprocating sliding. Such maps have proven very successful in other fields of materials science, e.g. creep at elevated temperatures. They are used to guide material selection and alloy development processes, yielding materials tailored for each specific tribological scenario, promising enormous savings in energy and resources, an important challenge of our time.","1985048","2018-09-01","2023-08-31"
"TRIFECTs","Trions and sp3-Defects in Single-walled Carbon Nanotubes for Optoelectronics","Jana ZAUMSEIL","RUPRECHT-KARLS-UNIVERSITAET HEIDELBERG","Semiconducting single-walled carbon nanotubes (SWNTs) combine solution-processability, large carrier mobilities, narrow emission linewidths and environmental stability for optoelectronic devices with light-emission in the near-infrared (800-1800 nm, e.g., for optical data communication and bio-imaging) when sorted by (n,m) species. The recent availability of highly pure, monochiral semiconducting SWNTs as bulk materials allows us to employ and further tailor their charge transport and light emission properties and thus enables their application in practical devices. Two new emissive species - charged excitons (trions) and bright sp3-defects - were recently discovered in SWNTs and have fundamentally changed our notions about SWNT luminescence. Both show red-shifted, narrow and enhanced emission. However, very little is yet known about their photophysical properties and especially their interactions with each other and their environment (e.g., in devices). Their emissive properties could potentially be tailored by external magnetic fields, dielectric environment and additional functional groups. Strong light-matter coupling in suitable optical cavities could be applied to create trion-polaritons in SWNTs as new low-mass charge carriers in polaritonic devices. Trions and emissive sp3-defects are not limited to SWNTs and hence these concepts could be transferred and applied to other low-dimensional semiconductors. 

The goals of this project are to
-  understand and use trions and trion-polaritons for light emission and polaritonic charge transport,
-  understand and tune the interactions of sp3-defects with charges and trions in SWNTs,
- modify and apply sp3-defects for enhanced light emission from SWNTs in optoelectronic devices,
-  explore trions in new low-dimensional materials (e.g., graphene nanoribbons and novel monolayered semiconductors).","1998500","2019-04-01","2024-03-31"
"TRITOS","TRansItions and Turbulence Of complex Suspensions","Luca Brandt","KUNGLIGA TEKNISKA HOEGSKOLAN","The aim of this project is to forge a physical understanding of the transitions and of the turbulent flow of semi-dilute/dense non-colloidal suspensions, for different particle features and suspending fluids.
It is estimated that 10% of the world energy consumption is due to the transport and handling of granular materials of which particle suspensions are an important part. A deep understanding of the mechanisms underlying the flow of particle suspensions, the transition to turbulence and the turbulence characteristics is crucial for many important practical applications involving engineered complex fluids, such as pastes and paper pulp. A better prediction and control of the flow of suspensions will therefore have a huge impact.
Complex fluids are multiscale by nature where the physics at the microscale affects the macroscopic behaviour of the flow and vice versa giving rise to surprising and spectacular phenomena as well as making this one of the most important practical problem still to solve. Investigating the mechanisms by which the system microstructure determines the macroscopic flow properties and vice versa will not only give valuable insights into the nature of flowing suspensions but also will also lead to new ways to model and control it. Future generations of engineering CFD tools will have to contain models for complex suspensions. The fundamental approach proposed here, combined with challenging scientific and engineering examples backed up by experimental evidence, will make this possible and demonstrate it to a wider engineering community. The proposed project is based on highly accurate simulations of multiphase flow systems and state-of-the-art experiments. Such a holistic approach will enable us to understand the underlying mechanisms of instabilities and suspension turbulence and to develop accurate criteria for their prediction far in advance of what we could achieve with either approach separately.","1998350","2014-04-01","2019-03-31"
"TryptoBoost","Boosting tryptophan fluorescence with optical nanoantennas to watch label-free protein dynamics with single molecule resolution at high concentration","jerome WENGER","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Proteins execute a broad range of functions that are central to life. Understanding these functions ultimately requires experiments at the single protein level to reveal dynamics and heterogeneities hidden in ensemble-averaged measurements. Currently, the preferred method to study single protein machineries is based on fluorescence techniques. However, fluorescence experiments suffer from major challenges: the need for external fluorescent labeling, weak signals and low non-physiological concentrations in the nanomolar range. These challenges severely limit the applicability and biological relevance of single molecule fluorescence on proteins. The TryptoBoost project aims to overcome all the previous challenges, and efficiently monitor single label-free proteins using their intrinsic tryptophan fluorescence enhanced by optical nanoantennas in the ultraviolet. Using the natural amino acid fluorescence rules out all drawbacks due to external labeling, while the optical nanoantennas enable single protein analysis at the physiologically relevant micromolar concentrations thanks to the localization and enhancement of light-matter interactions at the nanoscale. To demonstrate the power of this new technology, our interdisciplinary team will probe the important biological problems of amyloid aggregation and tumor suppressor p53 protein folding dynamics at high concentrations. The TryptoBoost approach is directly applicable to any protein containing aromatic amino acids. This condition is met by more than 90% of human proteins, so the project breakthroughs will benefit a broad range of biophysical, chemical, and medical applications. For instance, it will improve the development of therapeutic drugs, increase the detection sensitivity and read-out speed in analytical biosensing on chip, and provide new nanostructures to enhance ultraviolet photocatalysis.","1947208","2017-10-01","2022-09-30"
"TUgbOAT","Towards Unification of Algorithmic Tools","Piotr SANKOWSKI","UNIWERSYTET WARSZAWSKI","Over last 50 years, extensive algorithmic research gave rise to a plethora of fundamental results. These results equipped us with increasingly better solutions to a number of core problems. However, many of these solutions are incomparable. The main reason for that is the fact that many cutting-edge algorithmic results are very specialized in their applicability. Often, they are limited to particular parameter range or require different assumptions. 

A natural question arises: is it possible to get “one to rule them all” algorithm for some core problems such as matchings and maximum flow? In other words, can we unify our algorithms? That is, can we develop an algorithmic framework that enables us to combine a number of existing, only “conditionally” optimal, algorithms into a single all-around optimal solution? Such results would unify the landscape of algorithmic theory but would also greatly enhance the impact of these cutting-edge developments on the real world. After all, algorithms and data structures are the basic building blocks of every computer program. However, currently using cutting-edge algorithms in an optimal way requires extensive expertise and thorough understanding of both the underlying implementation and the characteristics of the input data. 

Hence, the need for such unified solutions seems to be critical from both theoretical and practical perspective. However, obtaining such algorithmic unification poses serious theoretical challenges. We believe that some of the recent advances in algorithms provide us with an opportunity to make serious progress towards solving these challenges in the context of several fundamental algorithmic problems. This project should be seen as the start of such a systematic study of unification of algorithmic tools with the aim to remove the need to “under the hood” while still guaranteeing an optimal performance independently of the particular usage case.","1510800","2018-09-01","2023-08-31"
"TUNEMEM","Externally Tuneable Separations for Membrane Reactors","Darrell Alec Patterson","UNIVERSITY OF BATH","I will develop an all new type of reactor for pharmaceutical and chemical process applications – the ‘tuneable membrane reactor’. These contain ground-breaking conducting polymer composite membranes that will allow in-situ tuning of the molecular selectivity for both neutral and charged species through them. This is revolutionary: current state-of-the-art membranes can be electrically tuned for charged species only. The project is timely, developing a new technology that can give the EU a competitive advantage for our declining pharmaceutical and (petro)chemical manufacturing base and builds on my recent research innovations.

To do this, my team of 3 PDRAs, 3 PhDs and I will develop unique stable polymer-polymer acid-nanoparticle composite membranes that can be externally electrically tuned to different pore sizes and/or molecular selectivity, uniquely tuning for neutral and charged species. We will characterise the chemical, physical and transport mechanisms responsible for the membrane tuneablity and relate these to transport models. We will then determine the feasibility of applying these unique tuneable membranes into membrane reactors, to allow in-situ external control of two key reactor parameters currently not possible: (1) Membrane fouling - membrane pore size/free volume and charge will be changed by applied potential allowing the fouling layer to be pushed off/through the membrane. (2) Precise external control of the reactant and product spectrum in the reactor by modifying species retention. By doing this, these tuneable membranes can be used to control the reaction rate, emissions and catalyst retention to maximise reaction rate and selectivity. This increases energy efficiency and emission control, helping the EU 20-20-20 environmental targets to be met. The overall impact applies beyond the project – we will be able to increase the control of membrane separations used worldwide, helping industries including food, water, healthcare and chemicals.","789824","2015-08-01","2018-02-28"
"TUNNELCHEM","Atom-Tunneling in Chemistry","Johannes Kästner","UNIVERSITAET STUTTGART","Quantum mechanical tunneling of atoms is emerging as an ubiquitous phenomenon in chemistry. Every chemical reaction that includes a hydrogen transfer can be expected to be influenced by tunneling at room temperature. While simulations can monitor tunneling directly, experimental approaches can only detect the consequences. Theoretical investigations, as planned in TUNNELCHEM, have to keep up in order to aid the rational interpretation. We build on significant algorithmic breakthroughs recently achieved in the applicant's group, which allow accurate predictions of tunneling rates in larger systems than previously possible. These possibilities are to be exploited, which requires a big, combined project that can afford high-risk components.

In TUNNELCHEM, we will investigate aspects of tunneling in several different areas of chemistry: biochemistry, astrochemistry, catalysis and algorithmic development. The investigation of tunneling contributions to enzymatic reactions will allow to plan modifications which increase the selectivity and efficiency. Several astrochemical processes can only be understood if their tunneling contributions are properly accounted for. Accurate tunneling rates will significantly improve the predictive power of models of the interstellar medium. Many processes in homogenous and heterogenous catalysis involve tunneling. A fundamental understanding of the principles involved allows for the design of improved catalysts. Further development of methods and algorithms in accordance with the demands of the applications is required. TUNNELCHEM will shift the present paradigm from descriptive investigations to a rational design of catalysts enabled by a mechanistic understanding of atom tunneling processes.

Only such a combined effort may allow us to understand the principles of tunneling in chemistry and to develop concepts to exploit the tunnel effect for optimizing reactivity and selectivity of chemical reactions in biochemistry and catalysis.","1986750","2015-07-01","2020-06-30"
"TUSUPO","Tubular Supramolecular Polymers: A new class of therapeutic polymers","Sebastien Perrier","THE UNIVERSITY OF WARWICK","This research programme will establish a new class of materials and develop them into functional devices for biomedical applications. We will design tubular supramolecular polymers, supramolecular polymer brushes (SPBs), based on the self-assembly of cyclic peptide – polymer conjugates.  The synergy between the cyclic peptide, which directs the formation of the SPBs and the polymer conjugate, which provides functionality, will open the route to a wealth of new functional structures.  We will build on our initial work and expand our research to generate new synthetic routes for the ligation of polymers to peptides, develop new protocols for the characterisation of the materials, and establish the mechanism of supramolecular polymerisation. This research programme will open new horizons in the fundamental understanding and production of supramolecular polymers. In particular, beyond the generation of new materials, the functionality of these systems may allow the development of supramolecular living polymers, a long-standing goal in polymer chemistry that is still elusive. The functionality and versatility of the SPBs obtained in this work open the route to a wealth of applications, and we will focus on one specific target: the fabrication of drug delivery vectors. We will exploit the unique combination of features presented by this new class of polymer therapeutics, such as multiple attachment points for one or more drug(s) / targeting ligands / markers, the ability to self-disassemble into smaller and easy-to-excrete components, and an elongated shape that enables diffusion and interaction with cells more efficiently than traditional globular delivery systems. We will study the pharmacology properties of the SPBs, including their stability, toxicity, mode of cell penetration and ability to deliver a single or a combination of bioactive agent(s) (in the case of concerted mechanisms).","1692376","2015-07-01","2020-06-30"
"TUVOLU","Tundra biogenic volatile emissions in the 21st century","Riikka Tiivi Mariisa Rinnan","KOBENHAVNS UNIVERSITET","Biogenic volatile organic compounds (BVOCs) influence atmospheric oxidation causing climate feedback thought to be especially significant in remote areas with low anthropogenic emissions, such as the Arctic. Still, we do not understand the dynamics and impact of climatic and biotic BVOC emission drivers in arctic and alpine tundra, which are highly temperature-sensitive BVOC sources.
TUVOLU will redefine tundra BVOC emission estimates to account for rapid and dramatic climate warming accompanied by effects of vegetation change, permafrost thaw, insect outbreaks and herbivory using multidisciplinary, established and novel methodology.
We will quantify the relationships between leaf and canopy temperatures and BVOC emissions to improve BVOC emission model predictions of emission rates in low-statured tundra vegetation, which efficiently heats up. We will experimentally determine the contribution of induced BVOC emissions from insect herbivory in the warming Arctic by field manipulation experiments addressing basal herbivory and insect outbreaks and by stable isotope labelling to identify sources of the induced emission. Complementary laboratory assessment will determine if permafrost thaw leads to significant BVOC emissions from thawing processes and newly available soil processes, or if released BVOCs are largely taken up by soil microbes. We will also use a global network of existing climate warming experiments in alpine tundra to assess how the BVOC emissions from tundra vegetation world-wide respond to climate change.
Measurement data will help develop and parameterize BVOC emission models to produce holistic enhanced predictions for global tundra emissions. Finally, modelling will be used to estimate emission impact on tropospheric ozone concentrations and secondary organic aerosol levels, producing the first assessment of arctic BVOC-mediated feedback on regional air quality and climate.","2347668","2018-04-01","2023-03-31"
"UCHEM","Frontier Non-Aqueous Uranium Chemistry: Structure, Bonding, Reactivity, and Nanomagnetism","Stephen Taylor Liddle","THE UNIVERSITY OF MANCHESTER","The Applicant has an outstanding track record of achievement and an international reputation for independent research in non-aqueous uranium chemistry. This high-impact, challenging CoG Proposal integrates four innovative ideas in uranium chemistry into a single overarching inter-/multi-disciplinary project to open up new horizons across molecular, catalysis, materials, magnetism and energy research. The Applicant’s ERC StG has been very successful and opened new doors to several new avenues of pioneering research that were not even conceivable before the work was done. This work extends out from the knowledge achievements of the StG into new, exciting research areas that are completely different. This is a strategically vital to understand yet poorly developed area due to legacy nuclear waste. This project will deliver innovation through studying: (i) uranium-nitrogen triple bonds as benchmarks for uranium bonding and for generating new small molecule activation and materials applications; (ii) homologation of CO to close the carbon cycle and sustainably remove reliance on dwindling oil; (iii) single molecule magnets that have applications in data storage, quantum computing, spintronics; (iv) uranium-metal bonds which act as exemplars for intermetalloids and bonding. This CoG will afford the freedom and impetus via consolidated funding to undertake fundamental, speculative research to deliver ‘big-hits’, whole new fields of actinide chemistry, and, based on this higher platform of understanding, new ways of thinking. This will induce previously impossible paradigm shifts in uranium chemistry and be included in future textbooks. This project addresses priority subjects in FP7 and the ERC, and, via an extensive network of international academic and industrial collaborations, will consolidate the PI’s team in an exciting, curiosity-driven environment, reverse a strategic skills shortage, and deliver high calibre, cross-disciplinary scientists for the EU.","2122596","2014-10-01","2019-09-30"
"UFLNMR","Ultrafast Laplace NMR","Ville-Veikko TELKKI","OULUN YLIOPISTO","Laplace NMR (LNMR), comprising diffusion and relaxation NMR experiments, provides detailed information on the dynamics and chemical resolution of molecular systems, which is complementary to NMR spectra. Similarly to the traditional NMR spectroscopy, the information content of LNMR can be significantly enhanced by a multidimensional approach. The long experiment time and low sensitivity restrict the applicability of the multidimensional method, however. Based on spatial encoding of multidimensional data, we develop a broad range of single-scan LNMR experiments, constituting a new class of NMR experiments called ultrafast multidimensional LNMR. The method shortens the experiment time by one to three orders of magnitude as compared to the conventional method, offering unprecedented opportunity to study fast processes in real time. Furthermore, it enables boosting the sensitivity by several orders of magnitude by using nuclear spin hyperpolarization, which allows investigation of low-concentration samples. Ultrafast LNMR opens paradigm-breaking prospects in chemical, biochemical, geologic, archaeologic and medical analysis. LNMR can, e.g., provide unique information on the intra- and extracellular metabolic processes, including those of cancer cells, which facilitates diagnostics and helps to find efficient treatments, and it can be exploited in the development of new types of biosensors. Furthermore, the method reveals previously unobservable details about the phase behaviour of ionic liquids, gel and polymer formation, as well as catalysis, which are essential in understanding their performance in technological applications. LNMR is also applicable to portable, single-sided magnets, implying potential to raise the sensitivity of low-field NMR to a completely new level. This entails significant impact on mobile chemical and medical analysis. The low cost of the low-field facility renders advanced NMR analysis broadly available, even in developing countries.","2625000","2018-04-01","2023-03-31"
"ULT-MAS-DNP","Dynamic Nuclear Polarization at ultra-fast sample spinning and ultra-low temperature","Gaël De Paëpe","COMMISSARIAT A L ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","The goal of the project is to develop a new hyperpolarization approach called Magic Angle Spinning Dynamic Nuclear Polarization (MAS-DNP) to reach levels of sensitivity and resolution that have never been achieved, in order to tackle highly relevant chemical and biological questions that remain unanswered so far. Firstly this will provide major advances in NMR crystallography (solving 3D structures by NMR) by showing that distance measurements between nuclei (13C, 15N, etc.) as well as 17O quadrupolar parameters can be extracted from NMR measurements without requiring isotopic labeling. This will be applied to systems that cannot be easily isotopically enriched and for which X-ray analysis is often not suitable. Secondly we propose an innovative strategy to hyperpolarize nuclear spins using MAS-DNP: rather than polarizing the entire system uniformly, we will selectively “light up” regions where we wish to gather important structural information. This will be developed to study protein-ligand interactions (with unprecedented resolution) to answer specific structural questions and potentially impact the field of drug engineering. Finally we will show that the unique experimental setup developed in this project will open up NMR to the routine study of “exotic”, yet ubiquitous and highly informative, nuclei such as 43Ca and 67Zn. Specifically, we will show that MAS-DNP can become a choice technique for the study of diamagnetic metal binding sites, complementing EPR for the study of metalloproteins. These goals will be achieved thanks to the development of original methods and advanced instrumentation, allowing sustainable access to low temperatures (down to 10-20 K) and fast pneumatic sample spinning, under microwave irradiation. We expect to improve the current sensitivity to such an extent that 4 orders of magnitude of experimental timesavings are obtained, resulting in completely new research directions and regimes.","1999805","2016-07-01","2021-06-30"
"ULT-NEMS","Ultra-Cold Nano-Mechanics: from Classical to Quantum Complexity","Eddy Charles Eric Collin","CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE CNRS","Nano-electro-mechanical devices (NEMS) are extremely small objects that can be actuated and detected by electric means. They are in the first place transducers that can be used as probes for forces down to the molecular level. Top-down fabricated NEMS using conventional microelectronics techniques are simple devices that intimately link mechanical and electrical degrees of freedom. As such, they can be viewed as model systems from basic (linear) harmonic motion up to complex nonlinear dynamics.

The most intriguing experimental situation is attained when the devices are cold enough to behave according to the laws of quantum mechanics, instead of classical physics. This leads to a unique approach of the classical-to-quantum crossover with truly macroscopic position-states. Complementarily, at low temperatures the forces sensed by the NEMS arise from materials themselves cold enough to exhibit exotic quantum properties, originating either in the devices’ constitutive amorphous materials and their intrinsic elusive Tunneling Systems, or from their interaction with a sophisticated fluid like superfluid 3He.

I propose unique research linking ultra-low temperature physics and nano-mechanics, building on my knowledge of both fields and my experience in superconducting quantum circuits. The research has two identified axes, which aim at pushing both the “sensor” and “model system” aspects of NEMS down to their quantum retrenchments. Macroscopic quantum position-states can be engineered with a hybrid quantum circuit arrangement (a combination of NEMS, microwaves and quantum bit), while topological states of confined superfluid 3He with their elementary excitations can be mechanically probed by dedicated NEMS (measuring friction). The scientific impact of this research is extremely wide, tackling fundamental questions like: what/where is the boundary between quantum and classical worlds, and do Majorana particles (potentially obtained in topological 3He) exist at all?","1990574","2015-11-01","2020-10-31"
"ULTIMATE","Towards the ultimate dark matter detector","Marc Tobias SCHUMANN","ALBERT-LUDWIGS-UNIVERSITAET FREIBURG","Dark matter is a major component of the Universe, outnumbering ordinary baryonic matter by a factor 5. As it has not yet been observed, its detection and subsequent characterization is one of the most important goals in particle physics. ULTIMATE will be the first project world-wide that focuses entirely on cutting-edge research towards the ultimate detector. Using a low-background time projection chamber (TPC) filled with ~40t of liquid xenon (LXe), this instrument will search for
Galactic dark matter in the form of Weakly Interacting Massive Particles (WIMPs). It will probe the entire experimentally accessible parameter space above masses of a few GeV/c², which is eventually limited by irreducible neutrino backgrounds. If dark matter will be detected by the next-generation experiments, the ultimate detector will deliver a high statistics WIMP sample to study its properties.

To eventually propose and build this detector, which will be also sensitive to many non-WIMP science channels, various fundamental experimental challenges need to be solved now. These include a significant reduction of radioactive backgrounds, which would seriously limit the instrument's sensitivity, and structural aspects related to the TPC size of ~2.5m. ULTIMATE will tackle both, following several orthogonal strategies: Two novel TPC concepts will be developed and
operated in LXe for the first time, to reduce background from 222Rn (hermetic TPC) and to optimize background rejection (single-phase TPC). Background neutrons and 222Rn emanation from the important material PTFE will be minimized by the identification of radio-pure PTFE, a systematic study of surface treatments, and by building a full-scale TPC mockup.
Such prototype has not been constructed before and will enable detailed design, construction and assembly studies of a TPC with minimal material budget. The combination of all strategies explored in ULTIMATE will represent an optimal concept for the ultimate WIMP detector's TPC.","1982938","2017-05-01","2022-04-30"
"ULTRA","Increasing the Spatial Correlation of Logical Units of Data to Enable an Ultra-Low Latency Internet","Dejan Manojlo KOSTIC","KUNGLIGA TEKNISKA HOEGSKOLAN","The cloud computing infrastructure that logically centralizes data storage and computation for many different actors is a prime example of a key societal system. A number of time-critical applications deployed in the cloud infrastructure have to provide high reliability and throughput, along with guaranteed low latency for delivering data. This low latency guarantee is sorely lacking today, with the so-called tail-latency of slowest responses in popular cloud services being several orders of magnitude longer than the median response times. Unfortunately, simply using a network with ample bandwidth does not guarantee low latency because of problems with congestion at the intra-and inter-data center levels and server overloads. All of these problems currently render the existing cloud infrastructures unsuitable for time-critical societal applications. The reasons for unpredictable delays across the Internet and within the cloud infrastructure are numerous, but some of the key culprits are: 1) slow memory subsystems limit server effectiveness, and 2) excess buffering in the Internet further limits correlation of data requests.

The aim of this project is to dramatically change the way data flows across the Internet, such that it is more highly correlated when it is to be processed at the servers. The overarching goal is to enforce a large degree of correlation in the data requests (logical units of data), both temporally (across time) and spatially (as server work units require correlation to achieve high cache hit rates). The result is that the logical units of data will be processed at almost the maximum processing speed of the cloud servers. By doing so, we will achieve an ultra-low latency Internet. This project will produce the tools and knowledge that will be key to dramatically reducing the latency of key societal services; these include cloud services used by a large number of users on a daily basis.","2000000","2018-06-01","2023-05-31"
"ULTRA-SOFC","Breaking the temperature limits of Solid Oxide Fuel Cells: Towards a newfamily of ultra-thin portable power sources","Alberto Tarancón Rubio","FUNDACIO INSTITUT DE RECERCA DE L'ENERGIA DE CATALUNYA","Solid Oxide Fuel Cells (SOFCs) are one of the most efficient and fuel flexible power generators. However, a great limitation on their applicability arises from temperature restrictions. Operation approaching room temperature (RT) is forbidden by the limited performance of known electrolytes and cathodes while typical high temperatures (HT) avoid their implementation in portable applications where quick start ups with low energy consumption are required.    

The ULTRASOFC project aims breaking these historical limits by taking advantage of the tremendous opportunities arising from novel fields in the domain of the nanoscale (nanoionics or nano photochemistry) and recent advances in the marriage between micro and nanotechnologies. From the required interdisciplinary approach, the ULTRASOFC project addresses materials challenges to (i) reduce the operation to RT and (ii) technological gaps to develop ultra-low-thermal mass structures able to reach high T with extremely low consumption and immediate start up.
 
A unique μSOFC technology fully integrated in ultrathin silicon will be developed to allow operation with hydrogen at room temperature and based on hydrocarbons at high temperature. Stacking these μSOFCs will bring a new family of ultrathin power sources able to provide 100 mW at RT and 5W at high T in a size of a one-cent coin. A stand-alone device fuelled with methane at HT will be fabricated in the size of a dice.

Apart from breaking the state-of-the-art of power portable generation, the ULTRASOFC project will cover the gap of knowledge existing for the migration of high T electrochemical devices to room temperature and MEMS to high T. Therefore, one should expect that ULTRASOFC will open up new horizons and opportunities for research in adjacent fields like electrochemical transducers or chemical sensors. Furthermore, new technological perspectives of integration of unconventional materials will allow exploring unknown devices and practical applications.","1841387","2016-04-01","2021-03-31"
"UNBICAT","Unconventional Bifunctional Catalysts","Jose Julian Aleman Lara","UNIVERSIDAD AUTONOMA DE MADRID","The development of sustainable chemical processes is one of the most important features in modern chemistry. It has become a key research area worldwide providing solutions to important societal demands by optimizing the use of natural resources and minimizing waste and environmental impact. Among the relevant methods for achieving this goal, catalysis represents a key and central approach. Both Organocatalysis and Metal Catalysis have emerged as solutions to the problems in this context. In this field, the progress of a novel bifunctional organocatalyst that could increase the number of different activations, and therefore the synthesis of valuable enantio-enriched molecules, would be highly desirable. Especially important, but still unknown, are the bifunctional-catalysts based on a Neutral Coordinate Organocatalyst and Photo-Organocatalysts. This proposal aims to develop two new unconventional approaches for the synthesis of bifunctional organocatalysts.
	The first one is based on the development of new Bifunctional Neutral Coordinate Organocatalyst and their application to the synthesis of biologically relevant compounds. I propose to use these bifunctional catalysts to promote the dual activation of silyl reagents and suitable electrophiles. This approach constitutes an unconventional way to synthesize asymmetric molecules and has no precedent in the literature.
	The second section of this proposal explores the photo-activation-bifunctional organocatalyst. I propose the design and application of new metal-free Bifunctional Photo-Organocatalysts which are able to chemically and photo-activate the substrate simultaneously in an asymmetric manner. 
	This project has the potential to change the general view of asymmetric Neutral Coordinate Organocatalyst and Photo-catalysis as we know it today. These unconventional bifunctional would be incorporated into the privileged catalyst library for its applications in new asymmetric transformations.","1987750","2015-09-01","2020-08-31"
"UNEARTH","Uranium isotope fractionation: a novel biosignature to identify microbial metabolism on early Earth","Rizlan BERNIER-LATMANI","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Prokaryotes (archaea and bacteria) are the most abundant form of life both at present and throughout paleohistory and exhibit exquisite metabolic diversity, unmatched by eukaryotes. On early Earth, the absence of atmospheric oxygen led to the emergence of anaerobic microbial metabolisms such as methanogenesis, sulfate reduction, iron reduction, and denitrification. Non-isotope and isotope tools used to study ancient microbial life have provided evidence for each of these types of metabolisms in the rock record. However, there remains much uncertainty and debate regarding this evidence, primarily because of confounding effects of abiotic processes, and ambiguity in interpretation of isotopic signatures. 
This proposal aims to develop a robust biosignature for microbially mediated reduction reactions, that, in conjunction with existing tools, provides insight into ancient microbial activity in the rock record and establishes temporal constraints on the emergence of specific metabolic groups. 
To this end, I propose to use uranium (U) as an isotopic biosignature for microbial life. This pursuit is driven by recent work in my laboratory that has revealed a readily resolved difference between the isotopic signatures of enzymatically reduced uranium and abiotically reduced uranium. Combined with the ability of most microbial metabolic groups to catalyze U reduction, this finding raises the tantalizing possibility that uranium isotopic fractionation could serve as a biosignature for specific metabolic groups in the rock record. 
The establishment of a robust, bulk universal isotopic biosignature would be valuable to paleontologists, astrobiologists, and geologists because it would provide direct insight into the timing of emergence of specific metabolisms in ancient sedimentary environments on Earth.","1998971","2017-09-01","2022-08-31"
"UniCoSM","Universality in Condensed Matter and Statistical Mechanics","Alessandro GIULIANI","UNIVERSITA DEGLI STUDI ROMA TRE","Universality is a central concept in several branches of mathematics and physics. In the broad context of statistical mechanics and condensed matter, it refers to the independence of certain key observables from the microscopic details of the system. Remarkable examples of this phenomenon are: the universality of the scaling theory at a second order phase transition, at a quantum critical point, or in a phase with broken continuous symmetry; the quantization of the conductivity in interacting or disordered quantum many-body systems; the equivalence between bulk and edge transport coefficients. Notwithstanding the striking evidence for the validity of the universality hypothesis in these and many other settings, a fundamental understanding of these phenomena is still lacking, particularly in the case of interacting systems. 

This project will investigate several key problems, representative of different instances of universality. It will develop along three inter-connected research lines: scaling limits in Ising and dimer models, quantum transport in interacting Fermi systems, continuous symmetry breaking in spin systems and in models for pattern formation or nematic order. Progresses on these problems will come from an effective combination of the complementary techniques that are currently used in the mathematical theory of universality, such as: constructive renormalization group, reflection positivity, functional inequalities, discrete harmonic analysis, rigidity estimates. We will pay particular attention to the study of some poorly understood aspects of the theory, such as the role of boundary corrections, the loss of translational invariance in multiscale analysis, and the phenomenon of continuous non-abelian symmetry breaking. The final goal of the project is the development of new tools for the mathematical analysis of strongly interacting systems. Its impact will be an improved fundamental understanding of universality phenomena in condensed matter.","1235875","2017-03-01","2022-02-28"
"UniSDyn","Building up a Unified Theory of Stellar Dynamos","Maarit KÄPYLÄ","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","Magnetic fields are ubiquitous in the universe. The special property of cosmic magnetism is that, in the majority of objects hosting magnetic fields, those fields are organized, such that some meaningful averaging can reveal global structure and systematic behavior. In the Sun, averaging over longitude reveals the equatorward migration of the emergence region of the sunspots, forming the famous butterfly diagram. Further, vigorous turbulence is present in a wide variety of astrophysical systems, and yet they still exhibit organized magnetic fields. These observations prompt the search for a theory to explain how order can arise and sustain itself in such chaos. We claim that the available theories are incomplete, especially in the case of solar-like stars which becomes apparent if we view the Sun as one star among many. We propose a coherent plan of advancement in which each theory shall be tested by requiring it also to explain the cyclic dynamo action seen in more active rapid rotators.

UNISDYN project attacks these very problems with novel simulations and data analysis tools. Our path to resolve them is to enhance the state-of-the-art stellar dynamo models with the relevant descriptions of the turbulent processes. This goal is reached in three steps. (i) We will produce improved convection dynamo simulations to serve as laboratories from which (ii) the turbulent transport coefficients are directly measured with a novel test methods suite. (iii) Finally, global dynamo models incorporating the turbulent effects in full are constructed based on (i) and (ii)  results. These results will allow us to unify stellar dynamo theory for solar-like inactive and rapidly rotating active stars. The developed toolbox has direct applications in other fields of astrophysics, such as accretion and galactic disk dynamos, and industry, such as combustion engines and fusion reactors.","1964688","2019-05-01","2024-04-30"
"UpFermi","Unconventional pairing in ultracold Fermi gases","Michael Karl Köhl","RHEINISCHE FRIEDRICH-WILHELMS-UNIVERSITAT BONN","We explore unconventional ways how ultracold fermions pair and form collective quantum phases exhibiting long-range order, such as superfluidity and magnetically order. Specifically, we plan to realize and study pairing with orbital angular momentum and pairing induced by long-range interaction. Besides the fundamental interest in unravelling unconventional pairing mechanisms and the interplay between superfluidity and quantum magnetism, our project will also lead to gaining experimental control over topologically protected quantum states. This will pave the way for future topological quantum computers, which are particularly robust to environmental decoherence.
Our project addresses three different aspects: (1) We plan to realize p-wave superfluids in two dimensions. This quantum phase exhibits topological excitations (vortices) with anyonic statistics and an isomorphism to the fractional quantum-Hall effect. We will investigate the unusual properties of p-wave superfluids, such as Majorana fermions, i.e. quasiparticles being their own anti-particles, which are predicted to be localized at vortices. This will boost the long-standing efforts in the cold atoms and condensed matter communities to understand topological states of matter. (2) We aim to realize d-wave pairing in optical lattices using a novel experimental approach. d-wave pairing is closely related to high-Tc superconductivity in the cuprates and we are interested in exploring its interplay with magnetic order. Superfluidity and magnetic order are antagonistic phenomena from a conventional BCS-theory point-of-view and hence several fundamental questions will be answered. (3) We plan to induce long-range interactions using a high-finesse optical cavity leading to a light-induced pairing mechanism. We will search for Cooper pairing in spin-polarized Fermi gases mediated by the interaction of Fermions with a quantized light field. This provides access to a new class of combined light-matter quantum states.","1925525","2014-10-01","2019-09-30"
"UpTEMPO","Ultrafast tunneling microscopy by optical field control of quantum currents","Daniele BRIDA","UNIVERSITE DU LUXEMBOURG","The project aims at imaging electronic dynamics in molecules with atomic precision and sub-femtosecond temporal resolution. This result will be achieved by establishing new experiments at the boundary of ultrafast optics and scanning probe microscopy where the electric field of single-cycle light pulses is harnessed to control currents in nanojunctions. The basic concept relies on the fact that state-of-the-art femtosecond optical wave packets exhibit only one cycle of radiation with a defined electric field maximum. These pulses need to be phase locked to a “cosine-like” electric field profile. If such radiation is focused onto a junction with a nonlinear current-voltage characteristics, a net charge flow results solely due to the bias induced by the optical field. 
In detail, we want to exploit the time resolution provided by this new technique and induce electron transport at the probe tip of a scanning tunneling microscope (STM). The optical control of the current over a sub-optical-cycle interval will guarantee a temporal resolution better that one femtosecond, thus improving by several orders of magnitude what can be achieved with standard electronic bias. 
The core of the experimental system will be an ultrabroadband and passively phase-locked Er:fiber laser that is designed to generate single-cycle optical pulses in the near/mid-infrared, i.e. off resonant to the transition energies of III-V and II-VI semiconductors and large molecules. This laser will operate at 80-MHz repetition rate for enhanced sensitivity and stability when coupled to an ultra-high-vacuum STM. The setup will allow for the direct combination of independent pulse trains to resonantly excite few-femtosecond dynamics and then probe the electron density via the optically driven tunneling. In this pump-probe scheme it will be possible to map with atomic resolution the coherent evolution of electronic wavefunctions that in molecules and nanosystems follows an impulsive photoexcitation.","1999509","2019-09-01","2024-08-31"
"UQMSI","Uncertainty Quantification and Modern Statistical Inference","Richard Nickl","THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE","Some of the most important and exciting challenges of our ‘information age’ have led to the development of novel statistical methodology and algorithms that are designed to deal with inference settings involving high-dimensionality, graphical and network structures, inverse problems, ‘big data’, stochastic differential equations, diffusion processes, cosmic microwave background maps, brain tomography etc. 
While an abundance of algorithms is now available, a scientifically rigorous theory of uncertainty quantification and statistical decision making for such procedures has not been developed yet. Traditional approaches such as maximum likelihood estimation or parametric Bayesian inference cannot be used naively in increasingly complex contemporary statistical models. The construction of confidence statements and critical values for significant hypothesis tests is, however, of crucial importance for all applications of the statistical sciences to the modern world. 
In this research we propose an objective, mathematically rigorous, and practical paradigm for uncertainty quantification in modern statistical inference problems, and illustrate how this approach can be used in some of the recently emerged areas of statistics. Our theory can validate both Bayesian and frequentist approaches to statistical inference, and can be expected to be optimal in an information-theoretic sense. It has potential impact on all areas of scientific theory building, on legal and medical practice, public management of the internet, modern media and other information structures, and also on the foundations of the mathematical discipline of statistics in itself.","1733767","2015-09-01","2020-08-31"
"UTOPES","Unifying concepts in the topological design of non-crystalline materials","Lothar Wondraczek","FRIEDRICH-SCHILLER-UNIVERSITAT JENA","Glasses have traditionally been enabling materials to major societal challenges. Significant breakthroughs on many areas of technological progress have been very closely linked to the exploitation of glassy materials. It is strong consensus that this key role will persist in the emerging solutions to major global challenges in living, energy, health, transport and information processing, provided that the fundamental limitations of the presently available empirical or semi-empirical approaches to glass processing can be overcome.
In the coming decade, it is therefore a major task to take the step towards ab initio exploitation of disordered materials through highly-adapted processing strategies. This requires pioneering work and in-depth conceptual developments which combine compositional design, structural evolution and the thermo-kinetics of material deposition into holistic tools. Only those would significantly contribute to solving some of the most urgent materials needs for glass applications in functional devices, be it in the form of thin films, particles or bulk materials. 
The present project challenges today’s engineering concepts towards the conception of such tools. For that, melt deposition, isothermal deposition from liquid phases, and gas-phase deposition of non-crystalline materials will be treated - within the class of inorganic glasses - in a generalist approach, unified by the understanding that glass formation represents the only strict deviation from self-organization, and that, hence, the evolution of structural complexity in glassy materials can be tailored on any length-scale through adequate processing. Providing a topological scheme for the quantification and chemical tailoring of structural complexity, UTOPES will answer to the challenge of finding order in disorder, and will thus break the grounds for the third generation of glasses with properties beyond what is presently thought as the limits of physical engineering.","1965917","2016-09-01","2021-08-31"
"UTOPEST","Unified Theory of Efficient Optimization and Estimation","David Steurer","EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH","The goal of this project is to make progress toward a unified theory of efficient
optimization and estimation. In many computing applications, especially machine learning,
optimization and estimation problems play an increasingly important role. For that reason, a large
research effort is devoted to developing and understanding the limitations of efficient algorithms
for these problems. For many of these problems, achieving the best known provable guarantees
required the use of algorithms that are tailored to problem specifics. In recent years, the PI’s
research with collaborators has shown that for many optimization problems, the conceptually
simple sum-of-squares meta-algorithm, despite not being tailored to problem specifics, can match
and often significantly outperform previous efficient algorithms in terms of provable guarantees.

This project aims to better understand the capabilities and limitations of this meta-algorithm,
especially for estimation problems, which have only recently begun to be studied in this light.
In this way, the project will establish new algorithmic guarantees for basic optimization and
estimation problems even in the face of non-convexity and adversarial outliers. In the same way,
the project will shed light on the limitations of efficient algorithms for basic average-case problems
like planted clique and stochastic block models.

The project also aims to transfer the obtained theoretical insights into practical algorithms
building on recent works by the PI and collaborators. Toward this goal the project will develop
new algorithms with close to linear running times that match the guarantees of the best known
polynomial-time algorithms. In order to assess their practicality, the project will perform systematic
empirical evaluations of these algorithms.","1993320","2019-03-01","2024-02-29"
"V-ECHO","Revealing hidden volcanic triggers for global environmental change events in Earth’s geological past using mercury (Hg)","Tamsin Mather","THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD","Rapid global change events such as mass extinctions punctuate Earth’s geological history. These have driven life’s evolution, shaping the world today. However, the exact processes that trigger or modulate them remain enigmatic. Episodes of large-scale volcanism, namely large igneous provinces (LIPs), are a prime contender. A major obstacle to unravelling the role of LIPs in rapid global change has been lack of a direct/unique proxy for volcanism in the sediments that record events. Without one, determining LIP occurrence and exact temporal relations is challenging, especially where the rock record of LIPs is incomplete. Recent studies have revealed the huge promise of mercury (Hg) as a marker of large-scale volcanism. However, while Hg-record acquisition is gaining pace, we still lack the vital process understanding of the proxy needed to realize its full potential. V-ECHO will test the overarching hypothesis: widespread mercury ‘spikes’ in the geological record are definitive evidence of LIP volcanism even in the absence of coeval lavas.

V-ECHO will take an integrated and interdisciplinary approach to develop a process understanding of LIP perturbations to the global Hg cycle and how these translate into sedimentary records. It will address key questions on Hg sources (emission from magmas or thermal metamorphism of intruded rocks) and sinks (deposition pathways and sedimentary preservation). It will combine new measurements with novel experimental techniques and explore key differences in the global Hg cycle deep in Earth’s past. V-ECHO will test whether we can ‘sniff out’ the sedimentary echoes of lost LIPs, especially in the Palaeozoic and Neoproterozoic where the LIP record becomes ever sparser. It will explore proposed volcanic triggers for major Earth change events (e.g., oceanic anoxic events, ‘snowball Earths’) in unprecedented ways. 

V-ECHO promises a step-change in understanding of environmental impacts of LIP volcanism throughout Earth history.","1999599","2019-06-01","2024-05-31"
"Valleys","Valley and spin devices based on two-dimensional semiconductors","Andras Kis","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","The main objective of this research proposal is to realize new types of electronic devices based on the valley/spin degree of freedom in two-dimensional semiconductors from the transition metal dichalcogenide family. These materials are analogous to graphene but have a direct band gap. Together with the unique band structure, this allows manipulating the spin and valley degrees of freedom interchangeably. In addition, it can give rise to a mechanism for protecting the spin which could in future result in very high spin relaxation lengths. This proposal will explore various spin/valley injection mechanisms as well as detection mechanisms with the goal of realizing an all-electric valleytronic device with no need of optical excitation which is bulky and difficult to scale and implement on chip scale. Various new device architectures such as valley interconnects, amplifiers and diodes will be realized in the central part of the proposal.","1998060","2016-07-01","2021-06-30"
"VERICOMP","Foundations of Verifiable Computing","Guy ROTHBLUM","WEIZMANN INSTITUTE OF SCIENCE LTD","Proof systems allow a weak verifier to ascertain the correctness of complex computational statements. Efficiently-verifiable proof systems are fundamental objects in the study of computation, and have led to some of the deepest and most celebrated insights in cryptography and in complexity theory.

The vast and rich literature on proof systems focuses primarily on proving the correctness of intractable statements, e.g. ones that are NP-complete. While the verification can be efficient, the proofs themselves cannot be generated in polynomial time. This limits the applicability of such proof systems, both from a theoretical perspective and in their real-world impact. This proposal aims to obtain a comprehensive understanding of proof systems with polynomial-time proof generation, to explore their practical applicability, and to investigate their connections with foundational questions in cryptography and in complexity theory.

Our study will focus primarily on interactive proof systems for tractable computations. The proposed research aims to revolutionize our understanding of these foundational objects by providing a complete and tight characterization of the complexity or proving and verifying general statements, by achieving breakthroughs in the study of related proof system notions, such as cryptographic arguments, and by building a fine-grained “algorithmic” theory of proof systems for central polynomial-time computational problems.

Our research will leverage these advances towards diverse applications: from real-world security challenges, such as verifying the correctness of computations performed by the cloud and cryptographic “proofs of work”, to a complexity-theoretic understanding of the complexity of approximating problems in P and of solving them on random instances.","1882460","2019-01-01","2023-12-31"
"VERTEBRATE HERBIVORY","Evolution of herbivory in vertebrates: developing combined isotope (Ca, Sr) and dental surface texture analysis as deep time diet proxies","Thomas Tütken","JOHANNES GUTENBERG-UNIVERSITAT MAINZ","Diet is a key factor driving vertebrate evolution. Exploring dietary traits and trophic relationships in fossil food webs is fundamental for understanding radiation and extinction events. This project aims to constrain the evolution of herbivory (plant feeding) and trophic interaction of extinct vertebrates at different spatiotemporal scales by analysing their teeth with isotopic and dental wear techniques. A new approach of combined Ca and stable Sr isotope as well as 3D surface texture (3DST) analysis will be developed and applied to fossil teeth of mammal-ancestors and dinosaurs. Teeth record time-series of diet-related isotope compositions in their enamel while their surface tracks short-term food abrasion. These diet proxies will be calibrated on extant vertebrates with well-known diets from wild animals and controlled feeding experiments simulating diet and trophic level switches. Both Ca isotopes and enamel surface textures have a high preservation potential in fossil teeth and enable micro sampling of enamel for Ca isotope and non-destructive 3DST analysis. For the first time, I will combine Ca isotope and 3DST analysis to reconstruct the diet of extinct key vertebrate taxa and their trophic level in fossil food webs. This multi-proxy approach will provide a versatile toolset to test independently feeding hypotheses that mostly hinge on tooth and skeletal morphology, leading to fundamental new insights into the palaeoecology, dietary flexibility and niche partitioning of fossil vertebrates. The aim is to reconstruct the evolution of herbivory in vertebrates. Here, major objectives are: 1) to infer ontogenetic and evolutionary diet changes by combined Ca isotope and 3DST analysis of fossil teeth, 2) explore stable and radiogenic Sr isotopes as combined proxies for trophic level and habitat use, and 3) pioneer 3DST analysis for reptiles. Beyond the field of palaeontology these dietary proxies will be broadly applicable in archaeology, anthropology and ecology.","1728065","2016-09-01","2021-08-31"
"VESTA","VErified STAtic analysis platform","David, Francois Pichardie","ECOLE NORMALE SUPERIEURE DE RENNES","Computer software pervades our life but far too much of it contains programming errors (bugs). Software is more and more complex and such errors are unavoidable if programmers are not accompanied with some tools that help auditing software codes. Static analysis is an increasingly popular technique that aims at automatically compute properties of software. These properties then help finding bugs, or proving absence of them. Industrial static analysers are flourishing. Facebook, Google, Microsoft develop their own static analysis tools to help maintaining their huge code base. Critical software industry (aircraft, railways, nuclear, etc.) has embraced the use of advanced static analysis tool as Astrée to companion and sometimes, ligthen their traditional software validation campaigns based on meticulous testing and reviews. Unfortunately, designing advanced static analyses like Astrée requires a very rare expertise in Abstract Interpretation, a foundational landmark in the research area, and implementing these ideas efficiently and correctly is specially tricky.
The VESTA project will propose guidance and tool-support to the designers of static analysis, in order to build advanced but reliable static analysis tools. We focus on analyzing low-level softwares written in C, leveraging on the CompCert verified compiler. This compiler toolchain is fully verified in the Coq proof assistant.
Verasco is a verified static analyser that I have architected. It analyses C programs and follows many of the advanced abstract interpretation technique developped for Astrée, but it is formally verified. The outcome of the VESTA project will be a platform that help designing other verified advanced abstract interpreters like Verasco, without starting from a white page. We will apply this technique to develop security analyses for C programs. The platform will be open-source and will help the adoption of abstract interpretation techniques.","1885566","2018-09-01","2023-08-31"
"VIBRA","Very fast Imaging by Broadband coherent RAman","Dario Polli","POLITECNICO DI MILANO","The VIBRA project aims at developing an innovative microscope for real-time non-invasive imaging of cells and tissues, which promises to have a revolutionary impact on several fields of biology and medicine. Chemically specific vibrational signatures of molecules enable their direct structural characterization. Reliable and quantitative endogenous bio-markers can be established, e.g., to follow cell differentiation and to identify crucial properties of tissues (malignant vs benign phenotype of a tumour). In this way neoplasms can be located and their borders with normal tissue traced for surgery. 

Spontaneous Raman spectroscopy demonstrated this capability, but it is intrinsically too slow for imaging. Coherent Raman microscopy, on the other hand, can reach extremely high speed (up to the video rate) but at the expense of poor chemical selectivity, being limited to a single vibrational frequency.

The ground-breaking goal of VIBRA is to combine the most detailed molecular information over the entire vibrational spectrum with the highest acquisition speed. The PI will develop a complete coherent Raman microscope for near-video-rate broadband vibrational imaging. This high risk/high gain goal will be achieved by the combination of four key developments: improved pulsed laser source; optimized non-linear interaction, enhancing the signal; increase in acquisition speed, thanks to innovative spectrometers; parallel on-board data processing.

In the final application phase, the VIBRA project will validate the performances of the novel vibrational imaging system studying two important bio-medical problems: cancerous cell differentiation and detection of neuronal tumours. This will pave the way towards future “virtual histopathology”: intraoperative non-invasive evaluation of cancerous tissue. My vision is to allow researchers and doctors without a specific knowledge in lasers and optics to routinely visualize functional properties of cells and tissues in vivo.","1822500","2015-06-01","2020-05-31"
"VIBRANT-BIO","High-throughput vibrational fingerprinting by nanoplasmonics for disease biology","Hatice Altug Yanik","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","Devastating diseases such as Alzheimer’s, Parkinson’s and various cancers are still without cures, continue to undermine the quality of life for millions of people and impose significant economic burdens. Misfolded toxic proteins constitute the microscopic basis of these diseases, but little is understood about their structure and biological function. This is due the fact that current technologies are severely limited for molecular-level identification of protein structures and high-throughput analysis of biomolecular interactions.
VIBRANT-BIO aims to introduce breakthrough mid-infrared spectroscopy technologies, including the first spectroscopic microarray, to overcome the limitations of current methods by enabling complete profiling of biomolecules from identification of their structure and composition to their biological function. 
To achieve its ambitious goals, VIBRANT-BIO will exploit plasmonics and newly discovered two-dimensional nanomaterials such as graphene and explore the ultimate limits of light-matter interaction to demonstrate biosensors with extreme sensitivity, throughput and functionality, well beyond the state-of the art. It will innovatively integrate nanoplasmonics with advanced photonics and bioanalytical tools to dramatically enhance sensor performance and introduce new functionalities. The proposed technologies will be applied to study toxic amyloid-beta proteins and their interaction with lipid membranes for understanding the molecular mechanisms underlying Alzheimer’s disease.
VIBRANT-BIO will contribute to define the road-map for next generation biosensor and spectroscopy technologies through interdisciplinary research covering physics, engineering, chemistry and biology. The capability of the proposed systems to analyze a broad range and ultra-low quantities of molecules and chemicals provides a general-purpose toolkit that can impact numerous fields such as bioscience, material science, pharmaceutical industry, and homeland security.","2562325","2017-01-01","2021-12-31"
"ViDa","Transforming Raw Data into Information through Virtualization","Anastasia Ailamaki","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","The unprecedented evolution of computing power, combined with the decreasing costs of computation and storage infrastructure, has revolutionized all scientific fields and enterprises; at the heart of this revolution is the ability to collect unprecedented amounts of data. Real progress, however, depends on how efficiently we can ‘extract value from chaos’, i.e., process the collected data and transform it into useful information. Unfortunately, despite the impressive growth of data management technologies,  data analysis application efficiency is hindered by the increasing data growth. The typical business intelligence architecture is far too complex to yield answers productively, with businesses operating large numbers of specialized data processing systems, with data being repeatedly moved, copied or transformed between them. The reason is that, despite tremendous progress, data management tools are based on legacy designs whose requirements are no longer adequate. A novel approach is needed urgently, or users risk losing the ability to leverage their hard-earned data.
In this proposal, we identify assumptions that do not scale with today’s massive data explosion, and design a comprehensive end-to-end solution that implements a novel form of data virtualization to vastly simplify data analysis. Our approach removes barriers to data handling and maximizes efficiency for science, businesses, and their users, by enabling new forms of data computation that are unrestrained by how data is collected or stored. This project constructs the building blocks for data-driven computing and the fourth paradigm of scientific discovery, thereby advancing our ability to automatically explore massive and complex datasets at sight, and dictate the new developments in sciences and the industry.","1976762","2014-05-01","2019-04-30"
"VINCAT","A Unified Approach to Redox-Neutral C-C Couplings: Exploiting Vinyl Cation Rearrangements","Nuno Xavier Dias Maulide","UNIVERSITAT WIEN","The preparation of complex molecular architectures employing multi-component reactions where the number of bond-forming events is maximised is a central goal of the discipline of Organic Synthesis. The contemporary, pressing need for sustainable chemical reactions has raised the demand for novel reaction families that explore the concept of redox-neutrality and proceed with the generation of minimal waste. In this proposal, I present a unified and conceptually novel approach to atom-economical C-C bond formation in challenging contexts without the need for transition metal promoters or reagents. To this end, I propose the innovative harvesting of the potential of vinyl cation intermediates as platforms for the deployment of nucleophilic entities capable of orchestrating rearrangement reactions. The combination of such high-energy intermediates, generated under mild conditions, with the power of carefully designed rearrangements leads to an array of useful new transformations. Furthermore, the very high atom-economy and simplicity of these reactions renders them not only sustainable and environmentally friendly but also highly appealing for large-scale applications. Additional approaches to enantioselective synthesis further enhance the methods proposed. 
The paradigm proposed herein for the exploitation of vinyl cations will also open up new vistas in the centuries-old aldol reaction and in amination chemistry. This showcases the vast potential of these simple principles of chemical reactivity. The myriad of new reactions and new product families made possible by VINCAT will decisively enrich the toolbox of the synthetic practitioner.","1940025","2017-01-01","2021-12-31"
"VOLCAPSE","Volcano dome growth, collapse and coupled processes","Thomas Ingo Rafael Walter","HELMHOLTZ ZENTRUM POTSDAM DEUTSCHESGEOFORSCHUNGSZENTRUM GFZ","The construction of volcanoes, i.e. the intrusive and eruptive growth, can be intermittently interrupted by destructive events. Dome building volcanoes, in specific, grow by magma extrusion and are partially destroyed again, posing a significant hazard in form of pyroclastic flows and other processes. The explosion at Merapi (Indonesia) in 2010, and at Colima volcano (Mexico) in 2013 are good examples of associated dramatic topographic changes. There is only limited understanding of the deformation style of the dome and the stress changes within and beneath, because sophisticated geodetic methods are hazardous to operate and are even destroyed during eruptions. In VolCapse, small scale displacements (<1 m/yr) at dome building volcanoes will be quantified by new generation satellite radar data. Larger scale displacements (>.1 m/yr) will be determined by time-lapse camera arrays that allow the visual recording of volcano summits from different viewing geometries, together with photogrammetric and image correlation approaches. This displacement data of the studied volcanoes shall allow to develop statistical and numerical models to investigate (i) how dome displacements affect the further magma extrusion position, (ii) how large morphology changes in the volcano summit affect dome growth by topographic loading or unloading, (iii) how dome growth is affected by extrinsic triggers such as tectonic quakes, and (iv) how simultaneous displacement processes such as cooling, extrusion and gravity driven deformation interfere.
The P.I., with yearlong experience in modern geodetic methods, modelling and physical volcanology, herein describes the VolCapse project with the goal to enlighten our understanding of the coupled processes occurring during the different stages of volcano growth and collapse. Understanding such processes is essential for assessing volcanic hazards associated with dome building volcanoes worldwide.","1955355","2015-09-01","2020-08-31"
"Vort3DEuler","3D Euler, Vortex Dynamics and PDE","Jose Luis Rodrigo","THE UNIVERSITY OF WARWICK","This proposal deals with a collection of problems in PDE arising from fluid mechanics.The primary motivation is the understanding of the evolution of isolated vortex lines for 3D Euler. The importance of the evolution of vorticity in incompressible fluid mechanics is very well known.

To date, only nonrigorous approaches are known to try to obtain an evolution equation for isolated vortex lines. Two desingularization procedures are carried out (including a time renormalization) to obtain an evolution equation (the binormal equation). While an isolated vortex line does not fit any known concept of solution (given the singularity of the velocity), and there has been significant recent activity on the nonuniqueness of solutions of Euler (De Lellis & Szekelyhidi, and recently Isett) it is expected that the geometric assumptions made about the solution will still make it possible to find a suitable concept of solution. In the proposal I describe an approach that should help to rigorously understand vortex lines. It is motivated by a programme developed for the Surface Quasi-Geostrophic (SQG) equation with C. Fefferman and for some related desingularized models with my student Zoe Atkins (Nov 2012 PhD).

SQG has been of great interest in the PDE community due to the striking similarities it exhibits with 3D Euler. In particular, the evolution of sharp fronts for SQG corresponds to the evolution of vortex lines. In recent years I have developed an approach  that overcomes the divergences known to exist for the velocity field (as in 3D Euler). The positive results obtained for SQG motivate the methodology and tools described in the proposal, including the construction of solutions with very large gradients and simple geometry and the use of a measure-theoretic approach to identify fundamental curves within these objects. Surprising connections with other equations motivate some other directions and linked projects, for example with Prandtl and boundary layer ther theory.","1182858","2014-07-01","2019-06-30"
"VORTEX","Plastic in the Ocean: Microbial Transformation of  an ‘Unconventional’ Carbon Substrate","Helge NIEMANN","STICHTING NEDERLANDSE WETENSCHAPPELIJK ONDERZOEK INSTITUTEN","Large quantities of plastics comprising a diverse set of hydrocarbon or hydrocarbon-like polymers are constantly released to the oceans. The impacts of plastics in marine environments are detrimental, as they are seemingly recalcitrant and harmful to marine life. The severity of this problem is gaining momentum because the untamed demand for plastics has led to an ever-increasing release of plastic to the sea. However, despite their seemingly persistent properties, they do not accumulate as expected, indicating a substantial sink for plastics in the ocean. Plastics are synthetic and thus rather new and ‘unconventional’ compounds in the marine realm, yet microbes can utilise plastics as carbon substrates. However, the potential for microbial degradation of plastics in the ocean as well as key factors controlling degradation kinetics are largely unknown and have been discussed controversially. Using innovative stable isotope assays, my preliminary research has shown that plastics can be degraded in marine sediments under aerobic as well as anaerobic conditions. Here I propose to further investigate the potential for marine plastic degradation by microbes in laboratory- and field-based experiments across a wide range of contrasting environmental boundary conditions. In the VORTEX project, we will use cutting-edge stable isotope labelling and stable isotope probing assays in combination with biogeochemical/microbiological and organic geochemical tools to trace isotopically labelled carbon from the plastic-substrate pools into microbial metabolites (e.g. CO2) and biomass (e.g. diagnostic lipid biomarkers, DNA/RNA). This will lead to a breakthrough in our understanding of microbial plastic degradation in the ocean because the proposed analytical approaches allow to quantify kinetics of microbial polymer breakdown, to identify and quantify the responsible microbes and degradation pathways, and to determine environmental conditions conducive for plastic degradation.","1999185","2018-06-01","2023-05-31"
"WakeOpColl","Learning and collective intelligence for optimized operations in wake flows","Philippe Christian CHATELAIN","UNIVERSITE CATHOLIQUE DE LOUVAIN","Physics dictate that a flow device has to leave a wake or the signature of it producing sustentation forces, extracting energy, or simply moving through the medium; these flow structures can then impact negatively or favorably another device downstream. Wake turbulence between aircraft in air traffic and wake losses within wind farms are prime examples of this phenomenon, and incidentally constitute pivotal challenges to their respective fields of transportation and wind energy. These are highly complex and unsteady flows, and distributed control based on affordable wake models has failed to produce robust schemes that can alleviate turbulence effects and achieve efficiency at the scale of the system of devices. 
This project proposes an Artificial Intelligence and bio-inspired paradigm for the control of flow devices subjected to wake effects. To each flow device, we associate an intelligent agent that pursues given goals of efficiency or turbulence alleviation. Every one of these flow agents now relies on machine-learning tools to learn how to make the right decision when confronted with wake or turbulent flow structures. At a system level, we employ Multi-Agent System and Distributed Learning paradigms. Based on Game Theory, we build a system of interactions that incite the emergence of collaborative behaviors between the agents and achieve global optimized operation among the devices. We claim that the design of a system that learns how to control the flow, is simpler than the design of the control scheme and will yield a more robust scheme. 
The learning of formation flying among aircraft and of wake alleviation between wind turbines will constitute our study cases. The investigation will essentially be carried by means of large-scale numerical simulations; such simulations will produce the first ever realizations of self-organized systems in a turbulent flow. We will then apply our learning frameworks to a small-scale wind farm.","1999591","2017-09-01","2022-08-31"
"WallCrossAG","Wall-Crossing and Algebraic Geometry","Arend BAYER","THE UNIVERSITY OF EDINBURGH","We will establish stability conditions and wall-crossing in derived categories as a standard methodology for a wide range of fundamental problems in algebraic geometry. Previous work based on wall-crossing, in particular my joint work with Macri, has led to breakthroughs on the birational geometry of moduli spaces and related varieties. Recent advances have made clear that the power of stability conditions extends far beyond this setting, allowing us to study vanishing theorems or bounds on global sections, Brill-Noether  problems, or moduli spaces of varieties. 

The Brill-Noether problem is one of the oldest and most fundamental questions of algebraic geometry, aiming to classify possible degrees and embedding dimensions of embeddings of a given variety into projective spaces. Recent work by myself, a post-doc (Chunyi Li) and a PhD student (Feyzbakhsh) of mine has established wall-crossing as a powerful new method for such questions. We will push this method further, all the way towards a proof of Green's conjecture, and the Green-Lazarsfeld conjecture, for all smooth curves. 

We will use similar methods to prove new Bogomolov-Gieseker type inequalities for Chern classes of stable sheaves and complexes on higher-dimensional varieties. In addition to constructing stability conditions on projective threefolds---the biggest open problem within the theory of stability conditions, we will apply them to study moduli spaces of sheaves on higher-dimensional varieties, and to characterise special abelian varieties.  

We will use the construction of stability conditions for families of varieties in my current joint work  to systematically study the geometry of Fano threefolds and fourfolds, in particular their moduli spaces, by establishing relations between different moduli spaces, and describing their Torelli maps. Finally, we will study rationality questions, with a particular view towards a wall-crossing proof of the irrationality of the very general cubic fourfold.","1999840","2019-06-01","2024-05-31"
"WATU","Wave turbulence: beyond weak turbulence","Nicolas Mordant","UNIVERSITE GRENOBLE ALPES","Wave turbulence and fluid turbulence belong to the same class of turbulent states made of a large number of nonlinearly coupled degrees of freedom driven far from equilibrium. The Weak Turbulence Theory is a statistical theory of low amplitude turbulent waves. The predicted phenomenology (energy cascade) is very similar to that of fluid turbulence, which badly lacks such a statistical theory. Weak Turbulence is thus a promising mathematical framework for turbulence in general. It is observed in many systems such as planetary atmospheres, astrophysical plasmas, tokomak fusion plasmas, superfluid turbulence or Bose-Einstein condensates for example. The theory is much less advanced in the strong wave turbulence case for which a richer phenomenology appears due to the generation of coherent structures. Furthermore, to a large extent the theory lacks experimental validation.
My project aims at studying several physical systems (vibrating elastic plate, 1D and 2D water surface waves, 3D internal waves in a stratified fluid) specifically chosen to highlight various features of wave turbulence both in the weak and strong regimes. Under strong forcing, coherent structures will appear such as developable cones (elastic plates), solitons and sharp water wave ridges (water surface waves) or even fluid turbulence for overturning 3D internal waves. I will specifically use two unique large-scale facilities available in LEGI (Grenoble, France): the 30 m 1D wave flume for surface water waves and the 13m-diameter Coriolis turntable for water surface waves and internal waves. I will setup advanced space-time resolved profilometry and velocimetry techniques adapted to the dimensionality and size of each one of these systems. Advanced statistical tools on massive datasets will provide a profound insight into the coupling between waves and structures in the various regimes of wave turbulence.","1991611","2015-10-01","2020-09-30"
"WII","""Water, Ions, Interfaces: Quantum effects, charge and cooperativity in water, aqueous solutions and interfaces""","Sylvie Roke","ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE","""Sixty percent of the human body consists of water. Water provides the 3D-network for life’s constituents. In a cell there are many interfaces: the average distance between two molecules or a molecule and a membrane interfaces is ~1 nm. Water and the interfaces it interacts with are of paramount importance for biological processes. The structural, dynamic, and biological properties of water, aqueous systems and aqueous interfaces are essential in understanding the complexity of life, and our ability to harness its features for novel technologies.
Waters’ 3D hydrogen bonded network is important for nearly all the macroscopic properties of water. The network is cooperative, yet it rearranges itself every few femtoseconds, and quantum level interactions determine its properties. Understanding the role water plays in living systems therefore requires information from the quantum level/femtosecond time scale up to the macroscopic level/time scale. Therefore, understanding water remains a considerable challenge.
I propose to investigate the structural, dynamic, and biological properties of water by probing the relationship between the properties of water on vastly different length and time scales. We will investigate quantum effects in water and on interfaces, and study long-range ordering (up from the femtosecond time scale). Furthermore, we will map how ions, hydrophilic, and hydrophobic solutes influence waters structural correlations and water-mediated interactions. Thus, we will use a worldwide unique multiscale toolbox that has for the most part been recently developed in my lab. We will map aqueous solutions by probing the structure of hydration shells, nanoscopic order and correlations between water molecules and viscosity. Interfacial structural and dynamical changes will be measured by mapping the surface chemical composition and conformation, the surface charge, and the electrokinetic mobility of nanodroplets.""","1999984","2014-11-01","2019-10-31"
"WILLOW","WIreLess LOWband communications: massive and ultra-reliable access","Petar Popovski","AALBORG UNIVERSITET","The overall objective of WILLOW is to make wireless communication a true commodity by enabling lowband communications: low-rate links for massive number of devices and ultra-reliable connectivity. This research effort is a major endeavour in the area of wireless communications, taking a different path from the mainstream research that aims at “4G, but faster”. Lowband communication is the key to enabling new applications, such as massive sensing, ultra-reliable vehicular links and wireless cloud connectivity with guaranteed minimal rate. The research in WILLOW is centred on two fundamental issues. First, it is the efficient communication with short packets, in which the data size is comparable to the size of the metadata, i.e. control information, which is not the case in broadband communication. Communication of short packets that come from a massive number of devices and/or need to meet a latency constraint requires fundamental rethinking of the packet structure and the associated communication protocols. Second is the system architecture in which graceful rate degradation, low latency and massive access can exist simultaneously with the broadband services. The principles from WILLOW will be applied to: (a) clean-slate wireless systems; (b) reengineer existing wireless systems. Option (b) is unique to lowband communication that does not require high physical-layer speed, but can reuse the physical layer of an existing system and redefine the metadata/data relationship to achieve massive/ultra-reliable communication. WILLOW carries high risk by conjecturing that it is possible to support an unprecedented number of connected devices and wireless reliability levels. Considering the timeliness and the relevance, the strong track record of the PI and the rich wireless research environment at Aalborg University, WILLOW is poised to make a breakthrough towards lowband communications and create the technology that will enable a plethora of new wireless usage modes.","1994411","2015-04-01","2020-03-31"
"X-MUSIC","XUV/X-ray Multidimensional Spectroscopy of Fundamental Electron Dynamics and Impulsive Control of X-ray Light","Thomas Pfeifer","MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISSENSCHAFTEN EV","""Interaction of extreme&controlled light fields with matter is driving an ongoing revolution in our understanding of quantum physics.  Controlled—pulsed—visible lasers have enabled time-dependent two-dimensional (2D) spectroscopy currently transforming chemistry, and led to key milestones such as frequency combs.

Despite progress on coherent soft- and hard-x-ray pulsed sources during the last 10 years—e.g. x-ray free-electron lasers (FELs) or high-harmonic generation of laser light, nonlinear (e.g. 2D) spectroscopy or phase control of x-ray light remained a major challenge.

Here, I propose to experimentally realize
- (a) x-ray two- and multi-dimensional spectroscopy
- (b) resonant gain without inversion and spectral control of x rays
for the scientific goals
- (a) time- and quantum-state-resolved measurement of fundamental few- and many-electron dynamics
- (b) generation of soft-(electronic) and hard-x-ray (nuclear) frequency combs

For (a), a 4-quadrant x-ray time-delay unit will generate coherently-timed pulses out of one spatially coherent beam. For (b) a new physical mechanism relating Fano to Lorentz resonances and absorption to gain by a single temporal phase will be harvested.
Scientific impact:
(a): Site-specific 2D-x-ray spectroscopy will phase-sensitively test&promote theory and allow to understand fundamental processes: excitation, ionization, and few-electron dynamics in atoms and molecular bonding orbitals.
(b): Impulsive phase control of resonant gain and absorption represents a disruptive key technology rivalling the LASER especially in the hard-x-ray domain, where long-lived population inversion in dense media seems impossible.  Frequency combs around a well-defined (5 neV) hard-x-ray Mössbauer Fe57 nuclear transition (14.4 keV) will be demonstrated.  Such combs (at >10 keV), will in the future allow the most sensitive tests of fundamental physics, e.g. quantum-electrodynamics (QED) in highly-charged ions and the variation of physical 'constants'.""","1983863","2014-01-01","2018-12-31"
"XFab","Xene Fabrication for a Two-Dimensional Nanotechnology Platform","Alessandro MOLLE","CONSIGLIO NAZIONALE DELLE RICERCHE","Xenes denote two-dimensional (2D) monoelemental (X) crystals beyond graphene with a honeycomb lattice. Unlike graphene, Xenes do not exist in Nature, but they become stable via epitaxy on substrates. So far experimental evidences of Xene epitaxy have been reported for X=Si, Ge, Sn, B, P, and Sb (named silicene, germanene, stanene, borophene, phosphorene, and antimonene, respectively). Xene single layers also serve as a background for the synthesis of new Xene-related materials (XRMs) such as Xene heterostructures and functionalized Xenes. Xenes can appear as metals, semimetals, semiconductors, and topological insulators thus allowing for a broad range of applications in nanotechnology. However only silicene has been integrated into transistors operating at room temperature albeit fast degradation. Nonetheless, a viable Xene-based nanotechnology is currently missing due to the lack of reliable standards for the Xene production and implementation. For this purpose, the proposal aims at developing viable schemes for high-quality crystal growth, environmental stabilization, and device integration of Xenes and XRMs frameworks. At first the effort will be focused on the high-quality synthesis of selected Xenes and XRMs by means of molecular beam epitaxy, and on their stabilization in encapsulated structures enabling subsequent processing into Xene-based device platforms. Validation of the Xene properties, quality, and performances will be carried out by means of advanced in situ and ex situ characterization of the atomic and electronic structure. Secondly, prototypical electronic device (e.g. field effect transistors or vertical diodes) incorporating stabilized Xene frameworks as active elements will be used to assess the Xene electrical behaviour and performances so as to establish a reliable Xene-based nanotechnology.","1998785","2018-04-01","2023-03-31"
"xPRINT","4-Dimensional printing for adaptive optoelectronic components","Andrea Camposeo","CONSIGLIO NAZIONALE DELLE RICERCHE","This project aims at developing four-dimensional printing of new adaptive systems, namely printing of complex, three-dimensional polymer objects embedding functional compounds and able to change or adapt their physical properties responding to environmental stimuli. Additive manufacturing of three-dimensional objects relies on depositing or curing materials in a layer-by-layer fashion, starting from computer assisted design. These technologies have rapidly evolved from laboratory research to commercially available desktop systems, with costs decreasing continuously. Notwithstanding such astonishing progress, the potentialities of three-dimensional printing are still poorly exploited in terms of both materials and process resolution. This project will shed new light on the fundamental aspects of three-dimensional polymerization, thus establishing new process design rules and predictive tools for printing resolution. It will also specifically engineer additive manufacturing for printing materials embedding active compounds, thus leading to real four-dimensional objects, namely structures that have three-dimensional features and time-changing physical properties at the same time. An integrated approach will be pursued to this aim, where modeling and process engineering will be complemented by process monitoring, in order to establish well defined and reproducible methods for four-dimensional printing of photonic structures. The operation of the adaptive components, for optical computing and data storage, will be based on their nonlinear response to optical inputs. Leading to a new and pioneering laboratory on four-dimensional printing technologies, this project will critically consolidate scientific independence.","1993908","2016-09-01","2021-08-31"
"ZIPgeting","Quantitative understanding of target recognition on DNA based on directional zipping processes","Ralf SEIDEL","UNIVERSITAET LEIPZIG","In the recent years a number of protein systems have been identified that recognize long (tens of base pairs) DNA sequences and allow flexible programmability of their target specificity. This promoted an enormous range of applications in genome engineering and synthetic biology. This project aims to decipher the mechanisms by which these proteins recognize their DNA targets in order to develop quantitative models/predictors for target recognition and to avoid off-target effects.
To obtain detailed insight into the targeting mechanisms of different programmable systems in a “bottom-up manner”, cutting-edge single-molecule experiments, such as mechanical DNA twisting combined with single-molecule fluorescence detection will be employed. This will provide a fully quantitative characterization of the targeting process and insight into the mechanisms of allosteric regulation coupled to targeting. The quantitative data will allow to develop physics-based models of the target recognition process. In particular, we will focus on recognition through non-equilibrium, directional zipping along the target sequence – as recently revealed for CRISPR-Cas enzymes – as a promising unifying mechanism. To obtain precise targeting predictors our first-principle models will be tested and refined using high-throughput measurements on many different targets in parallel. Finally, the predictions will be used in order to understand target selection in live cells using single-molecule imaging.
Within the project the following goals are defined: 
Goal 1:	Quantitative understanding of target binding/degradation for CRISPR-Cas systems
Goal 2:	Detailed mechanistic insight into the target recognition process by TALEs  
Goal 3:	Development of highly parallelized measurements on different target sequences down to the single-molecule level
Goal 4:	Target identification in the complex environment of live cells","2000000","2017-05-01","2022-04-30"
